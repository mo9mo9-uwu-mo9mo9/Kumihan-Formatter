#!/usr/bin/env python3
"""ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ«ãƒ¼ãƒ«ãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã‚³ãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å“è³ªã‚’ç›£è¦–ã—ã€Single Responsibility Principleã®
é•åã‚„è¨­è¨ˆä¸Šã®å•é¡Œã‚’æ—©æœŸç™ºè¦‹ã—ã¾ã™ã€‚

Usage:
    python scripts/architecture_check.py
    python scripts/architecture_check.py --strict
    python scripts/architecture_check.py --target-dir=kumihan_formatter/
"""

import argparse
import ast
import re
import sys
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple


class ArchitectureChecker:
    """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å“è³ªãƒã‚§ãƒƒã‚«ãƒ¼"""

    def __init__(self, strict_mode: bool = False):
        self.strict_mode = strict_mode
        self.violations: List[Tuple[str, str, str, Optional[int]]] = []
        self.dependency_graph: Dict[str, Set[str]] = defaultdict(set)
        self.metrics: Dict[str, Dict[str, int]] = {}

    def analyze_file(self, file_path: Path) -> Dict[str, int]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†"""
        try:
            content = file_path.read_text(encoding="utf-8")
            tree = ast.parse(content)

            metrics = {
                "lines": len(content.splitlines()),
                "classes": 0,
                "functions": 0,
                "methods": 0,
                "imports": 0,
                "complexity": 0,
                "max_function_lines": 0,
                "max_class_lines": 0,
            }

            # å„ãƒãƒ¼ãƒ‰ã‚’åˆ†æ
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    metrics["classes"] += 1
                    class_lines = self._get_node_lines(node, content)
                    metrics["max_class_lines"] = max(
                        metrics["max_class_lines"], class_lines
                    )

                elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    if self._is_method(node, tree):
                        metrics["methods"] += 1
                    else:
                        metrics["functions"] += 1

                    func_lines = self._get_node_lines(node, content)
                    metrics["max_function_lines"] = max(
                        metrics["max_function_lines"], func_lines
                    )

                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    metrics["imports"] += 1

                elif isinstance(node, (ast.If, ast.While, ast.For, ast.Try)):
                    metrics["complexity"] += 1

            return metrics

        except Exception as e:
            print(f"Warning: ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã‚¨ãƒ©ãƒ¼ {file_path}: {e}", file=sys.stderr)
            return {}

    def _get_node_lines(self, node: ast.AST, content: str) -> int:
        """ASTãƒãƒ¼ãƒ‰ã®è¡Œæ•°ã‚’è¨ˆç®—"""
        lines = content.splitlines()
        if hasattr(node, "lineno") and hasattr(node, "end_lineno"):
            if node.end_lineno:
                return int(node.end_lineno - node.lineno + 1)
        return 0

    def _is_method(
        self, func_node: ast.FunctionDef | ast.AsyncFunctionDef, tree: ast.AST
    ) -> bool:
        """é–¢æ•°ãŒã‚¯ãƒ©ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰ã‹ã©ã†ã‹åˆ¤å®š"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                for item in node.body:
                    if item == func_node:
                        return True
        return False

    def check_single_responsibility(
        self, file_path: Path, metrics: Dict[str, int]
    ) -> bool:
        """Single Responsibility Principleã®é•åã‚’ãƒã‚§ãƒƒã‚¯"""
        violations_found = False

        # 1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        if metrics.get("lines", 0) > 300:
            self.violations.append(
                (
                    str(file_path),
                    "SRPé•å",
                    f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§ãã™ãã¾ã™ ({metrics['lines']}è¡Œ)",
                    metrics["lines"],
                )
            )
            violations_found = True

        # 2. ã‚¯ãƒ©ã‚¹æ•°ãƒã‚§ãƒƒã‚¯
        if metrics.get("classes", 0) > 3:
            self.violations.append(
                (
                    str(file_path),
                    "SRPé•å",
                    f"ã‚¯ãƒ©ã‚¹æ•°ãŒå¤šã™ãã¾ã™ ({metrics['classes']}å€‹)",
                    metrics["classes"],
                )
            )
            violations_found = True

        # 3. å¤§ãã™ãã‚‹ã‚¯ãƒ©ã‚¹ãƒã‚§ãƒƒã‚¯
        if metrics.get("max_class_lines", 0) > 100:
            self.violations.append(
                (
                    str(file_path),
                    "SRPé•å",
                    f"å¤§ãã™ãã‚‹ã‚¯ãƒ©ã‚¹ãŒã‚ã‚Šã¾ã™ ({metrics['max_class_lines']}è¡Œ)",
                    metrics["max_class_lines"],
                )
            )
            violations_found = True

        # 4. å¤§ãã™ãã‚‹é–¢æ•°ãƒã‚§ãƒƒã‚¯
        if metrics.get("max_function_lines", 0) > 20:
            self.violations.append(
                (
                    str(file_path),
                    "SRPé•å",
                    f"å¤§ãã™ãã‚‹é–¢æ•°ãŒã‚ã‚Šã¾ã™ ({metrics['max_function_lines']}è¡Œ)",
                    metrics["max_function_lines"],
                )
            )
            violations_found = True

        return not violations_found

    def check_naming_conventions(self, file_path: Path) -> bool:
        """å‘½åè¦å‰‡ã®é•åã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            content = file_path.read_text(encoding="utf-8")
            tree = ast.parse(content)
            violations_found = False

            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    # ã‚¯ãƒ©ã‚¹åã¯PascalCase
                    if not re.match(r"^[A-Z][a-zA-Z0-9]*$", node.name):
                        self.violations.append(
                            (
                                str(file_path),
                                "å‘½åè¦å‰‡é•å",
                                f"ã‚¯ãƒ©ã‚¹å '{node.name}' ã¯PascalCaseã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™",
                                node.lineno,
                            )
                        )
                        violations_found = True

                elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    # é–¢æ•°åã¯snake_case
                    if not re.match(
                        r"^[a-z_][a-z0-9_]*$", node.name
                    ) and not node.name.startswith("__"):
                        self.violations.append(
                            (
                                str(file_path),
                                "å‘½åè¦å‰‡é•å",
                                f"é–¢æ•°å '{node.name}' ã¯snake_caseã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™",
                                node.lineno,
                            )
                        )
                        violations_found = True

            return not violations_found

        except Exception as e:
            print(f"Warning: å‘½åè¦å‰‡ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼ {file_path}: {e}", file=sys.stderr)
            return True

    def check_import_organization(self, file_path: Path) -> bool:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ§‹æˆã®å•é¡Œã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            content = file_path.read_text(encoding="utf-8")
            lines = content.splitlines()
            violations_found = False

            import_count = content.count("import ") + content.count("from ")

            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå¤šã™ãã‚‹å ´åˆ
            if import_count > 20:
                self.violations.append(
                    (
                        str(file_path),
                        "ã‚¤ãƒ³ãƒãƒ¼ãƒˆéå¤š",
                        f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ•°ãŒå¤šã™ãã¾ã™ ({import_count}å€‹)",
                        None,
                    )
                )
                violations_found = True

            # å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            relative_imports = [
                line for line in lines if line.strip().startswith("from .")
            ]
            if len(relative_imports) > 5:
                self.violations.append(
                    (
                        str(file_path),
                        "ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆéå¤š",
                        f"ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå¤šãå¾ªç’°ä¾å­˜ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ ({len(relative_imports)}å€‹)",
                        None,
                    )
                )
                violations_found = True

            return not violations_found

        except Exception as e:
            print(
                f"Warning: ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼ {file_path}: {e}", file=sys.stderr
            )
            return True

    def check_complexity(self, file_path: Path, metrics: Dict[str, int]) -> bool:
        """ã‚³ãƒ¼ãƒ‰è¤‡é›‘åº¦ã‚’ãƒã‚§ãƒƒã‚¯"""
        violations_found = False

        # è¤‡é›‘åº¦ãŒé«˜ã™ãã‚‹å ´åˆ
        complexity = metrics.get("complexity", 0)
        lines = metrics.get("lines", 1)
        complexity_ratio = complexity / lines if lines > 0 else 0

        if complexity_ratio > 0.1:  # 10è¡Œã«1ã¤ä»¥ä¸Šã®åˆ†å²
            self.violations.append(
                (
                    str(file_path),
                    "è¤‡é›‘åº¦éå¤š",
                    f"åˆ†å²ãŒå¤šã™ãã¾ã™ (è¤‡é›‘åº¦: {complexity}, æ¯”ç‡: {complexity_ratio:.2f})",
                    complexity,
                )
            )
            violations_found = True

        return not violations_found

    def check_directory(self, target_dir: Path) -> bool:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå…¨ä½“ã‚’ãƒã‚§ãƒƒã‚¯"""
        python_files = list(target_dir.rglob("*.py"))

        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³
        excluded_patterns = [
            "**/test_*.py",
            "**/tests/**",
            "**/__pycache__/**",
            "**/.*/**",
            "**/venv/**",
            "**/.venv/**",
            "**/build/**",
            "**/dist/**",
            "**/scripts/**",
        ]

        filtered_files = []
        for file_path in python_files:
            should_exclude = any(
                file_path.match(pattern) for pattern in excluded_patterns
            )
            if not should_exclude:
                filtered_files.append(file_path)

        print(f"ãƒã‚§ãƒƒã‚¯å¯¾è±¡: {len(filtered_files)} ãƒ•ã‚¡ã‚¤ãƒ«")

        all_passed = True
        for file_path in filtered_files:
            metrics = self.analyze_file(file_path)
            self.metrics[str(file_path)] = metrics

            # å„ç¨®ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
            checks = [
                self.check_single_responsibility(file_path, metrics),
                self.check_naming_conventions(file_path),
                self.check_import_organization(file_path),
                self.check_complexity(file_path, metrics),
            ]

            if not all(checks):
                all_passed = False

        return all_passed

    def print_violations(self) -> None:
        """é•åé …ç›®ã‚’å‡ºåŠ›"""
        if not self.violations:
            print("âœ… ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ«ãƒ¼ãƒ«ã«é•åã¯ã‚ã‚Šã¾ã›ã‚“")
            return

        print("\nâŒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ«ãƒ¼ãƒ«é•å:")
        print("=" * 80)

        # é•åã‚¿ã‚¤ãƒ—åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        by_type = defaultdict(list)
        for violation in self.violations:
            by_type[violation[1]].append(violation)

        for violation_type, violations in by_type.items():
            print(f"\nğŸš¨ {violation_type} ({len(violations)}ä»¶)")
            print("-" * 40)

            for file_path, _, message, line_num in violations:
                relative_path = (
                    Path(file_path).relative_to(Path.cwd())
                    if Path(file_path).is_absolute()
                    else file_path
                )
                line_info = f" (è¡Œ: {line_num})" if line_num else ""
                print(f"ğŸ“ {relative_path}{line_info}")
                print(f"   {message}")

        print("\nğŸ”§ æ¨å¥¨å¯¾ç­–:")
        if "SRPé•å" in by_type:
            print("  â€¢ Single Responsibility Principleã«å¾“ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ã‚¯ãƒ©ã‚¹ã‚’åˆ†å‰²")
        if "å‘½åè¦å‰‡é•å" in by_type:
            print("  â€¢ PascalCase (ã‚¯ãƒ©ã‚¹) / snake_case (é–¢æ•°ãƒ»å¤‰æ•°) ã«çµ±ä¸€")
        if "ã‚¤ãƒ³ãƒãƒ¼ãƒˆéå¤š" in by_type:
            print("  â€¢ é–¢é€£ã™ã‚‹æ©Ÿèƒ½ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å˜ä½ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–")
        if "è¤‡é›‘åº¦éå¤š" in by_type:
            print("  â€¢ æ¡ä»¶åˆ†å²ã‚’é–¢æ•°ã«åˆ†å‰²ã€ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é©ç”¨")

    def print_summary(self) -> None:
        """å…¨ä½“ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›"""
        if not self.metrics:
            return

        total_lines = sum(m.get("lines", 0) for m in self.metrics.values())
        total_classes = sum(m.get("classes", 0) for m in self.metrics.values())
        total_functions = sum(m.get("functions", 0) for m in self.metrics.values())

        print(f"\nğŸ“Š ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ:")
        print(f"  â€¢ ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(self.metrics)}")
        print(f"  â€¢ ç·è¡Œæ•°: {total_lines:,}")
        print(f"  â€¢ ç·ã‚¯ãƒ©ã‚¹æ•°: {total_classes}")
        print(f"  â€¢ ç·é–¢æ•°æ•°: {total_functions}")

        # æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
        largest_file = max(self.metrics.items(), key=lambda x: x[1].get("lines", 0))
        if largest_file[1].get("lines", 0) > 0:
            relative_path = (
                Path(largest_file[0]).relative_to(Path.cwd())
                if Path(largest_file[0]).is_absolute()
                else largest_file[0]
            )
            print(f"  â€¢ æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«: {relative_path} ({largest_file[1]['lines']}è¡Œ)")


def main() -> None:
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description="ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ«ãƒ¼ãƒ«ãƒã‚§ãƒƒã‚«ãƒ¼")
    parser.add_argument(
        "--target-dir",
        type=Path,
        default=Path("kumihan_formatter"),
        help="ãƒã‚§ãƒƒã‚¯å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: kumihan_formatter)",
    )
    parser.add_argument(
        "--strict", action="store_true", help="å³æ ¼ãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚ˆã‚Šå³ã—ã„ãƒã‚§ãƒƒã‚¯ï¼‰"
    )

    args = parser.parse_args()

    if not args.target_dir.exists():
        print(
            f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.target_dir}", file=sys.stderr
        )
        sys.exit(1)

    checker = ArchitectureChecker(strict_mode=args.strict)

    print(f"ğŸ—ï¸  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒã‚§ãƒƒã‚¯é–‹å§‹")
    print(f"å¯¾è±¡: {args.target_dir}")
    print(f"ãƒ¢ãƒ¼ãƒ‰: {'å³æ ¼' if args.strict else 'æ¨™æº–'}")
    print("-" * 60)

    success = checker.check_directory(args.target_dir)
    checker.print_violations()
    checker.print_summary()

    if success:
        print("\nğŸ‰ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ«ãƒ¼ãƒ«ã«æº–æ‹ ã—ã¦ã„ã¾ã™ï¼")
        sys.exit(0)
    else:
        print(f"\nâŒ {len(checker.violations)} ä»¶ã®é•åãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        print("æŠ€è¡“çš„è² å‚µã®è“„ç©ã‚’é˜²ããŸã‚ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ”¹å–„ã—ã¦ãã ã•ã„")
        sys.exit(1)


if __name__ == "__main__":
    main()
