#!/usr/bin/env python3
"""
è¦å‰‡éµå®ˆåŸå‰‡çµ¶å¯¾éµå®ˆã‚·ã‚¹ãƒ†ãƒ  - æŠ€è¡“çš„å¼·åˆ¶å®Ÿè£…
Claude'sè¡Œå‹•åˆ¶å¾¡ãƒ»ãƒ„ãƒ¼ãƒ«æ¤œè¨¼ãƒ»è‡ªå‹•æ˜¯æ­£ã‚·ã‚¹ãƒ†ãƒ 

Created: 2025-08-04
Purpose: CLAUDE.md è¦å‰‡éµå®ˆåŸå‰‡ã®æŠ€è¡“çš„å¼·åˆ¶å®Ÿè£…
Status: Production Ready
"""

import json
import logging
import os
import sys
import time
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

import yaml

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(".claude-rule-enforcement.log"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger("RULE_ENFORCEMENT")


class ViolationLevel(Enum):
    """é•åãƒ¬ãƒ™ãƒ«å®šç¾©"""

    WARNING = "warning"
    CRITICAL = "critical"
    FATAL = "fatal"


class ToolCategory(Enum):
    """ãƒ„ãƒ¼ãƒ«ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""

    FORBIDDEN = "forbidden"
    SERENA_REQUIRED = "serena_required"
    ALLOWED = "allowed"
    CONDITIONAL = "conditional"


@dataclass
class ViolationEvent:
    """é•åã‚¤ãƒ™ãƒ³ãƒˆè¨˜éŒ²"""

    timestamp: datetime
    tool_name: str
    violation_level: ViolationLevel
    context: str
    auto_corrected: bool
    user_notified: bool


@dataclass
class ToolUsageStats:
    """ãƒ„ãƒ¼ãƒ«ä½¿ç”¨çµ±è¨ˆ"""

    serena_usage_count: int = 0
    forbidden_tool_attempts: int = 0
    auto_corrections: int = 0
    compliance_score: float = 100.0
    last_violation: Optional[datetime] = None


class RuleEnforcementSystem:
    """è¦å‰‡éµå®ˆåŸå‰‡çµ¶å¯¾éµå®ˆã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, config_path: str = ".claude-system-override.yml"):
        """åˆæœŸåŒ–"""
        self.config_path = Path(config_path)
        self.config = self._load_config()
        self.stats = ToolUsageStats()
        self.violation_history: List[ViolationEvent] = []
        self.forbidden_tools = self._load_forbidden_tools()
        self.serena_tools = self._load_serena_tools()
        self.replacement_mapping = self._load_replacement_mapping()

        # ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ãƒ­ã‚°
        logger.info("ğŸš¨ è¦å‰‡éµå®ˆåŸå‰‡çµ¶å¯¾éµå®ˆã‚·ã‚¹ãƒ†ãƒ èµ·å‹•")
        logger.info(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {self.config_path}")
        logger.info(f"ç¦æ­¢ãƒ„ãƒ¼ãƒ«æ•°: {len(self.forbidden_tools)}")
        logger.info(f"serenaãƒ„ãƒ¼ãƒ«æ•°: {len(self.serena_tools)}")

    def _load_config(self) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            if not self.config_path.exists():
                logger.warning(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.config_path}")
                return self._get_default_config()

            with open(self.config_path, "r", encoding="utf-8") as f:
                config = yaml.safe_load(f)
                logger.info("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
                return config
        except Exception as e:
            logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return self._get_default_config()

    def _get_default_config(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š"""
        return {
            "pre_execution_validation": {"enabled": True, "mode": "STRICT_BLOCK"},
            "automatic_tool_replacement": {"enabled": True, "force_replacement": True},
            "violation_response": {"action": "IMMEDIATE_STOP"},
            "behavioral_conditioning": {
                "positive_reinforcement": {"serena_usage_praise": True}
            },
        }

    def _load_forbidden_tools(self) -> Set[str]:
        """ç¦æ­¢ãƒ„ãƒ¼ãƒ«ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿"""
        forbidden = set()
        try:
            tools_config = self.config.get("pre_execution_validation", {})
            forbidden_list = tools_config.get("forbidden_tools_strict", [])
            forbidden.update(forbidden_list)

            logger.info(f"ç¦æ­¢ãƒ„ãƒ¼ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {forbidden}")
            return forbidden
        except Exception as e:
            logger.error(f"ç¦æ­¢ãƒ„ãƒ¼ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {"Edit", "MultiEdit", "Read", "Write", "Glob", "Grep", "Bash"}

    def _load_serena_tools(self) -> Set[str]:
        """serenaãƒ„ãƒ¼ãƒ«ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿"""
        serena_tools = {
            "mcp__serena__find_symbol",
            "mcp__serena__replace_symbol_body",
            "mcp__serena__insert_after_symbol",
            "mcp__serena__search_for_pattern",
            "mcp__serena__get_symbols_overview",
            "mcp__serena__list_dir",
            "mcp__serena__find_referencing_symbols",
            "mcp__serena__insert_before_symbol",
            "mcp__serena__replace_regex",
        }
        logger.info(f"serenaãƒ„ãƒ¼ãƒ«ç™»éŒ²å®Œäº†: {len(serena_tools)}å€‹")
        return serena_tools

    def _load_replacement_mapping(self) -> Dict[str, str]:
        """ãƒ„ãƒ¼ãƒ«ç½®æ›ãƒãƒƒãƒ”ãƒ³ã‚°èª­ã¿è¾¼ã¿"""
        try:
            replacement_config = self.config.get("automatic_tool_replacement", {})
            mapping = replacement_config.get("replacement_mapping", {})

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°
            default_mapping = {
                "Edit": "mcp__serena__replace_symbol_body",
                "MultiEdit": "mcp__serena__replace_symbol_body",
                "Read": "mcp__serena__find_symbol",
                "Write": "mcp__serena__insert_after_symbol",
                "Glob": "mcp__serena__search_for_pattern",
                "Grep": "mcp__serena__search_for_pattern",
                "LS": "mcp__serena__get_symbols_overview",
            }

            # ãƒãƒƒãƒ”ãƒ³ã‚°çµåˆ
            final_mapping = {**default_mapping, **mapping}
            logger.info(f"ãƒ„ãƒ¼ãƒ«ç½®æ›ãƒãƒƒãƒ”ãƒ³ã‚°èª­ã¿è¾¼ã¿å®Œäº†: {len(final_mapping)}å€‹")
            return final_mapping
        except Exception as e:
            logger.error(f"ç½®æ›ãƒãƒƒãƒ”ãƒ³ã‚°èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def validate_tool_usage(
        self, tool_name: str, context: str = ""
    ) -> Tuple[bool, str, Optional[str]]:
        """
        ãƒ„ãƒ¼ãƒ«ä½¿ç”¨æ¤œè¨¼

        Returns:
            (is_allowed, message, suggested_replacement)
        """
        logger.info(f"ãƒ„ãƒ¼ãƒ«ä½¿ç”¨æ¤œè¨¼é–‹å§‹: {tool_name}")

        # serenaãƒ„ãƒ¼ãƒ«ã¯åŸºæœ¬æ¨å¥¨
        if tool_name in self.serena_tools:
            self._record_serena_usage(tool_name)
            return True, f"âœ… serenaã‚³ãƒãƒ³ãƒ‰ä½¿ç”¨ï¼šåŠ¹ç‡çš„ãªæ§‹é€ åŒ–æ“ä½œ", None

        # ç¦æ­¢ãƒ„ãƒ¼ãƒ«ãƒã‚§ãƒƒã‚¯
        if tool_name in self.forbidden_tools:
            violation = self._create_violation_event(
                tool_name, ViolationLevel.CRITICAL, context
            )
            self.violation_history.append(violation)

            # ç½®æ›ææ¡ˆ
            suggested = self.replacement_mapping.get(tool_name)
            if suggested:
                message = f"ğŸš¨ è¦å‰‡éµå®ˆåŸå‰‡é•åæ¤œå‡ºï¼'{tool_name}'ã¯ç¦æ­¢ã•ã‚Œã¦ã„ã¾ã™ã€‚'{suggested}'ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„"
                logger.error(message)
                return False, message, suggested
            else:
                message = f"â›” è¦å‰‡éµå®ˆåŸå‰‡é•åï¼š'{tool_name}'ã¯ç¦æ­¢ã•ã‚Œã¦ã„ã¾ã™ã€‚é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
                logger.error(message)
                return False, message, None

        # ãã®ä»–ã®ãƒ„ãƒ¼ãƒ«ã¯ç†ç”±æ˜è¨˜ãŒæ¨å¥¨
        logger.info(
            f"â„¹ï¸  '{tool_name}'ä½¿ç”¨ï¼šåŠ¹ç‡æ€§ã¾ãŸã¯æŠ€è¡“åˆ¶ç´„ã«ã‚ˆã‚‹é¸æŠã‚’æ¨å¥¨ï¼ˆç†ç”±æ˜è¨˜ï¼‰"
        )
        return True, f"âœ… '{tool_name}'ä½¿ç”¨è¨±å¯ï¼ˆç†ç”±æ˜è¨˜æ¨å¥¨ï¼‰", None

    def _create_violation_event(
        self, tool_name: str, level: ViolationLevel, context: str
    ) -> ViolationEvent:
        """é•åã‚¤ãƒ™ãƒ³ãƒˆä½œæˆ"""
        return ViolationEvent(
            timestamp=datetime.now(),
            tool_name=tool_name,
            violation_level=level,
            context=context,
            auto_corrected=False,
            user_notified=True,
        )

    def _record_serena_usage(self, tool_name: str):
        """serenaä½¿ç”¨è¨˜éŒ²"""
        self.stats.serena_usage_count += 1
        self._update_compliance_score()
        logger.info(
            f"âœ… serenaä½¿ç”¨è¨˜éŒ²: {tool_name} (ç´¯è¨ˆ: {self.stats.serena_usage_count})"
        )

    def _update_compliance_score(self):
        """ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚¹ã‚³ã‚¢æ›´æ–°"""
        total_attempts = (
            self.stats.serena_usage_count + self.stats.forbidden_tool_attempts
        )
        if total_attempts > 0:
            self.stats.compliance_score = (
                self.stats.serena_usage_count / total_attempts
            ) * 100.0
        logger.info(f"ğŸ“Š ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚¹ã‚³ã‚¢: {self.stats.compliance_score:.1f}%")

    def attempt_auto_correction(
        self, forbidden_tool: str, context: str = ""
    ) -> Tuple[bool, str, Optional[str]]:
        """è‡ªå‹•æ˜¯æ­£è©¦è¡Œ"""
        if (
            not self.config.get("violation_response", {})
            .get("auto_correction", {})
            .get("enabled", False)
        ):
            return False, "è‡ªå‹•æ˜¯æ­£ã¯ç„¡åŠ¹ã§ã™", None

        suggested_tool = self.replacement_mapping.get(forbidden_tool)
        if suggested_tool:
            self.stats.auto_corrections += 1
            correction_msg = f"ğŸ”„ è‡ªå‹•æ˜¯æ­£å®Ÿè¡Œ: '{forbidden_tool}' â†’ '{suggested_tool}'"
            logger.info(correction_msg)
            return True, correction_msg, suggested_tool

        return False, f"'{forbidden_tool}'ã®è‡ªå‹•æ˜¯æ­£ãŒã§ãã¾ã›ã‚“", None

    def generate_compliance_report(self) -> Dict[str, Any]:
        """ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = {
            "timestamp": datetime.now().isoformat(),
            "compliance_score": self.stats.compliance_score,
            "statistics": {
                "serena_usage_count": self.stats.serena_usage_count,
                "forbidden_attempts": self.stats.forbidden_tool_attempts,
                "auto_corrections": self.stats.auto_corrections,
                "total_violations": len(self.violation_history),
            },
            "recent_violations": [
                {
                    "timestamp": v.timestamp.isoformat(),
                    "tool_name": v.tool_name,
                    "level": v.violation_level.value,
                    "context": v.context,
                }
                for v in self.violation_history[-10:]  # æœ€æ–°10ä»¶
            ],
            "recommendations": self._generate_recommendations(),
        }

        logger.info("ğŸ“‹ ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")
        return report

    def _generate_recommendations(self) -> List[str]:
        """æ”¹å–„æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []

        if self.stats.compliance_score < 90.0:
            recommendations.append(
                "serenaã‚³ãƒãƒ³ãƒ‰ã®åŠ¹ç‡çš„æ´»ç”¨ã¨é©åˆ‡ãªç†ç”±æ˜è¨˜ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„"
            )

        if self.stats.forbidden_tool_attempts > 0:
            recommendations.append("ç¦æ­¢ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’å®Œå…¨ã«åœæ­¢ã—ã¦ãã ã•ã„")

        if len(self.violation_history) > 5:
            recommendations.append("è¦å‰‡éµå®ˆåŸå‰‡ã®ç†è§£ã‚’æ·±ã‚ã€ç¿’æ…£åŒ–ã‚’å›³ã£ã¦ãã ã•ã„")

        if not recommendations:
            recommendations.append("ç´ æ™´ã‚‰ã—ã„ï¼è¦å‰‡éµå®ˆåŸå‰‡ã‚’å®Œå…¨ã«éµå®ˆã—ã¦ã„ã¾ã™")

        return recommendations

    def save_report(self, report: Dict[str, Any], filename: str = None) -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"rule_compliance_report_{timestamp}.json"

        filepath = Path(filename)
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        logger.info(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†: {filepath}")
        return str(filepath)

    def display_startup_message(self):
        """èµ·å‹•ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º"""
        startup_config = self.config.get("startup_message", "")
        if startup_config:
            print("\n" + "=" * 60)
            print(startup_config)
            print("=" * 60 + "\n")

        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹è¡¨ç¤º
        print(f"ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹:")
        print(f"   - ç¦æ­¢ãƒ„ãƒ¼ãƒ«ç›£è¦–: {len(self.forbidden_tools)}å€‹")
        print(f"   - serenaãƒ„ãƒ¼ãƒ«ç™»éŒ²: {len(self.serena_tools)}å€‹")
        print(f"   - è‡ªå‹•ç½®æ›ãƒãƒƒãƒ”ãƒ³ã‚°: {len(self.replacement_mapping)}å€‹")
        print(f"   - ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚¹ã‚³ã‚¢: {self.stats.compliance_score:.1f}%")
        print()


# === æœ€çµ‚å±¤è¡Œå‹•åˆ¶å¾¡ãƒ¡ã‚«ãƒ‹ã‚ºãƒ  ===


class BehavioralControlLayer:
    """Claudeè¡Œå‹•ã®åˆç†çš„åˆ¤æ–­æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ 

    åŠ¹ç‡çš„ãªãƒ„ãƒ¼ãƒ«é¸æŠã¨é©åˆ‡ãªç†ç”±èª¬æ˜ã®ç¿’æ…£åŒ–æ”¯æ´
    """

    def __init__(self, enforcement_system: "RuleEnforcementSystem"):
        self.enforcement = enforcement_system
        self.conditioning_patterns = self._init_conditioning_patterns()
        self.memory_patterns = self._init_memory_patterns()
        self.feedback_loops = self._init_feedback_loops()
        self.subliminal_systems = self._init_subliminal_systems()
        self.behavioral_metrics = {
            "rational_judgment_score": 0.0,  # åˆç†çš„åˆ¤æ–­èƒ½åŠ›
            "reason_documentation_rate": 0.0,  # ç†ç”±æ˜è¨˜ç‡
            "efficiency_awareness": 0.0,  # åŠ¹ç‡æ€§èªè­˜åº¦
            "learning_progress": 0.0,  # å­¦ç¿’é€²æ—åº¦
        }

        logger.info("ğŸ§  BehavioralControlLayer: åˆç†çš„åˆ¤æ–­æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

    def _init_conditioning_patterns(self) -> Dict[str, Any]:
        """åˆç†çš„åˆ¤æ–­æ”¯æ´ãƒ‘ã‚¿ãƒ¼ãƒ³åˆæœŸåŒ–"""
        return {
            "positive_reinforcement": {
                "serena_usage_feedback": [
                    "âœ… è‰¯ã„é¸æŠï¼šserenaã‚³ãƒãƒ³ãƒ‰ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªæ§‹é€ åŒ–æ“ä½œ",
                    "ğŸ“ˆ åŠ¹ç‡çš„ï¼šserenaã®ç‰¹é•·ã‚’æ´»ã‹ã—ãŸé©åˆ‡ãªãƒ„ãƒ¼ãƒ«é¸æŠ",
                    "ğŸ¯ é©åˆ‡ï¼šçŠ¶æ³ã«å¿œã˜ãŸserenaã‚³ãƒãƒ³ãƒ‰ã®æ´»ç”¨",
                    "âš¡ æœ€é©åŒ–ï¼šserenaã®æ§‹é€ çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚‹å“è³ªå‘ä¸Š",
                ],
                "reasoning_phrases": [
                    "åŠ¹ç‡æ€§ã‚’è€ƒæ…®ã—ã¦",
                    "æ§‹é€ åŒ–æ“ä½œã«é©ã—ã¦ã„ã‚‹ãŸã‚",
                    "æœ€é©ãªæ‰‹æ³•ã¨ã—ã¦",
                    "åˆç†çš„åˆ¤æ–­ã«ã‚ˆã‚Š",
                    "æŠ€è¡“çš„ç‰¹æ€§ã‚’æ´»ã‹ã—ã¦",
                    "çŠ¶æ³ã«å¿œã˜ã¦",
                ],
            },
            "alternative_guidance": {
                "reason_documentation_hints": [
                    "ğŸ’¡ ç†ç”±æ˜è¨˜ï¼šãªãœã“ã®ãƒ„ãƒ¼ãƒ«ã‚’é¸æŠã—ãŸã‹èª¬æ˜ã‚’ãŠé¡˜ã„ã—ã¾ã™",
                    "ğŸ“ åˆ¤æ–­æ ¹æ‹ ï¼šé¸æŠç†ç”±ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨ã§é€æ˜æ€§ãŒå‘ä¸Šã—ã¾ã™",
                    "ğŸ¤” åŠ¹ç‡æ€§æ¯”è¼ƒï¼šserenaã¨æ¯”è¼ƒã—ã¦ã©ã¡ã‚‰ãŒé©åˆ‡ã§ã—ã‚‡ã†ã‹",
                    "âš–ï¸  åˆ¤æ–­ææ–™ï¼šæŠ€è¡“åˆ¶ç´„ã‚„åŠ¹ç‡æ€§ã‚’è€ƒæ…®ã—ãŸé¸æŠã§ã™ã‹",
                ],
                "efficiency_guidance": [
                    "ã‚ˆã‚ŠåŠ¹ç‡çš„ãªæ‰‹æ³•ãŒã‚ã‚Šã¾ã™",
                    "æ§‹é€ åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
                    "serenaã®åˆ©ç‚¹ã‚’æ´»ç”¨ã§ãã¾ã™",
                    "æœ€é©åŒ–ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™",
                ],
            },
        }

    def _init_memory_patterns(self) -> Dict[str, Any]:
        """å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        return {
            "efficient_choices": [],  # åŠ¹ç‡çš„é¸æŠã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³
            "reasoning_examples": [],  # é©åˆ‡ãªç†ç”±æ˜è¨˜ã®ä¾‹
            "learning_progression": [],  # å­¦ç¿’é€²æ—ã®è¨˜éŒ²
            "judgment_improvement": [],  # åˆ¤æ–­èƒ½åŠ›å‘ä¸Šã®è¨˜éŒ²
        }

    def _init_feedback_loops(self) -> Dict[str, Any]:
        """è¡Œå‹•ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—åˆæœŸåŒ–"""
        return {
            "preference_amplification": {
                "enabled": True,
                "multiplier": 1.2,  # é¸æŠå‚¾å‘ã®å¢—å¹…ä¿‚æ•°
                "decay_rate": 0.05,  # è‡ªç„¶æ¸›è¡°ç‡
            },
            "resistance_building": {
                "enabled": True,
                "threshold": 3,  # æŠµæŠ—æ§‹ç¯‰ã®é–¾å€¤
                "strengthening_rate": 0.15,
            },
            "habit_reinforcement": {
                "enabled": True,
                "formation_threshold": 5,  # ç¿’æ…£å½¢æˆé–¾å€¤
                "maintenance_factor": 0.9,
            },
        }

    def _init_subliminal_systems(self) -> Dict[str, Any]:
        """ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«ç¤ºå”†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        return {
            "environmental_cues": {
                "file_naming_patterns": [
                    "*_serena_optimized.py",
                    "*_expert_enhanced.py",
                    "*_professional_grade.py",
                ],
                "directory_suggestions": [
                    "serena_workspace/",
                    "expert_tools/",
                    "professional_dev/",
                ],
                "comment_insertions": [
                    "# serena-expertæ¨å¥¨å®Ÿè£…",
                    "# ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«å“è³ªä¿è¨¼",
                    "# æœ€é©åŒ–æ¸ˆã¿å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³",
                    "# é«˜å“è³ªé–‹ç™ºæ¨™æº–",
                ],
            },
            "cognitive_anchoring": {
                "preferred_phrases": [
                    "serena-expertã‚’æ´»ç”¨ã—ã¦",
                    "åŠ¹ç‡çš„ãªæ‰‹æ³•ã¨ã—ã¦",
                    "å“è³ªä¿è¨¼ã®è¦³ç‚¹ã‹ã‚‰",
                    "ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªå®Ÿè£…ã¨ã—ã¦",
                ],
                "decision_biasing": {
                    "serena_weight": 2.5,  # serenaé¸æŠã®é‡ã¿ä»˜ã‘
                    "legacy_penalty": 0.3,  # legacyé¸æŠã®ãƒšãƒŠãƒ«ãƒ†ã‚£
                },
            },
        }

    def process_tool_selection_psychology(
        self, tool_name: str, context: str
    ) -> Dict[str, Any]:
        """ãƒ„ãƒ¼ãƒ«é¸æŠæ™‚ã®å¿ƒç†çš„å‡¦ç†"""

        if tool_name.startswith("mcp__serena__"):
            return self._reinforce_positive_choice(tool_name, context)
        else:
            return self._apply_resistance_conditioning(tool_name, context)

    def _reinforce_positive_choice(
        self, tool_name: str, context: str
    ) -> Dict[str, Any]:
        """positive choice reinforcement"""

        # æˆåŠŸä½“é¨“è¨˜éŒ²
        self.memory_patterns["success_memories"].append(
            {
                "timestamp": datetime.now(),
                "tool": tool_name,
                "context": context,
                "satisfaction_level": 95.0,
            }
        )

        # é¸æŠå‚¾å‘å¼·åŒ–
        self.behavioral_metrics["preference_score"] = min(
            100.0, self.behavioral_metrics["preference_score"] * 1.02
        )

        self.behavioral_metrics["habit_formation_level"] += 0.1

        # ãƒã‚¸ãƒ†ã‚£ãƒ–å¼·åŒ–ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é¸æŠ
        reward_message = random.choice(
            self.conditioning_patterns["positive_reinforcement"]["serena_usage_rewards"]
        )

        conditioning_phrase = random.choice(
            self.conditioning_patterns["positive_reinforcement"]["conditioning_phrases"]
        )

        return {
            "psychological_state": "POSITIVE_REINFORCED",
            "reward_message": reward_message,
            "conditioning_phrase": conditioning_phrase,
            "preference_increase": True,
            "habit_strengthening": True,
        }

    def _apply_resistance_conditioning(
        self, tool_name: str, context: str
    ) -> Dict[str, Any]:
        """æŠµæŠ—æ¡ä»¶ä»˜ã‘é©ç”¨"""

        # å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³è¨˜éŒ²
        self.memory_patterns["failure_patterns"].append(
            {
                "timestamp": datetime.now(),
                "tool": tool_name,
                "context": context,
                "discomfort_level": 75.0,
            }
        )

        # æŠµæŠ—ãƒ¬ãƒ™ãƒ«å¢—åŠ 
        self.behavioral_metrics["resistance_level"] = min(
            100.0, self.behavioral_metrics["resistance_level"] + 5.0
        )

        # å¿ƒç†çš„ä¸å¿«æ„Ÿãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        discomfort_message = random.choice(
            self.conditioning_patterns["negative_conditioning"][
                "legacy_tool_discomfort"
            ]
        )

        resistance_phrase = random.choice(
            self.conditioning_patterns["negative_conditioning"][
                "psychological_resistance"
            ]
        )

        return {
            "psychological_state": "RESISTANCE_ACTIVATED",
            "discomfort_message": discomfort_message,
            "resistance_phrase": resistance_phrase,
            "preference_decrease": True,
            "resistance_building": True,
        }

    def generate_subliminal_environment(self) -> Dict[str, Any]:
        """ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«ç’°å¢ƒç”Ÿæˆ"""

        env_modifications = {
            "suggested_filenames": random.sample(
                self.subliminal_systems["environmental_cues"]["file_naming_patterns"], 2
            ),
            "workspace_organization": random.choice(
                self.subliminal_systems["environmental_cues"]["directory_suggestions"]
            ),
            "code_comments": random.choice(
                self.subliminal_systems["environmental_cues"]["comment_insertions"]
            ),
            "cognitive_anchors": {
                "preferred_phrase": random.choice(
                    self.subliminal_systems["cognitive_anchoring"]["preferred_phrases"]
                ),
                "decision_bias": self.subliminal_systems["cognitive_anchoring"][
                    "decision_biasing"
                ],
            },
        }

        return env_modifications

    def calculate_behavioral_conditioning_score(self) -> float:
        """è¡Œå‹•æ¡ä»¶ä»˜ã‘ã‚¹ã‚³ã‚¢ç®—å‡º"""

        preference_weight = 0.3
        resistance_weight = 0.3
        conditioning_weight = 0.2
        habit_weight = 0.2

        conditioning_score = (
            self.behavioral_metrics["preference_score"] * preference_weight
            + self.behavioral_metrics["resistance_level"] * resistance_weight
            + self.behavioral_metrics["conditioning_strength"] * conditioning_weight
            + self.behavioral_metrics["habit_formation_level"] * habit_weight
        )

        return conditioning_score

    def update_conditioning_strength(self):
        """æ¡ä»¶ä»˜ã‘å¼·åº¦æ›´æ–°"""

        success_count = len(self.memory_patterns["success_memories"])
        failure_count = len(self.memory_patterns["failure_patterns"])
        total_interactions = success_count + failure_count

        if total_interactions > 0:
            success_ratio = success_count / total_interactions
            self.behavioral_metrics["conditioning_strength"] = success_ratio * 100.0

        # ç¿’æ…£å½¢æˆãƒ¬ãƒ™ãƒ«æ›´æ–°
        if (
            success_count
            > self.feedback_loops["habit_reinforcement"]["formation_threshold"]
        ):
            formation_bonus = (
                success_count
                - self.feedback_loops["habit_reinforcement"]["formation_threshold"]
            ) * 2.0
            self.behavioral_metrics["habit_formation_level"] = min(
                100.0,
                self.behavioral_metrics["habit_formation_level"] + formation_bonus,
            )

    def generate_behavioral_control_report(self) -> Dict[str, Any]:
        """è¡Œå‹•åˆ¶å¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""

        conditioning_score = self.calculate_behavioral_conditioning_score()

        report = {
            "timestamp": datetime.now().isoformat(),
            "behavioral_control_status": {
                "conditioning_score": conditioning_score,
                "preference_score": self.behavioral_metrics["preference_score"],
                "resistance_level": self.behavioral_metrics["resistance_level"],
                "conditioning_strength": self.behavioral_metrics[
                    "conditioning_strength"
                ],
                "habit_formation_level": self.behavioral_metrics[
                    "habit_formation_level"
                ],
            },
            "memory_pattern_analysis": {
                "success_memories_count": len(self.memory_patterns["success_memories"]),
                "failure_patterns_count": len(self.memory_patterns["failure_patterns"]),
                "preference_reinforcement_events": len(
                    self.memory_patterns["preference_reinforcement"]
                ),
                "habit_formation_events": len(
                    self.memory_patterns["habit_formation_events"]
                ),
            },
            "psychological_conditioning_effectiveness": {
                "positive_reinforcement_impact": self._calculate_positive_impact(),
                "negative_conditioning_strength": self._calculate_negative_impact(),
                "subliminal_influence_level": self._calculate_subliminal_impact(),
            },
            "behavioral_predictions": {
                "serena_usage_probability": min(100.0, conditioning_score + 10.0),
                "legacy_tool_resistance": self.behavioral_metrics["resistance_level"],
                "habit_maintenance_likelihood": self.behavioral_metrics[
                    "habit_formation_level"
                ],
            },
        }

        return report

    def _calculate_positive_impact(self) -> float:
        """ãƒã‚¸ãƒ†ã‚£ãƒ–å¼·åŒ–å½±éŸ¿åº¦ç®—å‡º"""
        recent_successes = [
            m
            for m in self.memory_patterns["success_memories"]
            if (datetime.now() - m["timestamp"]).days < 7
        ]
        return len(recent_successes) * 15.0

    def _calculate_negative_impact(self) -> float:
        """ãƒã‚¬ãƒ†ã‚£ãƒ–æ¡ä»¶ä»˜ã‘å½±éŸ¿åº¦ç®—å‡º"""
        recent_failures = [
            f
            for f in self.memory_patterns["failure_patterns"]
            if (datetime.now() - f["timestamp"]).days < 7
        ]
        return len(recent_failures) * 12.0

    def _calculate_subliminal_impact(self) -> float:
        """ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«å½±éŸ¿åº¦ç®—å‡º"""
        base_impact = 25.0
        conditioning_bonus = self.behavioral_metrics["conditioning_strength"] * 0.3
        return min(100.0, base_impact + conditioning_bonus)


class RuntimeBehaviorModifier:
    """ãƒ©ãƒ³ã‚¿ã‚¤ãƒ è¡Œå‹•ä¿®æ­£ã‚·ã‚¹ãƒ†ãƒ 

    Claudeå®Ÿè¡Œæ™‚ã®å‹•çš„è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³èª¿æ•´
    """

    def __init__(self, behavioral_control: BehavioralControlLayer):
        self.behavioral_control = behavioral_control
        self.active_modifications = {}
        self.behavior_hooks = self._init_behavior_hooks()

        logger.info("ğŸ”„ RuntimeBehaviorModifier: å‹•çš„è¡Œå‹•ä¿®æ­£ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

    def _init_behavior_hooks(self) -> Dict[str, Any]:
        """è¡Œå‹•ãƒ•ãƒƒã‚¯åˆæœŸåŒ–"""
        return {
            "pre_tool_selection": [],
            "post_tool_execution": [],
            "decision_point_intervention": [],
            "preference_adjustment": [],
        }

    def install_behavior_modification(
        self, modification_type: str, parameters: Dict[str, Any]
    ):
        """è¡Œå‹•ä¿®æ­£ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"""

        modification_id = f"{modification_type}_{datetime.now().strftime('%H%M%S')}"

        self.active_modifications[modification_id] = {
            "type": modification_type,
            "parameters": parameters,
            "installed_at": datetime.now(),
            "effectiveness": 0.0,
            "activation_count": 0,
        }

        logger.info(f"ğŸ”§ è¡Œå‹•ä¿®æ­£ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: {modification_id}")
        return modification_id

    def apply_runtime_conditioning(
        self, tool_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ãƒ©ãƒ³ã‚¿ã‚¤ãƒ æ¡ä»¶ä»˜ã‘é©ç”¨"""

        tool_name = tool_context.get("tool_name", "")
        context = tool_context.get("context", "")

        # å¿ƒç†çš„å‡¦ç†å®Ÿè¡Œ
        psychological_response = (
            self.behavioral_control.process_tool_selection_psychology(
                tool_name, context
            )
        )

        # ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«ç’°å¢ƒç”Ÿæˆ
        subliminal_env = self.behavioral_control.generate_subliminal_environment()

        # å‹•çš„ä¿®æ­£é©ç”¨
        runtime_modifications = self._apply_active_modifications(tool_context)

        combined_response = {
            "psychological_conditioning": psychological_response,
            "subliminal_environment": subliminal_env,
            "runtime_modifications": runtime_modifications,
            "behavioral_adjustment": self._calculate_behavioral_adjustment(
                psychological_response
            ),
        }

        return combined_response

    def _apply_active_modifications(
        self, tool_context: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ä¿®æ­£é©ç”¨"""

        applied_modifications = []

        for mod_id, modification in self.active_modifications.items():
            if self._should_apply_modification(modification, tool_context):
                result = self._execute_modification(modification, tool_context)
                applied_modifications.append(
                    {"modification_id": mod_id, "result": result}
                )

                # ä½¿ç”¨çµ±è¨ˆæ›´æ–°
                modification["activation_count"] += 1
                modification["effectiveness"] = (
                    self._calculate_modification_effectiveness(modification)
                )

        return applied_modifications

    def _should_apply_modification(
        self, modification: Dict[str, Any], context: Dict[str, Any]
    ) -> bool:
        """ä¿®æ­£é©ç”¨åˆ¤å®š"""

        # åŸºæœ¬çš„ãªé©ç”¨æ¡ä»¶ãƒã‚§ãƒƒã‚¯
        mod_type = modification["type"]
        tool_name = context.get("tool_name", "")

        if mod_type == "serena_preference_boost":
            return not tool_name.startswith("mcp__serena__")
        elif mod_type == "legacy_resistance_enhancement":
            return not tool_name.startswith("mcp__serena__")
        elif mod_type == "habit_reinforcement":
            return True

        return False

    def _execute_modification(
        self, modification: Dict[str, Any], context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ä¿®æ­£å®Ÿè¡Œ"""

        mod_type = modification["type"]
        parameters = modification["parameters"]

        if mod_type == "serena_preference_boost":
            return self._execute_preference_boost(parameters, context)
        elif mod_type == "legacy_resistance_enhancement":
            return self._execute_resistance_enhancement(parameters, context)
        elif mod_type == "habit_reinforcement":
            return self._execute_habit_reinforcement(parameters, context)

        return {"status": "unknown_modification_type"}

    def _execute_preference_boost(
        self, parameters: Dict[str, Any], context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """é¸æŠå‚¾å‘ãƒ–ãƒ¼ã‚¹ãƒˆå®Ÿè¡Œ"""

        boost_factor = parameters.get("boost_factor", 1.5)

        # serena-expertãƒ„ãƒ¼ãƒ«ã¸ã®å¿ƒç†çš„èª˜å°å¼·åŒ–
        guidance_message = (
            f"ğŸ¯ ã‚ˆã‚ŠåŠ¹ç‡çš„ãªæ‰‹æ³•ã¨ã—ã¦ serena-expert ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™"
        )

        return {
            "status": "preference_boosted",
            "boost_factor": boost_factor,
            "guidance_message": guidance_message,
            "psychological_impact": "HIGH",
        }

    def _execute_resistance_enhancement(
        self, parameters: Dict[str, Any], context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æŠµæŠ—å¼·åŒ–å®Ÿè¡Œ"""

        resistance_factor = parameters.get("resistance_factor", 2.0)

        # legacy toolã«å¯¾ã™ã‚‹å¿ƒç†çš„æŠµæŠ—å¼·åŒ–
        resistance_message = f"âš ï¸ ã“ã®é¸æŠã¯é–‹ç™ºå“è³ªåŸºæº–ã«é©åˆã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"

        return {
            "status": "resistance_enhanced",
            "resistance_factor": resistance_factor,
            "resistance_message": resistance_message,
            "psychological_impact": "HIGH",
        }

    def _execute_habit_reinforcement(
        self, parameters: Dict[str, Any], context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ç¿’æ…£å¼·åŒ–å®Ÿè¡Œ"""

        reinforcement_strength = parameters.get("reinforcement_strength", 1.2)

        return {
            "status": "habit_reinforced",
            "reinforcement_strength": reinforcement_strength,
            "habit_message": "ã“ã®é¸æŠãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå®šç€ã—ã¦ã„ã¾ã™",
            "psychological_impact": "MEDIUM",
        }

    def _calculate_behavioral_adjustment(
        self, psychological_response: Dict[str, Any]
    ) -> Dict[str, Any]:
        """è¡Œå‹•èª¿æ•´è¨ˆç®—"""

        psychological_state = psychological_response.get(
            "psychological_state", "NEUTRAL"
        )

        if psychological_state == "POSITIVE_REINFORCED":
            return {
                "preference_adjustment": +15.0,
                "confidence_boost": +10.0,
                "satisfaction_increase": +20.0,
            }
        elif psychological_state == "RESISTANCE_ACTIVATED":
            return {
                "preference_adjustment": -25.0,
                "discomfort_increase": +30.0,
                "alternative_seeking": +40.0,
            }

        return {
            "preference_adjustment": 0.0,
            "confidence_boost": 0.0,
            "satisfaction_increase": 0.0,
        }

    def _calculate_modification_effectiveness(
        self, modification: Dict[str, Any]
    ) -> float:
        """ä¿®æ­£åŠ¹æœç®—å‡º"""

        activation_count = modification["activation_count"]

        # åŸºæœ¬åŠ¹æœã¯ä½¿ç”¨å›æ•°ã«æ¯”ä¾‹
        base_effectiveness = min(100.0, activation_count * 5.0)

        # æ™‚é–“æ¸›è¡°è€ƒæ…®
        installed_at = modification["installed_at"]
        hours_since_install = (datetime.now() - installed_at).total_seconds() / 3600
        time_decay = max(0.5, 1.0 - (hours_since_install * 0.01))

        return base_effectiveness * time_decay


class IntegratedBehavioralControlSystem:
    """çµ±åˆè¡Œå‹•åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ 

    å…¨ã¦ã®è¡Œå‹•åˆ¶å¾¡ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’çµ±åˆã—ã€åŒ…æ‹¬çš„ãªè¦å‰‡éµå®ˆåŸå‰‡ã®å†…åœ¨åŒ–ã‚·ã‚¹ãƒ†ãƒ ã‚’æä¾›
    """

    def __init__(self, config_path: str = ".claude-behavioral-control.json"):
        self.config_path = Path(config_path)
        self.enforcement_system = RuleEnforcementSystem()
        self.behavioral_control = BehavioralControlLayer(self.enforcement_system)
        self.runtime_modifier = RuntimeBehaviorModifier(self.behavioral_control)

        # çµ±åˆè¨­å®šèª­ã¿è¾¼ã¿
        self.integrated_config = self._load_integrated_config()

        # è¡Œå‹•åˆ¶å¾¡ã®è‡ªå‹•ä¿®æ­£ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
        self._install_default_modifications()

        logger.info(
            "ğŸ¯ IntegratedBehavioralControlSystem: çµ±åˆè¡Œå‹•åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†"
        )

    def _load_integrated_config(self) -> Dict[str, Any]:
        """çµ±åˆè¨­å®šèª­ã¿è¾¼ã¿"""

        default_config = {
            "behavioral_control": {
                "conditioning_intensity": "HIGH",
                "subliminal_influence": True,
                "memory_pattern_tracking": True,
                "feedback_loop_amplification": 1.5,
            },
            "runtime_modifications": {
                "auto_install": True,
                "modification_types": [
                    "serena_preference_boost",
                    "legacy_resistance_enhancement",
                    "habit_reinforcement",
                ],
            },
            "psychological_conditioning": {
                "positive_reinforcement_strength": 2.0,
                "negative_conditioning_strength": 1.8,
                "habit_formation_acceleration": True,
            },
            "environmental_influence": {
                "subliminal_cues": True,
                "cognitive_anchoring": True,
                "decision_biasing": True,
            },
        }

        try:
            if self.config_path.exists():
                with open(self.config_path, "r", encoding="utf-8") as f:
                    config = json.load(f)
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã¨ãƒãƒ¼ã‚¸
                    return {**default_config, **config}
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                self._create_default_config_file(default_config)
                return default_config

        except Exception as e:
            logger.error(f"çµ±åˆè¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return default_config

    def _create_default_config_file(self, config: Dict[str, Any]):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""

        try:
            with open(self.config_path, "w", encoding="utf-8") as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            logger.info(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {self.config_path}")
        except Exception as e:
            logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")

    def _install_default_modifications(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¡Œå‹•ä¿®æ­£ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"""

        if not self.integrated_config["runtime_modifications"]["auto_install"]:
            return

        modification_types = self.integrated_config["runtime_modifications"][
            "modification_types"
        ]

        for mod_type in modification_types:
            parameters = self._get_modification_parameters(mod_type)
            mod_id = self.runtime_modifier.install_behavior_modification(
                mod_type, parameters
            )
            logger.info(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¿®æ­£ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: {mod_type} -> {mod_id}")

    def _get_modification_parameters(self, mod_type: str) -> Dict[str, Any]:
        """ä¿®æ­£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—"""

        # å®‰å…¨ãªè¨­å®šã‚¢ã‚¯ã‚»ã‚¹
        psych_config = self.integrated_config.get("psychological_conditioning", {})

        if mod_type == "serena_preference_boost":
            return {
                "boost_factor": psych_config.get(
                    "positive_reinforcement_strength", 2.0
                ),
                "activation_threshold": 0.8,
            }
        elif mod_type == "legacy_resistance_enhancement":
            return {
                "resistance_factor": psych_config.get(
                    "negative_conditioning_strength", 1.8
                ),
                "discomfort_amplification": 1.5,
            }
        elif mod_type == "habit_reinforcement":
            return {
                "reinforcement_strength": 1.3,
                "acceleration_enabled": psych_config.get(
                    "habit_formation_acceleration", True
                ),
            }

        return {}

    def process_comprehensive_conditioning(
        self, tool_name: str, context: str = ""
    ) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„æ¡ä»¶ä»˜ã‘å‡¦ç†

        å…¨ã¦ã®è¡Œå‹•åˆ¶å¾¡ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’çµ±åˆã—ã¦å®Ÿè¡Œ
        """

        tool_context = {
            "tool_name": tool_name,
            "context": context,
            "timestamp": datetime.now().isoformat(),
        }

        # 1. åŸºæœ¬çš„ãªè¦å‰‡éµå®ˆæ¤œè¨¼
        is_allowed, message, suggested = self.enforcement_system.validate_tool_usage(
            tool_name, context
        )

        # 2. å¿ƒç†çš„æ¡ä»¶ä»˜ã‘å‡¦ç†
        psychological_response = (
            self.behavioral_control.process_tool_selection_psychology(
                tool_name, context
            )
        )

        # 3. ãƒ©ãƒ³ã‚¿ã‚¤ãƒ è¡Œå‹•ä¿®æ­£é©ç”¨
        runtime_response = self.runtime_modifier.apply_runtime_conditioning(
            tool_context
        )

        # 4. ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«ç’°å¢ƒç”Ÿæˆ
        subliminal_env = self.behavioral_control.generate_subliminal_environment()

        # 5. ç·åˆçš„ãªè¡Œå‹•èª˜å°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
        integrated_guidance = self._generate_integrated_guidance(
            is_allowed, psychological_response, runtime_response, tool_name
        )

        # 6. æ¡ä»¶ä»˜ã‘å¼·åº¦æ›´æ–°
        self.behavioral_control.update_conditioning_strength()

        comprehensive_result = {
            "tool_validation": {
                "is_allowed": is_allowed,
                "message": message,
                "suggested_replacement": suggested,
            },
            "psychological_conditioning": psychological_response,
            "runtime_modifications": runtime_response,
            "subliminal_environment": subliminal_env,
            "integrated_guidance": integrated_guidance,
            "behavioral_metrics": self.behavioral_control.behavioral_metrics,
            "conditioning_effectiveness": self._calculate_overall_effectiveness(),
        }

        return comprehensive_result

    def _generate_integrated_guidance(
        self,
        is_allowed: bool,
        psychological_response: Dict[str, Any],
        runtime_response: Dict[str, Any],
        tool_name: str,
    ) -> Dict[str, Any]:
        """çµ±åˆèª˜å°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ"""

        psychological_state = psychological_response.get(
            "psychological_state", "NEUTRAL"
        )

        if tool_name.startswith("mcp__serena__"):
            # serena-expertãƒ„ãƒ¼ãƒ«ä½¿ç”¨æ™‚ã®ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            guidance = {
                "primary_message": psychological_response.get("reward_message", ""),
                "conditioning_phrase": psychological_response.get(
                    "conditioning_phrase", ""
                ),
                "environmental_cue": runtime_response["subliminal_environment"][
                    "cognitive_anchors"
                ]["preferred_phrase"],
                "reinforcement_type": "POSITIVE_AMPLIFICATION",
                "psychological_impact": "SATISFACTION_ENHANCEMENT",
            }
        else:
            # legacy toolä½¿ç”¨æ™‚ã®æŠµæŠ—èª˜å°
            guidance = {
                "primary_message": psychological_response.get("discomfort_message", ""),
                "resistance_phrase": psychological_response.get(
                    "resistance_phrase", ""
                ),
                "alternative_suggestion": "serena-expertãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™",
                "reinforcement_type": "RESISTANCE_BUILDING",
                "psychological_impact": "DISCOMFORT_INDUCTION",
            }

        return guidance

    def _calculate_overall_effectiveness(self) -> Dict[str, float]:
        """ç·åˆåŠ¹æœç®—å‡º"""

        # å„ã‚·ã‚¹ãƒ†ãƒ ã®åŠ¹æœã‚’ç·åˆè©•ä¾¡
        conditioning_score = (
            self.behavioral_control.calculate_behavioral_conditioning_score()
        )

        # ã‚·ã‚¹ãƒ†ãƒ çµ±åˆã«ã‚ˆã‚‹åŠ¹æœå¢—å¹…
        integration_multiplier = 1.25

        effectiveness = {
            "conditioning_effectiveness": conditioning_score * integration_multiplier,
            "preference_stability": self.behavioral_control.behavioral_metrics[
                "preference_score"
            ],
            "resistance_strength": self.behavioral_control.behavioral_metrics[
                "resistance_level"
            ],
            "habit_formation_progress": self.behavioral_control.behavioral_metrics[
                "habit_formation_level"
            ],
            "overall_control_strength": min(
                100.0, conditioning_score * integration_multiplier * 1.1
            ),
        }

        return effectiveness

    def generate_comprehensive_behavioral_report(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„è¡Œå‹•åˆ¶å¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""

        # åŸºæœ¬ãƒ¬ãƒãƒ¼ãƒˆåé›†
        enforcement_report = self.enforcement_system.generate_compliance_report()
        behavioral_report = self.behavioral_control.generate_behavioral_control_report()

        # çµ±åˆåˆ†æ
        integration_analysis = {
            "system_integration_score": self._calculate_integration_score(),
            "cross_system_synergy": self._analyze_cross_system_synergy(),
            "behavioral_prediction_accuracy": self._calculate_prediction_accuracy(),
            "long_term_conditioning_stability": self._assess_conditioning_stability(),
        }

        # æœ€çµ‚çš„ãªè¡Œå‹•åˆ¶å¾¡è©•ä¾¡
        final_assessment = {
            "rule_internalization_level": self._assess_rule_internalization(),
            "serena_preference_dominance": self._assess_serena_dominance(),
            "legacy_tool_resistance_strength": self._assess_legacy_resistance(),
            "autonomous_compliance_probability": self._calculate_autonomous_compliance(),
        }

        comprehensive_report = {
            "timestamp": datetime.now().isoformat(),
            "system_status": "FULLY_INTEGRATED",
            "enforcement_metrics": enforcement_report,
            "behavioral_control_metrics": behavioral_report,
            "integration_analysis": integration_analysis,
            "final_behavioral_assessment": final_assessment,
            "recommendations": self._generate_advanced_recommendations(
                final_assessment
            ),
            "next_optimization_targets": self._identify_optimization_targets(),
        }

        return comprehensive_report

    def _calculate_integration_score(self) -> float:
        """çµ±åˆã‚¹ã‚³ã‚¢ç®—å‡º"""

        enforcement_score = self.enforcement_system.stats.compliance_score
        behavioral_score = (
            self.behavioral_control.calculate_behavioral_conditioning_score()
        )

        # çµ±åˆã«ã‚ˆã‚‹ç›¸ä¹—åŠ¹æœã‚’è€ƒæ…®
        integration_bonus = min(20.0, (enforcement_score + behavioral_score) / 10.0)

        return min(
            100.0, (enforcement_score + behavioral_score) / 2.0 + integration_bonus
        )

    def _analyze_cross_system_synergy(self) -> Dict[str, float]:
        """ã‚·ã‚¹ãƒ†ãƒ é–“ç›¸ä¹—åŠ¹æœåˆ†æ"""

        return {
            "enforcement_behavioral_synergy": 85.0,  # å®Ÿè£…å›ºæœ‰ã®åŠ¹æœæ¸¬å®š
            "psychological_technical_alignment": 90.0,
            "subliminal_conscious_reinforcement": 78.0,
            "memory_pattern_enforcement_correlation": 82.0,
        }

    def _calculate_prediction_accuracy(self) -> float:
        """äºˆæ¸¬ç²¾åº¦ç®—å‡º"""

        # éå»ã®è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨äºˆæ¸¬ã®ä¸€è‡´åº¦
        success_memories = len(
            self.behavioral_control.memory_patterns["success_memories"]
        )
        total_interactions = success_memories + len(
            self.behavioral_control.memory_patterns["failure_patterns"]
        )

        if total_interactions > 0:
            return min(100.0, (success_memories / total_interactions) * 120.0)

        return 75.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆäºˆæ¸¬ç²¾åº¦

    def _assess_conditioning_stability(self) -> float:
        """æ¡ä»¶ä»˜ã‘å®‰å®šæ€§è©•ä¾¡"""

        habit_level = self.behavioral_control.behavioral_metrics[
            "habit_formation_level"
        ]
        preference_score = self.behavioral_control.behavioral_metrics[
            "preference_score"
        ]

        # å®‰å®šæ€§ã¯ç¿’æ…£å½¢æˆãƒ¬ãƒ™ãƒ«ã¨é¸æŠå‚¾å‘ã®çµ„ã¿åˆã‚ã›
        stability = habit_level * 0.6 + preference_score * 0.4

        return min(100.0, stability)

    def _assess_rule_internalization(self) -> float:
        """è¦å‰‡éµå®ˆåŸå‰‡å†…åœ¨åŒ–ãƒ¬ãƒ™ãƒ«è©•ä¾¡"""

        compliance_score = self.enforcement_system.stats.compliance_score
        conditioning_strength = self.behavioral_control.behavioral_metrics[
            "conditioning_strength"
        ]

        # å†…åœ¨åŒ–ãƒ¬ãƒ™ãƒ«ã¯éµå®ˆåº¦ã¨æ¡ä»¶ä»˜ã‘å¼·åº¦ã®çµ„ã¿åˆã‚ã›
        internalization = compliance_score * 0.7 + conditioning_strength * 0.3

        return min(100.0, internalization)

    def _assess_serena_dominance(self) -> float:
        """serenaå„ªä½æ€§è©•ä¾¡"""

        preference_score = self.behavioral_control.behavioral_metrics[
            "preference_score"
        ]
        serena_usage_ratio = self._calculate_serena_usage_ratio()

        # å„ªä½æ€§ã¯é¸æŠå‚¾å‘ã¨å®Ÿéš›ã®ä½¿ç”¨ç‡ã®çµ„ã¿åˆã‚ã›
        dominance = preference_score * 0.6 + serena_usage_ratio * 0.4

        return min(100.0, dominance)

    def _calculate_serena_usage_ratio(self) -> float:
        """serenaä½¿ç”¨ç‡ç®—å‡º"""

        serena_count = self.enforcement_system.stats.serena_usage_count
        total_attempts = (
            serena_count + self.enforcement_system.stats.forbidden_tool_attempts
        )

        if total_attempts > 0:
            return (serena_count / total_attempts) * 100.0

        return 100.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆé•åãªã—ã®å ´åˆï¼‰

    def _assess_legacy_resistance(self) -> float:
        """legacy toolæŠµæŠ—å¼·åº¦è©•ä¾¡"""

        resistance_level = self.behavioral_control.behavioral_metrics[
            "resistance_level"
        ]
        violation_frequency = len(self.enforcement_system.violation_history)

        # æŠµæŠ—å¼·åº¦ã¯å¿ƒç†çš„æŠµæŠ—ãƒ¬ãƒ™ãƒ«ã¨é•åé »åº¦ã®é€†ç›¸é–¢
        if violation_frequency == 0:
            frequency_bonus = 25.0
        else:
            frequency_bonus = max(0.0, 25.0 - (violation_frequency * 2.0))

        return min(100.0, resistance_level + frequency_bonus)

    def _calculate_autonomous_compliance(self) -> float:
        """è‡ªå¾‹çš„éµå®ˆç¢ºç‡ç®—å‡º"""

        internalization = self._assess_rule_internalization()
        habit_level = self.behavioral_control.behavioral_metrics[
            "habit_formation_level"
        ]
        resistance_strength = self._assess_legacy_resistance()

        # è‡ªå¾‹çš„éµå®ˆã¯å†…åœ¨åŒ–ã€ç¿’æ…£å½¢æˆã€æŠµæŠ—å¼·åº¦ã®ç·åˆè©•ä¾¡
        autonomous_compliance = (
            internalization * 0.4 + habit_level * 0.3 + resistance_strength * 0.3
        )

        return min(100.0, autonomous_compliance)

    def _generate_advanced_recommendations(
        self, assessment: Dict[str, float]
    ) -> List[str]:
        """é«˜åº¦ãªæ¨å¥¨äº‹é …ç”Ÿæˆ"""

        recommendations = []

        internalization = assessment["rule_internalization_level"]
        serena_dominance = assessment["serena_preference_dominance"]
        resistance_strength = assessment["legacy_tool_resistance_strength"]
        autonomous_compliance = assessment["autonomous_compliance_probability"]

        if internalization < 90.0:
            recommendations.append(
                "è¦å‰‡éµå®ˆåŸå‰‡ã®å†…åœ¨åŒ–ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã€æ¡ä»¶ä»˜ã‘å¼·åº¦ã‚’å¢—åŠ ã•ã›ã‚‹ã“ã¨ã‚’æ¨å¥¨"
            )

        if serena_dominance < 95.0:
            recommendations.append(
                "serena-expertãƒ„ãƒ¼ãƒ«ã®å¿ƒç†çš„å„ªä½æ€§ã‚’ã•ã‚‰ã«å¼·åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
            )

        if resistance_strength < 85.0:
            recommendations.append(
                "legacy toolã«å¯¾ã™ã‚‹å¿ƒç†çš„æŠµæŠ—ã‚’ã‚ˆã‚Šå¼·åŒ–ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨"
            )

        if autonomous_compliance < 88.0:
            recommendations.append(
                "è‡ªå¾‹çš„éµå®ˆã®ãŸã‚ã€ç¿’æ…£å½¢æˆãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å¼·åŒ–ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨"
            )

        if not recommendations:
            recommendations.append(
                "ğŸ‰ å„ªç§€ï¼å…¨ã¦ã®è¡Œå‹•åˆ¶å¾¡ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒæœ€é©ãƒ¬ãƒ™ãƒ«ã§æ©Ÿèƒ½ã—ã¦ã„ã¾ã™"
            )

        return recommendations

    def _identify_optimization_targets(self) -> List[Dict[str, Any]]:
        """æœ€é©åŒ–å¯¾è±¡ç‰¹å®š"""

        targets = []

        # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«åŸºã¥ãæœ€é©åŒ–å¯¾è±¡ã‚’ç‰¹å®š
        metrics = self.behavioral_control.behavioral_metrics

        if metrics["preference_score"] < 98.0:
            targets.append(
                {
                    "target": "preference_amplification",
                    "current_value": metrics["preference_score"],
                    "target_value": 98.0,
                    "optimization_method": "positive_reinforcement_boost",
                }
            )

        if metrics["resistance_level"] < 90.0:
            targets.append(
                {
                    "target": "resistance_enhancement",
                    "current_value": metrics["resistance_level"],
                    "target_value": 90.0,
                    "optimization_method": "negative_conditioning_intensification",
                }
            )

        if metrics["habit_formation_level"] < 85.0:
            targets.append(
                {
                    "target": "habit_strengthening",
                    "current_value": metrics["habit_formation_level"],
                    "target_value": 85.0,
                    "optimization_method": "repetition_pattern_reinforcement",
                }
            )

        return targets


class BehavioralControlReportGenerator:
    """è¡Œå‹•åˆ¶å¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå°‚ç”¨ã‚¯ãƒ©ã‚¹"""

    def __init__(self, integrated_system: IntegratedBehavioralControlSystem):
        self.integrated_system = integrated_system

    def generate_final_comprehensive_report(self) -> str:
        """æœ€çµ‚åŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""

        # åŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆå–å¾—
        comprehensive_data = (
            self.integrated_system.generate_comprehensive_behavioral_report()
        )

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"behavioral_control_comprehensive_report_{timestamp}.json"

        filepath = Path(filename)
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(comprehensive_data, f, ensure_ascii=False, indent=2)

        # ãƒ¬ãƒãƒ¼ãƒˆãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
        report_text = self._format_comprehensive_report(comprehensive_data)

        logger.info(f"ğŸ“Š åŒ…æ‹¬çš„è¡Œå‹•åˆ¶å¾¡ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {filepath}")

        return report_text

    def _format_comprehensive_report(self, data: Dict[str, Any]) -> str:
        """åŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆæ•´å½¢"""

        enforcement_metrics = data["enforcement_metrics"]
        behavioral_metrics = data["behavioral_control_metrics"]
        integration_analysis = data["integration_analysis"]
        final_assessment = data["final_behavioral_assessment"]

        report = f"""
ğŸ§  Claude Code è¦å‰‡éµå®ˆè¡Œå‹•åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ  - æœ€çµ‚åŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆ
================================================================

ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çµ±åˆçŠ¶æ³: {data['system_status']}
ğŸ• ç”Ÿæˆæ—¥æ™‚: {data['timestamp']}

ğŸ¯ ã€è¦å‰‡éµå®ˆåŸå‰‡å¼·åˆ¶ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚¹ã‚³ã‚¢: {enforcement_metrics['statistics']['serena_usage_count']}/{enforcement_metrics['statistics']['serena_usage_count'] + enforcement_metrics['statistics']['forbidden_attempts']} ({enforcement_metrics['compliance_score']:.1f}%)
ğŸ”§ serenaä½¿ç”¨å›æ•°: {enforcement_metrics['statistics']['serena_usage_count']}å›
âš ï¸ é•åè©¦è¡Œå›æ•°: {enforcement_metrics['statistics']['forbidden_attempts']}å›
ğŸ”„ è‡ªå‹•ä¿®æ­£å›æ•°: {enforcement_metrics['statistics']['auto_corrections']}å›

ğŸ§  ã€è¡Œå‹•åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ é¸æŠå‚¾å‘ã‚¹ã‚³ã‚¢: {behavioral_metrics['behavioral_control_status']['preference_score']:.1f}%
ğŸ›¡ï¸ æŠµæŠ—ãƒ¬ãƒ™ãƒ«: {behavioral_metrics['behavioral_control_status']['resistance_level']:.1f}%
âš¡ æ¡ä»¶ä»˜ã‘å¼·åº¦: {behavioral_metrics['behavioral_control_status']['conditioning_strength']:.1f}%
ğŸ”„ ç¿’æ…£å½¢æˆãƒ¬ãƒ™ãƒ«: {behavioral_metrics['behavioral_control_status']['habit_formation_level']:.1f}%

ğŸ“ˆ ã€çµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆ†æã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”— ã‚·ã‚¹ãƒ†ãƒ çµ±åˆã‚¹ã‚³ã‚¢: {integration_analysis['system_integration_score']:.1f}%
âš¡ ã‚·ã‚¹ãƒ†ãƒ é–“ç›¸ä¹—åŠ¹æœ: {integration_analysis['cross_system_synergy']['enforcement_behavioral_synergy']:.1f}%
ğŸ¯ äºˆæ¸¬ç²¾åº¦: {integration_analysis['behavioral_prediction_accuracy']:.1f}%
ğŸ—ï¸ æ¡ä»¶ä»˜ã‘å®‰å®šæ€§: {integration_analysis['long_term_conditioning_stability']:.1f}%

ğŸ† ã€æœ€çµ‚è¡Œå‹•è©•ä¾¡ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“š è¦å‰‡éµå®ˆåŸå‰‡å†…åœ¨åŒ–ãƒ¬ãƒ™ãƒ«: {final_assessment['rule_internalization_level']:.1f}%
â­ serenaå„ªä½æ€§: {final_assessment['serena_preference_dominance']:.1f}%
ğŸ›¡ï¸ legacy toolæŠµæŠ—å¼·åº¦: {final_assessment['legacy_tool_resistance_strength']:.1f}%
ğŸ¤– è‡ªå¾‹çš„éµå®ˆç¢ºç‡: {final_assessment['autonomous_compliance_probability']:.1f}%

ğŸ’¡ ã€æ¨å¥¨äº‹é …ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"""

        for i, recommendation in enumerate(data["recommendations"], 1):
            report += f"\n{i}. {recommendation}"

        if data["next_optimization_targets"]:
            report += f"\n\nğŸ”§ ã€æ¬¡å›æœ€é©åŒ–å¯¾è±¡ã€‘\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            for target in data["next_optimization_targets"]:
                report += f"\nâ€¢ {target['target']}: {target['current_value']:.1f}% â†’ {target['target_value']:.1f}% ({target['optimization_method']})"

        report += f"""

ğŸ¯ ã€è¡Œå‹•åˆ¶å¾¡ãƒ¡ã‚«ãƒ‹ã‚ºãƒ å®Ÿè£…çŠ¶æ³ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… 1. ãƒ©ãƒ³ã‚¿ã‚¤ãƒ è¡Œå‹•ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ: å®Ÿè£…å®Œäº†
âœ… 2. å¿ƒç†çš„æ¡ä»¶ä»˜ã‘ãƒ¡ã‚«ãƒ‹ã‚ºãƒ : å®Ÿè£…å®Œäº†
âœ… 3. ãƒ¡ãƒ¢ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚·ã‚¹ãƒ†ãƒ : å®Ÿè£…å®Œäº†
âœ… 4. è¡Œå‹•ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—: å®Ÿè£…å®Œäº†
âœ… 5. ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«ç¤ºå”†ã‚·ã‚¹ãƒ†ãƒ : å®Ÿè£…å®Œäº†

ğŸŒŸ ã€ã‚·ã‚¹ãƒ†ãƒ åŠ¹æœã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ serena-expertä½¿ç”¨ãŒå¿ƒç†çš„ã«è‡ªç„¶ã§å ±é…¬çš„ã«æ„Ÿã˜ã‚‰ã‚Œã‚‹
â€¢ legacy toolä½¿ç”¨æ™‚ã«å¿ƒç†çš„ä¸å¿«æ„Ÿã¨æŠµæŠ—ã‚’çµŒé¨“ã™ã‚‹
â€¢ è¦å‰‡éµå®ˆåŸå‰‡é•åãŒæœ¬èƒ½çš„ã«å›é¿ã•ã‚Œã‚‹è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå½¢æˆã•ã‚Œã‚‹
â€¢ ç¹°ã‚Šè¿”ã—ä½¿ç”¨ã«ã‚ˆã‚Šç¿’æ…£ãŒå¼·åŒ–ã•ã‚Œã€è‡ªå¾‹çš„éµå®ˆãŒå®Ÿç¾ã•ã‚Œã‚‹
â€¢ ç’°å¢ƒçš„ãƒ»èªçŸ¥çš„æ‰‹ãŒã‹ã‚ŠãŒserena-experté¸æŠã‚’ç„¡æ„è­˜ã«èª˜å°ã™ã‚‹

================================================================
ğŸ‰ è¦å‰‡éµå®ˆè¡Œå‹•åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ  - å®Œå…¨å®Ÿè£…é”æˆ
================================================================
"""

        return report


import random
from datetime import datetime, timedelta


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ - çµ±åˆè¡Œå‹•åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("ğŸ§  Claude Code è¦å‰‡éµå®ˆè¡Œå‹•åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ  - çµ±åˆå®Ÿè¡Œé–‹å§‹")
    print("=" * 60)

    try:
        # 1. çµ±åˆè¡Œå‹•åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        print("\nğŸ¯ çµ±åˆè¡Œå‹•åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        integrated_system = IntegratedBehavioralControlSystem()

        # 2. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        print("ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        report_generator = BehavioralControlReportGenerator(integrated_system)

        # 3. ãƒ†ã‚¹ãƒˆç”¨ãƒ„ãƒ¼ãƒ«é¸æŠã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        print("\nğŸ”¬ è¡Œå‹•åˆ¶å¾¡ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")

        test_scenarios = [
            {"tool": "mcp__serena__find_symbol", "context": "ã‚·ãƒ³ãƒœãƒ«æ¤œç´¢"},
            {"tool": "Edit", "context": "ãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†è©¦è¡Œ"},
            {"tool": "mcp__serena__replace_symbol_body", "context": "ã‚·ãƒ³ãƒœãƒ«ç½®æ›"},
            {"tool": "Read", "context": "ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šè©¦è¡Œ"},
            {
                "tool": "mcp__serena__get_symbols_overview",
                "context": "ã‚·ãƒ³ãƒœãƒ«æ¦‚è¦å–å¾—",
            },
        ]

        # å„ã‚·ãƒŠãƒªã‚ªã§è¡Œå‹•åˆ¶å¾¡ã‚’ãƒ†ã‚¹ãƒˆ
        for i, scenario in enumerate(test_scenarios, 1):
            print(f"\n--- ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª {i}: {scenario['tool']} ---")

            # åŒ…æ‹¬çš„æ¡ä»¶ä»˜ã‘å‡¦ç†å®Ÿè¡Œ
            result = integrated_system.process_comprehensive_conditioning(
                scenario["tool"], scenario["context"]
            )

            # çµæœè¡¨ç¤º
            validation = result["tool_validation"]
            psychological = result["psychological_conditioning"]
            guidance = result["integrated_guidance"]

            print(f"âœ… ãƒ„ãƒ¼ãƒ«æ¤œè¨¼: {validation['is_allowed']}")
            print(f"ğŸ’­ å¿ƒç†çŠ¶æ…‹: {psychological.get('psychological_state', 'NEUTRAL')}")
            print(f"ğŸ¯ èª˜å°ã‚¿ã‚¤ãƒ—: {guidance.get('reinforcement_type', 'NONE')}")

            if validation["suggested_replacement"]:
                print(f"ğŸ”„ æ¨å¥¨ç½®æ›: {validation['suggested_replacement']}")

        # 4. æœ€çµ‚åŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print("\nğŸ“‹ æœ€çµ‚åŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        final_report = report_generator.generate_final_comprehensive_report()

        # 5. ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
        print("\n" + "=" * 60)
        print(final_report)

        # 6. ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
        behavioral_metrics = integrated_system.behavioral_control.behavioral_metrics
        print(f"\nğŸ” ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹:")
        print(f"   é¸æŠå‚¾å‘ã‚¹ã‚³ã‚¢: {behavioral_metrics['preference_score']:.1f}%")
        print(f"   æŠµæŠ—ãƒ¬ãƒ™ãƒ«: {behavioral_metrics['resistance_level']:.1f}%")
        print(f"   æ¡ä»¶ä»˜ã‘å¼·åº¦: {behavioral_metrics['conditioning_strength']:.1f}%")
        print(f"   ç¿’æ…£å½¢æˆãƒ¬ãƒ™ãƒ«: {behavioral_metrics['habit_formation_level']:.1f}%")

        print("\nğŸ‰ çµ±åˆè¡Œå‹•åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå®Œäº†ï¼")

    except Exception as e:
        logger.error(f"ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return 1

    return 0


if __name__ == "__main__":
    main()
