#!/usr/bin/env python3
"""
TDD Specification Generator - Issue #640 Phase 2
TDDä»•æ§˜ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 

ç›®çš„: Issueå†…å®¹ã‹ã‚‰TDDãƒ†ã‚¹ãƒˆä»•æ§˜ã®è‡ªå‹•ç”Ÿæˆ
- Issueåˆ†æãƒ»ãƒ†ã‚¹ãƒˆé …ç›®æŠ½å‡º
- Given-When-Thenãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆ
- ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ è‡ªå‹•ä½œæˆ
"""

import json
import sys
import subprocess
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import re

from kumihan_formatter.core.utilities.logger import get_logger

logger = get_logger(__name__)

@dataclass
class TestSpecification:
    """ãƒ†ã‚¹ãƒˆä»•æ§˜"""
    test_name: str
    description: str
    given: List[str]
    when: List[str]
    then: List[str]
    test_category: str  # "unit", "integration", "e2e"
    priority: str       # "high", "medium", "low"
    complexity: str     # "simple", "medium", "complex"

@dataclass
class SpecificationSet:
    """ä»•æ§˜ã‚»ãƒƒãƒˆ"""
    issue_number: str
    issue_title: str
    module_name: str
    class_name: str
    test_file_path: Path
    implementation_file_path: Path
    specifications: List[TestSpecification]
    setup_requirements: List[str]
    dependencies: List[str]

class TDDSpecGenerator:
    """TDDä»•æ§˜ç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.session_file = project_root / ".tdd_session.json"
        self.templates_dir = project_root / "scripts" / "tdd_templates"
        self.templates_dir.mkdir(exist_ok=True)
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
        self.test_patterns = {
            "parser": {
                "category": "unit",
                "base_class": "TestCase",
                "common_given": ["æœ‰åŠ¹ãªå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ", "ãƒ‘ãƒ¼ã‚µãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹"],
                "common_when": ["ãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æã™ã‚‹"],
                "common_then": ["é©åˆ‡ãªASTãƒãƒ¼ãƒ‰ãŒç”Ÿæˆã•ã‚Œã‚‹", "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„"]
            },
            "renderer": {
                "category": "unit", 
                "base_class": "TestCase",
                "common_given": ["æœ‰åŠ¹ãªASTãƒãƒ¼ãƒ‰", "ãƒ¬ãƒ³ãƒ€ãƒ©ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹"],
                "common_when": ["ãƒãƒ¼ãƒ‰ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã™ã‚‹"],
                "common_then": ["æœŸå¾…ã•ã‚Œã‚‹HTMLå‡ºåŠ›ãŒç”Ÿæˆã•ã‚Œã‚‹", "ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒæ­£ã—ã„"]
            },
            "validator": {
                "category": "unit",
                "base_class": "TestCase", 
                "common_given": ["æ¤œè¨¼å¯¾è±¡ãƒ‡ãƒ¼ã‚¿", "ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹"],
                "common_when": ["ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼ã™ã‚‹"],
                "common_then": ["æ¤œè¨¼çµæœãŒæ­£ã—ã„", "é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹"]
            },
            "command": {
                "category": "integration",
                "base_class": "TestCase",
                "common_given": ["ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°", "ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«"],
                "common_when": ["ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹"],
                "common_then": ["æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ãŒç”Ÿæˆã•ã‚Œã‚‹", "æ­£ã—ã„çµ‚äº†ã‚³ãƒ¼ãƒ‰ãŒè¿”ã•ã‚Œã‚‹"]
            }
        }
    
    def generate_specifications(self) -> SpecificationSet:
        """ä»•æ§˜ç”Ÿæˆãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        logger.info("ğŸ“‹ TDDä»•æ§˜ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆé–‹å§‹...")
        
        # ç¾åœ¨ã®TDDã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—
        session = self._load_current_session()
        if not session:
            logger.error("ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªTDDã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“")
            return None
        
        # Issueæƒ…å ±åˆ†æ
        issue_analysis = self._analyze_issue(session)
        
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»ã‚¯ãƒ©ã‚¹åæ±ºå®š
        naming_info = self._determine_naming(issue_analysis)
        
        # ãƒ†ã‚¹ãƒˆä»•æ§˜ç”Ÿæˆ
        specifications = self._generate_test_specifications(issue_analysis, naming_info)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æ±ºå®š
        file_paths = self._determine_file_paths(naming_info)
        
        # ä»•æ§˜ã‚»ãƒƒãƒˆä½œæˆ
        spec_set = SpecificationSet(
            issue_number=session["issue_number"],
            issue_title=session["issue_title"],
            module_name=naming_info["module_name"],
            class_name=naming_info["class_name"],
            test_file_path=file_paths["test_file"],
            implementation_file_path=file_paths["implementation_file"],
            specifications=specifications,
            setup_requirements=self._determine_setup_requirements(issue_analysis),
            dependencies=self._determine_dependencies(issue_analysis)
        )
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
        self._generate_template_files(spec_set)
        
        logger.info(f"âœ… TDDä»•æ§˜ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {len(specifications)}å€‹ã®ãƒ†ã‚¹ãƒˆä»•æ§˜")
        return spec_set
    
    def _load_current_session(self) -> Optional[Dict]:
        """ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿è¾¼ã¿"""
        if not self.session_file.exists():
            return None
            
        try:
            with open(self.session_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            return None
    
    def _analyze_issue(self, session: Dict) -> Dict:
        """Issueåˆ†æ"""
        title = session["issue_title"]
        description = session["issue_description"]
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        keywords = self._extract_keywords(title + " " + description)
        
        # æ©Ÿèƒ½åˆ†é¡
        feature_type = self._classify_feature_type(keywords, title)
        
        # è¤‡é›‘åº¦æ¨å®š
        complexity = self._estimate_complexity(description, keywords)
        
        # ãƒ†ã‚¹ãƒˆé …ç›®æŠ½å‡º
        test_scenarios = self._extract_test_scenarios(description)
        
        return {
            "title": title,
            "description": description,
            "keywords": keywords,
            "feature_type": feature_type,
            "complexity": complexity,
            "test_scenarios": test_scenarios,
            "acceptance_criteria": self._extract_acceptance_criteria(description)
        }
    
    def _extract_keywords(self, text: str) -> List[str]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º"""
        # æŠ€è¡“ç”¨èªãƒ‘ã‚¿ãƒ¼ãƒ³
        tech_patterns = [
            r'ãƒ‘ãƒ¼ã‚µãƒ¼?', r'parser', r'ãƒ¬ãƒ³ãƒ€ãƒ©ãƒ¼?', r'renderer',
            r'ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼?', r'validator', r'ã‚³ãƒãƒ³ãƒ‰', r'command',
            r'GUI', r'UI', r'API', r'HTML', r'CSS', r'JSON',
            r'ãƒ†ã‚¹ãƒˆ', r'test', r'ã‚­ãƒ£ãƒƒã‚·ãƒ¥', r'cache',
            r'ã‚¨ãƒ©ãƒ¼', r'error', r'ä¾‹å¤–', r'exception'
        ]
        
        keywords = []
        text_lower = text.lower()
        
        for pattern in tech_patterns:
            matches = re.findall(pattern, text_lower)
            keywords.extend(matches)
        
        # å‹•è©ãƒ‘ã‚¿ãƒ¼ãƒ³
        action_patterns = [
            r'è¿½åŠ ', r'add', r'ä¿®æ­£', r'fix', r'æ”¹å–„', r'improve',
            r'å®Ÿè£…', r'implement', r'å‰Šé™¤', r'remove', r'æ›´æ–°', r'update'
        ]
        
        for pattern in action_patterns:
            if re.search(pattern, text_lower):
                keywords.append(pattern)
        
        return list(set(keywords))
    
    def _classify_feature_type(self, keywords: List[str], title: str) -> str:
        """æ©Ÿèƒ½åˆ†é¡"""
        title_lower = title.lower()
        
        if any(k in keywords for k in ['parser', 'ãƒ‘ãƒ¼ã‚µãƒ¼']):
            return "parser"
        elif any(k in keywords for k in ['renderer', 'ãƒ¬ãƒ³ãƒ€ãƒ©ãƒ¼']):
            return "renderer"
        elif any(k in keywords for k in ['validator', 'ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼']):
            return "validator"
        elif any(k in keywords for k in ['command', 'ã‚³ãƒãƒ³ãƒ‰']):
            return "command"
        elif any(k in keywords for k in ['gui', 'ui']):
            return "gui"
        elif any(k in keywords for k in ['cache', 'ã‚­ãƒ£ãƒƒã‚·ãƒ¥']):
            return "cache"
        else:
            return "utility"
    
    def _estimate_complexity(self, description: str, keywords: List[str]) -> str:
        """è¤‡é›‘åº¦æ¨å®š"""
        complexity_indicators = {
            "simple": ["å˜ç´”", "simple", "åŸºæœ¬", "basic"],
            "medium": ["æ‹¡å¼µ", "extend", "æ”¹å–„", "improve"],
            "complex": ["å®Œå…¨", "complete", "æ ¹æœ¬", "fundamental", "å†æ§‹ç¯‰", "rebuild"]
        }
        
        description_lower = description.lower()
        
        for complexity, indicators in complexity_indicators.items():
            if any(indicator in description_lower for indicator in indicators):
                return complexity
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ–‡ç« é•·ã§åˆ¤å®š
        if len(description) > 500:
            return "complex"
        elif len(description) > 200:
            return "medium"
        else:
            return "simple"
    
    def _extract_test_scenarios(self, description: str) -> List[str]:
        """ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªæŠ½å‡º"""
        scenarios = []
        
        # ç®‡æ¡æ›¸ããƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
        bullet_patterns = [
            r'^\s*[-\*\+]\s+(.+)$',
            r'^\s*\d+\.\s+(.+)$',
            r'^\s*\d+\)\s+(.+)$'
        ]
        
        lines = description.split('\n')
        for line in lines:
            for pattern in bullet_patterns:
                match = re.match(pattern, line)
                if match:
                    scenario = match.group(1).strip()
                    if len(scenario) > 10:  # æ„å‘³ã®ã‚ã‚‹é•·ã•ã®ã‚‚ã®ã®ã¿
                        scenarios.append(scenario)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ã‚·ãƒŠãƒªã‚ªç”Ÿæˆ
        if not scenarios:
            scenarios = [
                "æ­£å¸¸ãªã‚±ãƒ¼ã‚¹ã§æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œã‚’ç¢ºèªã™ã‚‹",
                "ç•°å¸¸ãªã‚±ãƒ¼ã‚¹ã§ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹",
                "å¢ƒç•Œå€¤ã§ã®å‹•ä½œã‚’ç¢ºèªã™ã‚‹"
            ]
        
        return scenarios
    
    def _extract_acceptance_criteria(self, description: str) -> List[str]:
        """å—ã‘å…¥ã‚Œæ¡ä»¶æŠ½å‡º"""
        criteria = []
        
        # å—ã‘å…¥ã‚Œæ¡ä»¶ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¤œç´¢
        ac_section_patterns = [
            r'å—ã‘å…¥ã‚Œæ¡ä»¶[ï¼š:]\s*(.+?)(?=\n\n|\n#|\Z)',
            r'Acceptance Criteria[ï¼š:]\s*(.+?)(?=\n\n|\n#|\Z)',
            r'æ¡ä»¶[ï¼š:]\s*(.+?)(?=\n\n|\n#|\Z)'
        ]
        
        for pattern in ac_section_patterns:
            match = re.search(pattern, description, re.DOTALL | re.IGNORECASE)
            if match:
                section_text = match.group(1)
                # å„è¡Œã‚’æ¡ä»¶ã¨ã—ã¦è¿½åŠ 
                for line in section_text.split('\n'):
                    line = line.strip()
                    if line and not line.startswith('#'):
                        criteria.append(line)
                break
        
        return criteria
    
    def _determine_naming(self, analysis: Dict) -> Dict:
        """å‘½åæ±ºå®š"""
        feature_type = analysis["feature_type"]
        title = analysis["title"]
        
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åç”Ÿæˆ
        title_words = re.findall(r'\w+', title.lower())
        meaningful_words = [w for w in title_words if len(w) > 2 and w not in ['the', 'and', 'for', 'with']]
        
        if meaningful_words:
            module_name = "_".join(meaningful_words[:3])
        else:
            module_name = f"{feature_type}_module"
        
        # ã‚¯ãƒ©ã‚¹åç”Ÿæˆ
        class_words = [w.capitalize() for w in meaningful_words[:2]]
        if class_words:
            if feature_type == "parser":
                class_name = "".join(class_words) + "Parser"
            elif feature_type == "renderer":
                class_name = "".join(class_words) + "Renderer"
            elif feature_type == "validator":
                class_name = "".join(class_words) + "Validator"
            elif feature_type == "command":
                class_name = "".join(class_words) + "Command"
            else:
                class_name = "".join(class_words) + "Handler"
        else:
            class_name = f"{feature_type.capitalize()}Handler"
        
        return {
            "module_name": module_name,
            "class_name": class_name,
            "feature_type": feature_type
        }
    
    def _generate_test_specifications(self, analysis: Dict, naming: Dict) -> List[TestSpecification]:
        """ãƒ†ã‚¹ãƒˆä»•æ§˜ç”Ÿæˆ"""
        specifications = []
        feature_type = naming["feature_type"]
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå–å¾—
        pattern = self.test_patterns.get(feature_type, self.test_patterns["parser"])
        
        # åŸºæœ¬ä»•æ§˜ç”Ÿæˆ
        for i, scenario in enumerate(analysis["test_scenarios"], 1):
            spec = TestSpecification(
                test_name=f"test_{naming['module_name']}_scenario_{i}",
                description=scenario,
                given=pattern["common_given"].copy(),
                when=pattern["common_when"].copy(),
                then=pattern["common_then"].copy(),
                test_category=pattern["category"],
                priority="high" if i <= 2 else "medium",
                complexity=analysis["complexity"]
            )
            
            # ã‚·ãƒŠãƒªã‚ªå›ºæœ‰ã®èª¿æ•´
            spec.when.append(f"{scenario}ã‚’å®Ÿè¡Œã™ã‚‹")
            spec.then.append("æœŸå¾…ã•ã‚Œã‚‹çµæœãŒå¾—ã‚‰ã‚Œã‚‹")
            
            specifications.append(spec)
        
        # ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ä»•æ§˜è¿½åŠ 
        error_spec = TestSpecification(
            test_name=f"test_{naming['module_name']}_error_handling",
            description="ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã®é©åˆ‡ãªå‡¦ç†",
            given=["ç„¡åŠ¹ãªå…¥åŠ›ãƒ‡ãƒ¼ã‚¿", f"{naming['class_name']}ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹"],
            when=["ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã§å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹"],
            then=["é©åˆ‡ãªä¾‹å¤–ãŒç™ºç”Ÿã™ã‚‹", "ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹"],
            test_category=pattern["category"],
            priority="high",
            complexity="simple"
        )
        specifications.append(error_spec)
        
        # å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆä»•æ§˜è¿½åŠ 
        boundary_spec = TestSpecification(
            test_name=f"test_{naming['module_name']}_boundary_values",
            description="å¢ƒç•Œå€¤ã§ã®å‹•ä½œç¢ºèª",
            given=["å¢ƒç•Œå€¤ãƒ‡ãƒ¼ã‚¿", f"{naming['class_name']}ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹"],
            when=["å¢ƒç•Œå€¤ã§å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹"],
            then=["å¢ƒç•Œå€¤ãŒæ­£ã—ãå‡¦ç†ã•ã‚Œã‚‹", "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„"],
            test_category=pattern["category"],
            priority="medium",
            complexity="medium"
        )
        specifications.append(boundary_spec)
        
        return specifications
    
    def _determine_file_paths(self, naming: Dict) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æ±ºå®š"""
        module_name = naming["module_name"]
        feature_type = naming["feature_type"]
        
        # å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        if feature_type in ["parser", "renderer"]:
            impl_dir = self.project_root / "kumihan_formatter" / "core" / f"{feature_type}s"
        elif feature_type == "command":
            impl_dir = self.project_root / "kumihan_formatter" / "commands"
        else:
            impl_dir = self.project_root / "kumihan_formatter" / "core" / "utilities"
        
        impl_file = impl_dir / f"{module_name}.py"
        
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        test_dir = self.project_root / "tests" / "unit"
        if feature_type in ["parser", "renderer"]:
            test_dir = test_dir / f"{feature_type}s"
        
        test_file = test_dir / f"test_{module_name}.py"
        
        return {
            "implementation_file": impl_file,
            "test_file": test_file
        }
    
    def _determine_setup_requirements(self, analysis: Dict) -> List[str]:
        """ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—è¦ä»¶æ±ºå®š"""
        requirements = ["pytest", "unittest.mock"]
        
        if "gui" in analysis["keywords"]:
            requirements.append("pytest-qt")
        
        if "database" in analysis["keywords"]:
            requirements.append("pytest-database")
        
        if analysis["complexity"] == "complex":
            requirements.extend(["pytest-cov", "pytest-benchmark"])
        
        return requirements
    
    def _determine_dependencies(self, analysis: Dict) -> List[str]:
        """ä¾å­˜é–¢ä¿‚æ±ºå®š"""
        dependencies = []
        
        if "parser" in analysis["feature_type"]:
            dependencies.append("kumihan_formatter.core.ast_nodes")
        
        if "renderer" in analysis["feature_type"]:
            dependencies.append("kumihan_formatter.core.rendering")
        
        if "command" in analysis["feature_type"]:
            dependencies.append("kumihan_formatter.core.file_operations")
        
        return dependencies
    
    def _generate_template_files(self, spec_set: SpecificationSet):
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"""
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
        self._generate_test_file(spec_set)
        
        # å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ
        self._generate_implementation_skeleton(spec_set)
        
        # READMEç”Ÿæˆ
        self._generate_tdd_readme(spec_set)
    
    def _generate_test_file(self, spec_set: SpecificationSet):
        """ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"""
        test_content = f'''#!/usr/bin/env python3
"""
Test for {spec_set.class_name} - Issue #{spec_set.issue_number}
Generated by TDD Spec Generator

{spec_set.issue_title}
"""

import unittest
from unittest.mock import Mock, patch, MagicMock
import pytest
from pathlib import Path
import tempfile
import json

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
{chr(10).join(f"# from {dep}" for dep in spec_set.dependencies)}

class Test{spec_set.class_name}(unittest.TestCase):
    """
    {spec_set.class_name}ã®ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹
    
    TDDä»•æ§˜ã«åŸºã¥ãåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
    Issue #{spec_set.issue_number}: {spec_set.issue_title}
    """
    
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        # TODO: {spec_set.class_name}ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆ
        # self.{spec_set.module_name} = {spec_set.class_name}()
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
        self.test_data = {{
            "valid_input": "ãƒ†ã‚¹ãƒˆç”¨ã®æœ‰åŠ¹ãªå…¥åŠ›",
            "invalid_input": "",
            "boundary_input": "å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿"
        }}
        
        # ãƒ¢ãƒƒã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæº–å‚™
        self.mock_logger = Mock()
    
    def tearDown(self):
        """ãƒ†ã‚¹ãƒˆå¾Œã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ãªã©å¿…è¦ã«å¿œã˜ã¦å®Ÿè£…
        pass

'''

        # å„ä»•æ§˜ã®ãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ç”Ÿæˆ
        for spec in spec_set.specifications:
            test_content += self._generate_test_method(spec)
        
        test_content += '''

if __name__ == "__main__":
    unittest.main()
'''
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        spec_set.test_file_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿
        with open(spec_set.test_file_path, "w", encoding="utf-8") as f:
            f.write(test_content)
        
        logger.info(f"ğŸ“ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ: {spec_set.test_file_path}")
    
    def _generate_test_method(self, spec: TestSpecification) -> str:
        """ãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ç”Ÿæˆ"""
        method_content = f'''
    def {spec.test_name}(self):
        """
        {spec.description}
        
        Category: {spec.test_category}
        Priority: {spec.priority}
        Complexity: {spec.complexity}
        """
        # Given: {", ".join(spec.given)}
        # TODO: ãƒ†ã‚¹ãƒˆå‰ææ¡ä»¶ã®è¨­å®š
        
        # When: {", ".join(spec.when)}
        # TODO: ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®å®Ÿè¡Œ
        
        # Then: {", ".join(spec.then)}
        # TODO: çµæœã®æ¤œè¨¼
        
        # å®Ÿè£…ä¾‹:
        # result = self.{spec.test_name.replace("test_", "")}
        # self.assertIsNotNone(result)
        # self.assertEqual(expected_value, result)
        
        self.fail("TODO: ãƒ†ã‚¹ãƒˆå®Ÿè£…ãŒå¿…è¦ã§ã™ - TDD Red Phase")
'''
        return method_content
    
    def _generate_implementation_skeleton(self, spec_set: SpecificationSet):
        """å®Ÿè£…ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ"""
        impl_content = f'''#!/usr/bin/env python3
"""
{spec_set.class_name} - Issue #{spec_set.issue_number}
Generated by TDD Spec Generator

{spec_set.issue_title}

TODO: ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯TDD Green Phaseã§å®Ÿè£…ã—ã¦ãã ã•ã„
"""

from typing import Optional, List, Dict, Any
from pathlib import Path
from dataclasses import dataclass

from kumihan_formatter.core.utilities.logger import get_logger

logger = get_logger(__name__)

class {spec_set.class_name}:
    """
    {spec_set.issue_title}
    
    Issue #{spec_set.issue_number}ã®å®Ÿè£…
    TDDä»•æ§˜ã«åŸºã¥ãå®Ÿè£…
    """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        # TODO: å¿…è¦ãªåˆæœŸåŒ–å‡¦ç†ã‚’å®Ÿè£…
        pass
    
    # TODO: ãƒ†ã‚¹ãƒˆä»•æ§˜ã«åŸºã¥ã„ã¦ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè£…
    # å„ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã«å¯¾å¿œã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„
    
    def process(self, input_data: Any) -> Any:
        """
        ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            input_data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            å‡¦ç†çµæœ
            
        Raises:
            ValueError: ç„¡åŠ¹ãªå…¥åŠ›ã®å ´åˆ
        """
        # TODO: TDD Green Phaseã§æœ€å°å®Ÿè£…
        raise NotImplementedError("TDD Green Phaseã§å®Ÿè£…ã—ã¦ãã ã•ã„")
'''
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        spec_set.implementation_file_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã®ã¿ä½œæˆ
        if not spec_set.implementation_file_path.exists():
            with open(spec_set.implementation_file_path, "w", encoding="utf-8") as f:
                f.write(impl_content)
            
            logger.info(f"ğŸ“„ å®Ÿè£…ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ: {spec_set.implementation_file_path}")
        else:
            logger.info(f"âš ï¸  å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«æ—¢å­˜ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {spec_set.implementation_file_path}")
    
    def _generate_tdd_readme(self, spec_set: SpecificationSet):
        """TDD READMEç”Ÿæˆ"""
        readme_content = f'''# TDDä»•æ§˜æ›¸ - Issue #{spec_set.issue_number}

## æ¦‚è¦
**Issue**: #{spec_set.issue_number} - {spec_set.issue_title}
**ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**: {spec_set.module_name}
**ã‚¯ãƒ©ã‚¹**: {spec_set.class_name}

## ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ
- **ãƒ†ã‚¹ãƒˆ**: `{spec_set.test_file_path.relative_to(self.project_root)}`
- **å®Ÿè£…**: `{spec_set.implementation_file_path.relative_to(self.project_root)}`

## TDDå®Ÿè¡Œæ‰‹é †

### 1. Red Phase
```bash
make tdd-red
```
- ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦å¤±æ•—ã‚’ç¢ºèª
- å…¨ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã™ã‚‹ã“ã¨ã‚’ç¢ºèª

### 2. Green Phase  
```bash
make tdd-green
```
- æœ€å°é™ã®å®Ÿè£…ã§ãƒ†ã‚¹ãƒˆã‚’é€šã™
- `{spec_set.implementation_file_path.name}`ã‚’ç·¨é›†

### 3. Refactor Phase
```bash
make tdd-refactor
```
- ã‚³ãƒ¼ãƒ‰å“è³ªå‘ä¸Š
- ãƒ†ã‚¹ãƒˆãŒé€šã‚‹ã“ã¨ã‚’ç¢ºèª

## ãƒ†ã‚¹ãƒˆä»•æ§˜

### ãƒ†ã‚¹ãƒˆä¸€è¦§
'''

        for i, spec in enumerate(spec_set.specifications, 1):
            readme_content += f'''
#### {i}. {spec.test_name}
- **èª¬æ˜**: {spec.description}
- **ã‚«ãƒ†ã‚´ãƒª**: {spec.test_category}
- **å„ªå…ˆåº¦**: {spec.priority}
- **è¤‡é›‘åº¦**: {spec.complexity}

**Given (å‰ææ¡ä»¶)**:
{chr(10).join(f"- {given}" for given in spec.given)}

**When (å®Ÿè¡Œæ¡ä»¶)**:
{chr(10).join(f"- {when}" for when in spec.when)}

**Then (æœŸå¾…çµæœ)**:
{chr(10).join(f"- {then}" for then in spec.then)}
'''

        readme_content += f'''

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—è¦ä»¶
{chr(10).join(f"- {req}" for req in spec_set.setup_requirements)}

## ä¾å­˜é–¢ä¿‚
{chr(10).join(f"- {dep}" for dep in spec_set.dependencies)}

## å“è³ªåŸºæº–
- ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸: 95%ä»¥ä¸Š
- è¤‡é›‘åº¦: 10ä»¥ä¸‹
- å…¨ãƒ†ã‚¹ãƒˆãƒ‘ã‚¹

---
*Generated by TDD Spec Generator - Issue #640 Phase 2*
*Generated at: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
'''
        
        readme_path = self.templates_dir / f"TDD_SPEC_Issue_{spec_set.issue_number}.md"
        with open(readme_path, "w", encoding="utf-8") as f:
            f.write(readme_content)
        
        logger.info(f"ğŸ“š TDDä»•æ§˜æ›¸ç”Ÿæˆ: {readme_path}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    project_root = Path(__file__).parent.parent
    
    generator = TDDSpecGenerator(project_root)
    
    logger.info("ğŸš€ TDDä»•æ§˜ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆé–‹å§‹ - Issue #640 Phase 2")
    
    # ä»•æ§˜ç”Ÿæˆ
    spec_set = generator.generate_specifications()
    
    if spec_set:
        print(f"âœ… TDDä»•æ§˜ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆå®Œäº†")
        print(f"ğŸ“‹ ãƒ†ã‚¹ãƒˆä»•æ§˜æ•°: {len(spec_set.specifications)}")
        print(f"ğŸ“ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {spec_set.test_file_path}")
        print(f"ğŸ“„ å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«: {spec_set.implementation_file_path}")
        print(f"ğŸ“š ä»•æ§˜æ›¸: scripts/tdd_templates/TDD_SPEC_Issue_{spec_set.issue_number}.md")
        print()
        print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. `make tdd-red` ã§Red Phaseã‚’é–‹å§‹")
        print("2. ãƒ†ã‚¹ãƒˆã®å¤±æ•—ã‚’ç¢ºèª")
        print("3. `make tdd-green` ã§æœ€å°å®Ÿè£…")
    else:
        logger.error("âŒ TDDä»•æ§˜ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆå¤±æ•—")
        sys.exit(1)

if __name__ == "__main__":
    main()