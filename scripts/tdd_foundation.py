#!/usr/bin/env python3
"""
TDD Foundation System - Issue #640 Phase 1
åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ç›®çš„: Test-Driven Developmentç’°å¢ƒã®å®Œå…¨æ§‹ç¯‰
- ãƒ†ã‚¹ãƒˆè‡ªå‹•åŒ–ã‚¤ãƒ³ãƒ•ãƒ©
- å“è³ªã‚²ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ 
- TDDæ”¯æ´ãƒ„ãƒ¼ãƒ«
"""

import os
import sys
import subprocess
import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime

from kumihan_formatter.core.utilities.logger import get_logger

logger = get_logger(__name__)


@dataclass
class TDDFoundationConfig:
    """TDDåŸºç›¤è¨­å®š"""

    project_root: Path
    test_coverage_threshold: float = 90.0
    critical_tier_threshold: float = 95.0
    important_tier_threshold: float = 85.0
    supportive_tier_threshold: float = 70.0
    auto_test_on_save: bool = True
    quality_gate_strict: bool = True


@dataclass
class TestResult:
    """ãƒ†ã‚¹ãƒˆçµæœãƒ‡ãƒ¼ã‚¿"""

    total_tests: int
    passed: int
    failed: int
    skipped: int
    coverage_percentage: float
    duration: float
    timestamp: datetime


class TDDFoundation:
    """TDDåŸºç›¤ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config: TDDFoundationConfig):
        self.config = config
        self.project_root = config.project_root

    def initialize_tdd_infrastructure(self) -> bool:
        """TDDåŸºç›¤ã‚¤ãƒ³ãƒ•ãƒ©ã®åˆæœŸåŒ–"""
        logger.info("TDDåŸºç›¤ã‚¤ãƒ³ãƒ•ãƒ©ã‚’åˆæœŸåŒ–ä¸­...")

        steps = [
            self._setup_pytest_configuration,
            self._setup_coverage_configuration,
            self._setup_pre_commit_hooks,
            self._setup_quality_gates,
            self._setup_tdd_scripts,
        ]

        for step in steps:
            try:
                step()
                logger.info(f"âœ… {step.__name__} å®Œäº†")
            except Exception as e:
                logger.error(f"âŒ {step.__name__} å¤±æ•—: {e}")
                return False

        logger.info("ğŸ¯ TDDåŸºç›¤ã‚¤ãƒ³ãƒ•ãƒ©åˆæœŸåŒ–å®Œäº†")
        return True

    def _setup_pytest_configuration(self):
        """pytestè¨­å®šã®æœ€é©åŒ–"""
        pytest_config = {
            "testpaths": ["tests"],
            "python_files": ["test_*.py", "*_test.py"],
            "python_classes": ["Test*"],
            "python_functions": ["test_*"],
            "addopts": [
                "--verbose",
                "--tb=short",
                "--cov=kumihan_formatter",
                "--cov-report=term-missing",
                "--cov-report=html:htmlcov",
                "--cov-report=json:coverage.json",
                "--cov-fail-under=70",
                "--maxfail=5",
                "--timeout=300",
            ],
            "markers": [
                "slow: marks tests as slow",
                "integration: marks tests as integration tests",
                "unit: marks tests as unit tests",
                "critical: marks tests as critical tier",
                "important: marks tests as important tier",
                "supportive: marks tests as supportive tier",
            ],
            "filterwarnings": [
                "ignore::DeprecationWarning",
                "ignore::PendingDeprecationWarning",
            ],
        }

        # pyproject.tomlã«è¿½è¨˜
        pyproject_path = self.project_root / "pyproject.toml"
        if pyproject_path.exists():
            # æ—¢å­˜è¨­å®šã‚’æ›´æ–°
            logger.info("pytestè¨­å®šã‚’æ›´æ–°ä¸­...")

    def _setup_coverage_configuration(self):
        """ã‚«ãƒãƒ¬ãƒƒã‚¸è¨­å®šã®æ§‹ç¯‰"""
        coverage_config = {
            "run": {
                "source": ["kumihan_formatter"],
                "omit": [
                    "*/tests/*",
                    "*/test_*",
                    "*/__init__.py",
                    "*/gui/*",  # GUIç³»ã¯åˆ¥é€”E2Eãƒ†ã‚¹ãƒˆ
                    "*/playground/*",  # ãƒ—ãƒ¬ã‚¤ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã¯é–‹ç™ºç”¨
                ],
                "branch": True,
            },
            "report": {
                "exclude_lines": [
                    "pragma: no cover",
                    "def __repr__",
                    "if self.debug:",
                    "if settings.DEBUG",
                    "raise AssertionError",
                    "raise NotImplementedError",
                    "if 0:",
                    "if __name__ == .__main__.:",
                ],
                "show_missing": True,
            },
            "html": {
                "directory": "htmlcov",
                "title": "Kumihan-Formatter Coverage Report",
            },
        }

        # .coveragercãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        coveragerc_path = self.project_root / ".coveragerc"
        logger.info(f"ã‚«ãƒãƒ¬ãƒƒã‚¸è¨­å®šã‚’ä½œæˆ: {coveragerc_path}")

    def _setup_pre_commit_hooks(self):
        """Pre-commitãƒ•ãƒƒã‚¯ã®è¨­å®š"""
        hooks_config = {
            "repos": [
                {
                    "repo": "local",
                    "hooks": [
                        {
                            "id": "tdd-test-runner",
                            "name": "TDD Test Runner",
                            "entry": "python scripts/tdd_test_runner.py",
                            "language": "system",
                            "files": r"^(kumihan_formatter/.*\.py|tests/.*\.py)$",
                            "pass_filenames": False,
                        },
                        {
                            "id": "quality-gate-check",
                            "name": "Quality Gate Check",
                            "entry": "python scripts/quality_gate_checker.py",
                            "language": "system",
                            "files": r"^kumihan_formatter/.*\.py$",
                            "pass_filenames": False,
                        },
                    ],
                }
            ]
        }

        pre_commit_path = self.project_root / ".pre-commit-config.yaml"
        logger.info(f"Pre-commitãƒ•ãƒƒã‚¯è¨­å®š: {pre_commit_path}")

    def _setup_quality_gates(self):
        """å“è³ªã‚²ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰"""
        # å“è³ªã‚²ãƒ¼ãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
        quality_gates = {
            "critical_tier": {
                "modules": [
                    "kumihan_formatter.core.parser",
                    "kumihan_formatter.core.renderer",
                    "kumihan_formatter.commands",
                ],
                "min_coverage": self.config.critical_tier_threshold,
                "required_tests": ["unit", "integration"],
                "max_complexity": 10,
            },
            "important_tier": {
                "modules": [
                    "kumihan_formatter.core.validation",
                    "kumihan_formatter.core.file_operations",
                ],
                "min_coverage": self.config.important_tier_threshold,
                "required_tests": ["unit"],
                "max_complexity": 15,
            },
            "supportive_tier": {
                "modules": [
                    "kumihan_formatter.core.utilities",
                    "kumihan_formatter.core.caching",
                ],
                "min_coverage": self.config.supportive_tier_threshold,
                "required_tests": ["integration"],
                "max_complexity": 20,
            },
        }

        gates_path = self.project_root / "scripts" / "quality_gates.json"
        gates_path.parent.mkdir(exist_ok=True)

        with open(gates_path, "w", encoding="utf-8") as f:
            json.dump(quality_gates, f, indent=2, ensure_ascii=False)

        logger.info(f"å“è³ªã‚²ãƒ¼ãƒˆè¨­å®šã‚’ä½œæˆ: {gates_path}")

    def _setup_tdd_scripts(self):
        """TDDæ”¯æ´ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½œæˆ"""
        scripts_dir = self.project_root / "scripts"
        scripts_dir.mkdir(exist_ok=True)

        # TDDãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼
        test_runner_script = '''#!/usr/bin/env python3
"""TDD Test Runner - è‡ªå‹•ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ """

import subprocess
import sys
from pathlib import Path

def run_tdd_tests():
    """TDDãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    cmd = [
        sys.executable, "-m", "pytest",
        "--cov=kumihan_formatter",
        "--cov-report=term-missing",
        "--cov-fail-under=70",
        "--maxfail=3",
        "-x",  # æœ€åˆã®å¤±æ•—ã§åœæ­¢
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    if result.returncode != 0:
        print("âŒ ãƒ†ã‚¹ãƒˆå¤±æ•— - TDDè¦æ±‚é•å")
        print(result.stdout)
        print(result.stderr)
        sys.exit(1)
    else:
        print("âœ… å…¨ãƒ†ã‚¹ãƒˆé€šé - TDDè¦æ±‚æº€è¶³")
        
if __name__ == "__main__":
    run_tdd_tests()
'''

        with open(scripts_dir / "tdd_test_runner.py", "w") as f:
            f.write(test_runner_script)

        logger.info("TDDæ”¯æ´ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆå®Œäº†")

    def run_foundation_tests(self) -> TestResult:
        """åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        logger.info("TDDåŸºç›¤ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")

        start_time = datetime.now()

        # pytestå®Ÿè¡Œ
        cmd = [
            sys.executable,
            "-m",
            "pytest",
            "--cov=kumihan_formatter",
            "--cov-report=json:coverage.json",
            "--json-report",
            "--json-report-file=test_report.json",
            "-v",
        ]

        result = subprocess.run(
            cmd, capture_output=True, text=True, cwd=self.project_root
        )
        duration = (datetime.now() - start_time).total_seconds()

        # çµæœè§£æ
        try:
            with open(self.project_root / "coverage.json") as f:
                coverage_data = json.load(f)
                coverage_percentage = coverage_data["totals"]["percent_covered"]
        except:
            coverage_percentage = 0.0

        try:
            with open(self.project_root / "test_report.json") as f:
                test_data = json.load(f)
                summary = test_data["summary"]
                total_tests = summary["total"]
                passed = summary.get("passed", 0)
                failed = summary.get("failed", 0)
                skipped = summary.get("skipped", 0)
        except:
            total_tests = passed = failed = skipped = 0

        test_result = TestResult(
            total_tests=total_tests,
            passed=passed,
            failed=failed,
            skipped=skipped,
            coverage_percentage=coverage_percentage,
            duration=duration,
            timestamp=datetime.now(),
        )

        logger.info(
            f"ãƒ†ã‚¹ãƒˆçµæœ: {passed}/{total_tests} é€šé, ã‚«ãƒãƒ¬ãƒƒã‚¸: {coverage_percentage:.1f}%"
        )
        return test_result


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    project_root = Path(__file__).parent.parent

    config = TDDFoundationConfig(
        project_root=project_root,
        test_coverage_threshold=90.0,
        critical_tier_threshold=95.0,
        important_tier_threshold=85.0,
        supportive_tier_threshold=70.0,
        auto_test_on_save=True,
        quality_gate_strict=True,
    )

    tdd_foundation = TDDFoundation(config)

    logger.info("ğŸš€ TDDåŸºç›¤ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰é–‹å§‹ - Issue #640 Phase 1")

    # åŸºç›¤ã‚¤ãƒ³ãƒ•ãƒ©åˆæœŸåŒ–
    if not tdd_foundation.initialize_tdd_infrastructure():
        logger.error("âŒ TDDåŸºç›¤ã‚¤ãƒ³ãƒ•ãƒ©åˆæœŸåŒ–å¤±æ•—")
        sys.exit(1)

    # åŸºç›¤ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_result = tdd_foundation.run_foundation_tests()

    if test_result.failed > 0:
        logger.error(f"âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {test_result.failed}ä»¶")
        sys.exit(1)

    logger.info("ğŸ¯ TDDåŸºç›¤ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰å®Œäº†")
    logger.info(f"âœ… ç·ãƒ†ã‚¹ãƒˆæ•°: {test_result.total_tests}")
    if test_result.total_tests > 0:
        logger.info(f"âœ… é€šéç‡: {test_result.passed/test_result.total_tests*100:.1f}%")
    else:
        logger.info("âœ… é€šéç‡: 0.0% (ãƒ†ã‚¹ãƒˆãŒå®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ)")
    logger.info(f"âœ… ã‚«ãƒãƒ¬ãƒƒã‚¸: {test_result.coverage_percentage:.1f}%")


if __name__ == "__main__":
    main()
