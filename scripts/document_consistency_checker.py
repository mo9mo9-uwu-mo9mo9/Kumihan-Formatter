#!/usr/bin/env python3
"""
Kumihan-Formatter Document Consistency Checker
Issue #1240: Development Process Normalization

ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé–“ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€ä¸ä¸€è‡´ã‚’æ¤œå‡ºãƒ»å ±å‘Šã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import sys
import re
import json
import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass
from enum import Enum

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®å–å¾—
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

try:
    from kumihan_formatter.core.utilities.logger import get_logger

    logger = get_logger(__name__)
except ImportError:
    import logging

    logger = logging.getLogger(__name__)
    logging.basicConfig(level=logging.INFO)


class InconsistencyType(Enum):
    """ä¸æ•´åˆã®ã‚¿ã‚¤ãƒ—"""

    VERSION_MISMATCH = "version_mismatch"
    BROKEN_LINK = "broken_link"
    OUTDATED_CONTENT = "outdated_content"
    MISSING_DOCUMENTATION = "missing_documentation"
    STRUCTURAL_INCONSISTENCY = "structural_inconsistency"
    CODE_DOC_MISMATCH = "code_doc_mismatch"


class SeverityLevel(Enum):
    """é‡è¦åº¦ãƒ¬ãƒ™ãƒ«"""

    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"


@dataclass
class DocumentInconsistency:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸æ•´åˆé …ç›®"""

    id: str
    title: str
    description: str
    inconsistency_type: InconsistencyType
    severity: SeverityLevel
    source_file: str
    target_file: Optional[str]
    line_number: Optional[int]
    detected_date: datetime.datetime
    suggested_fix: Optional[str] = None


class DocumentConsistencyChecker:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚«ãƒ¼"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.project_root = PROJECT_ROOT
        self.doc_files = self._get_documentation_files()
        self.code_files = self._get_code_files()
        self.inconsistencies: List[DocumentInconsistency] = []

    def _get_documentation_files(self) -> List[Path]:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—"""
        doc_patterns = ["*.md", "*.rst", "*.txt", "*.yml", "*.yaml"]
        doc_files = []

        # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
        for pattern in doc_patterns:
            doc_files.extend(self.project_root.glob(pattern))

        # .githubãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        github_dir = self.project_root / ".github"
        if github_dir.exists():
            for pattern in doc_patterns:
                doc_files.extend(github_dir.rglob(pattern))

        # docsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚ã‚Œã°
        docs_dir = self.project_root / "docs"
        if docs_dir.exists():
            for pattern in doc_patterns:
                doc_files.extend(docs_dir.rglob(pattern))

        return sorted(doc_files)

    def _get_code_files(self) -> List[Path]:
        """ã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—"""
        code_files = []

        # Pythonãƒ•ã‚¡ã‚¤ãƒ«
        kumihan_dir = self.project_root / "kumihan_formatter"
        if kumihan_dir.exists():
            code_files.extend(kumihan_dir.rglob("*.py"))

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
        config_files = [
            "pyproject.toml",
            "setup.py",
            "setup.cfg",
            "Makefile",
            "requirements.txt",
            "package.json",
        ]
        for config_file in config_files:
            config_path = self.project_root / config_file
            if config_path.exists():
                code_files.append(config_path)

        return sorted(code_files)

    def check_version_consistency(self) -> List[DocumentInconsistency]:
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
        inconsistencies = []
        version_sources = {}

        # pyproject.tomlã‹ã‚‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³å–å¾—
        pyproject_path = self.project_root / "pyproject.toml"
        if pyproject_path.exists():
            content = pyproject_path.read_text(encoding="utf-8")
            version_match = re.search(r'version\s*=\s*["\']([^"\']+)["\']', content)
            if version_match:
                version_sources["pyproject.toml"] = version_match.group(1)

        # __init__.pyã‹ã‚‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³å–å¾—
        init_path = self.project_root / "kumihan_formatter" / "__init__.py"
        if init_path.exists():
            content = init_path.read_text(encoding="utf-8")
            version_match = re.search(r'__version__\s*=\s*["\']([^"\']+)["\']', content)
            if version_match:
                version_sources["__init__.py"] = version_match.group(1)

        # README.mdã‹ã‚‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³å–å¾—
        readme_path = self.project_root / "README.md"
        if readme_path.exists():
            content = readme_path.read_text(encoding="utf-8")
            version_matches = re.findall(r"v?(\d+\.\d+\.\d+)", content)
            if version_matches:
                version_sources["README.md"] = version_matches[0]

        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ä¸€è‡´ç¢ºèª
        if len(set(version_sources.values())) > 1:
            inconsistency = DocumentInconsistency(
                id=f"version_mismatch_{datetime.datetime.now().strftime('%Y%m%d')}",
                title="ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã®ä¸ä¸€è‡´",
                description=f"è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ç•°ãªã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™: {version_sources}",
                inconsistency_type=InconsistencyType.VERSION_MISMATCH,
                severity=SeverityLevel.HIGH,
                source_file="multiple",
                target_file=None,
                line_number=None,
                detected_date=datetime.datetime.now(),
                suggested_fix="å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’çµ±ä¸€ã—ã¦ãã ã•ã„",
            )
            inconsistencies.append(inconsistency)

        return inconsistencies

    def check_broken_links(self) -> List[DocumentInconsistency]:
        """ãƒªãƒ³ã‚¯åˆ‡ã‚Œãƒã‚§ãƒƒã‚¯"""
        inconsistencies = []

        for doc_file in self.doc_files:
            if doc_file.suffix.lower() != ".md":
                continue

            try:
                content = doc_file.read_text(encoding="utf-8")
                lines = content.split("\n")

                # Markdownãƒªãƒ³ã‚¯ã‚’æ¤œå‡º
                link_pattern = r"\[([^\]]+)\]\(([^)]+)\)"

                for line_num, line in enumerate(lines, 1):
                    for match in re.finditer(link_pattern, line):
                        link_text, link_url = match.groups()

                        # ç›¸å¯¾ãƒ‘ã‚¹ãƒªãƒ³ã‚¯ã®ãƒã‚§ãƒƒã‚¯
                        if not link_url.startswith(("http://", "https://", "#")):
                            link_path = doc_file.parent / link_url
                            if not link_path.exists():
                                inconsistency = DocumentInconsistency(
                                    id=f"broken_link_{doc_file.stem}_{line_num}",
                                    title=f"ãƒªãƒ³ã‚¯åˆ‡ã‚Œ: {link_text}",
                                    description=f"{doc_file.name}ã®{line_num}è¡Œç›®ã§ãƒªãƒ³ã‚¯åˆ‡ã‚Œã‚’æ¤œå‡º: {link_url}",
                                    inconsistency_type=InconsistencyType.BROKEN_LINK,
                                    severity=SeverityLevel.MEDIUM,
                                    source_file=str(
                                        doc_file.relative_to(self.project_root)
                                    ),
                                    target_file=link_url,
                                    line_number=line_num,
                                    detected_date=datetime.datetime.now(),
                                    suggested_fix=f"ãƒªãƒ³ã‚¯å…ˆãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆã¾ãŸã¯æ­£ã—ã„ãƒ‘ã‚¹ã¸ã®ä¿®æ­£: {link_url}",
                                )
                                inconsistencies.append(inconsistency)

            except Exception as e:
                logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {doc_file}: {e}")

        return inconsistencies

    def check_code_documentation_sync(self) -> List[DocumentInconsistency]:
        """ã‚³ãƒ¼ãƒ‰ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åŒæœŸãƒã‚§ãƒƒã‚¯"""
        inconsistencies = []

        # CLAUDEã§è¨­å®šã•ã‚ŒãŸAPIã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åŒæœŸç¢ºèª
        api_py_path = self.project_root / "API.md"
        if api_py_path.exists():
            api_content = api_py_path.read_text(encoding="utf-8")

            # å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã‚¯ãƒ©ã‚¹ãƒ»é–¢æ•°ã®ä¸€è¦§å–å¾—
            implemented_classes = set()
            implemented_functions = set()

            for py_file in self.code_files:
                if py_file.suffix == ".py":
                    try:
                        content = py_file.read_text(encoding="utf-8")

                        # ã‚¯ãƒ©ã‚¹å®šç¾©ã‚’æ¤œå‡º
                        class_matches = re.findall(
                            r"^class\s+([A-Za-z_][A-Za-z0-9_]*)", content, re.MULTILINE
                        )
                        implemented_classes.update(class_matches)

                        # é–¢æ•°å®šç¾©ã‚’æ¤œå‡ºï¼ˆprivateé™¤ãï¼‰
                        func_matches = re.findall(
                            r"^def\s+([A-Za-z_][A-Za-z0-9_]*)", content, re.MULTILINE
                        )
                        implemented_functions.update(
                            f for f in func_matches if not f.startswith("_")
                        )

                    except Exception as e:
                        logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼ {py_file}: {e}")

            # API.mdã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ãŒå®Ÿè£…ã•ã‚Œã¦ã„ãªã„é …ç›®
            documented_classes = set(
                re.findall(r"class\s+([A-Za-z_][A-Za-z0-9_]*)", api_content)
            )
            documented_functions = set(
                re.findall(r"def\s+([A-Za-z_][A-Za-z0-9_]*)", api_content)
            )

            missing_classes = documented_classes - implemented_classes
            missing_functions = documented_functions - implemented_functions

            if missing_classes or missing_functions:
                missing_items = list(missing_classes) + list(missing_functions)
                inconsistency = DocumentInconsistency(
                    id=f"code_doc_mismatch_{datetime.datetime.now().strftime('%Y%m%d')}",
                    title="APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨å®Ÿè£…ã®ä¸ä¸€è‡´",
                    description=f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ãŒå®Ÿè£…ã•ã‚Œã¦ã„ãªã„é …ç›®: {', '.join(missing_items[:10])}",
                    inconsistency_type=InconsistencyType.CODE_DOC_MISMATCH,
                    severity=SeverityLevel.HIGH,
                    source_file="API.md",
                    target_file="kumihan_formatter/",
                    line_number=None,
                    detected_date=datetime.datetime.now(),
                    suggested_fix="æœªå®Ÿè£…é …ç›®ã®å®Ÿè£…ã¾ãŸã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã®å‰Šé™¤",
                )
                inconsistencies.append(inconsistency)

        return inconsistencies

    def check_structural_consistency(self) -> List[DocumentInconsistency]:
        """æ§‹é€ çš„æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
        inconsistencies = []

        # å¿…é ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å­˜åœ¨ç¢ºèª
        required_docs = {
            "README.md": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ¦‚è¦ã¨ä½¿ç”¨æ–¹æ³•",
            "CLAUDE.md": "Claude Codeè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«",
            "CONTRIBUTING.md": "ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚¬ã‚¤ãƒ‰",
            "ARCHITECTURE.md": "ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
        }

        for doc_name, description in required_docs.items():
            doc_path = self.project_root / doc_name
            if not doc_path.exists():
                inconsistency = DocumentInconsistency(
                    id=f"missing_doc_{doc_name.lower().replace('.', '_')}",
                    title=f"å¿…é ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸è¶³: {doc_name}",
                    description=f"{description}ãŒä¸è¶³ã—ã¦ã„ã¾ã™",
                    inconsistency_type=InconsistencyType.MISSING_DOCUMENTATION,
                    severity=SeverityLevel.MEDIUM,
                    source_file="project_root",
                    target_file=doc_name,
                    line_number=None,
                    detected_date=datetime.datetime.now(),
                    suggested_fix=f"{doc_name}ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ",
                )
                inconsistencies.append(inconsistency)

        # CLAUDE.mdã®æ§‹é€ ãƒã‚§ãƒƒã‚¯
        claude_md = self.project_root / "CLAUDE.md"
        if claude_md.exists():
            content = claude_md.read_text(encoding="utf-8")
            required_sections = [
                "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦",
                "é–‹ç™ºåŸå‰‡",
                "é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼",
                "å“è³ªä¿è¨¼ã‚·ã‚¹ãƒ†ãƒ ",
            ]

            missing_sections = []
            for section in required_sections:
                if section not in content:
                    missing_sections.append(section)

            if missing_sections:
                inconsistency = DocumentInconsistency(
                    id=f"claude_md_structure_{datetime.datetime.now().strftime('%Y%m%d')}",
                    title="CLAUDE.mdæ§‹é€ ä¸æ•´åˆ",
                    description=f"å¿…è¦ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒä¸è¶³: {', '.join(missing_sections)}",
                    inconsistency_type=InconsistencyType.STRUCTURAL_INCONSISTENCY,
                    severity=SeverityLevel.MEDIUM,
                    source_file="CLAUDE.md",
                    target_file=None,
                    line_number=None,
                    detected_date=datetime.datetime.now(),
                    suggested_fix="ä¸è¶³ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è¿½åŠ ",
                )
                inconsistencies.append(inconsistency)

        return inconsistencies

    def check_outdated_content(self) -> List[DocumentInconsistency]:
        """å¤ã„å†…å®¹ã®ãƒã‚§ãƒƒã‚¯"""
        inconsistencies = []

        # æœ€çµ‚æ›´æ–°æ—¥ãŒå¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œå‡º
        cutoff_date = datetime.datetime.now() - datetime.timedelta(days=90)

        for doc_file in self.doc_files:
            try:
                mtime = datetime.datetime.fromtimestamp(doc_file.stat().st_mtime)
                if mtime < cutoff_date:
                    inconsistency = DocumentInconsistency(
                        id=f"outdated_{doc_file.stem}",
                        title=f"å¤ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {doc_file.name}",
                        description=f"{doc_file.name}ãŒ{(datetime.datetime.now() - mtime).days}æ—¥é–“æ›´æ–°ã•ã‚Œã¦ã„ã¾ã›ã‚“",
                        inconsistency_type=InconsistencyType.OUTDATED_CONTENT,
                        severity=SeverityLevel.LOW,
                        source_file=str(doc_file.relative_to(self.project_root)),
                        target_file=None,
                        line_number=None,
                        detected_date=datetime.datetime.now(),
                        suggested_fix="å†…å®¹ã®ç¢ºèªã¨å¿…è¦ã«å¿œã˜ãŸæ›´æ–°",
                    )
                    inconsistencies.append(inconsistency)

            except Exception as e:
                logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼ {doc_file}: {e}")

        return inconsistencies

    def run_full_check(self) -> List[DocumentInconsistency]:
        """å…¨æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ"""
        logger.info("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚’é–‹å§‹ã—ã¾ã™...")

        self.inconsistencies = []

        # å„ç¨®ãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ
        self.inconsistencies.extend(self.check_version_consistency())
        self.inconsistencies.extend(self.check_broken_links())
        self.inconsistencies.extend(self.check_code_documentation_sync())
        self.inconsistencies.extend(self.check_structural_consistency())
        self.inconsistencies.extend(self.check_outdated_content())

        logger.info(f"æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯å®Œäº†: {len(self.inconsistencies)}ä»¶ã®ä¸æ•´åˆã‚’æ¤œå‡º")

        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        self._save_results()

        return self.inconsistencies

    def _save_results(self):
        """ãƒã‚§ãƒƒã‚¯çµæœã®ä¿å­˜"""
        report_data = []
        for inconsistency in self.inconsistencies:
            report_data.append(
                {
                    "id": inconsistency.id,
                    "title": inconsistency.title,
                    "description": inconsistency.description,
                    "inconsistency_type": inconsistency.inconsistency_type.value,
                    "severity": inconsistency.severity.value,
                    "source_file": inconsistency.source_file,
                    "target_file": inconsistency.target_file,
                    "line_number": inconsistency.line_number,
                    "detected_date": inconsistency.detected_date.isoformat(),
                    "suggested_fix": inconsistency.suggested_fix,
                }
            )

        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        tmp_dir = self.project_root / "tmp"
        tmp_dir.mkdir(exist_ok=True)

        json_report = (
            tmp_dir
            / f"document_consistency_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        with open(json_report, "w", encoding="utf-8") as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)

        # äººé–“ãŒèª­ã¿ã‚„ã™ã„ãƒ¬ãƒãƒ¼ãƒˆã‚‚ç”Ÿæˆ
        md_report = (
            tmp_dir
            / f"document_consistency_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        )
        self._generate_markdown_report(md_report)

        logger.info(f"ãƒã‚§ãƒƒã‚¯çµæœã‚’ä¿å­˜: {json_report}, {md_report}")

    def _generate_markdown_report(self, output_path: Path):
        """Markdownãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        report_content = f"""# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ãƒ¬ãƒãƒ¼ãƒˆ

ç”Ÿæˆæ—¥æ™‚: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
å¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {len(self.doc_files)}ãƒ•ã‚¡ã‚¤ãƒ«
æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ: {len(self.inconsistencies)}ä»¶

## ğŸ“Š ã‚µãƒãƒªãƒ¼

"""

        # é‡è¦åº¦åˆ¥é›†è¨ˆ
        severity_counts = {}
        for severity in SeverityLevel:
            count = len([i for i in self.inconsistencies if i.severity == severity])
            severity_counts[severity.value] = count

        report_content += "### é‡è¦åº¦åˆ¥\n"
        for severity, count in severity_counts.items():
            emoji = {"critical": "ğŸ”´", "high": "ğŸŸ¡", "medium": "ğŸŸ¢", "low": "âšª"}
            report_content += (
                f"- {emoji.get(severity, 'â—')} {severity.upper()}: {count}ä»¶\n"
            )

        # ã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆ
        type_counts = {}
        for inc_type in InconsistencyType:
            count = len(
                [i for i in self.inconsistencies if i.inconsistency_type == inc_type]
            )
            type_counts[inc_type.value] = count

        report_content += "\n### ã‚¿ã‚¤ãƒ—åˆ¥\n"
        for inc_type, count in type_counts.items():
            if count > 0:
                report_content += f"- {inc_type.replace('_', ' ').title()}: {count}ä»¶\n"

        # è©³ç´°ãƒªã‚¹ãƒˆ
        if self.inconsistencies:
            report_content += "\n## ğŸ“ è©³ç´°\n\n"

            for i, inconsistency in enumerate(self.inconsistencies, 1):
                severity_emoji = {
                    "critical": "ğŸ”´",
                    "high": "ğŸŸ¡",
                    "medium": "ğŸŸ¢",
                    "low": "âšª",
                }
                report_content += f"### {i}. {inconsistency.title}\n\n"
                report_content += f"- **é‡è¦åº¦**: {severity_emoji.get(inconsistency.severity.value, 'â—')} {inconsistency.severity.value.upper()}\n"
                report_content += f"- **ã‚¿ã‚¤ãƒ—**: {inconsistency.inconsistency_type.value.replace('_', ' ').title()}\n"
                report_content += f"- **ãƒ•ã‚¡ã‚¤ãƒ«**: {inconsistency.source_file}\n"
                if inconsistency.target_file:
                    report_content += f"- **å¯¾è±¡**: {inconsistency.target_file}\n"
                if inconsistency.line_number:
                    report_content += f"- **è¡Œç•ªå·**: {inconsistency.line_number}\n"
                report_content += f"- **èª¬æ˜**: {inconsistency.description}\n"
                if inconsistency.suggested_fix:
                    report_content += f"- **æ¨å¥¨å¯¾å¿œ**: {inconsistency.suggested_fix}\n"
                report_content += "\n---\n\n"
        else:
            report_content += "\n## âœ… å•é¡Œãªã—\n\nãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ•´åˆæ€§ã«å•é¡Œã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n"

        report_content += (
            f"\n---\n*Generated by Document Consistency Checker - Issue #1240*"
        )

        with open(output_path, "w", encoding="utf-8") as f:
            f.write(report_content)

    def get_summary(self) -> Dict[str, Any]:
        """ã‚µãƒãƒªãƒ¼æƒ…å ±ã®å–å¾—"""
        severity_counts = {}
        type_counts = {}

        for severity in SeverityLevel:
            severity_counts[severity.value] = len(
                [i for i in self.inconsistencies if i.severity == severity]
            )

        for inc_type in InconsistencyType:
            type_counts[inc_type.value] = len(
                [i for i in self.inconsistencies if i.inconsistency_type == inc_type]
            )

        return {
            "total_inconsistencies": len(self.inconsistencies),
            "total_documents": len(self.doc_files),
            "severity_breakdown": severity_counts,
            "type_breakdown": type_counts,
            "check_date": datetime.datetime.now().isoformat(),
        }


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    if len(sys.argv) < 2:
        print("Usage: python document_consistency_checker.py [check|summary]")
        return

    command = sys.argv[1]
    checker = DocumentConsistencyChecker()

    if command == "check":
        inconsistencies = checker.run_full_check()
        print(
            f"âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯å®Œäº†: {len(inconsistencies)}ä»¶ã®ä¸æ•´åˆã‚’æ¤œå‡º"
        )

        if inconsistencies:
            print("\nğŸ“‹ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
            for i, inconsistency in enumerate(
                inconsistencies[:5], 1
            ):  # æœ€åˆã®5ä»¶ã‚’è¡¨ç¤º
                print(f"  {i}. {inconsistency.title} ({inconsistency.severity.value})")
            if len(inconsistencies) > 5:
                print(f"  ... ä»–{len(inconsistencies) - 5}ä»¶")
            print("\nè©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã¯ tmp/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã”ç¢ºèªãã ã•ã„ã€‚")

    elif command == "summary":
        if not checker.inconsistencies:
            checker.run_full_check()

        summary = checker.get_summary()
        print("ğŸ“Š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ã‚µãƒãƒªãƒ¼:")
        print(f"  - å¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {summary['total_documents']}ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"  - æ¤œå‡ºå•é¡Œæ•°: {summary['total_inconsistencies']}ä»¶")
        print(f"  - Critical: {summary['severity_breakdown']['critical']}ä»¶")
        print(f"  - High: {summary['severity_breakdown']['high']}ä»¶")
        print(f"  - Medium: {summary['severity_breakdown']['medium']}ä»¶")
        print(f"  - Low: {summary['severity_breakdown']['low']}ä»¶")

    else:
        print(f"Unknown command: {command}")


if __name__ == "__main__":
    main()
