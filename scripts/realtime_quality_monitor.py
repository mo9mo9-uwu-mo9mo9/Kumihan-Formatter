#!/usr/bin/env python3
"""
Real-time Quality Monitor - Issue #640 Phase 2
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

ç›®çš„: ã‚³ãƒ¼ãƒ‰å¤‰æ›´ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–
- ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æ¤œçŸ¥ â†’ å³åº§ã«å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
- å“è³ªåŠ£åŒ–ã®å³åº§ãªé€šçŸ¥
- VS Codeçµ±åˆè¡¨ç¤º
- TDDã‚µã‚¤ã‚¯ãƒ«é€²æ—ã®å¯è¦–åŒ–
"""

import os
import sys
import time
import json
import subprocess
import threading
from pathlib import Path
from typing import Dict, List, Optional, Set
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from queue import Queue, Empty
import signal
import hashlib

from kumihan_formatter.core.utilities.logger import get_logger

logger = get_logger(__name__)

@dataclass
class QualitySnapshot:
    """å“è³ªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ"""
    timestamp: datetime
    commit_hash: str
    coverage_percentage: float
    test_count: int
    failed_tests: int
    complexity_score: float
    code_lines: int
    quality_score: float
    violations: List[str]
    tdd_phase: Optional[str]

@dataclass
class QualityAlert:
    """å“è³ªã‚¢ãƒ©ãƒ¼ãƒˆ"""
    alert_type: str  # "degradation", "improvement", "violation"
    severity: str   # "critical", "warning", "info"
    message: str
    before_value: float
    after_value: float
    threshold: float
    file_path: Optional[str]
    timestamp: datetime

class RealTimeQualityMonitor:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.monitor_config = self._load_monitor_config()
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        self.quality_data_dir = project_root / ".quality_data"
        self.quality_data_dir.mkdir(exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®š
        self.snapshots_file = self.quality_data_dir / "quality_snapshots.json"
        self.alerts_file = self.quality_data_dir / "quality_alerts.json"
        self.vscode_status_file = self.quality_data_dir / "vscode_status.json"
        
        # ç›£è¦–çŠ¶æ…‹
        self.running = False
        self.file_change_queue = Queue()
        self.quality_history = []
        self.current_snapshot = None
        self.last_file_hashes = {}
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
        self.alert_thresholds = {
            "coverage_drop": 5.0,      # ã‚«ãƒãƒ¬ãƒƒã‚¸5%ä»¥ä¸Šã®ä½ä¸‹
            "complexity_increase": 3.0, # è¤‡é›‘åº¦3ä»¥ä¸Šã®å¢—åŠ 
            "test_failure": 1,          # ãƒ†ã‚¹ãƒˆå¤±æ•—1ä»¶ä»¥ä¸Š
            "quality_score_drop": 10.0  # å“è³ªã‚¹ã‚³ã‚¢10ä»¥ä¸Šã®ä½ä¸‹
        }
        
        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®š
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        logger.info("ğŸ” ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–ã‚’é–‹å§‹...")
        self.running = True
        
        # åˆæœŸã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆ
        self._create_initial_snapshot()
        
        # ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        threads = [
            threading.Thread(target=self._file_watcher, daemon=True),
            threading.Thread(target=self._quality_analyzer, daemon=True),
            threading.Thread(target=self._alert_processor, daemon=True),
            threading.Thread(target=self._vscode_updater, daemon=True),
        ]
        
        for thread in threads:
            thread.start()
        
        logger.info("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–é–‹å§‹å®Œäº†")
        
        try:
            # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
            while self.running:
                self._display_monitoring_status()
                time.sleep(10)  # 10ç§’é–“éš”ã§çŠ¶æ³è¡¨ç¤º
                
        except KeyboardInterrupt:
            self._shutdown()
    
    def _load_monitor_config(self) -> Dict:
        """ç›£è¦–è¨­å®šèª­ã¿è¾¼ã¿"""
        default_config = {
            "watch_patterns": [
                "kumihan_formatter/**/*.py",
                "tests/**/*.py",
                "pyproject.toml",
                "Makefile"
            ],
            "ignore_patterns": [
                "**/__pycache__/**",
                "**/*.pyc",
                ".tdd_logs/**",
                ".quality_data/**"
            ],
            "quality_check_interval": 5,  # ç§’
            "vscode_update_interval": 2,  # ç§’
            "alert_cooldown": 30,         # ç§’
            "snapshot_retention_days": 7
        }
        
        config_file = self.project_root / ".quality_monitor_config.json"
        if config_file.exists():
            try:
                with open(config_file, "r", encoding="utf-8") as f:
                    user_config = json.load(f)
                    default_config.update(user_config)
            except Exception as e:
                logger.warning(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        
        return default_config
    
    def _file_watcher(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ç›£è¦–"""
        logger.info("ğŸ‘€ ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ç›£è¦–é–‹å§‹")
        
        while self.running:
            try:
                changed_files = self._detect_file_changes()
                
                for file_path in changed_files:
                    logger.debug(f"ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æ¤œå‡º: {file_path}")
                    self.file_change_queue.put({
                        "type": "file_change",
                        "file_path": file_path,
                        "timestamp": datetime.now()
                    })
                
                time.sleep(1)  # 1ç§’é–“éš”ã§ç›£è¦–
                
            except Exception as e:
                logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(5)
    
    def _detect_file_changes(self) -> List[Path]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æ¤œå‡º"""
        changed_files = []
        
        # ç›£è¦–å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
        watch_files = set()
        for pattern in self.monitor_config["watch_patterns"]:
            matched_files = self.project_root.glob(pattern)
            watch_files.update(matched_files)
        
        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        for ignore_pattern in self.monitor_config["ignore_patterns"]:
            ignore_files = set(self.project_root.glob(ignore_pattern))
            watch_files -= ignore_files
        
        # ãƒãƒƒã‚·ãƒ¥æ¯”è¼ƒã§å¤‰æ›´æ¤œå‡º
        current_hashes = {}
        for file_path in watch_files:
            if file_path.is_file():
                try:
                    with open(file_path, "rb") as f:
                        content = f.read()
                        file_hash = hashlib.md5(content).hexdigest()
                        current_hashes[str(file_path)] = file_hash
                        
                        # å¤‰æ›´æ¤œå‡º
                        if str(file_path) in self.last_file_hashes:
                            if self.last_file_hashes[str(file_path)] != file_hash:
                                changed_files.append(file_path)
                        else:
                            # æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«
                            changed_files.append(file_path)
                            
                except Exception as e:
                    logger.debug(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—å¤±æ•— {file_path}: {e}")
        
        self.last_file_hashes = current_hashes
        return changed_files
    
    def _quality_analyzer(self):
        """å“è³ªåˆ†æå‡¦ç†"""
        logger.info("ğŸ“Š å“è³ªåˆ†æå‡¦ç†é–‹å§‹")
        
        last_analysis = datetime.now()
        
        while self.running:
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                has_changes = False
                try:
                    event = self.file_change_queue.get(timeout=1)
                    if event["type"] == "file_change":
                        has_changes = True
                        # ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢ï¼ˆè¤‡æ•°å¤‰æ›´ã‚’ä¸€åº¦ã«å‡¦ç†ï¼‰
                        while True:
                            try:
                                self.file_change_queue.get_nowait()
                            except Empty:
                                break
                except Empty:
                    pass
                
                # å®šæœŸçš„ã¾ãŸã¯å¤‰æ›´æ™‚ã«å“è³ªåˆ†æå®Ÿè¡Œ
                now = datetime.now()
                time_since_last = (now - last_analysis).total_seconds()
                
                if has_changes or time_since_last >= self.monitor_config["quality_check_interval"]:
                    new_snapshot = self._create_quality_snapshot()
                    
                    if new_snapshot:
                        self._process_quality_snapshot(new_snapshot)
                        last_analysis = now
                
                time.sleep(0.5)  # CPUä½¿ç”¨ç‡ã‚’æŠ‘åˆ¶
                
            except Exception as e:
                logger.error(f"å“è³ªåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(5)
    
    def _create_quality_snapshot(self) -> Optional[QualitySnapshot]:
        """å“è³ªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆ"""
        try:
            logger.debug("å“è³ªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆä¸­...")
            
            # ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ»ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            coverage_cmd = [
                sys.executable, "-m", "pytest",
                "--cov=kumihan_formatter",
                "--cov-report=json:temp_coverage.json",
                "--tb=no", "-q", "--disable-warnings"
            ]
            
            result = subprocess.run(coverage_cmd, capture_output=True, text=True, 
                                  cwd=self.project_root, timeout=60)
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è§£æ
            coverage_percentage = 0.0
            test_count = 0
            failed_tests = 0
            
            # ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ‡ãƒ¼ã‚¿
            coverage_file = self.project_root / "temp_coverage.json"
            if coverage_file.exists():
                try:
                    with open(coverage_file) as f:
                        coverage_data = json.load(f)
                        coverage_percentage = coverage_data["totals"]["percent_covered"]
                except:
                    pass
                finally:
                    coverage_file.unlink(missing_ok=True)
            
            # ãƒ†ã‚¹ãƒˆçµæœè§£æ
            if result.stdout:
                output_lines = result.stdout.split('\n')
                for line in output_lines:
                    if " passed" in line or " failed" in line:
                        parts = line.split()
                        for i, part in enumerate(parts):
                            if part == "passed" and i > 0:
                                try:
                                    test_count += int(parts[i-1])
                                except ValueError:
                                    pass
                            elif part == "failed" and i > 0:
                                try:
                                    failed_tests += int(parts[i-1])
                                except ValueError:
                                    pass
            
            # è¿½åŠ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            complexity_score = self._calculate_complexity()
            code_lines = self._count_source_lines()
            quality_score = self._calculate_quality_score(
                coverage_percentage, test_count, failed_tests, complexity_score
            )
            
            # å“è³ªé•åæ¤œå‡º
            violations = self._detect_quality_violations(
                coverage_percentage, complexity_score, failed_tests
            )
            
            # TDDãƒ•ã‚§ãƒ¼ã‚ºå–å¾—
            tdd_phase = self._get_current_tdd_phase()
            
            # ã‚³ãƒŸãƒƒãƒˆãƒãƒƒã‚·ãƒ¥å–å¾—
            commit_hash = self._get_commit_hash()
            
            snapshot = QualitySnapshot(
                timestamp=datetime.now(),
                commit_hash=commit_hash,
                coverage_percentage=coverage_percentage,
                test_count=test_count,
                failed_tests=failed_tests,
                complexity_score=complexity_score,
                code_lines=code_lines,
                quality_score=quality_score,
                violations=violations,
                tdd_phase=tdd_phase
            )
            
            logger.debug(f"ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆå®Œäº†: ã‚«ãƒãƒ¬ãƒƒã‚¸{coverage_percentage:.1f}%")
            return snapshot
            
        except subprocess.TimeoutExpired:
            logger.warning("å“è³ªåˆ†æã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            return None
        except Exception as e:
            logger.error(f"ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆå¤±æ•—: {e}")
            return None
    
    def _process_quality_snapshot(self, snapshot: QualitySnapshot):
        """å“è³ªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå‡¦ç†"""
        # å±¥æ­´ã«è¿½åŠ 
        self.quality_history.append(snapshot)
        
        # å¤ã„ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ï¼ˆä¿æŒæœŸé–“ã‚’è¶…ãˆãŸã‚‚ã®ï¼‰
        cutoff_date = datetime.now() - timedelta(days=self.monitor_config["snapshot_retention_days"])
        self.quality_history = [s for s in self.quality_history if s.timestamp > cutoff_date]
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆ
        if self.current_snapshot:
            alerts = self._generate_alerts(self.current_snapshot, snapshot)
            for alert in alerts:
                self._send_alert(alert)
        
        # ç¾åœ¨ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆæ›´æ–°
        self.current_snapshot = snapshot
        
        # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜
        self._save_snapshots()
    
    def _generate_alerts(self, before: QualitySnapshot, after: QualitySnapshot) -> List[QualityAlert]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆ"""
        alerts = []
        
        # ã‚«ãƒãƒ¬ãƒƒã‚¸ä½ä¸‹ãƒã‚§ãƒƒã‚¯
        coverage_drop = before.coverage_percentage - after.coverage_percentage
        if coverage_drop >= self.alert_thresholds["coverage_drop"]:
            alerts.append(QualityAlert(
                alert_type="degradation",
                severity="warning",
                message=f"ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ{coverage_drop:.1f}%ä½ä¸‹ã—ã¾ã—ãŸ",
                before_value=before.coverage_percentage,
                after_value=after.coverage_percentage,
                threshold=self.alert_thresholds["coverage_drop"],
                file_path=None,
                timestamp=datetime.now()
            ))
        
        # è¤‡é›‘åº¦å¢—åŠ ãƒã‚§ãƒƒã‚¯
        complexity_increase = after.complexity_score - before.complexity_score
        if complexity_increase >= self.alert_thresholds["complexity_increase"]:
            alerts.append(QualityAlert(
                alert_type="degradation",
                severity="warning",
                message=f"ã‚³ãƒ¼ãƒ‰è¤‡é›‘åº¦ãŒ{complexity_increase:.1f}å¢—åŠ ã—ã¾ã—ãŸ",
                before_value=before.complexity_score,
                after_value=after.complexity_score,
                threshold=self.alert_thresholds["complexity_increase"],
                file_path=None,
                timestamp=datetime.now()
            ))
        
        # ãƒ†ã‚¹ãƒˆå¤±æ•—ãƒã‚§ãƒƒã‚¯
        if after.failed_tests > before.failed_tests:
            alerts.append(QualityAlert(
                alert_type="violation",
                severity="critical",
                message=f"ãƒ†ã‚¹ãƒˆå¤±æ•—ãŒ{after.failed_tests - before.failed_tests}ä»¶å¢—åŠ ã—ã¾ã—ãŸ",
                before_value=float(before.failed_tests),
                after_value=float(after.failed_tests),
                threshold=float(self.alert_thresholds["test_failure"]),
                file_path=None,
                timestamp=datetime.now()
            ))
        
        # å“è³ªã‚¹ã‚³ã‚¢ä½ä¸‹ãƒã‚§ãƒƒã‚¯
        quality_drop = before.quality_score - after.quality_score
        if quality_drop >= self.alert_thresholds["quality_score_drop"]:
            alerts.append(QualityAlert(
                alert_type="degradation",
                severity="warning",
                message=f"å“è³ªã‚¹ã‚³ã‚¢ãŒ{quality_drop:.1f}ä½ä¸‹ã—ã¾ã—ãŸ",
                before_value=before.quality_score,
                after_value=after.quality_score,
                threshold=self.alert_thresholds["quality_score_drop"],
                file_path=None,
                timestamp=datetime.now()
            ))
        
        # æ”¹å–„ã®å ´åˆã‚‚ã‚¢ãƒ©ãƒ¼ãƒˆ
        if coverage_drop < -5.0:  # 5%ä»¥ä¸Šå‘ä¸Š
            alerts.append(QualityAlert(
                alert_type="improvement",
                severity="info",
                message=f"ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ{-coverage_drop:.1f}%å‘ä¸Šã—ã¾ã—ãŸ",
                before_value=before.coverage_percentage,
                after_value=after.coverage_percentage,
                threshold=5.0,
                file_path=None,
                timestamp=datetime.now()
            ))
        
        return alerts
    
    def _send_alert(self, alert: QualityAlert):
        """ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡"""
        logger.info(f"ğŸš¨ {alert.severity.upper()}: {alert.message}")
        
        # ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—é€šçŸ¥ï¼ˆmacOSï¼‰
        try:
            if sys.platform == "darwin":
                icon = "âš ï¸" if alert.severity == "warning" else "ğŸš¨" if alert.severity == "critical" else "ğŸ“ˆ"
                subprocess.run([
                    "osascript", "-e",
                    f'display notification "{alert.message}" with title "{icon} å“è³ªç›£è¦–ã‚¢ãƒ©ãƒ¼ãƒˆ" sound name "Glass"'
                ], check=False)
        except:
            pass
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆå±¥æ­´ä¿å­˜
        self._save_alert(alert)
    
    def _alert_processor(self):
        """ã‚¢ãƒ©ãƒ¼ãƒˆå‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰"""
        logger.info("ğŸš¨ ã‚¢ãƒ©ãƒ¼ãƒˆå‡¦ç†é–‹å§‹")
        
        while self.running:
            try:
                # ã‚¢ãƒ©ãƒ¼ãƒˆå‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰
                time.sleep(5)
            except Exception as e:
                logger.error(f"ã‚¢ãƒ©ãƒ¼ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(5)
    
    def _vscode_updater(self):
        """VS Codeçµ±åˆæ›´æ–°"""
        logger.info("ğŸ’» VS Codeçµ±åˆæ›´æ–°é–‹å§‹")
        
        while self.running:
            try:
                if self.current_snapshot:
                    self._update_vscode_status()
                    
                time.sleep(self.monitor_config["vscode_update_interval"])
                
            except Exception as e:
                logger.error(f"VS Codeæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(5)
    
    def _update_vscode_status(self):
        """VS Codeã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°"""
        if not self.current_snapshot:
            return
            
        # VS Codeæ‹¡å¼µç”¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
        status_data = {
            "timestamp": self.current_snapshot.timestamp.isoformat(),
            "coverage": {
                "percentage": self.current_snapshot.coverage_percentage,
                "status": self._get_coverage_status(self.current_snapshot.coverage_percentage)
            },
            "tests": {
                "total": self.current_snapshot.test_count,
                "failed": self.current_snapshot.failed_tests,
                "passed": self.current_snapshot.test_count - self.current_snapshot.failed_tests
            },
            "quality": {
                "score": self.current_snapshot.quality_score,
                "complexity": self.current_snapshot.complexity_score,
                "violations": self.current_snapshot.violations
            },
            "tdd": {
                "phase": self.current_snapshot.tdd_phase,
                "status": self._get_tdd_status()
            },
            "alerts": self._get_recent_alerts()
        }
        
        with open(self.vscode_status_file, "w", encoding="utf-8") as f:
            json.dump(status_data, f, indent=2, ensure_ascii=False)
    
    def _get_coverage_status(self, percentage: float) -> str:
        """ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—"""
        if percentage >= 90:
            return "excellent"
        elif percentage >= 75:
            return "good"
        elif percentage >= 60:
            return "fair"
        else:
            return "poor"
    
    def _get_tdd_status(self) -> str:
        """TDDã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—"""
        session_file = self.project_root / ".tdd_session.json"
        if session_file.exists():
            try:
                with open(session_file, "r", encoding="utf-8") as f:
                    session = json.load(f)
                    return f"active_{session.get('current_phase', 'unknown')}"
            except:
                pass
        return "inactive"
    
    def _get_recent_alerts(self) -> List[Dict]:
        """æœ€è¿‘ã®ã‚¢ãƒ©ãƒ¼ãƒˆå–å¾—"""
        alerts_file = self.alerts_file
        if not alerts_file.exists():
            return []
            
        try:
            with open(alerts_file, "r", encoding="utf-8") as f:
                all_alerts = json.load(f)
                
            # æœ€è¿‘1æ™‚é–“ã®ã‚¢ãƒ©ãƒ¼ãƒˆ
            recent_cutoff = datetime.now() - timedelta(hours=1)
            recent_alerts = []
            
            for alert_data in all_alerts[-10:]:  # æœ€æ–°10ä»¶
                alert_time = datetime.fromisoformat(alert_data["timestamp"])
                if alert_time > recent_cutoff:
                    recent_alerts.append(alert_data)
                    
            return recent_alerts
            
        except Exception as e:
            logger.debug(f"ã‚¢ãƒ©ãƒ¼ãƒˆå±¥æ­´èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            return []
    
    def _calculate_complexity(self) -> float:
        """è¤‡é›‘åº¦è¨ˆç®—"""
        try:
            # Pythonãƒ•ã‚¡ã‚¤ãƒ«ã®è¡Œæ•°ãƒ™ãƒ¼ã‚¹ç°¡æ˜“è¨ˆç®—
            py_files = list((self.project_root / "kumihan_formatter").rglob("*.py"))
            if not py_files:
                return 0.0
                
            total_lines = 0
            total_functions = 0
            
            for py_file in py_files[:20]:  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                try:
                    with open(py_file, "r", encoding="utf-8") as f:
                        content = f.read()
                        lines = [l for l in content.split('\n') if l.strip() and not l.strip().startswith('#')]
                        total_lines += len(lines)
                        total_functions += content.count('def ')
                except:
                    continue
            
            return total_lines / max(total_functions, 1)
            
        except Exception as e:
            logger.debug(f"è¤‡é›‘åº¦è¨ˆç®—å¤±æ•—: {e}")
            return 10.0
    
    def _count_source_lines(self) -> int:
        """ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰è¡Œæ•°ã‚«ã‚¦ãƒ³ãƒˆ"""
        try:
            py_files = list((self.project_root / "kumihan_formatter").rglob("*.py"))
            total_lines = 0
            
            for py_file in py_files:
                try:
                    with open(py_file, "r", encoding="utf-8") as f:
                        lines = [l for l in f if l.strip() and not l.strip().startswith('#')]
                        total_lines += len(lines)
                except:
                    continue
                    
            return total_lines
            
        except Exception as e:
            logger.debug(f"è¡Œæ•°è¨ˆç®—å¤±æ•—: {e}")
            return 0
    
    def _calculate_quality_score(self, coverage: float, test_count: int, failed_tests: int, complexity: float) -> float:
        """å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—"""
        # ã‚«ãƒãƒ¬ãƒƒã‚¸40% + ãƒ†ã‚¹ãƒˆæˆåŠŸç‡30% + è¤‡é›‘åº¦30%
        coverage_score = min(coverage / 100, 1.0) * 40
        
        test_success_rate = (test_count - failed_tests) / max(test_count, 1)
        test_score = test_success_rate * 30
        
        complexity_score = max(0, (20 - complexity) / 20) * 30
        
        return coverage_score + test_score + complexity_score
    
    def _detect_quality_violations(self, coverage: float, complexity: float, failed_tests: int) -> List[str]:
        """å“è³ªé•åæ¤œå‡º"""
        violations = []
        
        if coverage < 70:
            violations.append(f"ã‚«ãƒãƒ¬ãƒƒã‚¸ä¸è¶³: {coverage:.1f}% < 70%")
        
        if complexity > 15:
            violations.append(f"è¤‡é›‘åº¦è¶…é: {complexity:.1f} > 15")
        
        if failed_tests > 0:
            violations.append(f"ãƒ†ã‚¹ãƒˆå¤±æ•—: {failed_tests}ä»¶")
        
        return violations
    
    def _get_current_tdd_phase(self) -> Optional[str]:
        """ç¾åœ¨ã®TDDãƒ•ã‚§ãƒ¼ã‚ºå–å¾—"""
        session_file = self.project_root / ".tdd_session.json"
        if session_file.exists():
            try:
                with open(session_file, "r", encoding="utf-8") as f:
                    session = json.load(f)
                    return session.get("current_phase")
            except:
                pass
        return None
    
    def _get_commit_hash(self) -> str:
        """ã‚³ãƒŸãƒƒãƒˆãƒãƒƒã‚·ãƒ¥å–å¾—"""
        try:
            result = subprocess.run(["git", "rev-parse", "HEAD"], 
                                  capture_output=True, text=True, cwd=self.project_root)
            return result.stdout.strip()[:8]
        except:
            return "unknown"
    
    def _create_initial_snapshot(self):
        """åˆæœŸã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆ"""
        logger.info("ğŸ“¸ åˆæœŸå“è³ªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆä¸­...")
        snapshot = self._create_quality_snapshot()
        if snapshot:
            self.current_snapshot = snapshot
            self.quality_history.append(snapshot)
            self._save_snapshots()
            logger.info(f"âœ… åˆæœŸã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆå®Œäº†: ã‚«ãƒãƒ¬ãƒƒã‚¸{snapshot.coverage_percentage:.1f}%")
        else:
            logger.warning("åˆæœŸã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    def _save_snapshots(self):
        """ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜"""
        try:
            snapshots_data = [asdict(s) for s in self.quality_history]
            # datetime ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
            for snapshot in snapshots_data:
                snapshot["timestamp"] = snapshot["timestamp"].isoformat()
                
            with open(self.snapshots_file, "w", encoding="utf-8") as f:
                json.dump(snapshots_data, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.error(f"ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜å¤±æ•—: {e}")
    
    def _save_alert(self, alert: QualityAlert):
        """ã‚¢ãƒ©ãƒ¼ãƒˆä¿å­˜"""
        try:
            alerts_data = []
            if self.alerts_file.exists():
                with open(self.alerts_file, "r", encoding="utf-8") as f:
                    alerts_data = json.load(f)
            
            alert_dict = asdict(alert)
            alert_dict["timestamp"] = alert.timestamp.isoformat()
            alerts_data.append(alert_dict)
            
            # æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
            alerts_data = alerts_data[-100:]
            
            with open(self.alerts_file, "w", encoding="utf-8") as f:
                json.dump(alerts_data, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.error(f"ã‚¢ãƒ©ãƒ¼ãƒˆä¿å­˜å¤±æ•—: {e}")
    
    def _display_monitoring_status(self):
        """ç›£è¦–çŠ¶æ³è¡¨ç¤º"""
        if not self.current_snapshot:
            return
            
        snapshot = self.current_snapshot
        
        print(f"\rğŸ” å“è³ªç›£è¦–ä¸­ | ã‚«ãƒãƒ¬ãƒƒã‚¸: {snapshot.coverage_percentage:.1f}% | "
              f"å“è³ªã‚¹ã‚³ã‚¢: {snapshot.quality_score:.1f} | "
              f"ãƒ†ã‚¹ãƒˆ: {snapshot.test_count - snapshot.failed_tests}/{snapshot.test_count} | "
              f"TDD: {snapshot.tdd_phase or 'inactive'}", end="", flush=True)
    
    def _signal_handler(self, signum, frame):
        """ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
        logger.info(f"\nã‚·ã‚°ãƒŠãƒ« {signum} å—ä¿¡ã€‚ç›£è¦–ã‚’åœæ­¢ä¸­...")
        self._shutdown()
    
    def _shutdown(self):
        """ç›£è¦–åœæ­¢"""
        logger.info("ğŸ›‘ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–ã‚’åœæ­¢ä¸­...")
        self.running = False
        
        # æœ€çµ‚ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜
        if self.current_snapshot:
            self._save_snapshots()
        
        logger.info("ğŸ‘‹ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–åœæ­¢å®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    project_root = Path(__file__).parent.parent
    
    monitor = RealTimeQualityMonitor(project_root)
    
    logger.info("ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ èµ·å‹• - Issue #640 Phase 2")
    
    # ç›£è¦–é–‹å§‹
    monitor.start_monitoring()

if __name__ == "__main__":
    main()