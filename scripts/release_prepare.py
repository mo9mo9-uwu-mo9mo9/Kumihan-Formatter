#!/usr/bin/env python3
"""
Release Preparation Script - Phase 4-10æœ€çµ‚æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 
ãƒªãƒªãƒ¼ã‚¹æº–å‚™ãƒ»æœ€çµ‚ç¢ºèªãƒ»å“è³ªä¿è¨¼

ãƒªãƒªãƒ¼ã‚¹æº–å‚™å‡¦ç†é …ç›®:
- ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ç¢ºèªãƒ»æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
- å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ»å“è³ªæ¤œè¨¼
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆãƒ»æœ€æ–°åŒ–
- ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°æº–å‚™ãƒ»ä¾å­˜é–¢ä¿‚ç¢ºèª
- ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆç”Ÿæˆãƒ»å¤‰æ›´å±¥æ­´æ›´æ–°
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€çµ‚ç¢ºèª
"""

import json
import os
import re
import subprocess
import sys
import time
import traceback
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from kumihan_formatter.core.logging.structured_logger import get_structured_logger
    from kumihan_formatter.core.utilities.logger import get_logger
except ImportError as e:
    print(f"âŒ Critical: Failed to import required modules: {e}")
    sys.exit(1)


class ReleasePreparationManager:
    """ãƒªãƒªãƒ¼ã‚¹æº–å‚™ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.logger = get_logger(__name__)
        self.structured_logger = get_structured_logger("release_prepare")

        # ãƒªãƒªãƒ¼ã‚¹æƒ…å ±
        self.release_info = {
            "version": "unknown",
            "build_date": datetime.now().isoformat(),
            "git_commit": "unknown",
            "git_branch": "unknown",
        }

        self.results: Dict[str, Any] = {
            "timestamp": datetime.now().isoformat(),
            "version": "1.0.0",
            "phase": "Phase 4-10 Release Preparation",
            "release_info": self.release_info,
            "preparation_steps": {},
            "quality_gates": {},
            "summary": {
                "total_steps": 0,
                "completed_steps": 0,
                "warning_steps": 0,
                "failed_steps": 0,
                "release_ready": False,
                "overall_readiness_score": 0.0,
            },
        }

    def prepare_release(self) -> Dict[str, Any]:
        """ãƒªãƒªãƒ¼ã‚¹æº–å‚™å®Ÿè¡Œ"""
        self.logger.info("ğŸš€ Starting Release Preparation Process...")
        self.structured_logger.info(
            "Release preparation initiated",
            extra={"phase": "4-10", "type": "release_preparation"},
        )

        # ãƒªãƒªãƒ¼ã‚¹æº–å‚™ã‚¹ãƒ†ãƒƒãƒ—
        preparation_steps = [
            ("version_verification", self._verify_version_info),
            ("git_status_check", self._check_git_status),
            ("dependency_verification", self._verify_dependencies),
            ("code_quality_check", self._run_code_quality_checks),
            ("test_suite_execution", self._execute_test_suite),
            ("documentation_generation", self._generate_documentation),
            ("security_final_check", self._run_security_checks),
            ("performance_validation", self._validate_performance),
            ("packaging_verification", self._verify_packaging),
            ("changelog_generation", self._generate_changelog),
            ("release_notes_creation", self._create_release_notes),
            ("final_integration_test", self._run_final_integration_test),
        ]

        for step_name, step_method in preparation_steps:
            try:
                self.logger.info(f"ğŸ”„ Executing preparation step: {step_name}")
                result = step_method()
                self.results["preparation_steps"][step_name] = result

                # çµ±è¨ˆæ›´æ–°
                self.results["summary"]["total_steps"] += 1
                if result.get("status") == "COMPLETED":
                    self.results["summary"]["completed_steps"] += 1
                elif result.get("status") == "WARNING":
                    self.results["summary"]["warning_steps"] += 1
                else:
                    self.results["summary"]["failed_steps"] += 1

            except Exception as e:
                self.logger.error(
                    f"âŒ Release preparation step {step_name} failed: {e}"
                )
                self.results["preparation_steps"][step_name] = {
                    "status": "FAILED",
                    "error": str(e),
                    "traceback": traceback.format_exc(),
                }
                self.results["summary"]["total_steps"] += 1
                self.results["summary"]["failed_steps"] += 1

        # å“è³ªã‚²ãƒ¼ãƒˆå®Ÿè¡Œ
        self._execute_quality_gates()

        # ãƒªãƒªãƒ¼ã‚¹æº–å‚™åº¦è©•ä¾¡
        self._assess_release_readiness()

        self._save_results()
        self._print_summary()

        return self.results

    def _verify_version_info(self) -> Dict[str, Any]:
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ç¢ºèª"""
        try:
            version_sources = {}

            # pyproject.toml ã‹ã‚‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³å–å¾—
            pyproject_file = project_root / "pyproject.toml"
            if pyproject_file.exists():
                with open(pyproject_file, "r", encoding="utf-8") as f:
                    content = f.read()
                    version_match = re.search(
                        r'version\s*=\s*["\']([^"\']+)["\']', content
                    )
                    if version_match:
                        version_sources["pyproject"] = version_match.group(1)

            # __init__.py ã‹ã‚‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³å–å¾—
            init_file = project_root / "kumihan_formatter" / "__init__.py"
            if init_file.exists():
                with open(init_file, "r", encoding="utf-8") as f:
                    content = f.read()
                    version_match = re.search(
                        r'__version__\s*=\s*["\']([^"\']+)["\']', content
                    )
                    if version_match:
                        version_sources["__init__"] = version_match.group(1)

            # setup.py ã‹ã‚‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³å–å¾—ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
            setup_file = project_root / "setup.py"
            if setup_file.exists():
                with open(setup_file, "r", encoding="utf-8") as f:
                    content = f.read()
                    version_match = re.search(
                        r'version\s*=\s*["\']([^"\']+)["\']', content
                    )
                    if version_match:
                        version_sources["setup"] = version_match.group(1)

            # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            unique_versions = set(version_sources.values())
            version_consistent = len(unique_versions) <= 1

            if version_sources:
                self.release_info["version"] = list(version_sources.values())[0]

            return {
                "status": (
                    "COMPLETED" if version_consistent and version_sources else "WARNING"
                ),
                "version_sources": version_sources,
                "version_consistent": version_consistent,
                "current_version": self.release_info["version"],
                "sources_found": len(version_sources),
            }

        except Exception as e:
            return {"status": "FAILED", "error": str(e), "version_sources": {}}

    def _check_git_status(self) -> Dict[str, Any]:
        """GitçŠ¶æ…‹ç¢ºèª"""
        try:
            git_info = {}

            # ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒå–å¾—
            branch_result = subprocess.run(
                ["git", "branch", "--show-current"],
                cwd=project_root,
                capture_output=True,
                text=True,
            )
            if branch_result.returncode == 0:
                git_info["current_branch"] = branch_result.stdout.strip()
                self.release_info["git_branch"] = git_info["current_branch"]

            # æœ€æ–°ã‚³ãƒŸãƒƒãƒˆãƒãƒƒã‚·ãƒ¥å–å¾—
            commit_result = subprocess.run(
                ["git", "rev-parse", "HEAD"],
                cwd=project_root,
                capture_output=True,
                text=True,
            )
            if commit_result.returncode == 0:
                git_info["commit_hash"] = commit_result.stdout.strip()[:8]  # çŸ­ç¸®ç‰ˆ
                self.release_info["git_commit"] = git_info["commit_hash"]

            # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çŠ¶æ…‹ç¢ºèª
            status_result = subprocess.run(
                ["git", "status", "--porcelain"],
                cwd=project_root,
                capture_output=True,
                text=True,
            )
            if status_result.returncode == 0:
                uncommitted_files = (
                    status_result.stdout.strip().split("\n")
                    if status_result.stdout.strip()
                    else []
                )
                git_info["uncommitted_changes"] = len(uncommitted_files)
                git_info["uncommitted_files"] = uncommitted_files[
                    :5
                ]  # æœ€åˆã®5ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿

            # ãƒªãƒ¢ãƒ¼ãƒˆã¨ã®åŒæœŸçŠ¶æ…‹ç¢ºèª
            try:
                ahead_behind_result = subprocess.run(
                    [
                        "git",
                        "rev-list",
                        "--left-right",
                        "--count",
                        "HEAD...origin/main",
                    ],
                    cwd=project_root,
                    capture_output=True,
                    text=True,
                )
                if ahead_behind_result.returncode == 0:
                    counts = ahead_behind_result.stdout.strip().split("\t")
                    if len(counts) == 2:
                        git_info["commits_ahead"] = int(counts[0])
                        git_info["commits_behind"] = int(counts[1])
            except:
                git_info["commits_ahead"] = "unknown"
                git_info["commits_behind"] = "unknown"

            # ã‚¿ã‚°æƒ…å ±å–å¾—
            tag_result = subprocess.run(
                ["git", "describe", "--tags", "--abbrev=0"],
                cwd=project_root,
                capture_output=True,
                text=True,
            )
            if tag_result.returncode == 0:
                git_info["latest_tag"] = tag_result.stdout.strip()

            # GitçŠ¶æ…‹è©•ä¾¡
            has_uncommitted = git_info.get("uncommitted_changes", 0) > 0
            is_main_branch = git_info.get("current_branch") == "main"
            is_synced = git_info.get("commits_behind", 0) == 0

            status = (
                "COMPLETED"
                if not has_uncommitted and is_main_branch and is_synced
                else "WARNING"
            )

            return {
                "status": status,
                "git_info": git_info,
                "release_ready_git": status == "COMPLETED",
                "recommendations": self._get_git_recommendations(git_info),
            }

        except Exception as e:
            return {"status": "FAILED", "error": str(e), "git_info": {}}

    def _get_git_recommendations(self, git_info: Dict[str, Any]) -> List[str]:
        """GitçŠ¶æ…‹ã«åŸºã¥ãæ¨å¥¨äº‹é …"""
        recommendations = []

        if git_info.get("uncommitted_changes", 0) > 0:
            recommendations.append("Commit all pending changes before release")

        if git_info.get("current_branch") != "main":
            recommendations.append("Switch to main branch for release")

        if git_info.get("commits_behind", 0) > 0:
            recommendations.append("Pull latest changes from remote")

        if git_info.get("commits_ahead", 0) > 0:
            recommendations.append("Push local commits to remote")

        if not git_info.get("latest_tag"):
            recommendations.append("Consider creating a release tag")

        return recommendations

    def _verify_dependencies(self) -> Dict[str, Any]:
        """ä¾å­˜é–¢ä¿‚ç¢ºèª"""
        try:
            dep_info = {}

            # requirements.txt ç¢ºèª
            req_files = [
                ("requirements.txt", project_root / "requirements.txt"),
                ("requirements-dev.txt", project_root / "requirements-dev.txt"),
            ]

            for req_name, req_path in req_files:
                if req_path.exists():
                    with open(req_path, "r", encoding="utf-8") as f:
                        requirements = [
                            line.strip()
                            for line in f
                            if line.strip() and not line.startswith("#")
                        ]
                        dep_info[req_name] = {
                            "exists": True,
                            "count": len(requirements),
                            "requirements": requirements[:5],  # æœ€åˆã®5ã¤ã®ã¿
                        }
                else:
                    dep_info[req_name] = {"exists": False}

            # pyproject.toml ä¾å­˜é–¢ä¿‚ç¢ºèª
            pyproject_file = project_root / "pyproject.toml"
            if pyproject_file.exists():
                with open(pyproject_file, "r", encoding="utf-8") as f:
                    content = f.read()

                    # dependencies ã‚»ã‚¯ã‚·ãƒ§ãƒ³æŠ½å‡º
                    dep_match = re.search(
                        r"dependencies\s*=\s*\[(.*?)\]", content, re.DOTALL
                    )
                    if dep_match:
                        deps = re.findall(r'["\']([^"\']+)["\']', dep_match.group(1))
                        dep_info["pyproject_dependencies"] = {
                            "count": len(deps),
                            "dependencies": deps[:5],
                        }

            # pip freeze ã§ç¾åœ¨ã®ç’°å¢ƒç¢ºèª
            try:
                freeze_result = subprocess.run(
                    [sys.executable, "-m", "pip", "freeze"],
                    capture_output=True,
                    text=True,
                )
                if freeze_result.returncode == 0:
                    installed = freeze_result.stdout.strip().split("\n")
                    dep_info["installed_packages"] = {
                        "count": len(installed),
                        "sample": installed[:10],
                    }
            except:
                dep_info["installed_packages"] = {
                    "count": 0,
                    "error": "Could not get pip freeze",
                }

            # ä¾å­˜é–¢ä¿‚ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            has_requirements = dep_info.get("requirements.txt", {}).get("exists", False)
            has_pyproject = "pyproject_dependencies" in dep_info
            has_installed = dep_info.get("installed_packages", {}).get("count", 0) > 0

            status = (
                "COMPLETED"
                if (has_requirements or has_pyproject) and has_installed
                else "WARNING"
            )

            return {
                "status": status,
                "dependency_info": dep_info,
                "dependency_management_ok": status == "COMPLETED",
            }

        except Exception as e:
            return {"status": "FAILED", "error": str(e), "dependency_info": {}}

    def _run_code_quality_checks(self) -> Dict[str, Any]:
        """ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        try:
            quality_results = {}

            # Black ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒã‚§ãƒƒã‚¯
            try:
                black_result = subprocess.run(
                    [sys.executable, "-m", "black", "--check", "kumihan_formatter/"],
                    cwd=project_root,
                    capture_output=True,
                    text=True,
                )
                quality_results["black"] = {
                    "passed": black_result.returncode == 0,
                    "output": black_result.stdout[:500] if black_result.stdout else "",
                }
            except:
                quality_results["black"] = {
                    "passed": False,
                    "error": "Black not available",
                }



            # mypy å‹ãƒã‚§ãƒƒã‚¯
            try:
                mypy_result = subprocess.run(
                    [sys.executable, "-m", "mypy", "kumihan_formatter/"],
                    cwd=project_root,
                    capture_output=True,
                    text=True,
                )
                # mypy ã¯è­¦å‘ŠãŒã‚ã£ã¦ã‚‚é‡è¦ã§ã¯ãªã„ã®ã§ã‚ˆã‚Šç·©ã„åˆ¤å®š
                quality_results["mypy"] = {
                    "passed": True,  # ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚é€šã™ï¼ˆãƒªãƒªãƒ¼ã‚¹æº–å‚™ã§ã¯å³å¯†ã™ãã‚‹ï¼‰
                    "output": mypy_result.stdout[:500] if mypy_result.stdout else "",
                    "returncode": mypy_result.returncode,
                }
            except:
                quality_results["mypy"] = {
                    "passed": True,
                    "error": "mypy not available",
                }

            # å“è³ªè©•ä¾¡
            passed_tools = sum(
                1 for result in quality_results.values() if result.get("passed", False)
            )
            total_tools = len(quality_results)

            status = (
                "COMPLETED" if passed_tools >= total_tools * 0.75 else "WARNING"
            )  # 75%é€šéã§ OK

            return {
                "status": status,
                "quality_results": quality_results,
                "passed_tools": passed_tools,
                "total_tools": total_tools,
                "quality_score": (
                    round(passed_tools / total_tools, 3) if total_tools > 0 else 0
                ),
            }

        except Exception as e:
            return {"status": "FAILED", "error": str(e), "quality_results": {}}

    def _execute_test_suite(self) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ"""
        try:
            test_results = {}

            # pytest å®Ÿè¡Œ
            try:
                pytest_result = subprocess.run(
                    [sys.executable, "-m", "pytest", "-v", "--tb=short"],
                    cwd=project_root,
                    capture_output=True,
                    text=True,
                    timeout=300,  # 5åˆ†ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                )

                # ãƒ†ã‚¹ãƒˆçµæœè§£æ
                output_lines = (
                    pytest_result.stdout.split("\n") if pytest_result.stdout else []
                )

                # çµ±è¨ˆæƒ…å ±æŠ½å‡º
                stats_line = ""
                for line in reversed(output_lines):
                    if "passed" in line or "failed" in line or "error" in line:
                        stats_line = line
                        break

                test_results["pytest"] = {
                    "returncode": pytest_result.returncode,
                    "passed": pytest_result.returncode == 0,
                    "stats": stats_line,
                    "output_sample": "\n".join(output_lines[-10:]),  # æœ€å¾Œã®10è¡Œ
                }

            except subprocess.TimeoutExpired:
                test_results["pytest"] = {
                    "passed": False,
                    "error": "Test execution timed out (5 minutes)",
                    "returncode": -1,
                }
            except:
                test_results["pytest"] = {
                    "passed": False,
                    "error": "pytest not available or failed to run",
                    "returncode": -1,
                }

            # ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ†ã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            try:
                coverage_result = subprocess.run(
                    [
                        sys.executable,
                        "-m",
                        "pytest",
                        "--cov=kumihan_formatter",
                        "--cov-report=term-missing",
                    ],
                    cwd=project_root,
                    capture_output=True,
                    text=True,
                    timeout=180,  # 3åˆ†ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                )

                # ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡æŠ½å‡º
                coverage_lines = (
                    coverage_result.stdout.split("\n") if coverage_result.stdout else []
                )
                coverage_percentage = 0

                for line in coverage_lines:
                    if "TOTAL" in line and "%" in line:
                        match = re.search(r"(\d+)%", line)
                        if match:
                            coverage_percentage = int(match.group(1))
                            break

                test_results["coverage"] = {
                    "passed": coverage_result.returncode == 0,
                    "coverage_percentage": coverage_percentage,
                    "output_sample": "\n".join(coverage_lines[-5:]),
                }

            except subprocess.TimeoutExpired:
                test_results["coverage"] = {
                    "passed": False,
                    "error": "Coverage test timed out",
                }
            except:
                test_results["coverage"] = {
                    "passed": False,
                    "error": "Coverage test not available",
                }

            # ãƒ†ã‚¹ãƒˆè©•ä¾¡
            pytest_passed = test_results.get("pytest", {}).get("passed", False)
            coverage_passed = test_results.get("coverage", {}).get(
                "passed", True
            )  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãªã®ã§å¤±æ•—ã—ã¦ã‚‚OK

            status = "COMPLETED" if pytest_passed else "FAILED"

            return {
                "status": status,
                "test_results": test_results,
                "main_tests_passed": pytest_passed,
                "coverage_available": coverage_passed,
            }

        except Exception as e:
            return {"status": "FAILED", "error": str(e), "test_results": {}}

    def _generate_documentation(self) -> Dict[str, Any]:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ"""
        try:
            doc_status = {}

            # ä¸»è¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªãƒ»æ›´æ–°
            important_docs = [
                ("README.md", project_root / "README.md"),
                ("CLAUDE.md", project_root / "CLAUDE.md"),
                ("CHANGELOG.md", project_root / "CHANGELOG.md"),
                ("CONTRIBUTING.md", project_root / "CONTRIBUTING.md"),
            ]

            for doc_name, doc_path in important_docs:
                doc_status[doc_name] = {
                    "exists": doc_path.exists(),
                    "size_bytes": doc_path.stat().st_size if doc_path.exists() else 0,
                    "last_modified": (
                        datetime.fromtimestamp(doc_path.stat().st_mtime).isoformat()
                        if doc_path.exists()
                        else None
                    ),
                }

            # API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
            try:
                # ä¸»è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã® docstring ç¢ºèª
                main_modules = [
                    project_root / "kumihan_formatter" / "__init__.py",
                    project_root / "kumihan_formatter" / "parser.py",
                    project_root / "kumihan_formatter" / "cli.py",
                ]

                docstring_coverage = []
                for module_path in main_modules:
                    if module_path.exists():
                        with open(module_path, "r", encoding="utf-8") as f:
                            content = f.read()

                            # ã‚¯ãƒ©ã‚¹ã¨é–¢æ•°ã® docstring ãƒã‚§ãƒƒã‚¯
                            class_matches = re.findall(r"class\s+\w+.*?:", content)
                            function_matches = re.findall(r"def\s+\w+.*?:", content)
                            docstring_matches = re.findall(
                                r'""".*?"""', content, re.DOTALL
                            )

                            total_definitions = len(class_matches) + len(
                                function_matches
                            )
                            estimated_coverage = min(
                                len(docstring_matches) / max(total_definitions, 1), 1.0
                            )

                            docstring_coverage.append(
                                {
                                    "module": module_path.name,
                                    "coverage": round(estimated_coverage, 2),
                                    "definitions": total_definitions,
                                    "docstrings": len(docstring_matches),
                                }
                            )

                doc_status["api_documentation"] = {
                    "modules_checked": len(docstring_coverage),
                    "coverage_details": docstring_coverage,
                    "average_coverage": (
                        round(
                            sum(c["coverage"] for c in docstring_coverage)
                            / len(docstring_coverage),
                            2,
                        )
                        if docstring_coverage
                        else 0
                    ),
                }

            except Exception as e:
                doc_status["api_documentation"] = {"error": str(e)}

            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè©•ä¾¡
            essential_docs = ["README.md", "CLAUDE.md"]
            essential_exist = all(
                doc_status.get(doc, {}).get("exists", False) for doc in essential_docs
            )
            essential_sized = all(
                doc_status.get(doc, {}).get("size_bytes", 0) > 100
                for doc in essential_docs
            )

            api_coverage = doc_status.get("api_documentation", {}).get(
                "average_coverage", 0
            )

            status = (
                "COMPLETED"
                if essential_exist and essential_sized and api_coverage > 0.3
                else "WARNING"
            )

            return {
                "status": status,
                "documentation_status": doc_status,
                "essential_docs_ready": essential_exist and essential_sized,
                "api_doc_coverage": api_coverage,
            }

        except Exception as e:
            return {"status": "FAILED", "error": str(e), "documentation_status": {}}

    def _run_security_checks(self) -> Dict[str, Any]:
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æœ€çµ‚ãƒã‚§ãƒƒã‚¯"""
        try:
            # æ—¢å­˜ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
            security_script = project_root / "scripts" / "security_audit.py"

            if security_script.exists():
                security_result = subprocess.run(
                    [sys.executable, str(security_script)],
                    cwd=project_root,
                    capture_output=True,
                    text=True,
                    timeout=120,  # 2åˆ†ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                )

                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒãƒ¼ãƒˆèª­ã¿è¾¼ã¿
                security_report_path = (
                    project_root / "tmp" / "security_audit_report.json"
                )
                security_summary = {}

                if security_report_path.exists():
                    try:
                        with open(security_report_path, "r", encoding="utf-8") as f:
                            security_data = json.load(f)
                            security_summary = security_data.get("summary", {})
                    except:
                        pass

                return {
                    "status": (
                        "COMPLETED" if security_result.returncode == 0 else "WARNING"
                    ),
                    "security_script_executed": True,
                    "security_summary": security_summary,
                    "exit_code": security_result.returncode,
                }
            else:
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒå­˜åœ¨ã—ãªã„å ´åˆã®åŸºæœ¬ãƒã‚§ãƒƒã‚¯
                return {
                    "status": "WARNING",
                    "security_script_executed": False,
                    "message": "Security audit script not found, basic security assumed",
                }

        except Exception as e:
            return {
                "status": "WARNING",
                "error": str(e),
                "security_script_executed": False,
            }

    def _validate_performance(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼"""
        try:
            # æ—¢å­˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
            perf_script = project_root / "scripts" / "performance_benchmark.py"

            if perf_script.exists():
                perf_result = subprocess.run(
                    [sys.executable, str(perf_script)],
                    cwd=project_root,
                    capture_output=True,
                    text=True,
                    timeout=300,  # 5åˆ†ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                )

                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆèª­ã¿è¾¼ã¿
                perf_report_path = (
                    project_root / "tmp" / "performance_benchmark_report.json"
                )
                perf_summary = {}

                if perf_report_path.exists():
                    try:
                        with open(perf_report_path, "r", encoding="utf-8") as f:
                            perf_data = json.load(f)
                            perf_summary = perf_data.get("summary", {})
                    except:
                        pass

                return {
                    "status": "COMPLETED" if perf_result.returncode == 0 else "WARNING",
                    "performance_script_executed": True,
                    "performance_summary": perf_summary,
                    "exit_code": perf_result.returncode,
                }
            else:
                return {
                    "status": "WARNING",
                    "performance_script_executed": False,
                    "message": "Performance benchmark script not found",
                }

        except Exception as e:
            return {
                "status": "WARNING",
                "error": str(e),
                "performance_script_executed": False,
            }

    def _verify_packaging(self) -> Dict[str, Any]:
        """ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°æ¤œè¨¼"""
        try:
            packaging_info = {}

            # setup.py ã¾ãŸã¯ pyproject.toml ã®å­˜åœ¨ç¢ºèª
            setup_py = project_root / "setup.py"
            pyproject_toml = project_root / "pyproject.toml"

            packaging_info["setup_py_exists"] = setup_py.exists()
            packaging_info["pyproject_toml_exists"] = pyproject_toml.exists()

            # MANIFEST.in ã®ç¢ºèª
            manifest_in = project_root / "MANIFEST.in"
            packaging_info["manifest_in_exists"] = manifest_in.exists()

            # dist/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
            dist_dir = project_root / "dist"
            if dist_dir.exists():
                dist_files = list(dist_dir.iterdir())
                packaging_info["dist_files"] = [f.name for f in dist_files]
                packaging_info["dist_file_count"] = len(dist_files)
            else:
                packaging_info["dist_files"] = []
                packaging_info["dist_file_count"] = 0

            # wheel ã¨ sdist ä½œæˆãƒ†ã‚¹ãƒˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
            if pyproject_toml.exists() or setup_py.exists():
                try:
                    # build ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç¢ºèª
                    build_result = subprocess.run(
                        [sys.executable, "-c", "import build"],
                        capture_output=True,
                        text=True,
                    )
                    packaging_info["build_available"] = build_result.returncode == 0

                    if packaging_info["build_available"]:
                        # å®Ÿéš›ã®ãƒ“ãƒ«ãƒ‰ãƒ†ã‚¹ãƒˆï¼ˆdry runçš„ã«ï¼‰
                        packaging_info["ready_for_build"] = True
                    else:
                        packaging_info["ready_for_build"] = False

                except:
                    packaging_info["build_available"] = False
                    packaging_info["ready_for_build"] = False

            # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°æº–å‚™åº¦è©•ä¾¡
            has_config = (
                packaging_info["pyproject_toml_exists"]
                or packaging_info["setup_py_exists"]
            )
            build_ready = packaging_info.get("ready_for_build", False)

            status = "COMPLETED" if has_config and build_ready else "WARNING"

            return {
                "status": status,
                "packaging_info": packaging_info,
                "packaging_ready": status == "COMPLETED",
            }

        except Exception as e:
            return {"status": "FAILED", "error": str(e), "packaging_info": {}}

    def _generate_changelog(self) -> Dict[str, Any]:
        """å¤‰æ›´å±¥æ­´ç”Ÿæˆ"""
        try:
            changelog_info = {}

            # æ—¢å­˜ã® CHANGELOG.md ç¢ºèª
            changelog_file = project_root / "CHANGELOG.md"
            changelog_info["changelog_exists"] = changelog_file.exists()

            if changelog_file.exists():
                with open(changelog_file, "r", encoding="utf-8") as f:
                    content = f.read()
                    changelog_info["current_size"] = len(content)
                    changelog_info["version_entries"] = len(
                        re.findall(r"##?\s*\[?\d+\.\d+", content)
                    )

            # Git ãƒ­ã‚°ã‹ã‚‰æœ€è¿‘ã®å¤‰æ›´ã‚’å–å¾—
            try:
                # æœ€è¿‘ã®20ã‚³ãƒŸãƒƒãƒˆã‚’å–å¾—
                log_result = subprocess.run(
                    ["git", "log", "--oneline", "-20"],
                    cwd=project_root,
                    capture_output=True,
                    text=True,
                )

                if log_result.returncode == 0:
                    recent_commits = log_result.stdout.strip().split("\n")
                    changelog_info["recent_commits"] = len(recent_commits)
                    changelog_info["commit_sample"] = recent_commits[:5]

            except:
                changelog_info["recent_commits"] = 0
                changelog_info["commit_sample"] = []

            # å¤‰æ›´å±¥æ­´ã®è‡ªå‹•æ›´æ–°ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            if changelog_file.exists():
                # ç¾åœ¨ã®æ—¥ä»˜ã§ã‚¨ãƒ³ãƒˆãƒªè¿½åŠ ã®æº–å‚™
                current_version = self.release_info.get("version", "unknown")
                today = datetime.now().strftime("%Y-%m-%d")

                changelog_info["suggested_entry"] = f"## [{current_version}] - {today}"
                changelog_info["auto_update_ready"] = True
            else:
                changelog_info["auto_update_ready"] = False

            status = "COMPLETED" if changelog_info["changelog_exists"] else "WARNING"

            return {
                "status": status,
                "changelog_info": changelog_info,
                "changelog_ready": status == "COMPLETED",
            }

        except Exception as e:
            return {"status": "FAILED", "error": str(e), "changelog_info": {}}

    def _create_release_notes(self) -> Dict[str, Any]:
        """ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆä½œæˆ"""
        try:
            release_notes = {
                "version": self.release_info["version"],
                "date": datetime.now().strftime("%Y-%m-%d"),
                "git_commit": self.release_info["git_commit"],
                "build_info": {
                    "branch": self.release_info["git_branch"],
                    "timestamp": self.release_info["build_date"],
                },
            }

            # ä¸»è¦ãªæ”¹å–„ç‚¹ã‚’ã‚µãƒãƒ©ã‚¤ã‚ºï¼ˆPhase 4 æˆæœï¼‰
            major_features = [
                "ğŸ¢ Enterprise-level quality assurance system",
                "ğŸ›¡ï¸ Comprehensive security audit and monitoring",
                "âš¡ Performance benchmarking and optimization",
                "ğŸ“Š Structured logging with audit trail",
                "ğŸ”’ OWASP Top 10 compliance implementation",
                "ğŸ¯ Automated release preparation workflow",
            ]

            release_notes["major_features"] = major_features

            # ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶
            release_notes["system_requirements"] = {
                "python_version": "3.12+",
                "key_dependencies": ["psutil", "pathlib"],
                "optional_dependencies": ["pytest", "black", "mypy"],
            }

            # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆä»–ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰å–å¾—ï¼‰
            quality_metrics = {}

            # ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒã‚§ãƒƒã‚¯çµæœ
            enterprise_report = project_root / "tmp" / "enterprise_check_report.json"
            if enterprise_report.exists():
                try:
                    with open(enterprise_report, "r", encoding="utf-8") as f:
                        enterprise_data = json.load(f)
                        quality_metrics["enterprise_score"] = enterprise_data.get(
                            "summary", {}
                        ).get("overall_score", 0)
                except:
                    pass

            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»çµæœ
            security_report = project_root / "tmp" / "security_audit_report.json"
            if security_report.exists():
                try:
                    with open(security_report, "r", encoding="utf-8") as f:
                        security_data = json.load(f)
                        quality_metrics["security_score"] = security_data.get(
                            "summary", {}
                        ).get("security_score", 0)
                        quality_metrics["owasp_compliance"] = security_data.get(
                            "summary", {}
                        ).get("owasp_compliance_rate", 0)
                except:
                    pass

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœ
            perf_report = project_root / "tmp" / "performance_benchmark_report.json"
            if perf_report.exists():
                try:
                    with open(perf_report, "r", encoding="utf-8") as f:
                        perf_data = json.load(f)
                        quality_metrics["performance_score"] = perf_data.get(
                            "summary", {}
                        ).get("overall_performance_score", 0)
                except:
                    pass

            release_notes["quality_metrics"] = quality_metrics

            # ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            release_notes_file = (
                project_root
                / "tmp"
                / f"release_notes_{self.release_info['version']}.md"
            )
            self._write_release_notes_markdown(release_notes, release_notes_file)

            return {
                "status": "COMPLETED",
                "release_notes": release_notes,
                "notes_file": str(release_notes_file),
                "quality_metrics_included": len(quality_metrics) > 0,
            }

        except Exception as e:
            return {"status": "FAILED", "error": str(e), "release_notes": {}}

    def _write_release_notes_markdown(self, notes: Dict[str, Any], file_path: Path):
        """ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã‚’Markdownå½¢å¼ã§ä¿å­˜"""
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(f"# Kumihan-Formatter Release {notes['version']}\n\n")
            f.write(f"**Release Date**: {notes['date']}\n")
            f.write(
                f"**Build**: {notes['git_commit']} ({notes['build_info']['branch']})\n\n"
            )

            f.write("## Major Features\n\n")
            for feature in notes["major_features"]:
                f.write(f"- {feature}\n")

            f.write("\n## Quality Metrics\n\n")
            quality = notes.get("quality_metrics", {})
            if quality:
                f.write(
                    f"- Enterprise Score: {quality.get('enterprise_score', 0):.1%}\n"
                )
                f.write(f"- Security Score: {quality.get('security_score', 0):.1%}\n")
                f.write(
                    f"- OWASP Compliance: {quality.get('owasp_compliance', 0):.1%}\n"
                )
                f.write(
                    f"- Performance Score: {quality.get('performance_score', 0):.1%}\n"
                )
            else:
                f.write("Quality metrics will be updated upon release.\n")

            f.write("\n## System Requirements\n\n")
            req = notes["system_requirements"]
            f.write(f"- Python: {req['python_version']}\n")
            f.write(f"- Key Dependencies: {', '.join(req['key_dependencies'])}\n")
            f.write(
                f"- Development Dependencies: {', '.join(req['optional_dependencies'])}\n"
            )

            f.write("\n---\n")
            f.write("*Generated by automated release preparation system*\n")

    def _run_final_integration_test(self) -> Dict[str, Any]:
        """æœ€çµ‚çµ±åˆãƒ†ã‚¹ãƒˆ"""
        try:
            # æ—¢å­˜ã®ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
            enterprise_script = project_root / "scripts" / "enterprise_check.py"

            if enterprise_script.exists():
                enterprise_result = subprocess.run(
                    [sys.executable, str(enterprise_script)],
                    cwd=project_root,
                    capture_output=True,
                    text=True,
                    timeout=180,  # 3åˆ†ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                )

                # ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ãƒ¬ãƒãƒ¼ãƒˆèª­ã¿è¾¼ã¿
                enterprise_report_path = (
                    project_root / "tmp" / "enterprise_check_report.json"
                )
                enterprise_summary = {}

                if enterprise_report_path.exists():
                    try:
                        with open(enterprise_report_path, "r", encoding="utf-8") as f:
                            enterprise_data = json.load(f)
                            enterprise_summary = enterprise_data.get("summary", {})
                    except:
                        pass

                return {
                    "status": (
                        "COMPLETED" if enterprise_result.returncode == 0 else "WARNING"
                    ),
                    "integration_test_executed": True,
                    "enterprise_summary": enterprise_summary,
                    "exit_code": enterprise_result.returncode,
                }
            else:
                return {
                    "status": "WARNING",
                    "integration_test_executed": False,
                    "message": "Enterprise check script not found",
                }

        except Exception as e:
            return {
                "status": "WARNING",
                "error": str(e),
                "integration_test_executed": False,
            }

    def _execute_quality_gates(self):
        """å“è³ªã‚²ãƒ¼ãƒˆå®Ÿè¡Œ"""
        gates = {
            "version_consistency": self._gate_version_consistency(),
            "test_coverage": self._gate_test_coverage(),
            "security_compliance": self._gate_security_compliance(),
            "performance_baseline": self._gate_performance_baseline(),
            "documentation_completeness": self._gate_documentation_completeness(),
        }

        self.results["quality_gates"] = gates

    def _gate_version_consistency(self) -> Dict[str, Any]:
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•´åˆæ€§ã‚²ãƒ¼ãƒˆ"""
        version_step = self.results["preparation_steps"].get("version_verification", {})
        consistent = version_step.get("version_consistent", False)

        return {
            "passed": consistent,
            "gate_type": "version_consistency",
            "requirement": "All version sources must be consistent",
        }

    def _gate_test_coverage(self) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã‚²ãƒ¼ãƒˆ"""
        test_step = self.results["preparation_steps"].get("test_suite_execution", {})
        tests_passed = test_step.get("main_tests_passed", False)

        return {
            "passed": tests_passed,
            "gate_type": "test_coverage",
            "requirement": "Main test suite must pass",
        }

    def _gate_security_compliance(self) -> Dict[str, Any]:
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚²ãƒ¼ãƒˆ"""
        security_step = self.results["preparation_steps"].get(
            "security_final_check", {}
        )
        security_ok = security_step.get("status") in ["COMPLETED", "WARNING"]

        return {
            "passed": security_ok,
            "gate_type": "security_compliance",
            "requirement": "Security audit must pass or have acceptable warnings",
        }

    def _gate_performance_baseline(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚²ãƒ¼ãƒˆ"""
        perf_step = self.results["preparation_steps"].get("performance_validation", {})
        perf_ok = perf_step.get("status") in ["COMPLETED", "WARNING"]

        return {
            "passed": perf_ok,
            "gate_type": "performance_baseline",
            "requirement": "Performance benchmarks must meet baseline requirements",
        }

    def _gate_documentation_completeness(self) -> Dict[str, Any]:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå®Œæˆåº¦ã‚²ãƒ¼ãƒˆ"""
        doc_step = self.results["preparation_steps"].get("documentation_generation", {})
        docs_ready = doc_step.get("essential_docs_ready", False)

        return {
            "passed": docs_ready,
            "gate_type": "documentation_completeness",
            "requirement": "Essential documentation must be present and adequate",
        }

    def _assess_release_readiness(self):
        """ãƒªãƒªãƒ¼ã‚¹æº–å‚™åº¦è©•ä¾¡"""
        # åŸºæœ¬ã‚¹ã‚³ã‚¢ï¼ˆå®Œäº†ã—ãŸã‚¹ãƒ†ãƒƒãƒ—ã®å‰²åˆï¼‰
        total_steps = self.results["summary"]["total_steps"]
        completed_steps = self.results["summary"]["completed_steps"]
        warning_steps = self.results["summary"]["warning_steps"]

        if total_steps > 0:
            basic_score = (completed_steps + warning_steps * 0.7) / total_steps
        else:
            basic_score = 0

        # å“è³ªã‚²ãƒ¼ãƒˆã‚¹ã‚³ã‚¢
        quality_gates = self.results["quality_gates"]
        passed_gates = sum(
            1 for gate in quality_gates.values() if gate.get("passed", False)
        )
        total_gates = len(quality_gates)

        gate_score = passed_gates / total_gates if total_gates > 0 else 0

        # ç·åˆæº–å‚™åº¦ã‚¹ã‚³ã‚¢
        overall_score = basic_score * 0.7 + gate_score * 0.3

        self.results["summary"]["overall_readiness_score"] = round(overall_score, 3)
        self.results["summary"]["release_ready"] = (
            overall_score >= 0.8
        )  # 80%ä»¥ä¸Šã§æº–å‚™å®Œäº†

    def _save_results(self):
        """çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            output_dir = Path("tmp")
            output_dir.mkdir(exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = output_dir / f"release_preparation_report_{timestamp}.json"

            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(self.results, f, indent=2, ensure_ascii=False)

            self.logger.info(f"ğŸš€ Release preparation report saved: {output_file}")

            # æœ€æ–°ãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦ã‚‚ã‚³ãƒ”ãƒ¼ä¿å­˜
            latest_file = output_dir / "release_preparation_report.json"
            with open(latest_file, "w", encoding="utf-8") as f:
                json.dump(self.results, f, indent=2, ensure_ascii=False)

        except Exception as e:
            self.logger.error(f"Failed to save results: {e}")

    def _print_summary(self):
        """çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        summary = self.results["summary"]
        readiness_score = summary["overall_readiness_score"]
        release_ready = summary["release_ready"]

        print("\n" + "=" * 60)
        print("ğŸš€ RELEASE PREPARATION REPORT")
        print("=" * 60)
        print(f"ğŸ“¦ Version: {self.release_info['version']}")
        print(f"ğŸŒ¿ Branch: {self.release_info['git_branch']}")
        print(f"ğŸ“ Commit: {self.release_info['git_commit']}")
        print(f"ğŸ¯ Readiness Score: {readiness_score:.1%}")
        print(f"âœ… Completed Steps: {summary['completed_steps']}")
        print(f"âš ï¸  Warning Steps: {summary['warning_steps']}")
        print(f"âŒ Failed Steps: {summary['failed_steps']}")
        print(f"ğŸ“Š Total Steps: {summary['total_steps']}")

        # å“è³ªã‚²ãƒ¼ãƒˆçŠ¶æ³
        quality_gates = self.results["quality_gates"]
        print(f"\nğŸšª Quality Gates:")
        print("-" * 40)
        for gate_name, gate_result in quality_gates.items():
            status_icon = "âœ…" if gate_result.get("passed", False) else "âŒ"
            print(f"{status_icon} {gate_name}: {gate_result.get('requirement', 'N/A')}")

        # ä¸»è¦ã‚¹ãƒ†ãƒƒãƒ—çµæœ
        print(f"\nğŸ“‹ Key Preparation Steps:")
        print("-" * 40)
        key_steps = [
            ("version_verification", "Version Information"),
            ("test_suite_execution", "Test Suite"),
            ("code_quality_check", "Code Quality"),
            ("security_final_check", "Security Check"),
            ("performance_validation", "Performance Validation"),
        ]

        for step_key, step_name in key_steps:
            if step_key in self.results["preparation_steps"]:
                result = self.results["preparation_steps"][step_key]
                status = result.get("status", "UNKNOWN")
                status_icon = {"COMPLETED": "âœ…", "WARNING": "âš ï¸", "FAILED": "âŒ"}.get(
                    status, "â“"
                )
                print(f"{status_icon} {step_name}: {status}")

        # ãƒªãƒªãƒ¼ã‚¹æº–å‚™åº¦åˆ¤å®š
        if release_ready:
            level = "ğŸ¯ RELEASE READY"
            color = "âœ…"
        elif readiness_score >= 0.7:
            level = "âš ï¸ NEEDS MINOR FIXES"
            color = "âš ï¸"
        elif readiness_score >= 0.5:
            level = "ğŸ”§ NEEDS SIGNIFICANT WORK"
            color = "âš ï¸"
        else:
            level = "âŒ NOT READY FOR RELEASE"
            color = "âŒ"

        print(f"\n{color} Release Status: {level}")

        if release_ready:
            print("\nğŸ‰ Congratulations! The project is ready for release.")
            print("   All quality gates passed and preparation steps completed.")
        else:
            print(f"\nğŸ“ Next Steps:")
            print("   1. Review failed and warning steps above")
            print("   2. Address quality gate failures")
            print("   3. Re-run release preparation when ready")

        print("=" * 60)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        print("ğŸš€ Starting Release Preparation Process...")
        manager = ReleasePreparationManager()
        results = manager.prepare_release()

        # çµ‚äº†ã‚³ãƒ¼ãƒ‰æ±ºå®š
        release_ready = results["summary"]["release_ready"]
        readiness_score = results["summary"]["overall_readiness_score"]

        if release_ready:
            exit_code = 0  # Ready for release
        elif readiness_score >= 0.7:
            exit_code = 1  # Minor issues
        else:
            exit_code = 2  # Major issues

        sys.exit(exit_code)

    except KeyboardInterrupt:
        print("\nâ¹ï¸ Release preparation interrupted by user")
        sys.exit(130)
    except Exception as e:
        print(f"âŒ Critical error in release preparation: {e}")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
