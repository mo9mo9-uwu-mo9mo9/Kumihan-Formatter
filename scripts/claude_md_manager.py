#!/usr/bin/env python3
"""
CLAUDE.md Management System - Phase 2 & 3 Implementation
Issue #686 å¯¾å¿œ: æ§‹é€ åŒ–ç®¡ç†ãƒ»è‡ªå‹•æœ€é©åŒ–ãƒ»æŒç¶šå¯èƒ½é‹ç”¨
"""

import os
import re
import sys
import json
import yaml
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, asdict


@dataclass
class CLAUDEmdMetrics:
    """CLAUDE.md ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""

    timestamp: str
    lines: int
    bytes: int
    sections: int
    deep_nesting: int
    duplicates: int
    long_sections: int
    outdated_markers: int


@dataclass
class StructureIssue:
    """æ§‹é€ å•é¡Œ"""

    type: str
    severity: str  # 'critical', 'warning', 'info'
    line: Optional[int]
    description: str
    suggestion: Optional[str] = None


class CLAUDEmdManager:
    """CLAUDE.mdç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, claude_md_path: str = "CLAUDE.md"):
        self.claude_md_path = claude_md_path
        self.config = self._load_config()

    def _load_config(self) -> Dict:
        """è¨­å®šèª­ã¿è¾¼ã¿"""
        default_config = {
            "limits": {
                # æ®µéšåˆ¶é™ã‚·ã‚¹ãƒ†ãƒ ï¼ˆç·©å’Œç‰ˆï¼‰
                "warning": {"lines": 250, "bytes": 12288},  # 12KB
                "caution": {"lines": 300, "bytes": 15360},  # 15KB
                "critical": {"lines": 400, "bytes": 20480},  # 20KB
                # æ—§åˆ¶é™ï¼ˆå‚è€ƒå€¤ãƒ»æ¨å¥¨ï¼‰
                "recommended_lines": 150,
                "recommended_bytes": 8192,  # 8KB
                "max_section_lines": 20,
                "max_nesting_depth": 3,
            },
            "structure": {
                "required_sections": [
                    "AIé‹ç”¨7åŸå‰‡",
                    "åŸºæœ¬è¨­å®š",
                    "å¿…é ˆãƒ«ãƒ¼ãƒ«",
                    "è¨˜æ³•ä»•æ§˜",
                ],
                "outdated_markers": ["TODO", "FIXME", "v1.", "alpha-", "beta-"],
            },
            "optimization": {
                "enabled": True,
                "auto_fix": False,
                "backup_before_fix": True,
            },
        }

        config_path = Path(".claude_md_config.yaml")
        if config_path.exists():
            with open(config_path, "r", encoding="utf-8") as f:
                user_config = yaml.safe_load(f)
                default_config.update(user_config)

        return default_config

    def analyze(self) -> Tuple[CLAUDEmdMetrics, List[StructureIssue]]:
        """Phase 2: æ§‹é€ åŒ–åˆ†æ"""
        if not os.path.exists(self.claude_md_path):
            raise FileNotFoundError(f"{self.claude_md_path} not found")

        with open(self.claude_md_path, "r", encoding="utf-8") as f:
            content = f.read()

        lines = content.splitlines()
        metrics = CLAUDEmdMetrics(
            timestamp=datetime.now().isoformat(),
            lines=len(lines),
            bytes=len(content.encode("utf-8")),
            sections=content.count("#"),
            deep_nesting=content.count("####"),
            duplicates=0,
            long_sections=0,
            outdated_markers=0,
        )

        issues = []

        # å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ç¢ºèª
        for section in self.config["structure"]["required_sections"]:
            if section not in content:
                issues.append(
                    StructureIssue(
                        type="missing_section",
                        severity="critical",
                        line=None,
                        description=f"å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ä¸åœ¨: {section}",
                        suggestion=f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ '{section}' ã‚’è¿½åŠ ã—ã¦ãã ã•ã„",
                    )
                )

        # é‡è¤‡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¤œå‡º
        seen_lines = {}
        for i, line in enumerate(lines):
            if line.strip() and not line.startswith("#"):
                if line in seen_lines:
                    metrics.duplicates += 1
                    issues.append(
                        StructureIssue(
                            type="duplicate_content",
                            severity="warning",
                            line=i + 1,
                            description=f"é‡è¤‡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„: {line[:50]}...",
                            suggestion="é‡è¤‡ã™ã‚‹å†…å®¹ã‚’çµ±åˆã¾ãŸã¯å‰Šé™¤",
                        )
                    )
                else:
                    seen_lines[line] = i + 1

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³é•·åˆ†æ
        sections = re.split(r"^(#+\s.*)", content, flags=re.MULTILINE)
        for i in range(1, len(sections), 2):
            if i + 1 < len(sections):
                title = sections[i].strip()
                body = sections[i + 1]
                section_lines = len(body.splitlines())

                if section_lines > self.config["limits"]["max_section_lines"]:
                    metrics.long_sections += 1
                    issues.append(
                        StructureIssue(
                            type="long_section",
                            severity="warning",
                            line=None,
                            description=f"é•·å¤§ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ({section_lines}è¡Œ): {title[:30]}...",
                            suggestion=f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’{self.config['limits']['max_section_lines']}è¡Œä»¥å†…ã«åˆ†å‰²",
                        )
                    )

        # å¤ã„ãƒãƒ¼ã‚«ãƒ¼æ¤œå‡º
        for marker in self.config["structure"]["outdated_markers"]:
            if marker in content:
                metrics.outdated_markers += 1
                issues.append(
                    StructureIssue(
                        type="outdated_marker",
                        severity="info",
                        line=None,
                        description=f"å¤ã„ãƒãƒ¼ã‚«ãƒ¼æ¤œå‡º: {marker}",
                        suggestion="å¤ã„æƒ…å ±ã‚’æ›´æ–°ã¾ãŸã¯å‰Šé™¤",
                    )
                )

        return metrics, issues

    def optimize(self, auto_fix: bool = False) -> List[str]:
        """Phase 2: è‡ªå‹•æœ€é©åŒ–ææ¡ˆãƒ»å®Ÿè¡Œï¼ˆæ®µéšåˆ¶é™å¯¾å¿œï¼‰"""
        metrics, issues = self.analyze()
        suggestions = []

        # é‡è¤‡çµ±åˆææ¡ˆ
        if metrics.duplicates > 0:
            suggestions.append(f"ğŸ”„ {metrics.duplicates}å€‹ã®é‡è¤‡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„çµ±åˆã‚’æ¨å¥¨")

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²ææ¡ˆ
        if metrics.long_sections > 0:
            suggestions.append(
                f"âœ‚ï¸  {metrics.long_sections}å€‹ã®é•·å¤§ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²ã‚’æ¨å¥¨"
            )

        # å¤ã„æƒ…å ±æ›´æ–°ææ¡ˆ
        if metrics.outdated_markers > 0:
            suggestions.append(
                f"ğŸ• {metrics.outdated_markers}å€‹ã®å¤ã„ãƒãƒ¼ã‚«ãƒ¼æ›´æ–°ã‚’æ¨å¥¨"
            )

        # æ®µéšåˆ¶é™ãƒã‚§ãƒƒã‚¯
        limits = self.config["limits"]

        # ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«åˆ¶é™
        if metrics.lines > limits["critical"]["lines"]:
            suggestions.append(
                f"ğŸš¨ è¡Œæ•°ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«åˆ¶é™è¶…é ({metrics.lines}/{limits['critical']['lines']}) - å³åº§ã«å†…å®¹å‰Šæ¸›ãŒå¿…è¦"
            )
        elif metrics.bytes > limits["critical"]["bytes"]:
            suggestions.append(
                f"ğŸš¨ ã‚µã‚¤ã‚ºã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«åˆ¶é™è¶…é ({metrics.bytes}B/{limits['critical']['bytes']}B) - å³åº§ã«åœ§ç¸®ãŒå¿…è¦"
            )

        # æ³¨æ„åˆ¶é™
        elif metrics.lines > limits["caution"]["lines"]:
            suggestions.append(
                f"âš ï¸ è¡Œæ•°æ³¨æ„åˆ¶é™è¶…é ({metrics.lines}/{limits['caution']['lines']}) - å†…å®¹å‰Šæ¸›ã‚’æ¤œè¨"
            )
        elif metrics.bytes > limits["caution"]["bytes"]:
            suggestions.append(
                f"âš ï¸ ã‚µã‚¤ã‚ºæ³¨æ„åˆ¶é™è¶…é ({metrics.bytes}B/{limits['caution']['bytes']}B) - åœ§ç¸®ã‚’æ¤œè¨"
            )

        # è­¦å‘Šåˆ¶é™
        elif metrics.lines > limits["warning"]["lines"]:
            suggestions.append(
                f"ğŸ’¡ è¡Œæ•°è­¦å‘Šåˆ¶é™è¶…é ({metrics.lines}/{limits['warning']['lines']}) - è¦‹ç›´ã—ã‚’æ¨å¥¨"
            )
        elif metrics.bytes > limits["warning"]["bytes"]:
            suggestions.append(
                f"ğŸ’¡ ã‚µã‚¤ã‚ºè­¦å‘Šåˆ¶é™è¶…é ({metrics.bytes}B/{limits['warning']['bytes']}B) - æœ€é©åŒ–ã‚’æ¨å¥¨"
            )

        # æ¨å¥¨åˆ¶é™ï¼ˆæƒ…å ±æä¾›ï¼‰
        elif metrics.lines > limits["recommended_lines"]:
            suggestions.append(
                f"ğŸ“ æ¨å¥¨è¡Œæ•°è¶…é ({metrics.lines}/{limits['recommended_lines']}) - å“è³ªç¶­æŒã®ãŸã‚çŸ­ç¸®ã‚’æ¤œè¨"
            )
        elif metrics.bytes > limits["recommended_bytes"]:
            suggestions.append(
                f"ğŸ“¦ æ¨å¥¨ã‚µã‚¤ã‚ºè¶…é ({metrics.bytes}B/{limits['recommended_bytes']}B) - ã‚ˆã‚Šç°¡æ½”ãªè¨˜è¿°ã‚’æ¤œè¨"
            )

        # è‡ªå‹•ä¿®æ­£å®Ÿè¡Œ
        if auto_fix and self.config["optimization"]["auto_fix"]:
            if self.config["optimization"]["backup_before_fix"]:
                self._backup_file()
            suggestions.extend(self._auto_fix_issues(issues))

        return suggestions

    def _backup_file(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        backup_path = (
            f"{self.claude_md_path}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        )
        import shutil

        shutil.copy2(self.claude_md_path, backup_path)
        print(f"ğŸ“‹ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_path}")

    def _auto_fix_issues(self, issues: List[StructureIssue]) -> List[str]:
        """è‡ªå‹•ä¿®æ­£å®Ÿè¡Œ"""
        fixes = []

        with open(self.claude_md_path, "r", encoding="utf-8") as f:
            content = f.read()

        # ç°¡å˜ãªä¿®æ­£ã®ã¿å®Ÿè£…ï¼ˆå®‰å…¨æ€§é‡è¦–ï¼‰
        original_content = content

        # æœ«å°¾ç©ºç™½å‰Šé™¤
        content = re.sub(r" +$", "", content, flags=re.MULTILINE)
        if content != original_content:
            fixes.append("ğŸ§¹ æœ«å°¾ç©ºç™½ã‚’è‡ªå‹•å‰Šé™¤")

        # ç©ºè¡Œæ­£è¦åŒ–
        content = re.sub(r"\n{3,}", "\n\n", content)
        if content != original_content:
            fixes.append("ğŸ“ ç©ºè¡Œã‚’æ­£è¦åŒ–")

        if fixes:
            with open(self.claude_md_path, "w", encoding="utf-8") as f:
                f.write(content)

        return fixes

    def generate_dashboard(self) -> Dict:
        """Phase 3: ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆ"""
        metrics, issues = self.analyze()

        dashboard = {
            "timestamp": datetime.now().isoformat(),
            "status": self._get_overall_status(metrics, issues),
            "metrics": asdict(metrics),
            "issues": {
                "critical": len([i for i in issues if i.severity == "critical"]),
                "warning": len([i for i in issues if i.severity == "warning"]),
                "info": len([i for i in issues if i.severity == "info"]),
            },
            "trends": self._get_size_trends(),
            "recommendations": self.optimize(),
        }

        return dashboard

    def _get_overall_status(
        self, metrics: CLAUDEmdMetrics, issues: List[StructureIssue]
    ) -> str:
        """ç·åˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®šï¼ˆæ®µéšåˆ¶é™ã‚·ã‚¹ãƒ†ãƒ å¯¾å¿œï¼‰"""
        limits = self.config["limits"]

        # ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«å•é¡Œãƒã‚§ãƒƒã‚¯
        critical_issues = [i for i in issues if i.severity == "critical"]
        if critical_issues:
            return "ğŸš¨ CRITICAL"

        # ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«åˆ¶é™ãƒã‚§ãƒƒã‚¯
        if (
            metrics.lines > limits["critical"]["lines"]
            or metrics.bytes > limits["critical"]["bytes"]
        ):
            return "ğŸš¨ CRITICAL"

        # æ³¨æ„åˆ¶é™ãƒã‚§ãƒƒã‚¯
        if (
            metrics.lines > limits["caution"]["lines"]
            or metrics.bytes > limits["caution"]["bytes"]
        ):
            return "âš ï¸ CAUTION"

        # è­¦å‘Šåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if (
            metrics.lines > limits["warning"]["lines"]
            or metrics.bytes > limits["warning"]["bytes"]
        ):
            return "âš ï¸ WARNING"

        # è­¦å‘Šå•é¡Œãƒã‚§ãƒƒã‚¯
        warning_issues = [i for i in issues if i.severity == "warning"]
        if warning_issues:
            return "âš ï¸ WARNING"

        # æ¨å¥¨åˆ¶é™ãƒã‚§ãƒƒã‚¯ï¼ˆæƒ…å ±ãƒ¬ãƒ™ãƒ«ï¼‰
        if (
            metrics.lines > limits["recommended_lines"]
            or metrics.bytes > limits["recommended_bytes"]
        ):
            return "ğŸ’¡ INFO"

        return "âœ… GOOD"

    def _get_size_trends(self) -> List[Dict]:
        """ã‚µã‚¤ã‚ºæ¨ç§»å–å¾—"""
        # å®Ÿè£…ç°¡ç•¥åŒ–: å˜ç´”ãªå±¥æ­´ç®¡ç†
        history_file = Path(".claude_md_history.json")
        if not history_file.exists():
            return []

        try:
            with open(history_file, "r", encoding="utf-8") as f:
                return json.load(f)[-10:]  # æœ€æ–°10ä»¶
        except:
            return []

    def save_metrics(self, metrics: CLAUDEmdMetrics):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´ä¿å­˜"""
        history_file = Path(".claude_md_history.json")
        history = []

        if history_file.exists():
            try:
                with open(history_file, "r", encoding="utf-8") as f:
                    history = json.load(f)
            except:
                history = []

        history.append(asdict(metrics))

        # æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
        if len(history) > 100:
            history = history[-100:]

        with open(history_file, "w", encoding="utf-8") as f:
            json.dump(history, f, indent=2, ensure_ascii=False)


def main():
    """CLI ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    import argparse
    from pathlib import Path

    parser = argparse.ArgumentParser(description="CLAUDE.md Management System")
    parser.add_argument(
        "command", choices=["check", "analyze", "optimize", "dashboard"]
    )
    parser.add_argument("--auto-fix", action="store_true", help="è‡ªå‹•ä¿®æ­£å®Ÿè¡Œ")
    parser.add_argument("--output", help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument(
        "--claude-md", default="CLAUDE.md", help="CLAUDE.mdãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"
    )

    args = parser.parse_args()

    manager = CLAUDEmdManager(args.claude_md)

    try:
        if args.command == "check":
            metrics, issues = manager.analyze()

            print(f"ğŸ“Š CLAUDE.md Statistics:")
            print(f"   Lines: {metrics.lines}")
            print(f"   Bytes: {metrics.bytes} ({metrics.bytes/1024:.1f}KB)")
            print(f"   Sections: {metrics.sections}")
            print(f"   Deep nesting: {metrics.deep_nesting}")

            if issues:
                print(f"\nğŸ” Issues Found ({len(issues)}):")
                for issue in issues:
                    severity_icon = {"critical": "ğŸš¨", "warning": "âš ï¸", "info": "â„¹ï¸"}
                    print(f"   {severity_icon[issue.severity]} {issue.description}")

            manager.save_metrics(metrics)

            # çµ‚äº†ã‚³ãƒ¼ãƒ‰åˆ¤å®š
            critical = [i for i in issues if i.severity == "critical"]
            sys.exit(1 if critical else 0)

        elif args.command == "analyze":
            metrics, issues = manager.analyze()
            result = {"metrics": asdict(metrics), "issues": [asdict(i) for i in issues]}

            if args.output:
                # tmp/é…ä¸‹ã«ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
                tmp_dir = Path("tmp")
                tmp_dir.mkdir(exist_ok=True)
                output_path = tmp_dir / Path(args.output).name

                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump(result, f, indent=2, ensure_ascii=False)
                print(f"ğŸ“„ åˆ†æçµæœã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")
            else:
                print(json.dumps(result, indent=2, ensure_ascii=False))

        elif args.command == "optimize":
            suggestions = manager.optimize(auto_fix=args.auto_fix)

            print("ğŸ’¡ æœ€é©åŒ–ææ¡ˆ:")
            for suggestion in suggestions:
                print(f"   - {suggestion}")

            if args.output:
                # tmp/é…ä¸‹ã«ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
                tmp_dir = Path("tmp")
                tmp_dir.mkdir(exist_ok=True)
                output_path = tmp_dir / Path(args.output).name

                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump(
                        {"suggestions": suggestions}, f, indent=2, ensure_ascii=False
                    )
                print(f"ğŸ“„ æœ€é©åŒ–çµæœã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")

        elif args.command == "dashboard":
            dashboard_data = manager.generate_dashboard()

            print("ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆå®Œäº†:")
            print(f"   Status: {dashboard_data['status']}")
            print(
                f"   Issues: Critical={dashboard_data['issues']['critical']}, "
                f"Warning={dashboard_data['issues']['warning']}, "
                f"Info={dashboard_data['issues']['info']}"
            )

            if args.output:
                # tmp/é…ä¸‹ã«ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
                tmp_dir = Path("tmp")
                tmp_dir.mkdir(exist_ok=True)
                output_path = tmp_dir / Path(args.output).name

                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump(dashboard_data, f, indent=2, ensure_ascii=False)
                print(f"ğŸ“„ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")

    except FileNotFoundError:
        print(f"âŒ {args.claude_md} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        import traceback

        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", file=sys.stderr)
        print("è©³ç´°:", file=sys.stderr)
        traceback.print_exc(file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
