#!/usr/bin/env python3
"""
TDDæ ¹æœ¬åŽŸå› åˆ†æžã‚¹ã‚¯ãƒªãƒ—ãƒˆ

245ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆä¸è¶³å•é¡Œã‚’åˆ†æžã—ã€åˆ†é¡žãƒ»å„ªå…ˆé †ä½ä»˜ã‘ã‚’è¡Œã„ã¾ã™ã€‚
æ ¹æœ¬çš„æ”¹å–„ç­–ã®ç­–å®šã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import os
import re
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Tuple


class TDDRootCauseAnalyzer:
    """TDDæ ¹æœ¬åŽŸå› åˆ†æžã‚¯ãƒ©ã‚¹"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.untested_files = []
        self.analysis_results = {}

    def collect_untested_files(self) -> List[Path]:
        """ãƒ†ã‚¹ãƒˆä¸è¶³ãƒ•ã‚¡ã‚¤ãƒ«ã®åŽé›†"""
        # æ—¢å­˜ã®åˆ†æžçµæžœãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
        try:
            with open("tdd_analysis.txt", "r", encoding="utf-8") as f:
                content = f.read()

            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®æŠ½å‡º
            pattern = r"ðŸ“„ (kumihan_formatter/[^\n]+\.py)"
            matches = re.findall(pattern, content)

            self.untested_files = [Path(match) for match in matches]
            return self.untested_files
        except FileNotFoundError:
            print("âš ï¸  tdd_analysis.txt not found. Generating new analysis...")
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æž
            result = os.popen(
                "python3 scripts/enforce_tdd.py kumihan_formatter/"
            ).read()

            pattern = r"ðŸ“„ (kumihan_formatter/[^\n]+\.py)"
            matches = re.findall(pattern, result)

            self.untested_files = [Path(match) for match in matches]
            return self.untested_files

    def categorize_files(self) -> Dict[str, List[Path]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«åˆ†é¡ž"""
        categories = {
            "GUIé–¢é€£": [],
            "Coreæ©Ÿèƒ½": [],
            "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ç³»": [],
            "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°": [],
            "ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£": [],
            "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³": [],
            "ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°": [],
            "ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°": [],
            "æ§‹æ–‡è§£æž": [],
            "ã‚³ãƒžãƒ³ãƒ‰ç³»": [],
            "ãã®ä»–": [],
        }

        for file_path in self.untested_files:
            path_str = str(file_path)

            if "gui_" in path_str or "ui/" in path_str:
                categories["GUIé–¢é€£"].append(file_path)
            elif "/performance/" in path_str:
                categories["ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ç³»"].append(file_path)
            elif "/error_handling/" in path_str:
                categories["ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"].append(file_path)
            elif "/utilities/" in path_str or "/utils/" in path_str:
                categories["ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"].append(file_path)
            elif "/validators/" in path_str or "validator" in path_str:
                categories["ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"].append(file_path)
            elif "/rendering/" in path_str or "renderer" in path_str:
                categories["ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"].append(file_path)
            elif "/caching/" in path_str or "cache" in path_str:
                categories["ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°"].append(file_path)
            elif "/syntax/" in path_str or "parser" in path_str:
                categories["æ§‹æ–‡è§£æž"].append(file_path)
            elif "/commands/" in path_str:
                categories["ã‚³ãƒžãƒ³ãƒ‰ç³»"].append(file_path)
            elif "/core/" in path_str:
                categories["Coreæ©Ÿèƒ½"].append(file_path)
            else:
                categories["ãã®ä»–"].append(file_path)

        return categories

    def analyze_complexity(self, file_path: Path) -> Dict[str, int]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®è¤‡é›‘ã•åˆ†æž"""
        try:
            content = file_path.read_text(encoding="utf-8")

            # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            lines = len(content.splitlines())
            classes = len(re.findall(r"^class\s+\w+", content, re.MULTILINE))
            functions = len(re.findall(r"^def\s+\w+", content, re.MULTILINE))
            imports = len(re.findall(r"^(import|from)\s+", content, re.MULTILINE))

            # è¤‡é›‘åº¦æŒ‡æ¨™
            if_statements = len(re.findall(r"\bif\b", content))
            try_blocks = len(re.findall(r"\btry\b", content))
            async_funcs = len(re.findall(r"async def", content))

            return {
                "lines": lines,
                "classes": classes,
                "functions": functions,
                "imports": imports,
                "if_statements": if_statements,
                "try_blocks": try_blocks,
                "async_funcs": async_funcs,
                "complexity_score": lines
                + classes * 10
                + functions * 5
                + if_statements * 2,
            }
        except Exception:
            return {
                "lines": 0,
                "classes": 0,
                "functions": 0,
                "imports": 0,
                "if_statements": 0,
                "try_blocks": 0,
                "async_funcs": 0,
                "complexity_score": 0,
            }

    def prioritize_by_business_value(
        self, categories: Dict[str, List[Path]]
    ) -> Dict[str, int]:
        """ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã«ã‚ˆã‚‹å„ªå…ˆé †ä½ä»˜ã‘"""
        priority_map = {
            "Coreæ©Ÿèƒ½": 10,  # æœ€é‡è¦ï¼šã‚·ã‚¹ãƒ†ãƒ ã®ä¸­æ ¸æ©Ÿèƒ½
            "ã‚³ãƒžãƒ³ãƒ‰ç³»": 9,  # é‡è¦ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼ç›´æŽ¥æ“ä½œ
            "æ§‹æ–‡è§£æž": 8,  # é‡è¦ï¼šä¸»è¦æ©Ÿèƒ½
            "ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°": 7,  # ä¸­é‡è¦ï¼šå‡ºåŠ›å“è³ª
            "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³": 6,  # ä¸­é‡è¦ï¼šå“è³ªä¿è¨¼
            "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°": 5,  # ä¸­é‡è¦ï¼šå®‰å®šæ€§
            "ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£": 4,  # ä½Žé‡è¦ï¼šè£œåŠ©æ©Ÿèƒ½
            "ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°": 3,  # ä½Žé‡è¦ï¼šãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹
            "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ç³»": 2,  # ä½Žé‡è¦ï¼šæœ€é©åŒ–
            "GUIé–¢é€£": 1,  # æœ€ä½Žï¼šUIã¯æ‰‹å‹•ãƒ†ã‚¹ãƒˆä¸»ä½“
            "ãã®ä»–": 1,
        }
        return priority_map

    def calculate_test_effort(self, file_path: Path, complexity: Dict[str, int]) -> int:
        """ãƒ†ã‚¹ãƒˆä½œæˆå·¥æ•°ã®è¦‹ç©ã‚‚ã‚Šï¼ˆæ™‚é–“å˜ä½ï¼‰"""
        base_effort = 2  # åŸºæœ¬å·¥æ•° 2æ™‚é–“

        # è¤‡é›‘åº¦ã«ã‚ˆã‚‹ä¿‚æ•°
        complexity_factor = min(complexity["complexity_score"] / 100, 3.0)

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹ä¿‚æ•°
        path_str = str(file_path)
        if "gui_" in path_str or "/ui/" in path_str:
            type_factor = 3.0  # GUI ã¯3å€å›°é›£
        elif "/performance/" in path_str:
            type_factor = 2.5  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹æ¸¬å®šãŒå¿…è¦
        elif "/error_handling/" in path_str:
            type_factor = 2.0  # ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ãŒå¤šã„
        else:
            type_factor = 1.0

        return int(base_effort * complexity_factor * type_factor)

    def generate_improvement_plan(self) -> Dict:
        """æ®µéšŽçš„æ”¹å–„è¨ˆç”»ã®ç”Ÿæˆ"""
        categories = self.categorize_files()
        priorities = self.prioritize_by_business_value(categories)

        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æž
        file_analysis = []
        for category, files in categories.items():
            for file_path in files:
                complexity = self.analyze_complexity(file_path)
                effort = self.calculate_test_effort(file_path, complexity)

                file_analysis.append(
                    {
                        "file": file_path,
                        "category": category,
                        "priority": priorities[category],
                        "complexity": complexity,
                        "effort_hours": effort,
                        "test_type": self._recommend_test_type(file_path, complexity),
                    }
                )

        # å„ªå…ˆé †ä½ã§ã‚½ãƒ¼ãƒˆ
        file_analysis.sort(key=lambda x: (-x["priority"], x["effort_hours"]))

        # é€±æ¬¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç”Ÿæˆï¼ˆé€±20æ™‚é–“æƒ³å®šï¼‰
        weekly_schedule = self._generate_weekly_schedule(
            file_analysis, hours_per_week=20
        )

        return {
            "total_files": len(self.untested_files),
            "categories": {cat: len(files) for cat, files in categories.items()},
            "total_estimated_hours": sum(
                item["effort_hours"] for item in file_analysis
            ),
            "file_analysis": file_analysis,
            "weekly_schedule": weekly_schedule,
            "recommendations": self._generate_recommendations(
                categories, file_analysis
            ),
        }

    def _recommend_test_type(self, file_path: Path, complexity: Dict[str, int]) -> str:
        """æŽ¨å¥¨ãƒ†ã‚¹ãƒˆã‚¿ã‚¤ãƒ—ã®æ±ºå®š"""
        path_str = str(file_path)

        if "gui_" in path_str or "/ui/" in path_str:
            return "Manual/E2E"  # GUI ã¯æ‰‹å‹•ãƒ»E2Eãƒ†ã‚¹ãƒˆä¸»ä½“
        elif complexity["classes"] > 3 or complexity["functions"] > 10:
            return "Unit + Integration"  # è¤‡é›‘ãªã‚‚ã®ã¯ä¸¡æ–¹
        elif "/commands/" in path_str:
            return "Integration"  # ã‚³ãƒžãƒ³ãƒ‰ã¯çµ±åˆãƒ†ã‚¹ãƒˆ
        else:
            return "Unit"  # åŸºæœ¬ã¯ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

    def _generate_weekly_schedule(
        self, file_analysis: List[Dict], hours_per_week: int
    ) -> List[Dict]:
        """é€±æ¬¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ç”Ÿæˆ"""
        schedule = []
        current_week = 1
        current_hours = 0
        current_files = []

        for item in file_analysis:
            if current_hours + item["effort_hours"] > hours_per_week:
                # é€±ã®ä¸Šé™ã‚’è¶…ãˆã‚‹å ´åˆã€æ¬¡ã®é€±ã¸
                if current_files:
                    schedule.append(
                        {
                            "week": current_week,
                            "files": current_files.copy(),
                            "total_hours": current_hours,
                            "files_count": len(current_files),
                        }
                    )
                current_week += 1
                current_hours = 0
                current_files = []

            current_files.append(item)
            current_hours += item["effort_hours"]

        # æœ€å¾Œã®é€±ã‚’è¿½åŠ 
        if current_files:
            schedule.append(
                {
                    "week": current_week,
                    "files": current_files,
                    "total_hours": current_hours,
                    "files_count": len(current_files),
                }
            )

        return schedule

    def _generate_recommendations(
        self, categories: Dict[str, List[Path]], file_analysis: List[Dict]
    ) -> List[str]:
        """æ”¹å–„ææ¡ˆã®ç”Ÿæˆ"""
        recommendations = []

        # 1. GUIå•é¡Œã®è§£æ±ºææ¡ˆ
        gui_count = len(categories["GUIé–¢é€£"])
        if gui_count > 20:
            recommendations.append(
                f"GUIé–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«{gui_count}å€‹: E2Eãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å°Žå…¥ã‚’æ¤œè¨Ž"
            )

        # 2. é«˜è¤‡é›‘åº¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å¯¾ç­–
        high_complexity = [
            item
            for item in file_analysis
            if item["complexity"]["complexity_score"] > 300
        ]
        if high_complexity:
            recommendations.append(
                f"é«˜è¤‡é›‘åº¦ãƒ•ã‚¡ã‚¤ãƒ«{len(high_complexity)}å€‹: ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å„ªå…ˆæ¤œè¨Ž"
            )

        # 3. ã‚«ãƒ†ã‚´ãƒªåˆ¥å¯¾ç­–
        performance_count = len(categories["ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ç³»"])
        if performance_count > 30:
            recommendations.append(
                f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ç³»{performance_count}å€‹: ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆè‡ªå‹•åŒ–ã‚’æ¤œè¨Ž"
            )

        # 4. å·¥æ•°å‰Šæ¸›ææ¡ˆ
        total_hours = sum(item["effort_hours"] for item in file_analysis)
        if total_hours > 500:
            recommendations.append(
                f"ç·å·¥æ•°{total_hours}æ™‚é–“: ãƒ†ã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ»ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã®å°Žå…¥ã‚’æ¤œè¨Ž"
            )

        return recommendations


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    analyzer = TDDRootCauseAnalyzer(Path("."))

    print("ðŸ” TDDæ ¹æœ¬åŽŸå› åˆ†æžé–‹å§‹")
    print("=" * 50)

    # 1. ãƒ•ã‚¡ã‚¤ãƒ«åŽé›†
    untested_files = analyzer.collect_untested_files()
    print(f"ðŸ“Š ãƒ†ã‚¹ãƒˆä¸è¶³ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(untested_files)}")

    # 2. åŒ…æ‹¬çš„åˆ†æž
    analysis = analyzer.generate_improvement_plan()

    # 3. çµæžœå‡ºåŠ›
    print("\nðŸ“‹ ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æž:")
    for category, count in analysis["categories"].items():
        if count > 0:
            print(f"  {category}: {count}ãƒ•ã‚¡ã‚¤ãƒ«")

    print(f"\nâ±ï¸  ç·æŽ¨å®šå·¥æ•°: {analysis['total_estimated_hours']}æ™‚é–“")
    print(f"ðŸ“… äºˆæƒ³å®Œäº†æœŸé–“: {len(analysis['weekly_schedule'])}é€±é–“")

    print("\nðŸŽ¯ æ”¹å–„ææ¡ˆ:")
    for rec in analysis["recommendations"]:
        print(f"  â€¢ {rec}")

    print("\nðŸ“ é€±æ¬¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆæœ€åˆ5é€±é–“ï¼‰:")
    for week_data in analysis["weekly_schedule"][:5]:
        print(
            f"  Week {week_data['week']}: {week_data['files_count']}ãƒ•ã‚¡ã‚¤ãƒ« ({week_data['total_hours']}æ™‚é–“)"
        )
        for file_info in week_data["files"][:3]:  # ä¸Šä½3ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿è¡¨ç¤º
            print(
                f"    - {file_info['file'].name} ({file_info['category']}, {file_info['effort_hours']}h)"
            )
        if len(week_data["files"]) > 3:
            print(f"    ... ä»– {len(week_data['files']) - 3}ãƒ•ã‚¡ã‚¤ãƒ«")
        print()


if __name__ == "__main__":
    main()
