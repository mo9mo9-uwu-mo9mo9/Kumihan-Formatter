#!/usr/bin/env python3
"""
Resource Manager - Critical Memory Leak Fix
ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

ç›®çš„: é•·æ™‚é–“å®Ÿè¡Œæ™‚ã®ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯é˜²æ­¢
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
- è‡ªå‹•ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
- å¾ªç’°å‚ç…§è§£æ¶ˆ
- ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æœ€é©åŒ–
"""

import gc
import psutil
import threading
import time
import weakref
from pathlib import Path
from typing import Dict, List, Optional, Any, Callable, Set
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import deque
from contextlib import contextmanager
import logging

from kumihan_formatter.core.utilities.logger import get_logger

logger = get_logger(__name__)

@dataclass
class MemorySnapshot:
    """ãƒ¡ãƒ¢ãƒªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ"""
    timestamp: datetime
    process_memory: float  # MB
    python_objects: int
    gc_collections: Dict[int, int]
    active_threads: int
    open_files: int

@dataclass
class ResourceLeak:
    """ãƒªã‚½ãƒ¼ã‚¹ãƒªãƒ¼ã‚¯æƒ…å ±"""
    resource_type: str
    leak_count: int
    leak_rate: float  # per minute
    first_detected: datetime
    severity: str  # "low", "medium", "high", "critical"

class CircularReferenceTracker:
    """å¾ªç’°å‚ç…§è¿½è·¡ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self._tracked_objects = weakref.WeakSet()
        self._reference_graph = {}
        self._lock = threading.RLock()
    
    def track_object(self, obj: Any, name: str = None):
        """ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆè¿½è·¡é–‹å§‹"""
        with self._lock:
            self._tracked_objects.add(obj)
            if name:
                self._reference_graph[id(obj)] = {
                    'name': name,
                    'type': type(obj).__name__,
                    'created': datetime.now(),
                    'refs': []
                }
    
    def find_circular_references(self) -> List[Dict]:
        """å¾ªç’°å‚ç…§æ¤œå‡º"""
        with self._lock:
            circular_refs = []
            
            # GCã«ã‚ˆã‚‹å¾ªç’°å‚ç…§æ¤œå‡º
            gc.collect()  # å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            
            for generation in range(3):
                objects = gc.get_objects(generation)
                for obj in objects:
                    if gc.is_tracked(obj):
                        refs = gc.get_referents(obj)
                        for ref in refs:
                            if ref is obj:  # è‡ªå·±å‚ç…§
                                circular_refs.append({
                                    'type': 'self_reference',
                                    'object_type': type(obj).__name__,
                                    'object_id': id(obj),
                                    'generation': generation
                                })
            
            return circular_refs

class MemoryManager:
    """ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, max_memory_mb: int = 512, check_interval: int = 30):
        self.max_memory_mb = max_memory_mb
        self.check_interval = check_interval
        self.process = psutil.Process()
        
        # ãƒ¡ãƒ¢ãƒªå±¥æ­´ï¼ˆæœ€å¤§1000ä»¶ï¼‰
        self.memory_history = deque(maxlen=1000)
        
        # ãƒªã‚½ãƒ¼ã‚¹è¿½è·¡
        self.tracked_resources = {}
        self.resource_callbacks = {}
        
        # å¾ªç’°å‚ç…§è¿½è·¡
        self.circular_tracker = CircularReferenceTracker()
        
        # ç›£è¦–çŠ¶æ…‹
        self.monitoring = False
        self.monitor_thread = None
        self._lock = threading.RLock()
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
        self.memory_thresholds = {
            'warning': max_memory_mb * 0.7,
            'critical': max_memory_mb * 0.9
        }
        
        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è¨­å®šæœ€é©åŒ–
        self._optimize_gc_settings()
    
    def start_monitoring(self):
        """ãƒ¡ãƒ¢ãƒªç›£è¦–é–‹å§‹"""
        if self.monitoring:
            return
            
        logger.info("ğŸ” ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚’é–‹å§‹...")
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """ãƒ¡ãƒ¢ãƒªç›£è¦–åœæ­¢"""
        logger.info("ğŸ›‘ ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚’åœæ­¢...")
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
    
    def _monitor_loop(self):
        """ãƒ¡ãƒ¢ãƒªç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        while self.monitoring:
            try:
                snapshot = self._create_memory_snapshot()
                self.memory_history.append(snapshot)
                
                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
                self._check_memory_usage(snapshot)
                
                # ãƒªã‚½ãƒ¼ã‚¹ãƒªãƒ¼ã‚¯æ¤œå‡º
                leaks = self._detect_resource_leaks()
                if leaks:
                    self._handle_resource_leaks(leaks)
                
                # å¾ªç’°å‚ç…§æ¤œå‡º
                circular_refs = self.circular_tracker.find_circular_references()
                if circular_refs:
                    logger.warning(f"å¾ªç’°å‚ç…§æ¤œå‡º: {len(circular_refs)}ä»¶")
                
                time.sleep(self.check_interval)
                
            except Exception as e:
                logger.error(f"ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(self.check_interval)
    
    def _create_memory_snapshot(self) -> MemorySnapshot:
        """ãƒ¡ãƒ¢ãƒªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆ"""
        try:
            memory_info = self.process.memory_info()
            process_memory = memory_info.rss / 1024 / 1024  # MB
            
            # Pythonã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°
            python_objects = len(gc.get_objects())
            
            # GCçµ±è¨ˆ
            gc_stats = {}
            for i in range(3):
                gc_stats[i] = gc.get_count()[i]
            
            # ã‚¹ãƒ¬ãƒƒãƒ‰æ•°
            active_threads = threading.active_count()
            
            # ã‚ªãƒ¼ãƒ—ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«æ•°
            try:
                open_files = len(self.process.open_files())
            except (psutil.AccessDenied, AttributeError):
                open_files = 0
            
            return MemorySnapshot(
                timestamp=datetime.now(),
                process_memory=process_memory,
                python_objects=python_objects,
                gc_collections=gc_stats,
                active_threads=active_threads,
                open_files=open_files
            )
            
        except Exception as e:
            logger.error(f"ãƒ¡ãƒ¢ãƒªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆå¤±æ•—: {e}")
            return MemorySnapshot(
                timestamp=datetime.now(),
                process_memory=0,
                python_objects=0,
                gc_collections={},
                active_threads=0,
                open_files=0
            )
    
    def _check_memory_usage(self, snapshot: MemorySnapshot):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯"""
        memory_mb = snapshot.process_memory
        
        if memory_mb >= self.memory_thresholds['critical']:
            logger.critical(f"ğŸš¨ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå±é™ºãƒ¬ãƒ™ãƒ«: {memory_mb:.1f}MB")
            self._emergency_memory_cleanup()
            
        elif memory_mb >= self.memory_thresholds['warning']:
            logger.warning(f"âš ï¸ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒè­¦å‘Šãƒ¬ãƒ™ãƒ«: {memory_mb:.1f}MB")
            self._preventive_memory_cleanup()
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ãƒˆãƒ¬ãƒ³ãƒ‰ç›£è¦–
        if len(self.memory_history) >= 10:
            recent_snapshots = list(self.memory_history)[-10:]
            memory_trend = self._calculate_memory_trend(recent_snapshots)
            
            if memory_trend > 2.0:  # 2MB/åˆ†ä»¥ä¸Šã®å¢—åŠ 
                logger.warning(f"ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ç–‘ã„: å¢—åŠ ç‡ {memory_trend:.2f}MB/åˆ†")
    
    def _calculate_memory_trend(self, snapshots: List[MemorySnapshot]) -> float:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—"""
        if len(snapshots) < 2:
            return 0.0
        
        time_diff = (snapshots[-1].timestamp - snapshots[0].timestamp).total_seconds() / 60  # åˆ†
        memory_diff = snapshots[-1].process_memory - snapshots[0].process_memory
        
        return memory_diff / max(time_diff, 1)
    
    def _detect_resource_leaks(self) -> List[ResourceLeak]:
        """ãƒªã‚½ãƒ¼ã‚¹ãƒªãƒ¼ã‚¯æ¤œå‡º"""
        leaks = []
        
        if len(self.memory_history) < 5:
            return leaks
        
        recent_snapshots = list(self.memory_history)[-5:]
        
        # Pythonã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°ã®å¢—åŠ ãƒã‚§ãƒƒã‚¯
        object_counts = [s.python_objects for s in recent_snapshots]
        if len(set(object_counts)) > 1:  # å¤‰åŒ–ãŒã‚ã‚‹å ´åˆ
            object_increase = object_counts[-1] - object_counts[0]
            if object_increase > 1000:  # 1000ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä»¥ä¸Šå¢—åŠ 
                time_diff = (recent_snapshots[-1].timestamp - recent_snapshots[0].timestamp).total_seconds() / 60
                leak_rate = object_increase / max(time_diff, 1)
                
                severity = "critical" if leak_rate > 100 else "high" if leak_rate > 50 else "medium"
                
                leaks.append(ResourceLeak(
                    resource_type="python_objects",
                    leak_count=object_increase,
                    leak_rate=leak_rate,
                    first_detected=recent_snapshots[0].timestamp,
                    severity=severity
                ))
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã®å¢—åŠ ãƒã‚§ãƒƒã‚¯
        thread_counts = [s.active_threads for s in recent_snapshots]
        thread_increase = thread_counts[-1] - thread_counts[0]
        if thread_increase > 5:  # 5ã‚¹ãƒ¬ãƒƒãƒ‰ä»¥ä¸Šå¢—åŠ 
            leaks.append(ResourceLeak(
                resource_type="threads",
                leak_count=thread_increase,
                leak_rate=thread_increase,
                first_detected=recent_snapshots[0].timestamp,
                severity="high"
            ))
        
        return leaks
    
    def _handle_resource_leaks(self, leaks: List[ResourceLeak]):
        """ãƒªã‚½ãƒ¼ã‚¹ãƒªãƒ¼ã‚¯å¯¾å¿œ"""
        for leak in leaks:
            logger.error(f"ãƒªã‚½ãƒ¼ã‚¹ãƒªãƒ¼ã‚¯æ¤œå‡º: {leak.resource_type} (+{leak.leak_count}, {leak.leak_rate:.1f}/min)")
            
            if leak.severity in ['critical', 'high']:
                if leak.resource_type == "python_objects":
                    self._aggressive_memory_cleanup()
                elif leak.resource_type == "threads":
                    self._cleanup_dead_threads()
    
    def _emergency_memory_cleanup(self):
        """ç·Šæ€¥ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        logger.warning("ğŸš¨ ç·Šæ€¥ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ...")
        
        # å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        collected = gc.collect()
        logger.info(f"ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {collected}ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å›å")
        
        # ç™»éŒ²ã•ã‚ŒãŸã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
        for resource_type, callback in self.resource_callbacks.items():
            try:
                callback()
                logger.info(f"{resource_type} ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
            except Exception as e:
                logger.error(f"{resource_type} ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—: {e}")
        
        # ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æ”¾
        self._release_memory_maps()
    
    def _preventive_memory_cleanup(self):
        """äºˆé˜²çš„ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        logger.info("ğŸ§¹ äºˆé˜²çš„ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ...")
        
        # è»½é‡ãªã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        gc.collect(1)  # ä¸–ä»£1ã¾ã§
        
        # å¤ã„ãƒ¡ãƒ¢ãƒªå±¥æ­´å‰Šé™¤
        if len(self.memory_history) > 500:
            # å¤ã„åŠåˆ†ã‚’å‰Šé™¤
            for _ in range(len(self.memory_history) // 2):
                self.memory_history.popleft()
    
    def _aggressive_memory_cleanup(self):
        """ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        logger.warning("ğŸ’£ ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ...")
        
        # å…¨ä¸–ä»£ã®ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        for generation in range(3):
            collected = gc.collect(generation)
            logger.debug(f"ä¸–ä»£{generation} GC: {collected}ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå›å")
        
        # å¼±å‚ç…§ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        weakref_count = len(list(weakref.getweakrefs(self)))
        logger.debug(f"å¼±å‚ç…§æ•°: {weakref_count}")
    
    def _cleanup_dead_threads(self):
        """ãƒ‡ãƒƒãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        logger.info("ğŸ§µ ãƒ‡ãƒƒãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ...")
        
        active_threads = threading.enumerate()
        dead_threads = [t for t in active_threads if not t.is_alive()]
        
        for thread in dead_threads:
            try:
                thread.join(timeout=1)
                logger.debug(f"ãƒ‡ãƒƒãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰å›å: {thread.name}")
            except:
                pass
    
    def _release_memory_maps(self):
        """ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«è§£æ”¾"""
        try:
            # ãƒ—ãƒ­ã‚»ã‚¹ã®ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ—æƒ…å ±å–å¾—ãƒ»è§£æ”¾
            memory_maps = self.process.memory_maps()
            logger.debug(f"ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ—æ•°: {len(memory_maps)}")
        except (psutil.AccessDenied, AttributeError):
            pass
    
    def _optimize_gc_settings(self):
        """ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è¨­å®šæœ€é©åŒ–"""
        # GCé–¾å€¤ã‚’ãƒ¡ãƒ¢ãƒªåŠ¹ç‡é‡è¦–ã«èª¿æ•´
        gc.set_threshold(700, 10, 10)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: (700, 10, 10)
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ•ãƒ©ã‚°ã‚’ç„¡åŠ¹åŒ–ï¼ˆæœ¬ç•ªç’°å¢ƒï¼‰
        gc.set_debug(0)
        
        logger.debug("ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è¨­å®šã‚’æœ€é©åŒ–ã—ã¾ã—ãŸ")
    
    def register_cleanup_callback(self, resource_type: str, callback: Callable):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ç™»éŒ²"""
        self.resource_callbacks[resource_type] = callback
        logger.debug(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ç™»éŒ²: {resource_type}")
    
    def track_resource(self, resource_id: str, resource: Any):
        """ãƒªã‚½ãƒ¼ã‚¹è¿½è·¡"""
        with self._lock:
            self.tracked_resources[resource_id] = {
                'resource': weakref.ref(resource),
                'created': datetime.now(),
                'type': type(resource).__name__
            }
            
            # å¾ªç’°å‚ç…§è¿½è·¡ã«ã‚‚ç™»éŒ²
            self.circular_tracker.track_object(resource, resource_id)
    
    def release_resource(self, resource_id: str):
        """ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾"""
        with self._lock:
            if resource_id in self.tracked_resources:
                del self.tracked_resources[resource_id]
                logger.debug(f"ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾: {resource_id}")
    
    @contextmanager
    def memory_limit_context(self, limit_mb: Optional[int] = None):
        """ãƒ¡ãƒ¢ãƒªåˆ¶é™ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""
        original_limit = self.max_memory_mb
        if limit_mb:
            self.max_memory_mb = limit_mb
            
        try:
            yield
        finally:
            self.max_memory_mb = original_limit
    
    def get_memory_report(self) -> Dict:
        """ãƒ¡ãƒ¢ãƒªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not self.memory_history:
            return {"error": "ãƒ¡ãƒ¢ãƒªå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“"}
        
        current = self.memory_history[-1]
        
        # çµ±è¨ˆè¨ˆç®—
        memory_values = [s.process_memory for s in self.memory_history]
        
        report = {
            "current_memory_mb": current.process_memory,
            "max_memory_mb": max(memory_values),
            "min_memory_mb": min(memory_values),
            "avg_memory_mb": sum(memory_values) / len(memory_values),
            "python_objects": current.python_objects,
            "active_threads": current.active_threads,
            "open_files": current.open_files,
            "gc_collections": current.gc_collections,
            "memory_trend": self._calculate_memory_trend(list(self.memory_history)[-10:]) if len(self.memory_history) >= 10 else 0,
            "tracked_resources": len(self.tracked_resources),
            "monitoring_duration": len(self.memory_history) * self.check_interval,
            "timestamp": current.timestamp.isoformat()
        }
        
        return report

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
memory_manager = MemoryManager()

# ä¾¿åˆ©é–¢æ•°
def start_memory_monitoring():
    """ãƒ¡ãƒ¢ãƒªç›£è¦–é–‹å§‹"""
    memory_manager.start_monitoring()

def stop_memory_monitoring():
    """ãƒ¡ãƒ¢ãƒªç›£è¦–åœæ­¢"""
    memory_manager.stop_monitoring()

def emergency_cleanup():
    """ç·Šæ€¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    memory_manager._emergency_memory_cleanup()

def get_memory_status() -> Dict:
    """ãƒ¡ãƒ¢ãƒªçŠ¶æ³å–å¾—"""
    return memory_manager.get_memory_report()

@contextmanager
def memory_tracking(resource_id: str, resource: Any):
    """ãƒªã‚½ãƒ¼ã‚¹è¿½è·¡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""
    memory_manager.track_resource(resource_id, resource)
    try:
        yield resource
    finally:
        memory_manager.release_resource(resource_id)

# ãƒ†ã‚¹ãƒˆé–¢æ•°
def test_memory_manager():
    """ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãƒ†ã‚¹ãƒˆ"""
    logger.info("ğŸ§ª ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ç›£è¦–é–‹å§‹
    start_memory_monitoring()
    
    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ãƒ†ã‚¹ãƒˆ
    test_data = []
    for i in range(10):
        # æ„å›³çš„ã«ãƒ¡ãƒ¢ãƒªã‚’ä½¿ç”¨
        data = list(range(10000))
        test_data.append(data)
        time.sleep(1)
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = get_memory_status()
    logger.info(f"ãƒ¡ãƒ¢ãƒªãƒ¬ãƒãƒ¼ãƒˆ: {report}")
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ
    emergency_cleanup()
    
    # ç›£è¦–åœæ­¢
    stop_memory_monitoring()
    
    logger.info("ğŸ¯ ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    test_memory_manager()