import argparse
import ast
import json
import math
import os
import subprocess
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

from kumihan_formatter.core.utilities.logger import get_logger

logger = get_logger(__name__)

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå“è³ªã—ãã„å€¤è¨­å®š
DEFAULT_THRESHOLDS = {
    "cognitive_complexity": 15,
    "maintainability_index": 20,
    "code_duplication": 5.0,  # %
    "max_dead_code": 10,  # files
    "halstead_volume": 1000.0,
    "halstead_difficulty": 50.0,
    "halstead_effort": 100000.0,
    "halstead_bugs": 1.0,
}


class TechDebtMonitor:
    """
    æŠ€è¡“çš„è² å‚µã‚’ç›£è¦–ã—ã€ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    """

    def __init__(
        self,
        target_directory: str = "kumihan_formatter/",
        threshold_config: Optional[str] = None,
    ):
        """
        åˆæœŸåŒ–å‡¦ç†ã€‚

        Args:
            target_directory (str): åˆ†æå¯¾è±¡ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ "kumihan_formatter/"ã€‚
            threshold_config (Optional[str]): ã—ãã„å€¤è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚
        """
        self.target_directory = target_directory
        self.thresholds = self._load_threshold_config(threshold_config)

    def measure_cognitive_complexity(self) -> Dict[str, float]:
        """
        Cognitive Complexityã‚’æ¸¬å®šã™ã‚‹ï¼ˆå¼·åŒ–ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰ã€‚

        Returns:
            Dict[str, float]: ãƒ•ã‚¡ã‚¤ãƒ«åã¨Cognitive Complexityã®è¾æ›¸ã€‚
        """
        logger.debug("èªçŸ¥è¤‡é›‘åº¦æ¸¬å®šã‚’é–‹å§‹")

        try:
            logger.debug(f"radon ccã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ: {self.target_directory}")
            result = subprocess.run(
                ["radon", "cc", self.target_directory, "-j"],
                capture_output=True,
                text=True,
                check=True,
                timeout=60,  # 60ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )

            logger.debug(f"radon ccå®Ÿè¡Œå®Œäº†: return_code={result.returncode}")
            if result.stderr:
                logger.warning(f"radon cc stderr: {result.stderr}")

            try:
                result_data = json.loads(result.stdout)
                complexity_dict = dict(result_data) if isinstance(result_data, dict) else {}
                logger.info(f"èªçŸ¥è¤‡é›‘åº¦æ¸¬å®šæˆåŠŸ: {len(complexity_dict)}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ")
                return complexity_dict

            except json.JSONDecodeError as e:
                logger.error(f"radon cc JSONè§£æå¤±æ•—: {e}")
                logger.warning("ç©ºã®è¾æ›¸ã‚’è¿”ã—ã¦å‡¦ç†ç¶™ç¶š")
                return {}

        except subprocess.TimeoutExpired:
            logger.error("radon ccã‚³ãƒãƒ³ãƒ‰ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ60ç§’ï¼‰")
            logger.warning("graceful degradation: ç©ºã®çµæœã‚’è¿”ã—ã¦å‡¦ç†ç¶™ç¶š")
            return {}

        except FileNotFoundError:
            logger.error("radonã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„ï¼ˆæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰")
            logger.warning("graceful degradation: ç©ºã®çµæœã‚’è¿”ã—ã¦å‡¦ç†ç¶™ç¶š")
            return {}

        except subprocess.CalledProcessError as e:
            logger.error(f"radon ccã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œå¤±æ•—: return_code={e.returncode}")
            logger.error(
                f"stderr: {e.stderr}" if hasattr(e, "stderr") and e.stderr else "stderrãªã—"
            )
            logger.warning("graceful degradation: ç©ºã®çµæœã‚’è¿”ã—ã¦å‡¦ç†ç¶™ç¶š")
            return {}

        except Exception as e:
            logger.error(f"Cognitive Complexityæ¸¬å®šä¸­ã®äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            logger.warning("graceful degradation: ç©ºã®çµæœã‚’è¿”ã—ã¦å‡¦ç†ç¶™ç¶š")
            return {}

    def calculate_maintainability_index(self) -> Dict[str, float]:
        """
        Maintainability Indexã‚’è¨ˆç®—ã™ã‚‹ï¼ˆå¼·åŒ–ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰ã€‚

        Returns:
            Dict[str, float]: ãƒ•ã‚¡ã‚¤ãƒ«åã¨Maintainability Indexã®è¾æ›¸ã€‚
        """
        logger.debug("ä¿å®ˆæ€§æŒ‡æ¨™è¨ˆç®—ã‚’é–‹å§‹")

        try:
            logger.debug(f"radon miã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ: {self.target_directory}")
            result = subprocess.run(
                ["radon", "mi", self.target_directory, "-j"],
                capture_output=True,
                text=True,
                check=True,
                timeout=60,  # 60ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )

            logger.debug(f"radon miå®Ÿè¡Œå®Œäº†: return_code={result.returncode}")
            if result.stderr:
                logger.warning(f"radon mi stderr: {result.stderr}")

            try:
                result_data = json.loads(result.stdout)
                maintainability_dict = dict(result_data) if isinstance(result_data, dict) else {}
                logger.info(f"ä¿å®ˆæ€§æŒ‡æ¨™è¨ˆç®—æˆåŠŸ: {len(maintainability_dict)}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ")
                return maintainability_dict

            except json.JSONDecodeError as e:
                logger.error(f"radon mi JSONè§£æå¤±æ•—: {e}")
                logger.warning("ç©ºã®è¾æ›¸ã‚’è¿”ã—ã¦å‡¦ç†ç¶™ç¶š")
                return {}

        except subprocess.TimeoutExpired:
            logger.error("radon miã‚³ãƒãƒ³ãƒ‰ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ60ç§’ï¼‰")
            logger.warning("graceful degradation: ç©ºã®çµæœã‚’è¿”ã—ã¦å‡¦ç†ç¶™ç¶š")
            return {}

        except FileNotFoundError:
            logger.error("radonã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„ï¼ˆæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰")
            logger.warning("graceful degradation: ç©ºã®çµæœã‚’è¿”ã—ã¦å‡¦ç†ç¶™ç¶š")
            return {}

        except subprocess.CalledProcessError as e:
            logger.error(f"radon miã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œå¤±æ•—: return_code={e.returncode}")
            logger.error(
                f"stderr: {e.stderr}" if hasattr(e, "stderr") and e.stderr else "stderrãªã—"
            )
            logger.warning("graceful degradation: ç©ºã®çµæœã‚’è¿”ã—ã¦å‡¦ç†ç¶™ç¶š")
            return {}

        except Exception as e:
            logger.error(f"Maintainability Indexè¨ˆç®—ä¸­ã®äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            logger.warning("graceful degradation: ç©ºã®çµæœã‚’è¿”ã—ã¦å‡¦ç†ç¶™ç¶š")
            return {}

    def detect_code_duplication(self) -> List[Dict[Any, Any]]:
        """
        ã‚³ãƒ¼ãƒ‰ã®é‡è¤‡ã‚’æ¤œå‡ºã™ã‚‹ã€‚

        Returns:
            List[Dict]: é‡è¤‡ã‚³ãƒ¼ãƒ‰ã®æƒ…å ±ãƒªã‚¹ãƒˆã€‚
        """
        try:
            # duplicated ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€radon ã§ãƒ•ã‚¡ã‚¤ãƒ«è¤‡é›‘åº¦ãƒã‚§ãƒƒã‚¯
            result = subprocess.run(
                ["radon", "raw", self.target_directory, "-j"],
                capture_output=True,
                text=True,
                check=True,
            )
            result_data = json.loads(result.stdout)
            # ç°¡æ˜“çš„ãªé‡è¤‡æ¤œå‡ºï¼ˆé«˜è¤‡é›‘åº¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é‡è¤‡å€™è£œã¨ã™ã‚‹ï¼‰
            duplicates = []
            if isinstance(result_data, dict):
                for file_path, metrics in result_data.items():
                    if isinstance(metrics, dict) and metrics.get("loc", 0) > 100:
                        duplicates.append(
                            {
                                "file": file_path,
                                "lines": metrics.get("loc", 0),
                                "reason": "é«˜è¤‡é›‘åº¦ãƒ•ã‚¡ã‚¤ãƒ«",
                            }
                        )
            return duplicates
        except subprocess.CalledProcessError as e:
            logger.error(f"ã‚³ãƒ¼ãƒ‰åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return []

    def detect_dead_code(self) -> List[str]:
        """
        ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ã‚’æ¤œå‡ºã™ã‚‹ï¼ˆå¼·åŒ–ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰ã€‚

        Returns:
            List[str]: ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆã€‚
        """
        logger.debug("ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰æ¤œå‡ºã‚’é–‹å§‹")

        try:
            logger.debug(f"vultureã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ: {self.target_directory}")
            result = subprocess.run(
                ["vulture", self.target_directory],
                capture_output=True,
                text=True,
                timeout=90,  # 90ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )

            # vultureã¯return_codeãŒ0ä»¥å¤–ã§ã‚‚æ­£å¸¸ãªå‡ºåŠ›ã‚’ã™ã‚‹å ´åˆãŒã‚ã‚‹
            logger.debug(f"vultureå®Ÿè¡Œå®Œäº†: return_code={result.returncode}")
            if result.stderr:
                logger.warning(f"vulture stderr: {result.stderr}")

            dead_code_lines = [line for line in result.stdout.splitlines() if line.strip()]
            logger.info(f"ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰æ¤œå‡ºæˆåŠŸ: {len(dead_code_lines)}ä»¶ã‚’æ¤œå‡º")
            return dead_code_lines

        except subprocess.TimeoutExpired:
            logger.error("vultureã‚³ãƒãƒ³ãƒ‰ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ90ç§’ï¼‰")
            logger.warning("graceful degradation: ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã—ã¦å‡¦ç†ç¶™ç¶š")
            return []

        except FileNotFoundError:
            logger.error("vultureã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„ï¼ˆæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰")
            logger.warning("graceful degradation: ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã—ã¦å‡¦ç†ç¶™ç¶š")
            return []

        except subprocess.CalledProcessError as e:
            # vultureã¯ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ã‚’ç™ºè¦‹ã—ãŸå ´åˆã«return_codeãŒ0ä»¥å¤–ã«ãªã‚‹ã“ã¨ãŒã‚ã‚‹
            logger.debug(f"vultureã‚³ãƒãƒ³ãƒ‰çµæœ: return_code={e.returncode}")
            if hasattr(e, "stdout") and e.stdout:
                dead_code_lines = [line for line in e.stdout.splitlines() if line.strip()]
                logger.info(f"ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰æ¤œå‡ºæˆåŠŸ: {len(dead_code_lines)}ä»¶ã‚’æ¤œå‡º")
                return dead_code_lines
            else:
                logger.warning(f"vultureã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œå¤±æ•—: {e}")
                logger.warning("graceful degradation: ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã—ã¦å‡¦ç†ç¶™ç¶š")
                return []

        except Exception as e:
            logger.error(f"ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰æ¤œå‡ºä¸­ã®äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            logger.warning("graceful degradation: ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã—ã¦å‡¦ç†ç¶™ç¶š")
            return []

    def _load_threshold_config(self, config_path: Optional[str]) -> Dict[str, float]:
        """
        ã—ãã„å€¤è¨­å®šã‚’èª­ã¿è¾¼ã‚€ã€‚

        Args:
            config_path (Optional[str]): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚

        Returns:
            Dict[str, float]: ã—ãã„å€¤è¨­å®šã€‚
        """
        if config_path and os.path.exists(config_path):
            try:
                with open(config_path, "r", encoding="utf-8") as f:
                    config = json.load(f)
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ãƒãƒ¼ã‚¸
                    thresholds = DEFAULT_THRESHOLDS.copy()
                    thresholds.update(config)
                    return thresholds
            except (FileNotFoundError, json.JSONDecodeError) as e:
                logger.warning(f"ã—ãã„å€¤è¨­å®šã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨")
        return DEFAULT_THRESHOLDS.copy()

    def calculate_halstead_metrics(self) -> Dict[str, Any]:
        """
        Halstead Metricsã‚’è¨ˆç®—ã™ã‚‹ã€‚

        Returns:
            Dict[str, Any]: ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥Halstead Metricsã€‚
        """
        halstead_data = {}

        for root, _, files in os.walk(self.target_directory):
            for file in files:
                if file.endswith(".py"):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, "r", encoding="utf-8") as f:
                            source_code = f.read()
                        metrics = self._calculate_file_halstead(source_code)
                        if metrics:
                            halstead_data[file_path] = metrics
                    except Exception as e:
                        logger.warning(f"Halstead metricsè¨ˆç®—å¤±æ•— {file_path}: {e}")

        return halstead_data

    def _calculate_file_halstead(self, source_code: str) -> Optional[Dict[str, float]]:
        """
        å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®Halstead Metricsã‚’è¨ˆç®—ã™ã‚‹ã€‚

        Args:
            source_code (str): ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã€‚

        Returns:
            Optional[Dict[str, float]]: Halstead Metricsã€‚
        """
        try:
            tree = ast.parse(source_code)
        except SyntaxError:
            return None

        operators = []
        operands = []

        class HalsteadVisitor(ast.NodeVisitor):
            def visit_BinOp(self, node: ast.BinOp) -> None:
                operators.append(type(node.op).__name__)
                self.generic_visit(node)

            def visit_UnaryOp(self, node: ast.UnaryOp) -> None:
                operators.append(type(node.op).__name__)
                self.generic_visit(node)

            def visit_Compare(self, node: ast.Compare) -> None:
                for op in node.ops:
                    operators.append(type(op).__name__)
                self.generic_visit(node)

            def visit_Name(self, node: ast.Name) -> None:
                operands.append(node.id)
                self.generic_visit(node)

            def visit_Constant(self, node: ast.Constant) -> None:
                operands.append(str(node.value))
                self.generic_visit(node)

        visitor = HalsteadVisitor()
        visitor.visit(tree)

        if not operators and not operands:
            return None

        n1 = len(set(operators))  # distinct operators
        n2 = len(set(operands))  # distinct operands
        N1 = len(operators)  # total operators
        N2 = len(operands)  # total operands

        if n1 == 0 or n2 == 0:
            return None

        vocabulary = n1 + n2
        length = N1 + N2

        try:
            calculated_length = n1 * math.log2(n1) + n2 * math.log2(n2)
            volume = length * math.log2(vocabulary) if vocabulary > 1 else 0
            difficulty = (n1 / 2) * (N2 / n2)
            effort = difficulty * volume
            time_required = effort / 18
            bugs = volume / 3000

            return {
                "volume": volume,
                "difficulty": difficulty,
                "effort": effort,
                "time": time_required,
                "bugs": bugs,
                "vocabulary": vocabulary,
                "length": length,
                "calculated_length": calculated_length,
            }
        except (ValueError, ZeroDivisionError):
            return None

    def check_quality_thresholds(self, all_metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        å“è³ªã—ãã„å€¤ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€é•åé …ç›®ã‚’è¿”ã™ã€‚

        Args:
            all_metrics (Dict[str, Any]): å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€‚

        Returns:
            List[Dict[str, Any]]: é•åé …ç›®ã®ãƒªã‚¹ãƒˆã€‚
        """
        violations = []

        # Halstead Metricsã®ãƒã‚§ãƒƒã‚¯
        if "halstead_metrics" in all_metrics:
            for file_path, metrics in all_metrics["halstead_metrics"].items():
                if not isinstance(metrics, dict):
                    continue

                for metric_name, value in metrics.items():
                    threshold_key = f"halstead_{metric_name}"
                    if threshold_key in self.thresholds:
                        threshold = self.thresholds[threshold_key]
                        if value > threshold:
                            violations.append(
                                {
                                    "file": file_path,
                                    "metric": metric_name,
                                    "value": value,
                                    "threshold": threshold,
                                    "severity": ("WARNING" if value < threshold * 1.5 else "ERROR"),
                                }
                            )

        return violations

    def generate_html_report(self, output_path: str) -> str:
        """
        HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚

        Args:
            output_path (str): å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚

        Returns:
            str: HTMLãƒ¬ãƒãƒ¼ãƒˆã®ãƒ‘ã‚¹ã€‚
        """
        # TODO: Bootstrapã‚’ä½¿ç”¨ã—ã¦ã€ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºã‚’è¡Œã†HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹
        #       Cognitive Complexity, Maintainability Index, é‡è¤‡ã‚³ãƒ¼ãƒ‰, ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ã®æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹
        #       ã“ã®éƒ¨åˆ†ã¯å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®åˆ©ç”¨ã‚‚æ¤œè¨ã™ã‚‹ (ä¾‹: Jinja2)
        #       ç¾çŠ¶ã¯ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã¨ã—ã¦ã€ç°¡å˜ãªHTMLã‚’ç”Ÿæˆã™ã‚‹
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Tech Debt Report</title>
        </head>
        <body>
            <h1>Tech Debt Report</h1>
            <p>This is a placeholder for the HTML report.</p>
            <p>Output Path: {output_path}</p>
        </body>
        </html>
        """
        try:
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            with open(output_path, "w") as f:
                f.write(html_content)
            return output_path
        except Exception as e:
            logger.error(f"HTMLãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return ""

    def generate_json_report(self, output_path: str) -> Dict[str, Any]:
        """
        JSONãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚

        Args:
            output_path (str): å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚

        Returns:
            Dict: JSONãƒ¬ãƒãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã€‚
        """
        cognitive_complexity = self.measure_cognitive_complexity()
        maintainability_index = self.calculate_maintainability_index()
        code_duplication = self.detect_code_duplication()
        dead_code = self.detect_dead_code()
        halstead_metrics = self.calculate_halstead_metrics()

        report_data = {
            "cognitive_complexity": cognitive_complexity,
            "maintainability_index": maintainability_index,
            "code_duplication": code_duplication,
            "dead_code": dead_code,
            "halstead_metrics": halstead_metrics,
        }

        # å“è³ªã—ãã„å€¤ãƒã‚§ãƒƒã‚¯
        violations = self.check_quality_thresholds(report_data)
        if violations:
            report_data["threshold_violations"] = violations

        try:
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            with open(output_path, "w") as f:
                json.dump(report_data, f, indent=4)
            return report_data
        except Exception as e:
            logger.error(f"JSONãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return {}

    def run_ci_validation(self) -> bool:
        """
        CI/CDã®å“è³ªã‚²ãƒ¼ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã€‚

        Returns:
            bool: å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã‚‹å ´åˆã¯Trueã€ãã†ã§ãªã„å ´åˆã¯Falseã€‚
        """
        # å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
        all_metrics = {
            "cognitive_complexity": self.measure_cognitive_complexity(),
            "maintainability_index": self.calculate_maintainability_index(),
            "code_duplication": self.detect_code_duplication(),
            "dead_code": self.detect_dead_code(),
            "halstead_metrics": self.calculate_halstead_metrics(),
        }

        # å“è³ªã—ãã„å€¤ãƒã‚§ãƒƒã‚¯
        violations = self.check_quality_thresholds(all_metrics)

        # ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰æ•°ãƒã‚§ãƒƒã‚¯
        dead_code_count = len(all_metrics["dead_code"])
        if dead_code_count > self.thresholds["max_dead_code"]:
            violations.append(
                {
                    "file": "global",
                    "metric": "dead_code_count",
                    "value": dead_code_count,
                    "threshold": self.thresholds["max_dead_code"],
                    "severity": "ERROR",
                }
            )

        # é‡è¤‡ã‚³ãƒ¼ãƒ‰ç‡ãƒã‚§ãƒƒã‚¯
        duplication_count = len(all_metrics["code_duplication"])
        if duplication_count > 0:
            total_files = sum(
                len(files)
                for _, _, files in os.walk(self.target_directory)
                if any(f.endswith(".py") for f in files)
            )
            duplication_rate = (duplication_count / total_files * 100) if total_files > 0 else 0

            if duplication_rate > self.thresholds["code_duplication"]:
                violations.append(
                    {
                        "file": "global",
                        "metric": "code_duplication_rate",
                        "value": duplication_rate,
                        "threshold": self.thresholds["code_duplication"],
                        "severity": "WARNING",
                    }
                )

        is_valid = len([v for v in violations if v["severity"] == "ERROR"]) == 0

        if violations:
            logger.warning(f"å“è³ªã—ãã„å€¤é•å: {len(violations)}ä»¶")
            for violation in violations:
                logger.warning(
                    f"  {violation['severity']}: {violation['file']} - {violation['metric']}: "
                    f"{violation['value']:.2f} > {violation['threshold']}"
                )

        if not is_valid:
            logger.error("CI/CDå“è³ªã‚²ãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        else:
            logger.info("CI/CDå“è³ªã‚²ãƒ¼ãƒˆã«æˆåŠŸã—ã¾ã—ãŸã€‚")

        return is_valid

    def generate_improvement_report(self, output_path: str, format_type: str = "html") -> str:
        """
        æ”¹å–„ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆã‚’HTMLã¾ãŸã¯Markdownå½¢å¼ã§å‡ºåŠ›ã™ã‚‹ã€‚

        Args:
            output_path (str): å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚
            format_type (str): å‡ºåŠ›å½¢å¼ï¼ˆ"html" ã¾ãŸã¯ "markdown"ï¼‰ã€‚

        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã®ãƒ‘ã‚¹ã€‚
        """
        # å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
        all_metrics = {
            "cognitive_complexity": self.measure_cognitive_complexity(),
            "maintainability_index": self.calculate_maintainability_index(),
            "code_duplication": self.detect_code_duplication(),
            "dead_code": self.detect_dead_code(),
            "halstead_metrics": self.calculate_halstead_metrics(),
        }

        engine = QualityImprovementEngine(all_metrics)
        suggestions = engine.generate_improvement_suggestions()

        try:
            os.makedirs(os.path.dirname(output_path), exist_ok=True)

            if format_type == "html":
                content = self._generate_html_improvement_report(suggestions, all_metrics)
            else:  # markdown
                content = self._generate_markdown_improvement_report(suggestions, all_metrics)

            with open(output_path, "w", encoding="utf-8") as f:
                f.write(content)

            logger.info(f"æ”¹å–„ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {output_path}")
            return output_path

        except Exception as e:
            logger.error(f"æ”¹å–„ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return ""

    def _generate_html_improvement_report(
        self, suggestions: List[Dict[str, Any]], all_metrics: Dict[str, Any]
    ) -> str:
        """
        HTMLå½¢å¼ã®æ”¹å–„ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚

        Args:
            suggestions (List[Dict[str, Any]]): æ”¹å–„ææ¡ˆãƒªã‚¹ãƒˆã€‚
            all_metrics (Dict[str, Any]): å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€‚

        Returns:
            str: HTMLå½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆã€‚
        """
        html = """<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ã‚³ãƒ¼ãƒ‰å“è³ªæ”¹å–„ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆ</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
          \n          rel="stylesheet">
    <style>
        .priority-high { border-left: 5px solid #dc3545; }
        .priority-medium { border-left: 5px solid #ffc107; }
        .priority-low { border-left: 5px solid #28a745; }
        .metric-card { margin-bottom: 1rem; }
    </style>
</head>
<body>
    <div class="container mt-4">
        <h1 class="mb-4">ğŸ¯ ã‚³ãƒ¼ãƒ‰å“è³ªæ”¹å–„ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆ</h1>
        <div class="row">
            <div class="col-md-8">
"""
        from datetime import datetime

        html += (
            f'                <p class="text-muted">ç”Ÿæˆæ—¥æ™‚: '
            f'{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>\n'
        )
        html += f"                <p><strong>æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:</strong> {len(suggestions)}ä»¶</p>\n"

        if not suggestions:
            html += (
                '                <div class="alert alert-success">'
                "âœ… ä¸»è¦ãªå“è³ªå•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ç´ æ™´ã‚‰ã—ã„ã‚³ãƒ¼ãƒ‰ã§ã™ï¼"
                "</div>\n"
            )
        else:
            # å„ªå…ˆåº¦åˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            high_priority = [s for s in suggestions if s["priority"] >= 0.7]
            medium_priority = [s for s in suggestions if 0.4 <= s["priority"] < 0.7]
            low_priority = [s for s in suggestions if s["priority"] < 0.4]

            for priority_level, suggestions_group, color_class in [
                ("é«˜å„ªå…ˆåº¦ï¼ˆå³åº§å¯¾å¿œæ¨å¥¨ï¼‰", high_priority, "priority-high"),
                ("ä¸­å„ªå…ˆåº¦ï¼ˆè¨ˆç”»çš„å¯¾å¿œæ¨å¥¨ï¼‰", medium_priority, "priority-medium"),
                ("ä½å„ªå…ˆåº¦ï¼ˆä½™è£•ãŒã‚ã‚‹æ™‚ã«å¯¾å¿œï¼‰", low_priority, "priority-low"),
            ]:
                if suggestions_group:
                    if "é«˜" in priority_level:
                        html += f'                <h2 class="mt-4">ğŸ”´ {priority_level}</h2>\n'
                    elif "ä¸­" in priority_level:
                        html += f'                <h2 class="mt-4">ğŸŸ¡ {priority_level}</h2>\n'
                    else:
                        html += f'                <h2 class="mt-4">ğŸŸ¢ {priority_level}</h2>\n'
                    for suggestion in suggestions_group:
                        html += f"""                <div class="card metric-card {color_class}">
                    <div class="card-body">
                        <h5 class="card-title">{suggestion["file"]}</h5>
                        <p class="card-text">{suggestion["description"]}</p>
                        <div class="row">
                            <div class="col-md-4"><strong>å„ªå…ˆåº¦:</strong> {suggestion["priority"]:.2f}</div>
                            <div class="col-md-4"><strong>å·¥æ•°:</strong> {suggestion["effort_estimate"]}</div>
                            <div class="col-md-4"><strong>å½±éŸ¿åº¦:</strong> {suggestion["impact"]}</div>
                        </div>
                        <h6 class="mt-3">æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:</h6>
                        <ul>
"""
                        for action in suggestion["actions"]:
                            html += f"                            <li>{action}</li>\n"
                        html += """                        </ul>
                    </div>
                </div>
"""

        html += """            </div>
            <div class="col-md-4">
                <h3>ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¦‚è¦</h3>
"""

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¦‚è¦ã‚’è¿½åŠ 
        html+= (
            f'                <div class="card"><div class="card-body"><h6>Cognitive Complexity</h6><p>{len(all_metrics.get("cognitive_complexity", {}))}ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ</p></div></div>\n'
        )
        html+= (
            f'                <div class="card"><div class="card-body"><h6>Maintainability Index</h6><p>{len(all_metrics.get("maintainability_index", {}))}ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ</p></div></div>\n'
        )
        html+= (
            f'                <div class="card"><div class="card-body"><h6>Halstead Metrics</h6><p>{len(all_metrics.get("halstead_metrics", {}))}ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ</p></div></div>\n'
        )
        html+= (
            f'                <div class="card"><div class="card-body"><h6>Dead Code</h6><p>{len(all_metrics.get("dead_code", []))}ä»¶æ¤œå‡º</p></div></div>\n'
        )

        html += """            </div>
        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>"""
        return html

    def _generate_markdown_improvement_report(
        self, suggestions: List[Dict[str, Any]], all_metrics: Dict[str, Any]
    ) -> str:
        """
        Markdownå½¢å¼ã®æ”¹å–„ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚

        Args:
            suggestions (List[Dict[str, Any]]): æ”¹å–„ææ¡ˆãƒªã‚¹ãƒˆã€‚
            all_metrics (Dict[str, Any]): å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€‚

        Returns:
            str: Markdownå½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆã€‚
        """
        engine = QualityImprovementEngine(all_metrics)
        return engine.create_action_plan()

    def get_quality_score(self) -> float:
        """
        ç·åˆçš„ãªå“è³ªã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰ã‚’ç®—å‡ºã™ã‚‹ã€‚

        Returns:
            float: å“è³ªã‚¹ã‚³ã‚¢ã€‚
        """
        # å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
        all_metrics = {
            "cognitive_complexity": self.measure_cognitive_complexity(),
            "maintainability_index": self.calculate_maintainability_index(),
            "code_duplication": self.detect_code_duplication(),
            "dead_code": self.detect_dead_code(),
            "halstead_metrics": self.calculate_halstead_metrics(),
        }

        engine = QualityImprovementEngine(all_metrics)
        issues = engine.analyze_code_issues()

        if not issues:
            return 100.0

        # å•é¡Œã®é‡è¦åº¦ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢æ¸›ç‚¹
        total_penalty = 0.0
        for issue in issues:
            if issue["severity"] == "high":
                total_penalty += 20.0
            elif issue["severity"] == "medium":
                total_penalty += 10.0
            else:  # low
                total_penalty += 5.0

        # æœ€ä½ã‚¹ã‚³ã‚¢ã¯10ç‚¹ã¨ã™ã‚‹
        quality_score = max(10.0, 100.0 - total_penalty)
        return quality_score


class QualityImprovementEngine:
    """
    ã‚³ãƒ¼ãƒ‰å“è³ªæ”¹å–„ã®ãŸã‚ã®ææ¡ˆã‚’ç”Ÿæˆã™ã‚‹ã‚¨ãƒ³ã‚¸ãƒ³ã€‚
    """

    def __init__(self, all_metrics: Dict[str, Any]) -> None:
        """
        åˆæœŸåŒ–å‡¦ç†ã€‚

        Args:
            all_metrics (Dict[str, Any]): å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æçµæœã€‚
        """
        self.all_metrics = all_metrics

    def analyze_code_issues(self) -> List[Dict[str, Any]]:
        """
        å“è³ªå•é¡Œã‚’åˆ†æã—ã€æ”¹å–„å¯èƒ½ãªé …ç›®ã‚’ç‰¹å®šã™ã‚‹ã€‚

        Returns:
            List[Dict[str, Any]]: æ¤œå‡ºã•ã‚ŒãŸå•é¡Œç‚¹ã®ãƒªã‚¹ãƒˆã€‚
        """
        issues = []

        # Cognitive Complexityå•é¡Œæ¤œå‡º
        if "cognitive_complexity" in self.all_metrics:
            for file_path, complexity in self.all_metrics["cognitive_complexity"].items():
                if isinstance(complexity, (int, float)) and complexity > 15:
                    issues.append(
                        {
                            "file": file_path,
                            "issue_type": "high_cognitive_complexity",
                            "metric": "cognitive_complexity",
                            "value": complexity,
                            "severity": "high" if complexity > 25 else "medium",
                            "description": f"èªçŸ¥è¤‡é›‘æ€§ãŒé«˜ã™ãã¾ã™ï¼ˆ{complexity}ï¼‰ã€‚é–¢æ•°åˆ†å‰²ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚",
                        }
                    )

        # Maintainability Indexå•é¡Œæ¤œå‡º
        if "maintainability_index" in self.all_metrics:
            for file_path, index in self.all_metrics["maintainability_index"].items():
                if isinstance(index, (int, float)) and index < 20:
                    issues.append(
                        {
                            "file": file_path,
                            "issue_type": "low_maintainability",
                            "metric": "maintainability_index",
                            "value": index,
                            "severity": "high" if index < 10 else "medium",
                            "description": f"ä¿å®ˆæ€§æŒ‡æ¨™ãŒä½ã„ã§ã™ï¼ˆ{index}ï¼‰ã€‚ã‚³ãƒ¼ãƒ‰ã®å¯èª­æ€§å‘ä¸ŠãŒå¿…è¦ã§ã™ã€‚",
                        }
                    )

        # Halstead Metricså•é¡Œæ¤œå‡º
        if "halstead_metrics" in self.all_metrics:
            for file_path, metrics in self.all_metrics["halstead_metrics"].items():
                if isinstance(metrics, dict):
                    volume = metrics.get("volume", 0)
                    difficulty = metrics.get("difficulty", 0)
                    effort = metrics.get("effort", 0)

                    if volume > 1000:
                        issues.append(
                            {
                                "file": file_path,
                                "issue_type": "high_halstead_volume",
                                "metric": "halstead_volume",
                                "value": volume,
                                "severity": "medium",
                                "description": (
                                    f"Halstead VolumeãŒé«˜ã„ã§ã™ï¼ˆ{volume:.2f}ï¼‰ã€‚ã‚³ãƒ¼ãƒ‰åˆ†å‰²ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚",
                                ),
                            }
                        )

                    if difficulty > 50:
                        issues.append(
                            {
                                "file": file_path,
                                "issue_type": "high_halstead_difficulty",
                                "metric": "halstead_difficulty",
                                "value": difficulty,
                                "severity": "medium",
                                "description": (
                                    f"Halstead DifficultyãŒé«˜ã„ã§ã™ï¼ˆ{difficulty:.2f}ï¼‰ã€‚ã‚³ãƒ¼ãƒ‰ç°¡ç•¥åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚",
                                ),
                            }
                        )

        # Dead Codeå•é¡Œæ¤œå‡º
        if "dead_code" in self.all_metrics:
            dead_code_files = self.all_metrics["dead_code"]
            if len(dead_code_files) > 0:
                issues.append(
                    {
                        "file": "multiple",
                        "issue_type": "dead_code_detected",
                        "metric": "dead_code_count",
                        "value": len(dead_code_files),
                        "severity": "low",
                        "description": f"æœªä½¿ç”¨ã‚³ãƒ¼ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼ˆ{len(dead_code_files)}ä»¶ï¼‰ã€‚å‰Šé™¤ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚",
                    }
                )

        return issues

    def generate_improvement_suggestions(self) -> List[Dict[str, Any]]:
        """
        å…·ä½“çš„ãªæ”¹å–„ææ¡ˆã‚’ç”Ÿæˆã™ã‚‹ã€‚

        Returns:
            List[Dict[str, Any]]: æ”¹å–„ææ¡ˆã®ãƒªã‚¹ãƒˆã€‚
        """
        issues = self.analyze_code_issues()
        suggestions = []

        for issue in issues:
            suggestion = {
                "file": issue["file"],
                "issue_type": issue["issue_type"],
                "priority": self.calculate_roi_priority(issue),
                "effort_estimate": self._estimate_effort(issue),
                "impact": self._estimate_impact(issue),
                "description": issue["description"],
            }

            # å…·ä½“çš„ãªæ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ
            if issue["issue_type"] == "high_cognitive_complexity":
                suggestion["actions"] = [
                    "é•·ã„ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¤‡æ•°ã®å°ã•ãªãƒ¡ã‚½ãƒƒãƒ‰ã«åˆ†å‰²",
                    "è¤‡é›‘ãªæ¡ä»¶åˆ†å²ã‚’early returnãƒ‘ã‚¿ãƒ¼ãƒ³ã§ç°¡ç•¥åŒ–",
                    "ãƒã‚¹ãƒˆã—ãŸå‡¦ç†ã‚’åˆ¥ãƒ¡ã‚½ãƒƒãƒ‰ã¨ã—ã¦æŠ½å‡º",
                ]
            elif issue["issue_type"] == "low_maintainability":
                suggestion["actions"] = [
                    "å¤‰æ•°ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰åã‚’ã‚ˆã‚Šåˆ†ã‹ã‚Šã‚„ã™ãå‘½å",
                    "å‡¦ç†ã«å¯¾ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆãƒ»docstringã‚’è¿½åŠ ",
                    "å‹ãƒ’ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¦å¯èª­æ€§å‘ä¸Š",
                ]
            elif issue["issue_type"] == "high_halstead_volume":
                suggestion["actions"] = [
                    "å¤§ããªãƒ¡ã‚½ãƒƒãƒ‰ã‚’è²¬ä»»åˆ¥ã«åˆ†å‰²",
                    "å…±é€šå‡¦ç†ã‚’ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã¨ã—ã¦æŠ½å‡º",
                    "ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’è¦‹ç›´ã—ã¦ãƒ­ã‚¸ãƒƒã‚¯ç°¡ç•¥åŒ–",
                ]
            elif issue["issue_type"] == "high_halstead_difficulty":
                suggestion["actions"] = [
                    "è¤‡é›‘ãªæ¼”ç®—å­ã®ä½¿ç”¨ã‚’é¿ã‘ã‚‹",
                    "æ¡ä»¶åˆ†å²ã‚’ guard clause ã§ç°¡ç•¥åŒ–",
                    "ä¸€è¡Œã§è¤‡æ•°ã®å‡¦ç†ã‚’è¡Œã‚ãªã„",
                ]
            elif issue["issue_type"] == "dead_code_detected":
                suggestion["actions"] = [
                    "æœªä½¿ç”¨ã®å¤‰æ•°ãƒ»é–¢æ•°ãƒ»ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å‰Šé™¤",
                    "åˆ°é”ä¸èƒ½ãªã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»",
                    "ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã‚¯ãƒ©ã‚¹ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‰Šé™¤",
                ]

            suggestions.append(suggestion)

        # å„ªå…ˆåº¦ã§ã‚½ãƒ¼ãƒˆ
        suggestions.sort(key=lambda x: x["priority"], reverse=True)
        return suggestions

    def calculate_roi_priority(self, issue: Dict[str, Any]) -> float:
        """
        ROIï¼ˆReturn on Investmentï¼‰ãƒ™ãƒ¼ã‚¹ã§å„ªå…ˆåº¦ã‚’è¨ˆç®—ã™ã‚‹ã€‚

        Args:
            issue (Dict[str, Any]): å•é¡Œæƒ…å ±ã€‚

        Returns:
            float: ROIãƒ™ãƒ¼ã‚¹ã®å„ªå…ˆåº¦ï¼ˆ0.0-1.0ï¼‰ã€‚
        """
        severity_weights = {"high": 0.8, "medium": 0.6, "low": 0.4}
        issue_type_weights = {
            "high_cognitive_complexity": 0.9,
            "low_maintainability": 0.8,
            "high_halstead_difficulty": 0.7,
            "high_halstead_volume": 0.6,
            "dead_code_detected": 0.5,
        }

        severity_score = severity_weights.get(issue.get("severity", "medium"), 0.6)
        issue_type_score = issue_type_weights.get(issue.get("issue_type", ""), 0.5)

        # å€¤ã®å¤§ãã•ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
        value_score = 0.5
        if issue.get("metric") == "cognitive_complexity":
            value_score = min(1.0, issue.get("value", 0) / 50.0)
        elif issue.get("metric") == "maintainability_index":
            value_score = max(0.0, 1.0 - issue.get("value", 50) / 50.0)

        return severity_score * 0.4 + issue_type_score * 0.4 + value_score * 0.2

    def _estimate_effort(self, issue: Dict[str, Any]) -> str:
        """
        æ”¹å–„ã«å¿…è¦ãªå·¥æ•°ã‚’æ¨å®šã™ã‚‹ã€‚

        Args:
            issue (Dict[str, Any]): å•é¡Œæƒ…å ±ã€‚

        Returns:
            str: å·¥æ•°æ¨å®šï¼ˆ"ä½", "ä¸­", "é«˜"ï¼‰ã€‚
        """
        effort_map = {
            "high_cognitive_complexity": "é«˜",
            "low_maintainability": "ä¸­",
            "high_halstead_difficulty": "é«˜",
            "high_halstead_volume": "é«˜",
            "dead_code_detected": "ä½",
        }
        return effort_map.get(issue.get("issue_type", ""), "ä¸­")

    def _estimate_impact(self, issue: Dict[str, Any]) -> str:
        """
        æ”¹å–„ã«ã‚ˆã‚‹å½±éŸ¿åº¦ã‚’æ¨å®šã™ã‚‹ã€‚

        Args:
            issue (Dict[str, Any]): å•é¡Œæƒ…å ±ã€‚

        Returns:
            str: å½±éŸ¿åº¦æ¨å®šï¼ˆ"ä½", "ä¸­", "é«˜"ï¼‰ã€‚
        """
        impact_map = {
            "high_cognitive_complexity": "é«˜",
            "low_maintainability": "é«˜",
            "high_halstead_difficulty": "ä¸­",
            "high_halstead_volume": "ä¸­",
            "dead_code_detected": "ä½",
        }
        return impact_map.get(issue.get("issue_type", ""), "ä¸­")

    def create_action_plan(self) -> str:
        """
        çµ±åˆçš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’Markdownå½¢å¼ã§ç”Ÿæˆã™ã‚‹ã€‚

        Returns:
            str: Markdownå½¢å¼ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã€‚
        """
        suggestions = self.generate_improvement_suggestions()

        action_plan = "# ğŸ¯ ã‚³ãƒ¼ãƒ‰å“è³ªæ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³\n\n"
        action_plan += f"**ç”Ÿæˆæ—¥æ™‚:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        action_plan += f"**æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:** {len(suggestions)}ä»¶\n\n"

        if not suggestions:
            action_plan += "âœ… **ç´ æ™´ã‚‰ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼** ä¸»è¦ãªå“è³ªå•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n"
            return action_plan

        # å„ªå…ˆåº¦åˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        high_priority = [s for s in suggestions if s["priority"] >= 0.7]
        medium_priority = [s for s in suggestions if 0.4 <= s["priority"] < 0.7]
        low_priority = [s for s in suggestions if s["priority"] < 0.4]

        if high_priority:
            action_plan += "## ğŸ”´ é«˜å„ªå…ˆåº¦ï¼ˆå³åº§å¯¾å¿œæ¨å¥¨ï¼‰\n\n"
            for suggestion in high_priority:
                action_plan += f"### {suggestion['file']}\n"
                action_plan += f"**å•é¡Œ:** {suggestion['description']}\n\n"
                action_plan +=(
                    f"**å„ªå…ˆåº¦:** {suggestion['priority']:.2f} | **å·¥æ•°:** {suggestion['effort_estimate']} | **å½±éŸ¿åº¦:** {suggestion['impact']}\n\n"
                )
                action_plan += "**æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:**\n"
                for action in suggestion["actions"]:
                    action_plan += f"- [ ] {action}\n"
                action_plan += "\n---\n\n"

        if medium_priority:
            action_plan += "## ğŸŸ¡ ä¸­å„ªå…ˆåº¦ï¼ˆè¨ˆç”»çš„å¯¾å¿œæ¨å¥¨ï¼‰\n\n"
            for suggestion in medium_priority:
                action_plan += f"### {suggestion['file']}\n"
                action_plan += f"**å•é¡Œ:** {suggestion['description']}\n\n"
                action_plan +=(
                    f"**å„ªå…ˆåº¦:** {suggestion['priority']:.2f} | **å·¥æ•°:** {suggestion['effort_estimate']} | **å½±éŸ¿åº¦:** {suggestion['impact']}\n\n"
                )
                action_plan += "**æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:**\n"
                for action in suggestion["actions"]:
                    action_plan += f"- [ ] {action}\n"
                action_plan += "\n---\n\n"

        if low_priority:
            action_plan += "## ğŸŸ¢ ä½å„ªå…ˆåº¦ï¼ˆä½™è£•ãŒã‚ã‚‹æ™‚ã«å¯¾å¿œï¼‰\n\n"
            for suggestion in low_priority:
                action_plan += f"### {suggestion['file']}\n"
                action_plan += f"**å•é¡Œ:** {suggestion['description']}\n\n"
                action_plan +=(
                    f"**å„ªå…ˆåº¦:** {suggestion['priority']:.2f} | **å·¥æ•°:** {suggestion['effort_estimate']} | **å½±éŸ¿åº¦:** {suggestion['impact']}\n\n"
                )
                action_plan += "**æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:**\n"
                for action in suggestion["actions"]:
                    action_plan += f"- [ ] {action}\n"
                action_plan += "\n---\n\n"

        action_plan += "## ğŸ“Š æ”¹å–„åŠ¹æœäºˆæ¸¬\n\n"
        action_plan += f"- **é«˜å„ªå…ˆåº¦å¯¾å¿œ:** ã‚³ãƒ¼ãƒ‰å“è³ª +{len(high_priority) * 15}%å‘ä¸Šè¦‹è¾¼ã¿\n"
        action_plan += f"- **ä¸­å„ªå…ˆåº¦å¯¾å¿œ:** ã‚³ãƒ¼ãƒ‰å“è³ª +{len(medium_priority) * 10}%å‘ä¸Šè¦‹è¾¼ã¿\n"
        action_plan +=(
            f"- **å…¨å¯¾å¿œå®Œäº†:** ã‚³ãƒ¼ãƒ‰å“è³ª +{(len(high_priority) * 15) + (len(medium_priority) * 10) + (len(low_priority) * 5)}%å‘ä¸Šè¦‹è¾¼ã¿\n\n"
        )

        return action_plan


def main() -> None:
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°ã€‚
    """
    parser = argparse.ArgumentParser(description="æŠ€è¡“çš„è² å‚µç›£è¦–ãƒ„ãƒ¼ãƒ«")
    parser.add_argument(
        "--format",
        choices=["console", "html", "json"],
        default="console",
        help="å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (console, html, json)",
    )
    parser.add_argument(
        "--output",
        default="tmp/tech_debt_report.html",
        help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
    )
    parser.add_argument("--ci", action="store_true", help="CI/CDãƒ¢ãƒ¼ãƒ‰ï¼ˆå“è³ªã‚²ãƒ¼ãƒˆï¼‰")
    parser.add_argument("--threshold-config", help="ã‚«ã‚¹ã‚¿ãƒ ã—ãã„å€¤è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    # Phase 3: è‡ªå‹•æ”¹å–„ææ¡ˆã‚·ã‚¹ãƒ†ãƒ ã®CLIå¼•æ•°
    parser.add_argument("--improvement", action="store_true", help="æ”¹å–„ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ¢ãƒ¼ãƒ‰")
    parser.add_argument("--action-plan", action="store_true", help="ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰")
    parser.add_argument("--quality-score", action="store_true", help="å“è³ªã‚¹ã‚³ã‚¢è¡¨ç¤ºã®ã¿")
    parser.add_argument(
        "--report-format",
        choices=["html", "markdown"],
        default="html",
        help="æ”¹å–„ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆã®å‡ºåŠ›å½¢å¼ï¼ˆhtml ã¾ãŸã¯ markdownï¼‰",
    )

    args = parser.parse_args()

    monitor = TechDebtMonitor(threshold_config=args.threshold_config)

    if args.ci:
        if not monitor.run_ci_validation():
            exit(1)  # CI/CDå¤±æ•—æ™‚ã¯exit code 1
        else:
            exit(0)  # CI/CDæˆåŠŸæ™‚ã¯exit code 0

    # Phase 3: è‡ªå‹•æ”¹å–„ææ¡ˆã‚·ã‚¹ãƒ†ãƒ æ©Ÿèƒ½
    if args.improvement:
        output_path = (
            args.output.replace(".html", "_improvement.html")
            if args.report_format == "html"
            else args.output.replace(".html", "_improvement.md")
        )
        if not output_path.startswith("tmp/"):
            output_path = f"tmp/{os.path.basename(output_path)}"

        result_path = monitor.generate_improvement_report(output_path, args.report_format)
        if result_path:
            print(f"æ”¹å–„ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {result_path}")
        else:
            print("æ”¹å–„ææ¡ˆãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    elif args.action_plan:
        # å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã—ã¦ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆ
        all_metrics = {
            "cognitive_complexity": monitor.measure_cognitive_complexity(),
            "maintainability_index": monitor.calculate_maintainability_index(),
            "code_duplication": monitor.detect_code_duplication(),
            "dead_code": monitor.detect_dead_code(),
            "halstead_metrics": monitor.calculate_halstead_metrics(),
        }

        engine = QualityImprovementEngine(all_metrics)
        action_plan = engine.create_action_plan()

        # tmp/é…ä¸‹ã«Markdownãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        output_path = "tmp/action_plan.md"
        try:
            os.makedirs("tmp", exist_ok=True)
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(action_plan)
            print(f"ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {output_path}")
            print("\n" + action_plan)
        except Exception as e:
            logger.error(f"ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            print(action_plan)  # ä¿å­˜ã«å¤±æ•—ã—ã¦ã‚‚ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã¯è¡¨ç¤º

    elif args.quality_score:
        score = monitor.get_quality_score()
        print(f"ğŸ“Š ç·åˆå“è³ªã‚¹ã‚³ã‚¢: {score:.1f}/100")

        if score >= 90:
            print("ğŸ‰ å„ªç§€ï¼ã‚³ãƒ¼ãƒ‰å“è³ªã¯éå¸¸ã«é«˜ã„ãƒ¬ãƒ™ãƒ«ã§ã™ã€‚")
        elif score >= 75:
            print("ğŸ‘ è‰¯å¥½ï¼ã‚³ãƒ¼ãƒ‰å“è³ªã¯ååˆ†ãªãƒ¬ãƒ™ãƒ«ã§ã™ã€‚")
        elif score >= 60:
            print("âš ï¸  æ™®é€šã€‚ã„ãã¤ã‹ã®æ”¹å–„ç‚¹ãŒã‚ã‚Šã¾ã™ã€‚")
        elif score >= 40:
            print("ğŸ”„ è¦æ”¹å–„ã€‚å“è³ªå‘ä¸ŠãŒå¿…è¦ã§ã™ã€‚")
        else:
            print("ğŸš¨ è¦ç·Šæ€¥å¯¾å¿œã€‚å¤§å¹…ãªå“è³ªæ”¹å–„ãŒå¿…è¦ã§ã™ã€‚")

    elif args.format == "console":
        cognitive_complexity = monitor.measure_cognitive_complexity()
        maintainability_index = monitor.calculate_maintainability_index()
        code_duplication = monitor.detect_code_duplication()
        dead_code = monitor.detect_dead_code()
        halstead_metrics = monitor.calculate_halstead_metrics()

        print("Cognitive Complexity:", cognitive_complexity)
        print("Maintainability Index:", maintainability_index)
        print("Code Duplication:", code_duplication)
        print("Dead Code:", dead_code)
        print("Halstead Metrics:", f"{len(halstead_metrics)} files analyzed")

    elif args.format == "html":
        monitor.generate_html_report(args.output)
        print(f"HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {args.output}")

    elif args.format == "json":
        monitor.generate_json_report(args.output)
        print(f"JSONãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {args.output}")


if __name__ == "__main__":
    main()
