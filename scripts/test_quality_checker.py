#!/usr/bin/env python3
"""
ãƒ†ã‚¹ãƒˆå“è³ªè‡ªå‹•ãƒã‚§ãƒƒã‚«ãƒ¼

Issue #1120: ãƒ†ã‚¹ãƒˆå“è³ªã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ç­–å®š
ãƒ†ã‚¹ãƒˆè‚¥å¤§åŒ–é˜²æ­¢ã®ãŸã‚ã®è‡ªå‹•å“è³ªãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½

Usage:
    python3 scripts/test_quality_checker.py
    python3 scripts/test_quality_checker.py --category unit
    python3 scripts/test_quality_checker.py --strict
"""

import os
import re
import argparse
from pathlib import Path
from typing import List, Dict, Tuple, NamedTuple
from collections import defaultdict


class TestQualityReport(NamedTuple):
    """ãƒ†ã‚¹ãƒˆå“è³ªãƒ¬ãƒãƒ¼ãƒˆã®æ§‹é€ """
    total_tests: int
    category_counts: Dict[str, int]
    violations: List[str]
    warnings: List[str]
    recommendations: List[str]


class TestQualityChecker:
    """ãƒ†ã‚¹ãƒˆå“è³ªãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½"""

    # ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³åŸºæº–å€¤
    LIMITS = {
        'total_tests': 1500,
        'categories': {
            'unit': 1450,
            'unit/rendering': 130,
            'unit/config': 100,
            'unit/ast_nodes': 100,
            'unit/patterns': 95,
            'unit/parsing': 80,
            'integration': 100,
            'performance': 50,
            'system': 30,
            'end_to_end': 30,
        }
    }

    # å‘½åè¦ç´„ãƒ‘ã‚¿ãƒ¼ãƒ³
    NAMING_PATTERNS = {
        'good': [
            r'test_\w+_\w+_\w+',  # test_function_condition_result
            r'test_\w+_returns_\w+',  # test_function_returns_value
            r'test_\w+_raises_\w+',   # test_function_raises_error
            r'test_\w+_when_\w+',     # test_function_when_condition
        ],
        'bad': [
            r'test_\d+$',           # test_1
            r'test_[a-z]$',         # test_a
            r'test_\w{1,3}$',       # test_fn (too short)
            r'test_\w*æ­£å¸¸ç³»\w*',     # Japanese in test name
        ]
    }

    def __init__(self, tests_dir: str = "tests"):
        self.tests_dir = Path(tests_dir)
        self.test_files = list(self.tests_dir.rglob("test_*.py"))

    def count_test_methods(self, file_path: Path) -> List[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰åãƒªã‚¹ãƒˆã‚’å–å¾—"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            return re.findall(r'def (test_\w+)', content)
        except Exception as e:
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
            return []

    def categorize_test(self, file_path: Path) -> str:
        """ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®š"""
        relative_path = file_path.relative_to(self.tests_dir)
        parts = relative_path.parts

        if len(parts) >= 2:
            return f"{parts[0]}/{parts[1]}" if parts[0] == 'unit' else parts[0]
        return parts[0] if parts else 'unknown'

    def check_test_count_limits(self) -> Tuple[List[str], List[str]]:
        """ãƒ†ã‚¹ãƒˆæ•°ã®ä¸Šé™ãƒã‚§ãƒƒã‚¯"""
        violations = []
        warnings = []

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
        category_counts = defaultdict(int)
        total_tests = 0

        for test_file in self.test_files:
            test_methods = self.count_test_methods(test_file)
            category = self.categorize_test(test_file)
            category_counts[category] += len(test_methods)
            total_tests += len(test_methods)

        # ç·æ•°ãƒã‚§ãƒƒã‚¯
        if total_tests > self.LIMITS['total_tests']:
            violations.append(
                f"âŒ ãƒ†ã‚¹ãƒˆç·æ•°ä¸Šé™è¶…é: {total_tests}/{self.LIMITS['total_tests']}"
            )
        elif total_tests > self.LIMITS['total_tests'] * 0.9:
            warnings.append(
                f"âš ï¸ ãƒ†ã‚¹ãƒˆç·æ•°ãŒä¸Šé™ã«æ¥è¿‘: {total_tests}/{self.LIMITS['total_tests']} "
                f"({total_tests/self.LIMITS['total_tests']*100:.1f}%)"
            )

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒã‚§ãƒƒã‚¯
        for category, count in category_counts.items():
            limit = self.LIMITS['categories'].get(category)
            if limit and count > limit:
                violations.append(
                    f"âŒ {category} ãƒ†ã‚¹ãƒˆæ•°ä¸Šé™è¶…é: {count}/{limit}"
                )
            elif limit and count > limit * 0.9:
                warnings.append(
                    f"âš ï¸ {category} ãƒ†ã‚¹ãƒˆæ•°ãŒä¸Šé™ã«æ¥è¿‘: {count}/{limit} "
                    f"({count/limit*100:.1f}%)"
                )

        return violations, warnings, category_counts, total_tests

    def check_naming_conventions(self) -> Tuple[List[str], List[str]]:
        """å‘½åè¦ç´„ãƒã‚§ãƒƒã‚¯"""
        violations = []
        warnings = []

        for test_file in self.test_files:
            test_methods = self.count_test_methods(test_file)

            for method_name in test_methods:
                # æ‚ªã„ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
                for bad_pattern in self.NAMING_PATTERNS['bad']:
                    if re.match(bad_pattern, method_name):
                        violations.append(
                            f"âŒ å‘½åè¦ç´„é•å: {method_name} in {test_file.relative_to(self.tests_dir)}"
                        )
                        break
                else:
                    # è‰¯ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã„ãšã‚Œã‹ã«ãƒãƒƒãƒã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    good_match = False
                    for good_pattern in self.NAMING_PATTERNS['good']:
                        if re.match(good_pattern, method_name):
                            good_match = True
                            break

                    if not good_match and len(method_name.split('_')) < 4:
                        warnings.append(
                            f"âš ï¸ å‘½åæ¨å¥¨æ”¹å–„: {method_name} "
                            f"(æ¨å¥¨: test_æ©Ÿèƒ½å_æ¡ä»¶_æœŸå¾…çµæœ)"
                        )

        return violations, warnings

    def check_test_density(self) -> List[str]:
        """ãƒ†ã‚¹ãƒˆå¯†åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆ1ãƒ•ã‚¡ã‚¤ãƒ«ã‚ãŸã‚Šã®ãƒ†ã‚¹ãƒˆæ•°ï¼‰"""
        warnings = []

        for test_file in self.test_files:
            test_methods = self.count_test_methods(test_file)
            test_count = len(test_methods)

            # 1ãƒ•ã‚¡ã‚¤ãƒ«ã«éåº¦ã«å¤šãã®ãƒ†ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆ
            if test_count > 50:
                warnings.append(
                    f"âš ï¸ ãƒ†ã‚¹ãƒˆå¯†åº¦éå¤š: {test_file.relative_to(self.tests_dir)} "
                    f"({test_count}å€‹) - åˆ†å‰²ã‚’æ¤œè¨"
                )
            # 1ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ†ã‚¹ãƒˆãŒ1å€‹ã—ã‹ãªã„å ´åˆ
            elif test_count == 1:
                warnings.append(
                    f"âš ï¸ ãƒ†ã‚¹ãƒˆå¯†åº¦éå°‘: {test_file.relative_to(self.tests_dir)} "
                    f"(1å€‹) - çµ±åˆã‚’æ¤œè¨"
                )

        return warnings

    def check_duplicate_patterns(self) -> List[str]:
        """é‡è¤‡ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º"""
        warnings = []
        test_patterns = defaultdict(list)

        for test_file in self.test_files:
            test_methods = self.count_test_methods(test_file)
            for method_name in test_methods:
                # ãƒ†ã‚¹ãƒˆåã‹ã‚‰æ©Ÿèƒ½éƒ¨åˆ†ã‚’æŠ½å‡º
                pattern = re.sub(r'test_(\w+)_.*', r'\1', method_name)
                test_patterns[pattern].append((method_name, test_file))

        # åŒã˜ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå¤šæ•°ã‚ã‚‹å ´åˆ
        for pattern, tests in test_patterns.items():
            if len(tests) > 10 and pattern not in ['config', 'parse', 'render']:
                warnings.append(
                    f"âš ï¸ ãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³é‡è¤‡ã®å¯èƒ½æ€§: '{pattern}' "
                    f"({len(tests)}å€‹) - çµ±åˆãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚’æ¤œè¨"
                )

        return warnings

    def generate_quality_report(self, strict: bool = False) -> TestQualityReport:
        """ç·åˆå“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        all_violations = []
        all_warnings = []
        recommendations = []

        # å„ç¨®ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
        count_violations, count_warnings, category_counts, total_tests = self.check_test_count_limits()
        naming_violations, naming_warnings = self.check_naming_conventions()
        density_warnings = self.check_test_density()
        duplicate_warnings = self.check_duplicate_patterns()

        all_violations.extend(count_violations)
        all_violations.extend(naming_violations)

        all_warnings.extend(count_warnings)
        all_warnings.extend(naming_warnings)
        all_warnings.extend(density_warnings)
        all_warnings.extend(duplicate_warnings)

        # æ¨å¥¨äº‹é …ç”Ÿæˆ
        if total_tests < self.LIMITS['total_tests'] * 0.7:
            recommendations.append(
                f"ğŸ’¡ ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸å‘ä¸Šã®ä½™åœ°: ç¾åœ¨{total_tests}å€‹ã€ä¸Šé™{self.LIMITS['total_tests']}å€‹"
            )

        if len(all_warnings) > 10:
            recommendations.append(
                "ğŸ’¡ è­¦å‘Šæ•°ãŒå¤šã„ãŸã‚ã€æ®µéšçš„ãªæ”¹å–„ã‚’æ¨å¥¨"
            )

        return TestQualityReport(
            total_tests=total_tests,
            category_counts=dict(category_counts),
            violations=all_violations,
            warnings=all_warnings if not strict else all_warnings[:5],
            recommendations=recommendations
        )

    def print_report(self, report: TestQualityReport, verbose: bool = False):
        """å“è³ªãƒ¬ãƒãƒ¼ãƒˆã®å‡ºåŠ›"""
        print("ğŸ“Š ãƒ†ã‚¹ãƒˆå“è³ªãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 50)
        print()

        # ç·åˆçŠ¶æ³
        print("ğŸ“ˆ ãƒ†ã‚¹ãƒˆæ•°ã‚µãƒãƒªãƒ¼")
        print("-" * 25)
        print(f"ç·ãƒ†ã‚¹ãƒˆæ•°: {report.total_tests}/{self.LIMITS['total_tests']} "
              f"({report.total_tests/self.LIMITS['total_tests']*100:.1f}%)")

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥å†…è¨³
        print("\nğŸ“‹ ã‚«ãƒ†ã‚´ãƒªåˆ¥å†…è¨³")
        print("-" * 25)
        for category, count in sorted(report.category_counts.items(),
                                     key=lambda x: x[1], reverse=True):
            limit = self.LIMITS['categories'].get(category, 'N/A')
            if isinstance(limit, int):
                percentage = f"{count/limit*100:.1f}%"
                status = "âœ…" if count <= limit else "âŒ"
                print(f"{status} {category}: {count}/{limit} ({percentage})")
            else:
                print(f"ğŸ“Š {category}: {count}")

        # å“è³ªè©•ä¾¡
        print(f"\nğŸ” å“è³ªè©•ä¾¡")
        print("-" * 25)

        if not report.violations and not report.warnings:
            print("âœ… å…¨å“è³ªåŸºæº–ã‚’ã‚¯ãƒªã‚¢ - å„ªç§€ãªçŠ¶æ…‹ã§ã™")
        elif not report.violations:
            print("âš ï¸ åŸºæœ¬å“è³ªåŸºæº–ã‚¯ãƒªã‚¢ - ä¸€éƒ¨æ”¹å–„ã®ä½™åœ°ã‚ã‚Š")
        else:
            print("âŒ å“è³ªåŸºæº–é•åã‚ã‚Š - æ”¹å–„ãŒå¿…è¦ã§ã™")

        # é•åäº‹é …
        if report.violations:
            print(f"\nğŸš¨ å“è³ªåŸºæº–é•å ({len(report.violations)}ä»¶)")
            print("-" * 25)
            for violation in report.violations:
                print(violation)

        # è­¦å‘Šäº‹é …
        if report.warnings:
            print(f"\nâš ï¸ æ”¹å–„æ¨å¥¨äº‹é … ({len(report.warnings)}ä»¶)")
            print("-" * 25)
            for warning in report.warnings:
                print(warning)

        # æ¨å¥¨äº‹é …
        if report.recommendations:
            print(f"\nğŸ’¡ æ¨å¥¨äº‹é … ({len(report.recommendations)}ä»¶)")
            print("-" * 25)
            for recommendation in report.recommendations:
                print(recommendation)

        print()
        print("ğŸ¯ è©³ç´°ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³: docs/TESTING_GUIDELINES.md")
        print("ğŸ”§ ç¶™ç¶šæ”¹å–„: æœˆæ¬¡å“è³ªãƒ¬ãƒ“ãƒ¥ãƒ¼ã§åŸºæº–è¦‹ç›´ã—")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description='ãƒ†ã‚¹ãƒˆå“è³ªè‡ªå‹•ãƒã‚§ãƒƒã‚«ãƒ¼')
    parser.add_argument('--category', help='ç‰¹å®šã‚«ãƒ†ã‚´ãƒªã®ã¿ãƒã‚§ãƒƒã‚¯')
    parser.add_argument('--strict', action='store_true', help='å³æ ¼ãƒ¢ãƒ¼ãƒ‰ï¼ˆè­¦å‘Šã‚’åˆ¶é™ï¼‰')
    parser.add_argument('--verbose', action='store_true', help='è©³ç´°å‡ºåŠ›')
    parser.add_argument('--fail-on-violation', action='store_true',
                       help='é•åæ™‚ã«éé›¶çµ‚äº†ã‚³ãƒ¼ãƒ‰ã‚’è¿”ã™')

    args = parser.parse_args()

    # testsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
    if not os.path.exists('tests'):
        print("âŒ testsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return 1

    # ãƒã‚§ãƒƒã‚«ãƒ¼å®Ÿè¡Œ
    checker = TestQualityChecker()
    report = checker.generate_quality_report(strict=args.strict)
    checker.print_report(report, verbose=args.verbose)

    # çµ‚äº†ã‚³ãƒ¼ãƒ‰æ±ºå®š
    if args.fail_on_violation and report.violations:
        return 1

    return 0


if __name__ == '__main__':
    exit(main())
