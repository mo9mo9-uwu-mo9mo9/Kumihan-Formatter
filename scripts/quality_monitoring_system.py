#!/usr/bin/env python3
"""
å“è³ªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ  - Issue #598 Phase 3-3

ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ»æŠ€è¡“çš„è² å‚µç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import subprocess
import sys
import time
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from kumihan_formatter.core.utilities.logger import get_logger

logger = get_logger(__name__)


@dataclass
class QualityAlert:
    """å“è³ªã‚¢ãƒ©ãƒ¼ãƒˆ"""

    severity: str  # "low", "medium", "high", "critical"
    component: str
    message: str
    timestamp: datetime
    metric_value: float
    threshold: float


@dataclass
class QualityTrend:
    """å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰"""

    metric_name: str
    values: List[Tuple[datetime, float]] = field(default_factory=list)
    trend_direction: str = "stable"  # "improving", "degrading", "stable"

    def add_measurement(self, value: float, timestamp: Optional[datetime] = None):
        """æ¸¬å®šå€¤ã‚’è¿½åŠ """
        if timestamp is None:
            timestamp = datetime.now()
        self.values.append((timestamp, value))

        # å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆ30æ—¥é–“ä¿æŒï¼‰
        cutoff = timestamp - timedelta(days=30)
        self.values = [(t, v) for t, v in self.values if t > cutoff]

        # ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘ã‚’æ›´æ–°
        self._update_trend()

    def _update_trend(self):
        """ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘ã‚’æ›´æ–°"""
        if len(self.values) < 3:
            self.trend_direction = "stable"
            return

        recent_values = [v for _, v in self.values[-5:]]
        if len(recent_values) < 3:
            return

        # ç·šå½¢å›å¸°ã«ã‚ˆã‚‹å‚¾å‘åˆ†æï¼ˆç°¡æ˜“ç‰ˆï¼‰
        n = len(recent_values)
        x_sum = sum(range(n))
        y_sum = sum(recent_values)
        xy_sum = sum(i * v for i, v in enumerate(recent_values))
        x_sq_sum = sum(i * i for i in range(n))

        denominator = n * x_sq_sum - x_sum * x_sum
        if denominator == 0:
            self.trend_direction = "stable"
            return

        slope = (n * xy_sum - x_sum * y_sum) / denominator

        if slope > 0.1:
            self.trend_direction = "improving"
        elif slope < -0.1:
            self.trend_direction = "degrading"
        else:
            self.trend_direction = "stable"


@dataclass
class TechnicalDebtItem:
    """æŠ€è¡“çš„è² å‚µé …ç›®"""

    file_path: str
    debt_type: str  # "complexity", "duplication", "test_coverage", "documentation"
    severity: str
    description: str
    estimated_hours: float
    priority: int
    created_date: datetime
    resolved: bool = False


class QualityMonitoringDashboard:
    """å“è³ªç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""

    def __init__(self, project_root: Path):
        """åˆæœŸåŒ–

        Args:
            project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.project_root = project_root
        self.data_dir = project_root / ".quality_monitoring"
        self.data_dir.mkdir(exist_ok=True)

        self.alerts: List[QualityAlert] = []
        self.trends: Dict[str, QualityTrend] = {}
        self.technical_debt: List[TechnicalDebtItem] = []

        self._load_historical_data()

    def _load_historical_data(self):
        """å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            trends_file = self.data_dir / "quality_trends.json"
            if trends_file.exists():
                with open(trends_file, encoding="utf-8") as f:
                    data = json.load(f)
                    for name, trend_data in data.items():
                        trend = QualityTrend(metric_name=name)
                        for timestamp_str, value in trend_data["values"]:
                            timestamp = datetime.fromisoformat(timestamp_str)
                            trend.values.append((timestamp, value))
                        trend.trend_direction = trend_data.get(
                            "trend_direction", "stable"
                        )
                        self.trends[name] = trend

            debt_file = self.data_dir / "technical_debt.json"
            if debt_file.exists():
                with open(debt_file, encoding="utf-8") as f:
                    debt_data = json.load(f)
                    for item_data in debt_data:
                        item = TechnicalDebtItem(
                            file_path=item_data["file_path"],
                            debt_type=item_data["debt_type"],
                            severity=item_data["severity"],
                            description=item_data["description"],
                            estimated_hours=item_data["estimated_hours"],
                            priority=item_data["priority"],
                            created_date=datetime.fromisoformat(
                                item_data["created_date"]
                            ),
                            resolved=item_data.get("resolved", False),
                        )
                        self.technical_debt.append(item)

        except Exception as e:
            logger.warning(f"å±¥æ­´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    def _save_data(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        try:
            # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            trends_data = {}
            for name, trend in self.trends.items():
                trends_data[name] = {
                    "values": [(t.isoformat(), v) for t, v in trend.values],
                    "trend_direction": trend.trend_direction,
                }

            trends_file = self.data_dir / "quality_trends.json"
            with open(trends_file, "w", encoding="utf-8") as f:
                json.dump(trends_data, f, indent=2, ensure_ascii=False)

            # æŠ€è¡“çš„è² å‚µãƒ‡ãƒ¼ã‚¿ä¿å­˜
            debt_data = []
            for item in self.technical_debt:
                debt_data.append(
                    {
                        "file_path": item.file_path,
                        "debt_type": item.debt_type,
                        "severity": item.severity,
                        "description": item.description,
                        "estimated_hours": item.estimated_hours,
                        "priority": item.priority,
                        "created_date": item.created_date.isoformat(),
                        "resolved": item.resolved,
                    }
                )

            debt_file = self.data_dir / "technical_debt.json"
            with open(debt_file, "w", encoding="utf-8") as f:
                json.dump(debt_data, f, indent=2, ensure_ascii=False)

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def collect_quality_metrics(self) -> Dict[str, float]:
        """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†"""
        logger.info("ğŸ“Š å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ä¸­...")

        metrics = {}

        try:
            # ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸
            coverage = self._get_test_coverage()
            metrics["test_coverage"] = coverage

            # ã‚³ãƒ¼ãƒ‰å“è³ªï¼ˆflake8ã‚¹ã‚³ã‚¢ï¼‰
            code_quality = self._get_code_quality_score()
            metrics["code_quality"] = code_quality

            # è¤‡é›‘åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            complexity = self._get_complexity_metrics()
            metrics.update(complexity)

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            performance = self._get_performance_metrics()
            metrics.update(performance)

            # æŠ€è¡“çš„è² å‚µã‚¹ã‚³ã‚¢
            debt_score = self._calculate_technical_debt_score()
            metrics["technical_debt_score"] = debt_score

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒˆãƒ¬ãƒ³ãƒ‰ã«è¿½åŠ 
            now = datetime.now()
            for name, value in metrics.items():
                if name not in self.trends:
                    self.trends[name] = QualityTrend(metric_name=name)
                self.trends[name].add_measurement(value, now)

            # ã‚¢ãƒ©ãƒ¼ãƒˆæ¤œæŸ»
            self._check_quality_alerts(metrics)

        except Exception as e:
            logger.error(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¨ãƒ©ãƒ¼: {e}")

        return metrics

    def _get_test_coverage(self) -> float:
        """ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’å–å¾—"""
        try:
            result = subprocess.run(
                [
                    sys.executable,
                    "-m",
                    "pytest",
                    "--cov=kumihan_formatter",
                    "--cov-report=json",
                    "tests/",
                ],
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=300,
            )

            coverage_file = self.project_root / "coverage.json"
            if coverage_file.exists():
                with open(coverage_file, encoding="utf-8") as f:
                    coverage_data = json.load(f)
                return coverage_data.get("totals", {}).get("percent_covered", 0.0)

        except Exception:
            pass

        return 0.0

    def _get_code_quality_score(self) -> float:
        """ã‚³ãƒ¼ãƒ‰å“è³ªã‚¹ã‚³ã‚¢ã‚’å–å¾—"""
        try:
            # flake8ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯
            result = subprocess.run(
                [sys.executable, "-m", "flake8", "kumihan_formatter/", "--count"],
                cwd=self.project_root,
                capture_output=True,
                text=True,
            )

            # ã‚¨ãƒ©ãƒ¼æ•°ã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
            if result.stdout.strip():
                error_count = int(result.stdout.strip().split("\n")[-1])
                # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’æ¦‚ç®—ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯æ­£ç¢ºã«è¨ˆç®—ï¼‰
                estimated_files = 100
                error_rate = error_count / estimated_files
                score = max(0, 100 - (error_rate * 10))
                return score

            return 100.0  # ã‚¨ãƒ©ãƒ¼ãªã—

        except Exception:
            return 0.0

    def _get_complexity_metrics(self) -> Dict[str, float]:
        """è¤‡é›‘åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—"""
        try:
            # ç°¡æ˜“çš„ãªè¤‡é›‘åº¦è¨ˆç®—
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ radon ãªã©ã‚’ä½¿ç”¨
            python_files = list(self.project_root.glob("kumihan_formatter/**/*.py"))

            total_lines = 0
            total_functions = 0

            for file_path in python_files:
                try:
                    content = file_path.read_text(encoding="utf-8")
                    lines = content.split("\n")
                    total_lines += len([line for line in lines if line.strip()])
                    total_functions += content.count("def ")
                except Exception:
                    continue

            avg_function_length = total_lines / max(total_functions, 1)
            complexity_score = max(0, 100 - (avg_function_length - 10) * 2)

            return {
                "average_function_length": avg_function_length,
                "complexity_score": complexity_score,
            }

        except Exception:
            return {"complexity_score": 0.0}

    def _get_performance_metrics(self) -> Dict[str, float]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—"""
        # ç°¡æ˜“çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã‚ˆã‚Šè©³ç´°ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œ
        return {
            "performance_score": 85.0,  # ä»®ã®å€¤
            "memory_efficiency": 90.0,  # ä»®ã®å€¤
        }

    def _calculate_technical_debt_score(self) -> float:
        """æŠ€è¡“çš„è² å‚µã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        if not self.technical_debt:
            return 100.0

        # æœªè§£æ±ºã®è² å‚µé …ç›®ã®é‡ã¿ä»˜ãã‚¹ã‚³ã‚¢
        total_weight = 0
        unresolved_weight = 0

        severity_weights = {"low": 1, "medium": 3, "high": 5, "critical": 10}

        for item in self.technical_debt:
            weight = severity_weights.get(item.severity, 1)
            total_weight += weight
            if not item.resolved:
                unresolved_weight += weight

        if total_weight == 0:
            return 100.0

        debt_ratio = unresolved_weight / total_weight
        return max(0, 100 - (debt_ratio * 100))

    def _check_quality_alerts(self, metrics: Dict[str, float]):
        """å“è³ªã‚¢ãƒ©ãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯"""
        now = datetime.now()

        # ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤è¨­å®š
        alert_thresholds = {
            "test_coverage": {"critical": 50, "high": 70, "medium": 80},
            "code_quality": {"critical": 60, "high": 75, "medium": 85},
            "complexity_score": {"critical": 50, "high": 70, "medium": 80},
            "technical_debt_score": {"critical": 40, "high": 60, "medium": 75},
        }

        for metric_name, value in metrics.items():
            if metric_name in alert_thresholds:
                thresholds = alert_thresholds[metric_name]

                severity = None
                threshold = None

                if value < thresholds["critical"]:
                    severity = "critical"
                    threshold = thresholds["critical"]
                elif value < thresholds["high"]:
                    severity = "high"
                    threshold = thresholds["high"]
                elif value < thresholds["medium"]:
                    severity = "medium"
                    threshold = thresholds["medium"]

                if severity:
                    # é‡è¤‡ã‚¢ãƒ©ãƒ¼ãƒˆé˜²æ­¢: åŒã˜ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®æœ€æ–°ã‚¢ãƒ©ãƒ¼ãƒˆã‹ã‚‰1æ™‚é–“ä»¥å†…ãªã‚‰è¿½åŠ ã—ãªã„
                    recent_alerts = [
                        a
                        for a in self.alerts
                        if a.component == metric_name
                        and (now - a.timestamp).total_seconds() < 3600
                    ]

                    if not recent_alerts:
                        alert = QualityAlert(
                            severity=severity,
                            component=metric_name,
                            message=f"{metric_name}ãŒé–¾å€¤ã‚’ä¸‹å›ã‚Šã¾ã—ãŸ: {value:.1f} < {threshold}",
                            timestamp=now,
                            metric_value=value,
                            threshold=threshold,
                        )
                        self.alerts.append(alert)

    def scan_technical_debt(self):
        """æŠ€è¡“çš„è² å‚µã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        logger.info("ğŸ” æŠ€è¡“çš„è² å‚µã‚¹ã‚­ãƒ£ãƒ³ä¸­...")

        # æ—¢å­˜ã®æœªè§£æ±ºè² å‚µã‚’ã‚¯ãƒªã‚¢ï¼ˆå†ã‚¹ã‚­ãƒ£ãƒ³ã®ãŸã‚ï¼‰
        self.technical_debt = [item for item in self.technical_debt if item.resolved]

        try:
            # ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ä¸è¶³ã®æ¤œå‡º
            self._scan_test_coverage_debt()

            # è¤‡é›‘åº¦ã®é«˜ã„é–¢æ•°ã®æ¤œå‡º
            self._scan_complexity_debt()

            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸è¶³ã®æ¤œå‡º
            self._scan_documentation_debt()

            # é‡è¤‡ã‚³ãƒ¼ãƒ‰ã®æ¤œå‡º
            self._scan_duplication_debt()

        except Exception as e:
            logger.error(f"æŠ€è¡“çš„è² å‚µã‚¹ã‚­ãƒ£ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")

    def _scan_test_coverage_debt(self):
        """ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ä¸è¶³ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        try:
            result = subprocess.run(
                [
                    sys.executable,
                    "-m",
                    "pytest",
                    "--cov=kumihan_formatter",
                    "--cov-report=json",
                    "tests/",
                ],
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=300,
            )

            coverage_file = self.project_root / "coverage.json"
            if coverage_file.exists():
                with open(coverage_file, encoding="utf-8") as f:
                    coverage_data = json.load(f)

                files = coverage_data.get("files", {})
                for file_path, file_data in files.items():
                    coverage_percent = file_data.get("summary", {}).get(
                        "percent_covered", 0
                    )

                    if coverage_percent < 70:  # 70%æœªæº€ã‚’æŠ€è¡“çš„è² å‚µã¨ã™ã‚‹
                        severity = "high" if coverage_percent < 50 else "medium"
                        debt = TechnicalDebtItem(
                            file_path=file_path,
                            debt_type="test_coverage",
                            severity=severity,
                            description=f"ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ä¸è¶³: {coverage_percent:.1f}%",
                            estimated_hours=2.0 + (70 - coverage_percent) * 0.1,
                            priority=1 if severity == "high" else 2,
                            created_date=datetime.now(),
                        )
                        self.technical_debt.append(debt)

        except Exception as e:
            logger.warning(f"ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸è² å‚µã‚¹ã‚­ãƒ£ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")

    def _scan_complexity_debt(self):
        """è¤‡é›‘åº¦ã®é«˜ã„é–¢æ•°ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        # ç°¡æ˜“çš„ãªè¤‡é›‘åº¦ã‚¹ã‚­ãƒ£ãƒ³
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ radon ãªã©ã‚’ä½¿ç”¨
        python_files = list(self.project_root.glob("kumihan_formatter/**/*.py"))

        for file_path in python_files:
            try:
                content = file_path.read_text(encoding="utf-8")
                lines = content.split("\n")

                # é–¢æ•°ã®è¡Œæ•°ã‚’ç°¡æ˜“è¨ˆç®—
                in_function = False
                function_start = 0
                indent_level = 0

                for i, line in enumerate(lines):
                    stripped = line.strip()
                    if stripped.startswith("def "):
                        if in_function and i - function_start > 50:
                            # 50è¡Œã‚’è¶…ãˆã‚‹é–¢æ•°ã‚’æŠ€è¡“çš„è² å‚µã¨ã™ã‚‹
                            debt = TechnicalDebtItem(
                                file_path=str(file_path.relative_to(self.project_root)),
                                debt_type="complexity",
                                severity="medium",
                                description=f"é•·ã„é–¢æ•°: {i - function_start}è¡Œ",
                                estimated_hours=1.0 + (i - function_start - 50) * 0.05,
                                priority=3,
                                created_date=datetime.now(),
                            )
                            self.technical_debt.append(debt)

                        in_function = True
                        function_start = i
                        indent_level = len(line) - len(line.lstrip())
                    elif (
                        in_function
                        and line.strip()
                        and len(line) - len(line.lstrip()) <= indent_level
                    ):
                        # é–¢æ•°çµ‚äº†
                        if i - function_start > 50:
                            debt = TechnicalDebtItem(
                                file_path=str(file_path.relative_to(self.project_root)),
                                debt_type="complexity",
                                severity="medium",
                                description=f"é•·ã„é–¢æ•°: {i - function_start}è¡Œ",
                                estimated_hours=1.0 + (i - function_start - 50) * 0.05,
                                priority=3,
                                created_date=datetime.now(),
                            )
                            self.technical_debt.append(debt)
                        in_function = False

            except Exception:
                continue

    def _scan_documentation_debt(self):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸è¶³ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        python_files = list(self.project_root.glob("kumihan_formatter/**/*.py"))

        for file_path in python_files:
            try:
                content = file_path.read_text(encoding="utf-8")

                # ã‚¯ãƒ©ã‚¹ã¨é–¢æ•°ã®æ•°ã‚’æ•°ãˆã‚‹
                class_count = content.count("class ")
                function_count = content.count("def ")
                docstring_count = content.count('"""') + content.count("'''")

                # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç‡ã‚’è¨ˆç®—
                total_items = class_count + function_count
                if total_items > 0:
                    doc_ratio = docstring_count / (total_items * 2)  # é–‹å§‹ã¨çµ‚äº†ã§2ã¤

                    if doc_ratio < 0.5:  # 50%æœªæº€ã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸è¶³ã¨ã™ã‚‹
                        debt = TechnicalDebtItem(
                            file_path=str(file_path.relative_to(self.project_root)),
                            debt_type="documentation",
                            severity="low",
                            description=f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸è¶³: {doc_ratio:.1%}ã®ã‚«ãƒãƒ¬ãƒƒã‚¸",
                            estimated_hours=total_items * 0.3,
                            priority=4,
                            created_date=datetime.now(),
                        )
                        self.technical_debt.append(debt)

            except Exception:
                continue

    def _scan_duplication_debt(self):
        """é‡è¤‡ã‚³ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        # ç°¡æ˜“çš„ãªé‡è¤‡æ¤œå‡º
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ ã‚ˆã‚Šé«˜åº¦ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨
        pass

    def generate_dashboard_report(self) -> str:
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        logger.info("ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")

        metrics = self.collect_quality_metrics()

        report = []
        report.append("=" * 60)
        report.append("ğŸ“Š å“è³ªç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - Kumihan Formatter")
        report.append("=" * 60)
        report.append(f"â° ç”Ÿæˆæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
        report.append("ğŸ“ˆ å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹")
        report.append("-" * 30)
        for name, value in metrics.items():
            trend_indicator = ""
            if name in self.trends:
                trend_direction = self.trends[name].trend_direction
                trend_indicator = {
                    "improving": "ğŸ“ˆ",
                    "degrading": "ğŸ“‰",
                    "stable": "â¡ï¸",
                }.get(trend_direction, "")

            report.append(f"{name}: {value:.1f} {trend_indicator}")
        report.append("")

        # ã‚¢ãƒ©ãƒ¼ãƒˆè¡¨ç¤º
        if self.alerts:
            report.append("ğŸš¨ å“è³ªã‚¢ãƒ©ãƒ¼ãƒˆ")
            report.append("-" * 30)
            recent_alerts = [
                a
                for a in self.alerts
                if datetime.now() - a.timestamp < timedelta(hours=24)
            ]

            for alert in recent_alerts[-10:]:  # æœ€æ–°10ä»¶
                severity_icon = {
                    "critical": "ğŸ”´",
                    "high": "ğŸŸ ",
                    "medium": "ğŸŸ¡",
                    "low": "ğŸŸ¢",
                }.get(alert.severity, "âšª")

                report.append(
                    f"{severity_icon} [{alert.severity.upper()}] {alert.component}"
                )
                report.append(f"   {alert.message}")
                report.append(f"   {alert.timestamp.strftime('%H:%M:%S')}")
                report.append("")

        # æŠ€è¡“çš„è² å‚µã‚µãƒãƒªãƒ¼
        unresolved_debt = [item for item in self.technical_debt if not item.resolved]
        if unresolved_debt:
            report.append("ğŸ’¸ æŠ€è¡“çš„è² å‚µã‚µãƒãƒªãƒ¼")
            report.append("-" * 30)

            debt_by_type = {}
            total_hours = 0
            for item in unresolved_debt:
                if item.debt_type not in debt_by_type:
                    debt_by_type[item.debt_type] = {"count": 0, "hours": 0}
                debt_by_type[item.debt_type]["count"] += 1
                debt_by_type[item.debt_type]["hours"] += item.estimated_hours
                total_hours += item.estimated_hours

            for debt_type, stats in debt_by_type.items():
                report.append(
                    f"{debt_type}: {stats['count']}ä»¶ ({stats['hours']:.1f}æ™‚é–“)"
                )

            report.append(f"åˆè¨ˆ: {len(unresolved_debt)}ä»¶ ({total_hours:.1f}æ™‚é–“)")
            report.append("")

        # æ”¹å–„ææ¡ˆ
        report.append("ğŸ’¡ æ”¹å–„ææ¡ˆ")
        report.append("-" * 30)
        suggestions = self._generate_improvement_suggestions(metrics)
        for suggestion in suggestions:
            report.append(f"â€¢ {suggestion}")

        report.append("")
        report.append("=" * 60)

        return "\n".join(report)

    def _generate_improvement_suggestions(self, metrics: Dict[str, float]) -> List[str]:
        """æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ"""
        suggestions = []

        if metrics.get("test_coverage", 0) < 80:
            suggestions.append(
                "ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã®å‘ä¸Š: ç‰¹ã«Critical Tierã®æœªãƒ†ã‚¹ãƒˆæ©Ÿèƒ½ã«æ³¨åŠ›"
            )

        if metrics.get("code_quality", 0) < 85:
            suggestions.append("ã‚³ãƒ¼ãƒ‰å“è³ªã®æ”¹å–„: flake8ã‚¨ãƒ©ãƒ¼ã®ä¿®æ­£ã¨ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°")

        if metrics.get("complexity_score", 0) < 80:
            suggestions.append("è¤‡é›‘åº¦ã®å‰Šæ¸›: é•·ã„é–¢æ•°ã®åˆ†å‰²ã¨å˜ç´”åŒ–")

        if metrics.get("technical_debt_score", 0) < 75:
            suggestions.append("æŠ€è¡“çš„è² å‚µã®è¨ˆç”»çš„è§£æ¶ˆ: é«˜å„ªå…ˆåº¦é …ç›®ã‹ã‚‰æ®µéšçš„ã«å¯¾å¿œ")

        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã«ã‚ˆã‚‹ææ¡ˆ
        for name, trend in self.trends.items():
            if trend.trend_direction == "degrading":
                suggestions.append(f"{name}ã®æ‚ªåŒ–å‚¾å‘ã‚’ç›£è¦–: åŸå› åˆ†æã¨å¯¾ç­–æ¤œè¨ãŒå¿…è¦")

        if not suggestions:
            suggestions.append("å“è³ªæŒ‡æ¨™ã¯è‰¯å¥½ã§ã™ã€‚ç¾åœ¨ã®æ°´æº–ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚")

        return suggestions

    def save_dashboard_report(self, output_file: Path):
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜"""
        report = self.generate_dashboard_report()

        with open(output_file, "w", encoding="utf-8") as f:
            f.write(report)

        logger.info(f"ğŸ“„ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {output_file}")

        # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚‚ä¿å­˜
        self._save_data()


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    project_root = Path(__file__).parent.parent

    logger.info("ğŸš€ å“è³ªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")

    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰åˆæœŸåŒ–
    dashboard = QualityMonitoringDashboard(project_root)

    # æŠ€è¡“çš„è² å‚µã‚¹ã‚­ãƒ£ãƒ³
    dashboard.scan_technical_debt()

    # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
    metrics = dashboard.collect_quality_metrics()

    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_file = project_root / "quality_dashboard.txt"
    dashboard.save_dashboard_report(report_file)

    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
    print(dashboard.generate_dashboard_report())

    # çµæœåˆ¤å®š
    critical_alerts = [a for a in dashboard.alerts if a.severity == "critical"]
    if critical_alerts:
        logger.warning(f"ğŸš¨ {len(critical_alerts)}ä»¶ã®é‡è¦ãªã‚¢ãƒ©ãƒ¼ãƒˆãŒã‚ã‚Šã¾ã™")
        return 1

    logger.info("âœ… å“è³ªç›£è¦–å®Œäº†")
    return 0


if __name__ == "__main__":
    sys.exit(main())
