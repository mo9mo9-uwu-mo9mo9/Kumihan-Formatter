#!/usr/bin/env python3
"""
æœªä½¿ç”¨importè‡ªå‹•æ¤œå‡ºãƒ»å‰Šé™¤ãƒ„ãƒ¼ãƒ«
Issue #1239: å“è³ªä¿è¨¼ã‚·ã‚¹ãƒ†ãƒ å†æ§‹ç¯‰ - ä¾å­˜é–¢ä¿‚æ•´ç†
"""

import ast
import os
import sys
from pathlib import Path
from typing import Dict, List, Set, Tuple
import subprocess


class ImportOptimizer:
    """Importæœ€é©åŒ–ã‚¯ãƒ©ã‚¹"""

    def __init__(self, src_dir: str = "kumihan_formatter"):
        self.src_dir = Path(src_dir)
        self.unused_imports = []
        self.stats = {"files_processed": 0, "imports_removed": 0, "imports_total": 0}

    def find_python_files(self) -> List[Path]:
        """Pythonãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        return list(self.src_dir.glob("**/*.py"))

    def analyze_file(self, file_path: Path) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®importä½¿ç”¨çŠ¶æ³ã‚’åˆ†æ"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            tree = ast.parse(content)

            # importæ–‡ã¨ãã®ä½¿ç”¨çŠ¶æ³ã‚’åˆ†æ
            imports = self._extract_imports(tree)
            used_names = self._extract_used_names(tree)

            unused = []
            for imp in imports:
                if not self._is_import_used(imp, used_names, content):
                    unused.append(imp)

            return {
                "file": file_path,
                "total_imports": len(imports),
                "unused_imports": unused,
                "content": content,
            }

        except (SyntaxError, UnicodeDecodeError) as e:
            print(f"âš ï¸  {file_path}: è§£æã‚¨ãƒ©ãƒ¼ - {e}")
            return None

    def _extract_imports(self, tree: ast.AST) -> List[Dict]:
        """importæ–‡ã‚’æŠ½å‡º"""
        imports = []

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(
                        {
                            "type": "import",
                            "module": alias.name,
                            "name": alias.asname or alias.name.split(".")[0],
                            "line": node.lineno,
                            "full_line": f"import {alias.name}"
                            + (f" as {alias.asname}" if alias.asname else ""),
                        }
                    )
            elif isinstance(node, ast.ImportFrom):
                module = node.module or ""
                for alias in node.names:
                    imports.append(
                        {
                            "type": "from_import",
                            "module": module,
                            "name": alias.asname or alias.name,
                            "imported": alias.name,
                            "line": node.lineno,
                            "full_line": f"from {module} import {alias.name}"
                            + (f" as {alias.asname}" if alias.asname else ""),
                        }
                    )

        return imports

    def _extract_used_names(self, tree: ast.AST) -> Set[str]:
        """ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹åå‰ã‚’æŠ½å‡º"""
        used_names = set()

        for node in ast.walk(tree):
            if isinstance(node, ast.Name):
                used_names.add(node.id)
            elif isinstance(node, ast.Attribute):
                # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«.é–¢æ•°å½¢å¼ã®ä½¿ç”¨ã‚’æ¤œå‡º
                if isinstance(node.value, ast.Name):
                    used_names.add(node.value.id)

        return used_names

    def _is_import_used(
        self, import_info: Dict, used_names: Set[str], content: str
    ) -> bool:
        """importãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        name = import_info["name"]

        # åŸºæœ¬çš„ãªåå‰ãƒã‚§ãƒƒã‚¯
        if name in used_names:
            return True

        # ç‰¹æ®Šã‚±ãƒ¼ã‚¹: __all__ ã§ã®æ˜ç¤ºçš„ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        if "__all__" in content and name in content:
            return True

        # ç‰¹æ®Šã‚±ãƒ¼ã‚¹: å‹æ³¨é‡ˆã§ã®ä½¿ç”¨
        if any(keyword in content for keyword in ["TYPE_CHECKING", "typing"]):
            if name in content:
                return True

        # ç‰¹æ®Šã‚±ãƒ¼ã‚¹: ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã§ã®ä½¿ç”¨
        if f"@{name}" in content:
            return True

        return False

    def optimize_file(self, analysis: Dict, dry_run: bool = True) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®importæœ€é©åŒ–å®Ÿè¡Œ"""
        if not analysis or not analysis["unused_imports"]:
            return False

        file_path = analysis["file"]
        content = analysis["content"]
        lines = content.splitlines()

        # å‰Šé™¤å¯¾è±¡è¡Œã‚’ç‰¹å®šï¼ˆé€†é †ã§å‰Šé™¤ï¼‰
        lines_to_remove = []
        for imp in analysis["unused_imports"]:
            lines_to_remove.append(imp["line"] - 1)  # 0-based index

        lines_to_remove.sort(reverse=True)

        if dry_run:
            print(f"ğŸ“ {file_path}")
            for line_idx in reversed(lines_to_remove):
                print(f"  ğŸ—‘ï¸  L{line_idx + 1}: {lines[line_idx].strip()}")
            return True

        # å®Ÿéš›ã®å‰Šé™¤å®Ÿè¡Œ
        for line_idx in lines_to_remove:
            del lines[line_idx]

        # ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãæˆ»ã—
        new_content = "\n".join(lines) + "\n"
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(new_content)

        print(f"âœ… {file_path}: {len(lines_to_remove)}å€‹ã®importå‰Šé™¤")
        return True

    def run_optimization(self, dry_run: bool = True) -> Dict:
        """æœ€é©åŒ–ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        print(f"ğŸ” Importæœ€é©åŒ–é–‹å§‹ - {'DRY RUN' if dry_run else 'LIVE RUN'}")
        print(f"å¯¾è±¡: {self.src_dir}")
        print("=" * 50)

        files = self.find_python_files()
        total_removed = 0

        for file_path in files:
            analysis = self.analyze_file(file_path)
            if analysis:
                self.stats["files_processed"] += 1
                self.stats["imports_total"] += analysis["total_imports"]

                if analysis["unused_imports"]:
                    self.unused_imports.append(analysis)
                    if self.optimize_file(analysis, dry_run):
                        total_removed += len(analysis["unused_imports"])

        self.stats["imports_removed"] = total_removed
        self._print_summary()

        return self.stats

    def _print_summary(self):
        """çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print("\n" + "=" * 50)
        print("ğŸ“Š Importæœ€é©åŒ–çµæœã‚µãƒãƒªãƒ¼")
        print(f"  - å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {self.stats['files_processed']}")
        print(f"  - ç·importæ–‡: {self.stats['imports_total']}")
        print(f"  - å‰Šé™¤å¯¾è±¡: {self.stats['imports_removed']}")

        if self.stats["imports_total"] > 0:
            reduction_rate = (
                self.stats["imports_removed"] / self.stats["imports_total"]
            ) * 100
            print(f"  - å‰Šæ¸›ç‡: {reduction_rate:.1f}%")

        remaining = self.stats["imports_total"] - self.stats["imports_removed"]
        target = 300

        print(f"  - æœ€é©åŒ–å¾Œäºˆæƒ³: {remaining} (ç›®æ¨™: <{target})")

        if remaining <= target:
            print("ğŸ¯ ç›®æ¨™é”æˆäºˆå®šï¼")
        else:
            excess = remaining - target
            print(f"âš ï¸  ç›®æ¨™ã¾ã§ ã‚ã¨{excess}å€‹ã®å‰Šæ¸›ãŒå¿…è¦")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse

    parser = argparse.ArgumentParser(description="æœªä½¿ç”¨importè‡ªå‹•æ¤œå‡ºãƒ»å‰Šé™¤ãƒ„ãƒ¼ãƒ«")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        default=True,
        help="å®Ÿéš›ã®å‰Šé™¤ã¯è¡Œã‚ãšã€å‰Šé™¤å¯¾è±¡ã®ã¿è¡¨ç¤º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)",
    )
    parser.add_argument("--execute", action="store_true", help="å®Ÿéš›ã«importã‚’å‰Šé™¤å®Ÿè¡Œ")
    parser.add_argument(
        "--src-dir",
        default="kumihan_formatter",
        help="å¯¾è±¡ã‚½ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: kumihan_formatter)",
    )

    args = parser.parse_args()

    # å®‰å…¨æ€§ã®ãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯dry-run
    dry_run = not args.execute

    if not dry_run:
        confirm = input("âš ï¸  å®Ÿéš›ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›´ã—ã¾ã™ã€‚ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿ (y/N): ")
        if confirm.lower() != "y":
            print("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
            sys.exit(1)

    optimizer = ImportOptimizer(args.src_dir)
    stats = optimizer.run_optimization(dry_run=dry_run)

    if dry_run:
        print("\nğŸ’¡ å®Ÿéš›ã«å‰Šé™¤ã™ã‚‹ã«ã¯: python scripts/optimize_imports.py --execute")


if __name__ == "__main__":
    main()
