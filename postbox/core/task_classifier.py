#!/usr/bin/env python3
"""
Task Classifier for Postbox System
æ–°è¦å®Ÿè£…ãƒ»ä¿®æ­£ãƒ»çµ±åˆã®è‡ªå‹•åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ 
"""

import ast
import os
import re
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from enum import Enum
from dataclasses import dataclass


class TaskCategory(Enum):
    """ã‚¿ã‚¹ã‚¯ã‚«ãƒ†ã‚´ãƒª"""
    CODE_MODIFICATION = "code_modification"  # æ—¢å­˜ã‚³ãƒ¼ãƒ‰ä¿®æ­£
    NEW_IMPLEMENTATION = "new_implementation"  # æ–°è¦å®Ÿè£…
    HYBRID_IMPLEMENTATION = "hybrid_implementation"  # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼ˆæ—¢å­˜+æ–°è¦ï¼‰
    FEATURE_DEVELOPMENT = "new_feature_development"  # æ©Ÿèƒ½é–‹ç™º
    REFACTORING = "refactoring"  # ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°
    TESTING = "testing"  # ãƒ†ã‚¹ãƒˆé–¢é€£
    DOCUMENTATION = "documentation"  # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
    CONFIGURATION = "configuration"  # è¨­å®šå¤‰æ›´


class ComplexityLevel(Enum):
    """è¤‡é›‘åº¦ãƒ¬ãƒ™ãƒ«"""
    TRIVIAL = "trivial"      # äº›ç´°ï¼ˆ5åˆ†ä»¥å†…ï¼‰
    SIMPLE = "simple"        # ç°¡å˜ï¼ˆ30åˆ†ä»¥å†…ï¼‰
    MODERATE = "moderate"    # ä¸­ç¨‹åº¦ï¼ˆ2æ™‚é–“ä»¥å†…ï¼‰
    COMPLEX = "complex"      # è¤‡é›‘ï¼ˆåŠæ—¥ä»¥å†…ï¼‰
    CRITICAL = "critical"    # é‡è¦ï¼ˆ1æ—¥ä»¥ä¸Šï¼‰


@dataclass
class TaskClassification:
    """ã‚¿ã‚¹ã‚¯åˆ†é¡çµæœ"""
    category: TaskCategory
    complexity: ComplexityLevel
    confidence: float  # 0.0-1.0
    reasoning: str
    estimated_time: int  # åˆ†
    risk_level: str  # low, medium, high
    recommended_approach: str
    dependencies: List[str]  # ä¾å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«


class TaskClassifier:
    """ã‚¿ã‚¹ã‚¯è‡ªå‹•åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.classification_rules = {
            # ã‚³ãƒ¼ãƒ‰ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³
            "error_patterns": {
                "no-untyped-def": TaskCategory.CODE_MODIFICATION,
                "no-untyped-call": TaskCategory.CODE_MODIFICATION,
                "type-arg": TaskCategory.CODE_MODIFICATION,
                "call-arg": TaskCategory.CODE_MODIFICATION,
                "attr-defined": TaskCategory.CODE_MODIFICATION,
            },
            
            # æ–°è¦å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³
            "implementation_keywords": {
                "æ–°è¦ä½œæˆ", "æ–°è¦å®Ÿè£…", "create new", "implement new",
                "add class", "add function", "add module"
            },
            
            # æ©Ÿèƒ½é–‹ç™ºãƒ‘ã‚¿ãƒ¼ãƒ³
            "feature_keywords": {
                "æ©Ÿèƒ½è¿½åŠ ", "æ©Ÿèƒ½é–‹ç™º", "feature", "functionality",
                "enhancement", "capability"
            },
            
            # ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³
            "refactoring_keywords": {
                "ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°", "refactor", "restructure", "reorganize",
                "clean up", "improve structure"
            }
        }

    def classify_task(self, task_description: str, target_files: List[str],
                     context: Dict[str, Any] = None) -> TaskClassification:
        """ã‚¿ã‚¹ã‚¯ã®è‡ªå‹•åˆ†é¡"""

        print(f"ğŸ” ã‚¿ã‚¹ã‚¯åˆ†é¡é–‹å§‹: {task_description}")
        
        context = context or {}
        
        # 1. åŸºæœ¬åˆ†é¡
        category = self._classify_basic_category(task_description, target_files, context)
        
        # 2. è¤‡é›‘åº¦åˆ†æ
        complexity = self._analyze_complexity(task_description, target_files, category)
        
        # 3. ä¿¡é ¼åº¦è¨ˆç®—
        confidence = self._calculate_confidence(task_description, target_files, category)
        
        # 4. æ¨å®šæ™‚é–“è¨ˆç®—
        estimated_time = self._estimate_time(complexity, len(target_files))
        
        # 5. ãƒªã‚¹ã‚¯è©•ä¾¡
        risk_level = self._assess_risk(category, complexity, target_files)
        
        # 6. æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
        approach = self._recommend_approach(category, complexity, target_files)
        
        # 7. ä¾å­˜é–¢ä¿‚åˆ†æ
        dependencies = self._analyze_dependencies(target_files)
        
        # 8. ç†ç”±ç”Ÿæˆ
        reasoning = self._generate_reasoning(
            category, complexity, confidence, task_description, target_files
        )
        
        classification = TaskClassification(
            category=category,
            complexity=complexity,
            confidence=confidence,
            reasoning=reasoning,
            estimated_time=estimated_time,
            risk_level=risk_level,
            recommended_approach=approach,
            dependencies=dependencies
        )
        
        print(f"ğŸ“Š åˆ†é¡çµæœ: {category.value} ({complexity.value}, ä¿¡é ¼åº¦: {confidence:.2f})")
        
        return classification

    def _classify_basic_category(self, task_description: str, target_files: List[str],
                                context: Dict[str, Any]) -> TaskCategory:
        """åŸºæœ¬ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""

        desc_lower = task_description.lower()
        
        # æ—¢å­˜ã‚¨ãƒ©ãƒ¼ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        for error_pattern, category in self.classification_rules["error_patterns"].items():
            if error_pattern in desc_lower:
                return category
        
        # æ–°è¦å®Ÿè£…ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
        for keyword in self.classification_rules["implementation_keywords"]:
            if keyword.lower() in desc_lower:
                # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèªã§ç´°åˆ†åŒ–
                existing_files = [f for f in target_files if os.path.exists(f)]
                if len(existing_files) == 0:
                    return TaskCategory.NEW_IMPLEMENTATION
                elif len(existing_files) < len(target_files):
                    return TaskCategory.HYBRID_IMPLEMENTATION
                else:
                    return TaskCategory.CODE_MODIFICATION
        
        # æ©Ÿèƒ½é–‹ç™ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
        for keyword in self.classification_rules["feature_keywords"]:
            if keyword.lower() in desc_lower:
                return TaskCategory.FEATURE_DEVELOPMENT
        
        # ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
        for keyword in self.classification_rules["refactoring_keywords"]:
            if keyword.lower() in desc_lower:
                return TaskCategory.REFACTORING
        
        # ãƒ†ã‚¹ãƒˆé–¢é€£ãƒã‚§ãƒƒã‚¯
        if any(keyword in desc_lower for keyword in ["test", "ãƒ†ã‚¹ãƒˆ", "pytest", "unittest"]):
            return TaskCategory.TESTING
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé–¢é€£ãƒã‚§ãƒƒã‚¯
        if any(keyword in desc_lower for keyword in ["document", "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ", "readme", "doc"]):
            return TaskCategory.DOCUMENTATION
        
        # è¨­å®šé–¢é€£ãƒã‚§ãƒƒã‚¯
        if any(keyword in desc_lower for keyword in ["config", "è¨­å®š", "configuration", ".json", ".yaml"]):
            return TaskCategory.CONFIGURATION
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨çŠ¶æ³ã§åˆ¤å®š
        existing_files = [f for f in target_files if os.path.exists(f)]
        if len(existing_files) == 0:
            return TaskCategory.NEW_IMPLEMENTATION
        elif len(existing_files) < len(target_files):
            return TaskCategory.HYBRID_IMPLEMENTATION
        else:
            return TaskCategory.CODE_MODIFICATION

    def _analyze_complexity(self, task_description: str, target_files: List[str],
                           category: TaskCategory) -> ComplexityLevel:
        """è¤‡é›‘åº¦åˆ†æ"""

        complexity_score = 0
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã«ã‚ˆã‚‹å½±éŸ¿
        complexity_score += min(len(target_files) * 0.5, 3)
        
        # ã‚¿ã‚¹ã‚¯ã‚«ãƒ†ã‚´ãƒªã«ã‚ˆã‚‹åŸºæœ¬è¤‡é›‘åº¦
        category_complexity = {
            TaskCategory.CODE_MODIFICATION: 1,
            TaskCategory.NEW_IMPLEMENTATION: 3,
            TaskCategory.HYBRID_IMPLEMENTATION: 4,
            TaskCategory.FEATURE_DEVELOPMENT: 5,
            TaskCategory.REFACTORING: 3,
            TaskCategory.TESTING: 2,
            TaskCategory.DOCUMENTATION: 1,
            TaskCategory.CONFIGURATION: 1
        }
        complexity_score += category_complexity.get(category, 2)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒ»å†…å®¹ã«ã‚ˆã‚‹å½±éŸ¿
        for file_path in target_files:
            if os.path.exists(file_path):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    lines = len(content.split('\n'))
                    if lines > 500:
                        complexity_score += 1
                    if lines > 1000:
                        complexity_score += 1
                    
                    # é–¢æ•°ãƒ»ã‚¯ãƒ©ã‚¹æ•°
                    functions = content.count('def ')
                    classes = content.count('class ')
                    complexity_score += min(functions // 10, 2)
                    complexity_score += min(classes // 3, 2)
                    
                except Exception:
                    pass  # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
        
        # è¤‡é›‘ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        desc_lower = task_description.lower()
        complex_keywords = ["architecture", "integration", "migration", "refactor", "optimization"]
        for keyword in complex_keywords:
            if keyword in desc_lower:
                complexity_score += 2
                break
        
        # è¤‡é›‘åº¦ãƒ¬ãƒ™ãƒ«æ±ºå®š
        if complexity_score <= 2:
            return ComplexityLevel.TRIVIAL
        elif complexity_score <= 4:
            return ComplexityLevel.SIMPLE
        elif complexity_score <= 7:
            return ComplexityLevel.MODERATE
        elif complexity_score <= 10:
            return ComplexityLevel.COMPLEX
        else:
            return ComplexityLevel.CRITICAL

    def _calculate_confidence(self, task_description: str, target_files: List[str],
                             category: TaskCategory) -> float:
        """åˆ†é¡ä¿¡é ¼åº¦è¨ˆç®—"""

        confidence = 0.7  # ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦
        
        # æ˜ç¢ºãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãŒã‚ã‚‹å ´åˆ
        desc_lower = task_description.lower()
        
        # ã‚«ãƒ†ã‚´ãƒªå›ºæœ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å­˜åœ¨ç¢ºèª
        if category == TaskCategory.CODE_MODIFICATION:
            if any(pattern in desc_lower for pattern in self.classification_rules["error_patterns"]):
                confidence += 0.2
        elif category == TaskCategory.NEW_IMPLEMENTATION:
            if any(keyword.lower() in desc_lower for keyword in self.classification_rules["implementation_keywords"]):
                confidence += 0.2
        
        # ãƒ•ã‚¡ã‚¤ãƒ«çŠ¶æ³ã®ä¸€è²«æ€§
        existing_files = [f for f in target_files if os.path.exists(f)]
        if category == TaskCategory.NEW_IMPLEMENTATION and len(existing_files) == 0:
            confidence += 0.1
        elif category == TaskCategory.CODE_MODIFICATION and len(existing_files) == len(target_files):
            confidence += 0.1
        
        # ã‚¿ã‚¹ã‚¯è¨˜è¿°ã®è©³ç´°åº¦
        if len(task_description.split()) > 10:
            confidence += 0.05
        
        return min(confidence, 1.0)

    def _estimate_time(self, complexity: ComplexityLevel, file_count: int) -> int:
        """æ™‚é–“æ¨å®šï¼ˆåˆ†ï¼‰"""

        base_times = {
            ComplexityLevel.TRIVIAL: 5,
            ComplexityLevel.SIMPLE: 20,
            ComplexityLevel.MODERATE: 60,
            ComplexityLevel.COMPLEX: 180,
            ComplexityLevel.CRITICAL: 480
        }
        
        base_time = base_times[complexity]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã«ã‚ˆã‚‹èª¿æ•´
        file_factor = min(file_count * 0.3, 2.0)
        
        return int(base_time * (1 + file_factor))

    def _assess_risk(self, category: TaskCategory, complexity: ComplexityLevel,
                    target_files: List[str]) -> str:
        """ãƒªã‚¹ã‚¯è©•ä¾¡"""

        risk_score = 0
        
        # ã‚«ãƒ†ã‚´ãƒªã«ã‚ˆã‚‹ãƒªã‚¹ã‚¯
        category_risk = {
            TaskCategory.CODE_MODIFICATION: 1,
            TaskCategory.NEW_IMPLEMENTATION: 2,
            TaskCategory.HYBRID_IMPLEMENTATION: 3,
            TaskCategory.FEATURE_DEVELOPMENT: 3,
            TaskCategory.REFACTORING: 4,
            TaskCategory.TESTING: 1,
            TaskCategory.DOCUMENTATION: 0,
            TaskCategory.CONFIGURATION: 2
        }
        risk_score += category_risk.get(category, 2)
        
        # è¤‡é›‘åº¦ã«ã‚ˆã‚‹ãƒªã‚¹ã‚¯
        complexity_risk = {
            ComplexityLevel.TRIVIAL: 0,
            ComplexityLevel.SIMPLE: 1,
            ComplexityLevel.MODERATE: 2,
            ComplexityLevel.COMPLEX: 3,
            ComplexityLevel.CRITICAL: 4
        }
        risk_score += complexity_risk[complexity]
        
        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿®æ­£
        critical_paths = ["main", "core", "__init__", "config", "settings"]
        for file_path in target_files:
            if any(critical in file_path.lower() for critical in critical_paths):
                risk_score += 1
                break
        
        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«æ±ºå®š
        if risk_score <= 2:
            return "low"
        elif risk_score <= 5:
            return "medium"
        else:
            return "high"

    def _recommend_approach(self, category: TaskCategory, complexity: ComplexityLevel,
                           target_files: List[str]) -> str:
        """æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ"""

        approach = f"{category.value}å‘ã‘ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ:\n"
        
        if category == TaskCategory.CODE_MODIFICATION:
            if complexity in [ComplexityLevel.TRIVIAL, ComplexityLevel.SIMPLE]:
                approach += "- ç›´æ¥ä¿®æ­£ãƒ»ä¸€æ‹¬å‡¦ç†\n- è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«ã®æ´»ç”¨"
            else:
                approach += "- æ®µéšçš„ä¿®æ­£\n- è©³ç´°ãƒ†ã‚¹ãƒˆãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼"
        
        elif category == TaskCategory.NEW_IMPLEMENTATION:
            approach += "- ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹å®Ÿè£…\n- æ®µéšçš„é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆ\n- å“è³ªåŸºæº–å³æ ¼é©ç”¨"
        
        elif category == TaskCategory.HYBRID_IMPLEMENTATION:
            approach += "- æ—¢å­˜å½±éŸ¿æœ€å°åŒ–\n- æ–°è¦éƒ¨åˆ†ã®ç‹¬ç«‹å®Ÿè£…\n- çµ±åˆãƒ†ã‚¹ãƒˆé‡è¦–"
        
        elif category == TaskCategory.FEATURE_DEVELOPMENT:
            approach += "- è¦æ±‚ä»•æ§˜è©³ç´°åŒ–\n- ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—é–‹ç™º\n- æ®µéšçš„æ©Ÿèƒ½å®Ÿè£…"
        
        elif category == TaskCategory.REFACTORING:
            approach += "- ç¾çŠ¶åˆ†æãƒ»è¨­è¨ˆ\n- å®‰å…¨ãªãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•\n- å›å¸°ãƒ†ã‚¹ãƒˆå¾¹åº•"
        
        else:
            approach += "- ã‚«ãƒ†ã‚´ãƒªå›ºæœ‰ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹é©ç”¨"
        
        return approach

    def _analyze_dependencies(self, target_files: List[str]) -> List[str]:
        """ä¾å­˜é–¢ä¿‚åˆ†æ"""

        dependencies = []
        
        for file_path in target_files:
            if not os.path.exists(file_path):
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # importæ–‡ã®æŠ½å‡º
                import_lines = [line.strip() for line in content.split('\n')
                               if line.strip().startswith(('import ', 'from '))]
                
                for line in import_lines:
                    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
                    if 'kumihan_formatter' in line or '.' in line:
                        dependencies.append(line)
                
            except Exception:
                pass  # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
        
        return list(set(dependencies))  # é‡è¤‡é™¤å»

    def _generate_reasoning(self, category: TaskCategory, complexity: ComplexityLevel,
                           confidence: float, task_description: str,
                           target_files: List[str]) -> str:
        """åˆ†é¡ç†ç”±ç”Ÿæˆ"""

        reasoning = f"ã‚¿ã‚¹ã‚¯è‡ªå‹•åˆ†é¡çµæœ:\n"
        reasoning += f"ã‚«ãƒ†ã‚´ãƒª: {category.value} (ä¿¡é ¼åº¦: {confidence:.2f})\n"
        reasoning += f"è¤‡é›‘åº¦: {complexity.value}\n"
        reasoning += f"å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {len(target_files)}ä»¶\n\n"
        
        reasoning += "åˆ†é¡æ ¹æ‹ :\n"
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡æ ¹æ‹ 
        desc_lower = task_description.lower()
        
        if category == TaskCategory.CODE_MODIFICATION:
            for pattern in self.classification_rules["error_patterns"]:
                if pattern in desc_lower:
                    reasoning += f"- ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern}' ã‚’æ¤œå‡º\n"
                    break
        
        elif category == TaskCategory.NEW_IMPLEMENTATION:
            for keyword in self.classification_rules["implementation_keywords"]:
                if keyword.lower() in desc_lower:
                    reasoning += f"- æ–°è¦å®Ÿè£…ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ '{keyword}' ã‚’æ¤œå‡º\n"
                    break
            
            existing_files = [f for f in target_files if os.path.exists(f)]
            if len(existing_files) == 0:
                reasoning += "- å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¨ã¦æœªä½œæˆ\n"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«çŠ¶æ³
        existing_count = len([f for f in target_files if os.path.exists(f)])
        reasoning += f"- æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«: {existing_count}/{len(target_files)}ä»¶\n"
        
        # è¤‡é›‘åº¦è¦å› 
        if complexity in [ComplexityLevel.COMPLEX, ComplexityLevel.CRITICAL]:
            reasoning += f"- é«˜è¤‡é›‘åº¦è¦å› : å¤šæ•°ãƒ•ã‚¡ã‚¤ãƒ«ã€å¤§è¦æ¨¡å¤‰æ›´ã€ã¾ãŸã¯ãƒªã‚¹ã‚¯è¦å› \n"
        
        return reasoning

    def get_classification_stats(self) -> Dict[str, Any]:
        """åˆ†é¡çµ±è¨ˆæƒ…å ±"""
        
        return {
            "available_categories": [cat.value for cat in TaskCategory],
            "complexity_levels": [level.value for level in ComplexityLevel],
            "classification_rules": {
                "error_patterns": len(self.classification_rules["error_patterns"]),
                "implementation_keywords": len(self.classification_rules["implementation_keywords"]),
                "feature_keywords": len(self.classification_rules["feature_keywords"]),
                "refactoring_keywords": len(self.classification_rules["refactoring_keywords"])
            }
        }


def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    classifier = TaskClassifier()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        {
            "description": "no-untyped-def ã‚¨ãƒ©ãƒ¼ä¿®æ­£",
            "files": ["kumihan_formatter/core/utilities/logger.py"],
        },
        {
            "description": "æ–°è¦ã‚¯ãƒ©ã‚¹ UserManager ã‚’å®Ÿè£…",
            "files": ["src/user_manager.py"],
        },
        {
            "description": "æ–°æ©Ÿèƒ½ï¼šãƒ­ã‚°åˆ†æã‚·ã‚¹ãƒ†ãƒ é–‹ç™º",
            "files": ["src/analysis/log_analyzer.py", "tests/test_log_analyzer.py"],
        }
    ]
    
    print("ğŸ§ª TaskClassifier ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ\n")
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"=== ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i} ===")
        
        classification = classifier.classify_task(
            test_case["description"],
            test_case["files"]
        )
        
        print(f"åˆ†é¡çµæœ:")
        print(f"  ã‚«ãƒ†ã‚´ãƒª: {classification.category.value}")
        print(f"  è¤‡é›‘åº¦: {classification.complexity.value}")
        print(f"  æ¨å®šæ™‚é–“: {classification.estimated_time}åˆ†")
        print(f"  ãƒªã‚¹ã‚¯: {classification.risk_level}")
        print(f"  ä¿¡é ¼åº¦: {classification.confidence:.2f}")
        print(f"  æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: {classification.recommended_approach}")
        print()


if __name__ == "__main__":
    main()