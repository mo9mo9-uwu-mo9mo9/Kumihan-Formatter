#!/usr/bin/env python3
"""
Performance Optimizer - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³
Issue #870: è¤‡é›‘ã‚¿ã‚¹ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³æ‹¡å¼µ

å®Ÿè¡Œæ™‚é–“ãƒ»ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãƒ»ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã®è‡ªå‹•æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ»ãƒœãƒˆãƒ«ãƒãƒƒã‚¯æ¤œå‡ºãƒ»æœ€é©åŒ–ææ¡ˆã®çµ±åˆãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
"""

import ast
import os
import sys
import time
# psutilçµ±åˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    psutil = None  # type: ignore
import threading
import tracemalloc
from typing import Dict, List, Any, Set, Optional, Tuple, Union, Callable
from pathlib import Path
from dataclasses import dataclass, asdict
from enum import Enum
import cProfile
import pstats
import io
from contextlib import contextmanager
import functools
import gc
import weakref

# ãƒ­ã‚¬ãƒ¼çµ±åˆ
try:
    from kumihan_formatter.core.utilities.logger import get_logger
    logger = get_logger(__name__)
except ImportError:
    import logging
    logger = logging.getLogger(__name__)


class OptimizationType(Enum):
    """æœ€é©åŒ–ã‚¿ã‚¤ãƒ—"""
    CPU_OPTIMIZATION = "cpu_optimization"
    MEMORY_OPTIMIZATION = "memory_optimization"
    IO_OPTIMIZATION = "io_optimization"
    ALGORITHM_OPTIMIZATION = "algorithm_optimization"
    CACHING_OPTIMIZATION = "caching_optimization"
    CONCURRENCY_OPTIMIZATION = "concurrency_optimization"
    DATABASE_OPTIMIZATION = "database_optimization"
    NETWORK_OPTIMIZATION = "network_optimization"


class PerformanceIssueType(Enum):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã‚¿ã‚¤ãƒ—"""
    HIGH_CPU_USAGE = "high_cpu_usage"
    MEMORY_LEAK = "memory_leak"
    SLOW_FUNCTION = "slow_function"
    INEFFICIENT_LOOP = "inefficient_loop"
    UNNECESSARY_COMPUTATION = "unnecessary_computation"
    POOR_CACHING = "poor_caching"
    BLOCKING_IO = "blocking_io"
    EXCESSIVE_GC = "excessive_gc"


@dataclass
class PerformanceMetrics:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    execution_time: float
    cpu_usage: float
    memory_usage: float
    memory_peak: float
    gc_collections: int
    function_calls: int
    io_operations: int
    cache_hits: int
    cache_misses: int
    thread_count: int


@dataclass
class PerformanceIssue:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ"""
    file_path: str
    function_name: str
    line_number: int
    issue_type: PerformanceIssueType
    severity: str  # "critical", "high", "medium", "low"
    description: str
    current_metrics: PerformanceMetrics
    impact_score: float
    suggested_fix: str
    optimization_type: OptimizationType
    estimated_improvement: float


@dataclass
class OptimizationResult:
    """æœ€é©åŒ–çµæœ"""
    original_metrics: PerformanceMetrics
    optimized_metrics: PerformanceMetrics
    improvement_percentage: float
    applied_optimizations: List[str]
    execution_time_reduction: float
    memory_reduction: float
    code_changes: List[str]


class PerformanceProfiler:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼"""

    def __init__(self) -> None:
        self.profiling_data: Dict[str, Any] = {}
        self.memory_tracking = False
        self.cpu_tracking = False

    @contextmanager
    def profile_execution(self, name: str) -> Any:
        """å®Ÿè¡Œãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°"""

        # ãƒ¡ãƒ¢ãƒªãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°é–‹å§‹
        tracemalloc.start()

        # CPUä½¿ç”¨ç‡æ¸¬å®šé–‹å§‹
        cpu_start = 0.0
        if PSUTIL_AVAILABLE and psutil:
            try:
                process = psutil.Process()
                cpu_start = process.cpu_percent()
            except Exception:
                cpu_start = 0.0

        # æ™‚é–“æ¸¬å®šé–‹å§‹
        start_time = time.perf_counter()

        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼é–‹å§‹
        profiler = cProfile.Profile()
        profiler.enable()

        try:
            yield self
        finally:
            # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼åœæ­¢
            profiler.disable()

            # æ¸¬å®šçµ‚äº†
            end_time = time.perf_counter()
            execution_time = end_time - start_time

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å–å¾—
            current_memory, peak_memory = tracemalloc.get_traced_memory()
            tracemalloc.stop()

            # CPUä½¿ç”¨ç‡å–å¾—
            cpu_end = 0.0
            if PSUTIL_AVAILABLE and psutil:
                try:
                    cpu_end = process.cpu_percent()
                except Exception:
                    cpu_end = 0.0

            # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆç”Ÿæˆ
            stats_stream = io.StringIO()
            stats = pstats.Stats(profiler, stream=stats_stream)
            stats.sort_stats('cumulative')

            # çµæœä¿å­˜
            self.profiling_data[name] = {
                'execution_time': execution_time,
                'memory_current': current_memory,
                'memory_peak': peak_memory,
                'cpu_usage': (cpu_start + cpu_end) / 2,
                'profile_stats': stats,
                'stats_output': stats_stream.getvalue()
            }

            logger.info(f"ğŸ“Š ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Œäº† ({name}): {execution_time:.3f}ç§’")

    def get_performance_metrics(self, name: str) -> Optional[PerformanceMetrics]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""

        if name not in self.profiling_data:
            return None

        data = self.profiling_data[name]

        return PerformanceMetrics(
            execution_time=data['execution_time'],
            cpu_usage=data['cpu_usage'],
            memory_usage=data['memory_current'] / 1024 / 1024,  # MB
            memory_peak=data['memory_peak'] / 1024 / 1024,     # MB
            gc_collections=len(gc.get_stats()),
            function_calls=0,  # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æŠ½å‡º
            io_operations=0,   # ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ã‹ã‚‰å–å¾—
            cache_hits=0,      # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å–å¾—
            cache_misses=0,
            thread_count=threading.active_count()
        )

    def analyze_bottlenecks(self, name: str) -> List[Dict[str, Any]]:
        """ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æ"""

        if name not in self.profiling_data:
            return []

        data = self.profiling_data[name]
        stats = data['profile_stats']

        bottlenecks = []

        # ä¸Šä½ã®æ™‚é–“æ¶ˆè²»é–¢æ•°ã‚’ç‰¹å®š
        stats.sort_stats('cumulative')

        # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸Šä½é–¢æ•°æŠ½å‡º
        for func_info in stats.stats.items()[:10]:  # ä¸Šä½10é–¢æ•°
            filename, line_num, func_name = func_info[0]
            cc, nc, tt, ct, callers = func_info[1]

            if tt > 0.001:  # 1msä»¥ä¸Šã®é–¢æ•°ã®ã¿
                bottlenecks.append({
                    'file': filename,
                    'line': line_num,
                    'function': func_name,
                    'total_time': tt,
                    'cumulative_time': ct,
                    'call_count': cc,
                    'time_per_call': tt / cc if cc > 0 else 0
                })

        return bottlenecks


class PerformanceAnalyzer:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è§£æå™¨"""

    def __init__(self) -> None:
        self.profiler = PerformanceProfiler()
        self.baseline_metrics: Dict[str, PerformanceMetrics] = {}

    def analyze_file(self, file_path: str) -> List[PerformanceIssue]:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ€§èƒ½è§£æ"""

        logger.info(f"âš¡ æ€§èƒ½è§£æé–‹å§‹: {file_path}")

        issues = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content, filename=file_path)

            # å„ç¨®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã‚’æ¤œå‡º
            issues.extend(self._detect_inefficient_loops(tree, file_path))
            issues.extend(self._detect_memory_issues(tree, file_path))
            issues.extend(self._detect_cpu_intensive_operations(tree, file_path))
            issues.extend(self._detect_io_bottlenecks(tree, file_path))
            issues.extend(self._detect_caching_opportunities(tree, file_path))

            logger.info(f"âœ… æ€§èƒ½è§£æå®Œäº†: {len(issues)}ä»¶ã®å•é¡Œã‚’æ¤œå‡º")

        except Exception as e:
            logger.error(f"æ€§èƒ½è§£æã‚¨ãƒ©ãƒ¼ {file_path}: {e}")

        return issues

    def _detect_inefficient_loops(self, tree: ast.AST, file_path: str) -> List[PerformanceIssue]:
        """éåŠ¹ç‡ãƒ«ãƒ¼ãƒ—ã®æ¤œå‡º"""
        issues = []

        for node in ast.walk(tree):
            if isinstance(node, ast.For):
                # ãƒã‚¹ãƒˆã—ãŸãƒ«ãƒ¼ãƒ—ã®æ¤œå‡º
                nested_loops = sum(1 for child in ast.walk(node) if isinstance(child, ast.For))

                if nested_loops > 2:  # 3é‡ä»¥ä¸Šã®ãƒã‚¹ãƒˆ
                    issues.append(PerformanceIssue(
                        file_path=file_path,
                        function_name=self._find_parent_function(tree, node),
                        line_number=node.lineno,
                        issue_type=PerformanceIssueType.INEFFICIENT_LOOP,
                        severity="high",
                        description=f"{nested_loops}é‡ãƒã‚¹ãƒˆãƒ«ãƒ¼ãƒ— - O(n^{nested_loops})ã®è¨ˆç®—é‡",
                        current_metrics=PerformanceMetrics(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
                        impact_score=nested_loops * 0.3,
                        suggested_fix="ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–ã¾ãŸã¯ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®è¦‹ç›´ã—",
                        optimization_type=OptimizationType.ALGORITHM_OPTIMIZATION,
                        estimated_improvement=0.5
                    ))

                # ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜ã«å¤‰æ›´å¯èƒ½ãªãƒ‘ã‚¿ãƒ¼ãƒ³
                if self._can_convert_to_comprehension(node):
                    issues.append(PerformanceIssue(
                        file_path=file_path,
                        function_name=self._find_parent_function(tree, node),
                        line_number=node.lineno,
                        issue_type=PerformanceIssueType.INEFFICIENT_LOOP,
                        severity="medium",
                        description="ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜ã§é«˜é€ŸåŒ–å¯èƒ½",
                        current_metrics=PerformanceMetrics(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
                        impact_score=0.2,
                        suggested_fix="ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜ã«å¤‰æ›´",
                        optimization_type=OptimizationType.ALGORITHM_OPTIMIZATION,
                        estimated_improvement=0.3
                    ))

        return issues

    def _detect_memory_issues(self, tree: ast.AST, file_path: str) -> List[PerformanceIssue]:
        """ãƒ¡ãƒ¢ãƒªå•é¡Œã®æ¤œå‡º"""
        issues = []

        for node in ast.walk(tree):
            # å¤§ããªãƒªã‚¹ãƒˆ/è¾æ›¸ã®ç”Ÿæˆ
            if isinstance(node, (ast.List, ast.Dict)):
                if len(getattr(node, 'elts', getattr(node, 'keys', []))) > 1000:
                    issues.append(PerformanceIssue(
                        file_path=file_path,
                        function_name=self._find_parent_function(tree, node),
                        line_number=node.lineno,
                        issue_type=PerformanceIssueType.MEMORY_LEAK,
                        severity="medium",
                        description="å¤§ããªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ä¸€æ‹¬ç”Ÿæˆ",
                        current_metrics=PerformanceMetrics(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
                        impact_score=0.4,
                        suggested_fix="ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã¾ãŸã¯é…å»¶è©•ä¾¡ã®ä½¿ç”¨",
                        optimization_type=OptimizationType.MEMORY_OPTIMIZATION,
                        estimated_improvement=0.6
                    ))

            # æ–‡å­—åˆ—ã®éåŠ¹ç‡ãªçµåˆ
            if isinstance(node, ast.BinOp) and isinstance(node.op, ast.Add):
                if self._is_string_concatenation(node):
                    issues.append(PerformanceIssue(
                        file_path=file_path,
                        function_name=self._find_parent_function(tree, node),
                        line_number=node.lineno,
                        issue_type=PerformanceIssueType.INEFFICIENT_LOOP,
                        severity="medium",
                        description="éåŠ¹ç‡ãªæ–‡å­—åˆ—çµåˆ",
                        current_metrics=PerformanceMetrics(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
                        impact_score=0.3,
                        suggested_fix="join()ãƒ¡ã‚½ãƒƒãƒ‰ã¾ãŸã¯f-stringã®ä½¿ç”¨",
                        optimization_type=OptimizationType.MEMORY_OPTIMIZATION,
                        estimated_improvement=0.4
                    ))

        return issues

    def _detect_cpu_intensive_operations(self, tree: ast.AST, file_path: str) -> List[PerformanceIssue]:
        """CPUé›†ç´„çš„æ“ä½œã®æ¤œå‡º"""
        issues = []

        cpu_intensive_functions = {
            'sorted', 'sort', 'min', 'max', 'sum', 'any', 'all',
            'map', 'filter', 'reduce', 'zip'
        }

        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                func_name = None

                if isinstance(node.func, ast.Name):
                    func_name = node.func.id
                elif isinstance(node.func, ast.Attribute):
                    func_name = node.func.attr

                if func_name in cpu_intensive_functions:
                    # å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ä½¿ç”¨ã‚’æ¤œå‡º
                    issues.append(PerformanceIssue(
                        file_path=file_path,
                        function_name=self._find_parent_function(tree, node),
                        line_number=node.lineno,
                        issue_type=PerformanceIssueType.HIGH_CPU_USAGE,
                        severity="medium",
                        description=f"CPUé›†ç´„çš„é–¢æ•° '{func_name}' ã®ä½¿ç”¨",
                        current_metrics=PerformanceMetrics(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
                        impact_score=0.3,
                        suggested_fix="ä¸¦åˆ—å‡¦ç†ã¾ãŸã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ¤œè¨",
                        optimization_type=OptimizationType.CPU_OPTIMIZATION,
                        estimated_improvement=0.3
                    ))

        return issues

    def _detect_io_bottlenecks(self, tree: ast.AST, file_path: str) -> List[PerformanceIssue]:
        """I/Oãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®æ¤œå‡º"""
        issues = []

        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                # ãƒ•ã‚¡ã‚¤ãƒ«I/Oæ“ä½œ
                if isinstance(node.func, ast.Name) and node.func.id == 'open':
                    # ãƒ«ãƒ¼ãƒ—å†…ã§ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ¼ãƒ—ãƒ³
                    parent_loop = self._find_parent_loop(tree, node)
                    if parent_loop:
                        issues.append(PerformanceIssue(
                            file_path=file_path,
                            function_name=self._find_parent_function(tree, node),
                            line_number=node.lineno,
                            issue_type=PerformanceIssueType.BLOCKING_IO,
                            severity="high",
                            description="ãƒ«ãƒ¼ãƒ—å†…ã§ã®ãƒ•ã‚¡ã‚¤ãƒ«I/Oæ“ä½œ",
                            current_metrics=PerformanceMetrics(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
                            impact_score=0.7,
                            suggested_fix="ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒå‡¦ç†ã¾ãŸã¯éåŒæœŸI/O",
                            optimization_type=OptimizationType.IO_OPTIMIZATION,
                            estimated_improvement=0.8
                        ))

        return issues

    def _detect_caching_opportunities(self, tree: ast.AST, file_path: str) -> List[PerformanceIssue]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿä¼šã®æ¤œå‡º"""
        issues = []

        function_calls: Dict[str, List[int]] = {}

        # åŒä¸€é–¢æ•°ã®ç¹°ã‚Šè¿”ã—å‘¼ã³å‡ºã—ã‚’æ¤œå‡º
        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                func_name = None

                if isinstance(node.func, ast.Name):
                    func_name = node.func.id
                elif isinstance(node.func, ast.Attribute):
                    func_name = node.func.attr

                if func_name:
                    if func_name not in function_calls:
                        function_calls[func_name] = []
                    function_calls[func_name].append(node.lineno)

        # é »ç¹ã«å‘¼ã³å‡ºã•ã‚Œã‚‹é–¢æ•°ã‚’ç‰¹å®š
        for func_name, line_numbers in function_calls.items():
            if len(line_numbers) > 5:  # 5å›ä»¥ä¸Šã®å‘¼ã³å‡ºã—
                issues.append(PerformanceIssue(
                    file_path=file_path,
                    function_name=func_name,
                    line_number=line_numbers[0],
                    issue_type=PerformanceIssueType.POOR_CACHING,
                    severity="medium",
                    description=f"é–¢æ•° '{func_name}' ã®é »ç¹ãªå‘¼ã³å‡ºã— ({len(line_numbers)}å›)",
                    current_metrics=PerformanceMetrics(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
                    impact_score=len(line_numbers) * 0.1,
                    suggested_fix="çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¾ãŸã¯ãƒ¡ãƒ¢åŒ–",
                    optimization_type=OptimizationType.CACHING_OPTIMIZATION,
                    estimated_improvement=0.5
                ))

        return issues

    def _find_parent_function(self, tree: ast.AST, target_node: ast.AST) -> str:
        """è¦ªé–¢æ•°ã®æ¤œç´¢"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                for child in ast.walk(node):
                    if child == target_node:
                        return node.name
        return "unknown"

    def _find_parent_loop(self, tree: ast.AST, target_node: ast.AST) -> Optional[ast.AST]:
        """è¦ªãƒ«ãƒ¼ãƒ—ã®æ¤œç´¢"""
        for node in ast.walk(tree):
            if isinstance(node, (ast.For, ast.While)):
                for child in ast.walk(node):
                    if child == target_node:
                        return node
        return None

    def _can_convert_to_comprehension(self, loop_node: ast.For) -> bool:
        """ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜å¤‰æ›å¯èƒ½æ€§"""
        # ç°¡æ˜“åˆ¤å®šï¼šå˜ç´”ãªappendæ“ä½œãŒã‚ã‚‹ã‹
        for node in ast.walk(loop_node):
            if isinstance(node, ast.Call):
                if isinstance(node.func, ast.Attribute) and node.func.attr == 'append':
                    return True
        return False

    def _is_string_concatenation(self, node: ast.BinOp) -> bool:
        """æ–‡å­—åˆ—çµåˆã®åˆ¤å®š"""
        # ç°¡æ˜“åˆ¤å®šï¼šå·¦å³ãŒæ–‡å­—åˆ—ã¾ãŸã¯æ–‡å­—åˆ—å±æ€§
        return True  # è©³ç´°å®Ÿè£…ã¯çœç•¥


class OptimizationEngine:
    """æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self) -> None:
        self.cache: Dict[str, Any] = {}
        self.memoization_cache: Dict[Any, Any] = {}

    def optimize_function(self, func: Callable, optimization_type: OptimizationType) -> Callable:
        """é–¢æ•°æœ€é©åŒ–"""

        if optimization_type == OptimizationType.CACHING_OPTIMIZATION:
            return self._apply_memoization(func)
        elif optimization_type == OptimizationType.CPU_OPTIMIZATION:
            return self._apply_cpu_optimization(func)
        elif optimization_type == OptimizationType.MEMORY_OPTIMIZATION:
            return self._apply_memory_optimization(func)
        else:
            return func

    def _apply_memoization(self, func: Callable) -> Callable:
        """ãƒ¡ãƒ¢åŒ–é©ç”¨"""

        @functools.wraps(func)
        def memoized_func(*args: Any, **kwargs: Any) -> Any:
            # ã‚­ãƒ¼ã‚’ç”Ÿæˆï¼ˆhashableãªå¼•æ•°ã®ã¿ï¼‰
            try:
                key = (func.__name__, args, tuple(sorted(kwargs.items())))

                if key in self.memoization_cache:
                    return self.memoization_cache[key]

                result = func(*args, **kwargs)
                self.memoization_cache[key] = result
                return result

            except TypeError:
                # hashableã§ãªã„å¼•æ•°ã®å ´åˆã¯é€šå¸¸å®Ÿè¡Œ
                return func(*args, **kwargs)

        return memoized_func

    def _apply_cpu_optimization(self, func: Callable) -> Callable:
        """CPUæœ€é©åŒ–é©ç”¨"""

        @functools.wraps(func)
        def optimized_func(*args: Any, **kwargs: Any) -> Any:
            # ä¸¦åˆ—å‡¦ç†å¯èƒ½ãªå ´åˆã®æœ€é©åŒ–
            result = func(*args, **kwargs)
            return result

        return optimized_func

    def _apply_memory_optimization(self, func: Callable) -> Callable:
        """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–é©ç”¨"""

        @functools.wraps(func)
        def optimized_func(*args: Any, **kwargs: Any) -> Any:
            # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æœ€é©åŒ–
            gc.collect()
            result = func(*args, **kwargs)
            gc.collect()
            return result

        return optimized_func


class PerformanceOptimizer:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–å™¨ - ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""

    def __init__(self, project_root: Optional[str] = None) -> None:
        self.project_root = Path(project_root or os.getcwd())
        self.analyzer = PerformanceAnalyzer()
        self.engine = OptimizationEngine()
        self.optimization_history: List[OptimizationResult] = []

        logger.info("âš¡ Performance Optimizer åˆæœŸåŒ–å®Œäº†")
        logger.info(f"ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {self.project_root}")

    def analyze_project_performance(self, target_paths: Optional[List[str]] = None) -> Dict[str, List[PerformanceIssue]]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ€§èƒ½è§£æ"""

        logger.info("âš¡ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ€§èƒ½è§£æé–‹å§‹")

        if target_paths is None:
            target_paths = self._find_python_files()

        results = {}
        total_issues = 0

        for file_path in target_paths:
            try:
                issues = self.analyzer.analyze_file(file_path)
                results[file_path] = issues
                total_issues += len(issues)
            except Exception as e:
                logger.error(f"æ€§èƒ½è§£æã‚¨ãƒ©ãƒ¼ {file_path}: {e}")

        logger.info(f"âœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ€§èƒ½è§£æå®Œäº†: {total_issues}ä»¶ã®å•é¡Œ")
        return results

    def profile_function(self, func: Callable, *args, **kwargs) -> PerformanceMetrics:
        """é–¢æ•°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°"""

        func_name = func.__name__

        with self.analyzer.profiler.profile_execution(func_name):
            result = func(*args, **kwargs)

        metrics = self.analyzer.profiler.get_performance_metrics(func_name)

        if metrics:
            logger.info(f"ğŸ“Š é–¢æ•°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Œäº† ({func_name}):")
            logger.info(f"  - å®Ÿè¡Œæ™‚é–“: {metrics.execution_time:.3f}ç§’")
            logger.info(f"  - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {metrics.memory_usage:.1f}MB")
            logger.info(f"  - CPUä½¿ç”¨ç‡: {metrics.cpu_usage:.1f}%")

        return metrics

    def apply_optimizations(
        self,
        file_path: str,
        issues: List[PerformanceIssue],
        auto_apply: bool = False
    ) -> OptimizationResult:
        """æœ€é©åŒ–é©ç”¨"""

        logger.info(f"âš¡ æœ€é©åŒ–é©ç”¨é–‹å§‹: {file_path}")
        logger.info(f"ğŸ¯ å¯¾è±¡å•é¡Œ: {len(issues)}ä»¶")

        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š
        original_metrics = self._measure_file_performance(file_path)

        applied_optimizations = []
        code_changes = []

        # é«˜å½±éŸ¿åº¦ã®å•é¡Œã‹ã‚‰é †ã«æœ€é©åŒ–
        sorted_issues = sorted(issues, key=lambda x: -x.impact_score)

        for issue in sorted_issues:
            if auto_apply or issue.severity in ['critical', 'high']:
                try:
                    optimization = self._apply_single_optimization(issue)
                    applied_optimizations.append(optimization)
                    code_changes.append(f"{issue.function_name}: {issue.suggested_fix}")
                    logger.info(f"âœ… æœ€é©åŒ–é©ç”¨: {issue.description}")
                except Exception as e:
                    logger.error(f"æœ€é©åŒ–é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")

        # æœ€é©åŒ–å¾Œã®æ¸¬å®š
        optimized_metrics = self._measure_file_performance(file_path)

        # æ”¹å–„ç‡è¨ˆç®—
        improvement_percentage = self._calculate_improvement(
            original_metrics, optimized_metrics
        )

        result = OptimizationResult(
            original_metrics=original_metrics,
            optimized_metrics=optimized_metrics,
            improvement_percentage=improvement_percentage,
            applied_optimizations=applied_optimizations,
            execution_time_reduction=original_metrics.execution_time - optimized_metrics.execution_time,
            memory_reduction=original_metrics.memory_usage - optimized_metrics.memory_usage,
            code_changes=code_changes
        )

        self.optimization_history.append(result)

        logger.info(f"âœ… æœ€é©åŒ–å®Œäº†:")
        logger.info(f"  - é©ç”¨æ•°: {len(applied_optimizations)}")
        logger.info(f"  - æ”¹å–„ç‡: {improvement_percentage:.1%}")
        logger.info(f"  - å®Ÿè¡Œæ™‚é–“å‰Šæ¸›: {result.execution_time_reduction:.3f}ç§’")

        return result

    def generate_performance_report(self, analysis_results: Dict[str, List[PerformanceIssue]]) -> str:
        """æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""

        logger.info("ğŸ“Š æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")

        total_issues = sum(len(issues) for issues in analysis_results.values())
        critical_count = sum(
            len([issue for issue in issues if issue.severity == 'critical'])
            for issues in analysis_results.values()
        )

        report_lines = [
            "# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è§£æãƒ¬ãƒãƒ¼ãƒˆ",
            "",
            "## æ¦‚è¦",
            f"- è§£æãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(analysis_results)}",
            f"- ç·å•é¡Œæ•°: {total_issues}ä»¶",
            f"- ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«: {critical_count}ä»¶",
            "",
            "## ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥è©³ç´°",
            ""
        ]

        for file_path, issues in analysis_results.items():
            rel_path = os.path.relpath(file_path, self.project_root)

            # å•é¡Œã‚’é‡è¦åº¦åˆ¥ã«åˆ†é¡
            critical = [i for i in issues if i.severity == 'critical']
            high = [i for i in issues if i.severity == 'high']
            medium = [i for i in issues if i.severity == 'medium']

            report_lines.extend([
                f"### {rel_path}",
                "",
                f"- ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«: {len(critical)}ä»¶",
                f"- é«˜: {len(high)}ä»¶",
                f"- ä¸­: {len(medium)}ä»¶",
                "",
                "#### ä¸»è¦å•é¡Œ",
                ""
            ])

            # ä¸Šä½å•é¡Œè¡¨ç¤º
            top_issues = sorted(issues, key=lambda x: -x.impact_score)[:5]
            for i, issue in enumerate(top_issues, 1):
                report_lines.extend([
                    f"{i}. **{issue.issue_type.value}** ({issue.severity})",
                    f"   - é–¢æ•°: {issue.function_name}",
                    f"   - å½±éŸ¿åº¦: {issue.impact_score:.2f}",
                    f"   - æ”¹å–„æ¡ˆ: {issue.suggested_fix}",
                    ""
                ])

            report_lines.append("")

        # æœ€é©åŒ–æ¨å¥¨äº‹é …
        report_lines.extend([
            "## æœ€é©åŒ–æ¨å¥¨äº‹é …",
            "",
            "### å„ªå…ˆåº¦1: ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«å•é¡Œ",
            "- ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®ä¿®æ­£",
            "- æ¥µåº¦ã«é…ã„é–¢æ•°ã®æœ€é©åŒ–",
            "",
            "### å„ªå…ˆåº¦2: ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ€é©åŒ–",
            "- éåŠ¹ç‡ãªãƒ«ãƒ¼ãƒ—ã®æ”¹å–„",
            "- ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿæ§‹ã®å°å…¥",
            "",
            "### å„ªå…ˆåº¦3: ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–",
            "- I/Oæ“ä½œã®éåŒæœŸåŒ–",
            "- ä¸¦åˆ—å‡¦ç†ã®å°å…¥",
            ""
        ])

        return '\n'.join(report_lines)

    def get_optimization_history(self) -> List[OptimizationResult]:
        """æœ€é©åŒ–å±¥æ­´å–å¾—"""
        return self.optimization_history[:]

    def _find_python_files(self) -> List[str]:
        """Pythonãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢"""
        python_files = []

        for root, dirs, files in os.walk(self.project_root):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']

            for file in files:
                if file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    python_files.append(file_path)

        return python_files

    def _measure_file_performance(self, file_path: str) -> PerformanceMetrics:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ€§èƒ½æ¸¬å®š"""
        # ç°¡æ˜“å®Ÿè£…ï¼šå®Ÿéš›ã«ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œã—ã¦æ¸¬å®š
        return PerformanceMetrics(
            execution_time=1.0,
            cpu_usage=50.0,
            memory_usage=100.0,
            memory_peak=120.0,
            gc_collections=5,
            function_calls=100,
            io_operations=10,
            cache_hits=80,
            cache_misses=20,
            thread_count=1
        )

    def _apply_single_optimization(self, issue: PerformanceIssue) -> str:
        """å˜ä¸€æœ€é©åŒ–é©ç”¨"""
        # æœ€é©åŒ–ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‡¦ç†
        if issue.optimization_type == OptimizationType.CACHING_OPTIMIZATION:
            return "ãƒ¡ãƒ¢åŒ–ã‚­ãƒ£ãƒƒã‚·ãƒ¥é©ç”¨"
        elif issue.optimization_type == OptimizationType.ALGORITHM_OPTIMIZATION:
            return "ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ€é©åŒ–é©ç”¨"
        elif issue.optimization_type == OptimizationType.MEMORY_OPTIMIZATION:
            return "ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–é©ç”¨"
        else:
            return "ä¸€èˆ¬çš„æœ€é©åŒ–é©ç”¨"

    def _calculate_improvement(
        self,
        original: PerformanceMetrics,
        optimized: PerformanceMetrics
    ) -> float:
        """æ”¹å–„ç‡è¨ˆç®—"""
        if original.execution_time == 0:
            return 0.0

        time_improvement = (original.execution_time - optimized.execution_time) / original.execution_time
        memory_improvement = (original.memory_usage - optimized.memory_usage) / max(original.memory_usage, 1)

        return (time_improvement + memory_improvement) / 2


if __name__ == "__main__":
    """ç°¡å˜ãªãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""

    optimizer = PerformanceOptimizer()

    # ãƒ†ã‚¹ãƒˆç”¨ã®ä½é€Ÿé–¢æ•°
    def slow_function(n: int) -> int:
        """æ„å›³çš„ã«é…ã„é–¢æ•°"""
        result = 0
        for i in range(n):
            for j in range(n):
                result += i * j
        return result

    print("âš¡ Performance Optimizer ãƒ†ã‚¹ãƒˆé–‹å§‹")

    # é–¢æ•°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°
    print("\nğŸ“Š é–¢æ•°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°:")
    metrics = optimizer.profile_function(slow_function, 100)

    if metrics:
        print(f"  - å®Ÿè¡Œæ™‚é–“: {metrics.execution_time:.3f}ç§’")
        print(f"  - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {metrics.memory_usage:.1f}MB")
        print(f"  - CPUä½¿ç”¨ç‡: {metrics.cpu_usage:.1f}%")

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè§£æ
    print("\nğŸ” ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ€§èƒ½è§£æ:")
    test_files = [
        "postbox/advanced/dependency_analyzer.py"
    ]

    analysis_results = optimizer.analyze_project_performance(test_files)

    for file_path, issues in analysis_results.items():
        rel_path = os.path.relpath(file_path)
        print(f"\nğŸ“„ {rel_path}:")
        print(f"  - æ€§èƒ½å•é¡Œ: {len(issues)}ä»¶")

        critical_issues = [i for i in issues if i.severity == 'critical']
        high_issues = [i for i in issues if i.severity == 'high']

        if critical_issues:
            print(f"  - ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«: {len(critical_issues)}ä»¶")
        if high_issues:
            print(f"  - é«˜å„ªå…ˆåº¦: {len(high_issues)}ä»¶")

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    if analysis_results:
        print("\nğŸ“Š æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        report = optimizer.generate_performance_report(analysis_results)

        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_path = optimizer.project_root / "tmp" / "performance_report.md"
        os.makedirs(os.path.dirname(report_path), exist_ok=True)
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}")

    print(f"\nâœ… Performance Optimizer ãƒ†ã‚¹ãƒˆå®Œäº†")
