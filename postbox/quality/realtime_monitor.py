#!/usr/bin/env python3
"""
Enhanced RealtimeQualityMonitor
æ—¢å­˜QualityMonitorã‚’æ‹¡å¼µã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æ¤œçŸ¥ãƒ»ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«å“è³ªè©•ä¾¡ãƒ»ãƒ›ãƒƒãƒˆãƒªãƒ­ãƒ¼ãƒ‰å¯¾å¿œ
"""

import os
import json
import time
import threading
import datetime
import hashlib
from typing import Dict, List, Any, Optional, Set, Callable
from pathlib import Path
from dataclasses import dataclass, asdict
from enum import Enum
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler, FileModifiedEvent, FileCreatedEvent

# æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from .quality_manager import QualityManager, QualityMetrics, CheckType
    from ..monitoring.quality_monitor import QualityMonitor, QualityAlert, AlertLevel
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨
    import sys
    sys.path.append('postbox')
    try:
        from quality.quality_manager import QualityManager, QualityMetrics, CheckType
        from monitoring.quality_monitor import QualityMonitor, QualityAlert, AlertLevel
    except ImportError:
        print("âš ï¸ å“è³ªç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ¢ãƒƒã‚¯å®Ÿè£…ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        QualityManager = None
        QualityMonitor = None

class RealtimeQualityLevel(Enum):
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªãƒ¬ãƒ™ãƒ«"""
    EXCELLENT = "excellent"     # å„ªç§€ï¼ˆ95%ä»¥ä¸Šï¼‰- å³åº§ãƒªãƒªãƒ¼ã‚¹å¯èƒ½
    GOOD = "good"              # è‰¯å¥½ï¼ˆ85-94%ï¼‰- ãƒãƒ¼ã‚¸å¯èƒ½
    ACCEPTABLE = "acceptable"   # è¨±å®¹ï¼ˆ75-84%ï¼‰- ãƒ¬ãƒ“ãƒ¥ãƒ¼æ¨å¥¨
    WARNING = "warning"        # è­¦å‘Šï¼ˆ65-74%ï¼‰- ä¿®æ­£å¿…è¦
    CRITICAL = "critical"       # é‡å¤§ï¼ˆ65%æœªæº€ï¼‰- å³åº§ä¿®æ­£å¿…é ˆ

class FileChangeType(Enum):
    """ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã‚¿ã‚¤ãƒ—"""
    CREATED = "created"
    MODIFIED = "modified"
    DELETED = "deleted"
    MOVED = "moved"

@dataclass
class FileQualitySnapshot:
    """ãƒ•ã‚¡ã‚¤ãƒ«å“è³ªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ"""
    file_path: str
    timestamp: str
    file_hash: str
    quality_metrics: Dict[str, float]
    overall_score: float
    quality_level: RealtimeQualityLevel
    errors: List[str]
    warnings: List[str]
    change_type: FileChangeType
    previous_score: Optional[float] = None
    improvement: Optional[float] = None

@dataclass
class IncrementalQualityResult:
    """ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«å“è³ªè©•ä¾¡çµæœ"""
    file_snapshots: List[FileQualitySnapshot]
    overall_project_score: float
    changed_files_count: int
    improved_files: List[str]
    degraded_files: List[str]
    critical_files: List[str]
    recommendations: List[str]
    processing_time: float

class QualityFileWatcher(FileSystemEventHandler):
    """å“è³ªç›£è¦–ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚¦ã‚©ãƒƒãƒãƒ£ãƒ¼"""
    
    def __init__(self, realtime_monitor: 'EnhancedRealtimeQualityMonitor'):
        self.realtime_monitor = realtime_monitor
        self.debounce_delay = 2.0  # 2ç§’ã®ãƒ‡ãƒã‚¦ãƒ³ã‚¹
        self.pending_changes: Dict[str, float] = {}
        self.lock = threading.Lock()
        
    def on_modified(self, event):
        if event.is_directory:
            return
            
        file_path = event.src_path
        if self._should_monitor_file(file_path):
            self._schedule_quality_check(file_path, FileChangeType.MODIFIED)
    
    def on_created(self, event):
        if event.is_directory:
            return
            
        file_path = event.src_path
        if self._should_monitor_file(file_path):
            self._schedule_quality_check(file_path, FileChangeType.CREATED)
    
    def _should_monitor_file(self, file_path: str) -> bool:
        """ç›£è¦–å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‹ãƒã‚§ãƒƒã‚¯"""
        if not file_path.endswith('.py'):
            return False
        
        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³
        exclude_patterns = [
            '__pycache__',
            '.pyc',
            'test_',
            '.git',
            'venv',
            'env',
            '.venv'
        ]
        
        for pattern in exclude_patterns:
            if pattern in file_path:
                return False
        
        return True
    
    def _schedule_quality_check(self, file_path: str, change_type: FileChangeType):
        """å“è³ªãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆãƒ‡ãƒã‚¦ãƒ³ã‚¹æ©Ÿèƒ½ä»˜ãï¼‰"""
        with self.lock:
            current_time = time.time()
            self.pending_changes[file_path] = current_time
            
            # ãƒ‡ãƒã‚¦ãƒ³ã‚¹å‡¦ç†
            def delayed_check():
                time.sleep(self.debounce_delay)
                with self.lock:
                    if (file_path in self.pending_changes and 
                        current_time == self.pending_changes[file_path]):
                        del self.pending_changes[file_path]
                        self.realtime_monitor.process_file_change(file_path, change_type)
            
            # æ–°ã—ã„ã‚¹ãƒ¬ãƒƒãƒ‰ã§é…å»¶ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
            threading.Thread(target=delayed_check, daemon=True).start()

class EnhancedRealtimeQualityMonitor:
    """å¼·åŒ–ç‰ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, watch_directories: Optional[List[str]] = None):
        self.watch_directories = watch_directories or ["kumihan_formatter/", "postbox/"]
        self.monitoring_active = False
        self.file_quality_cache: Dict[str, FileQualitySnapshot] = {}
        
        # ãƒ‘ã‚¹è¨­å®š
        self.data_dir = Path("postbox/quality/realtime_data")
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        self.snapshots_path = self.data_dir / "file_snapshots.json"
        self.realtime_history_path = self.data_dir / "realtime_history.json"
        self.performance_metrics_path = self.data_dir / "performance_metrics.json"
        
        # æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ é€£æº
        if QualityManager:
            self.quality_manager = QualityManager()
        else:
            self.quality_manager = MockQualityManager()
            
        if QualityMonitor:
            self.base_monitor = QualityMonitor(check_interval=60)  # 1åˆ†é–“éš”ã§åŸºæœ¬ç›£è¦–
        else:
            self.base_monitor = MockQualityMonitor()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–è¨­å®š
        self.observer = Observer()
        self.file_watcher = QualityFileWatcher(self)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        self.performance_stats = {
            "files_processed": 0,
            "total_processing_time": 0.0,
            "average_processing_time": 0.0,
            "cache_hits": 0,
            "cache_misses": 0
        }
        
        # è³¼èª­è€…
        self.subscribers: List[Callable] = []
        
        print("ğŸš€ EnhancedRealtimeQualityMonitor åˆæœŸåŒ–å®Œäº†")
    
    def start_realtime_monitoring(self) -> None:
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–é–‹å§‹"""
        if self.monitoring_active:
            print("âš ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã¯æ—¢ã«é–‹å§‹ã•ã‚Œã¦ã„ã¾ã™")
            return
        
        print("ğŸ” ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–é–‹å§‹...")
        
        # ãƒ™ãƒ¼ã‚¹ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹
        if hasattr(self.base_monitor, 'start_monitoring'):
            self.base_monitor.start_monitoring()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–é–‹å§‹
        for watch_dir in self.watch_directories:
            if os.path.exists(watch_dir):
                self.observer.schedule(self.file_watcher, watch_dir, recursive=True)
                print(f"ğŸ“ ç›£è¦–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¿½åŠ : {watch_dir}")
        
        self.observer.start()
        self.monitoring_active = True
        
        # åˆæœŸå“è³ªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆ
        self._create_initial_snapshot()
        
        print("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–é–‹å§‹å®Œäº†")
    
    def stop_realtime_monitoring(self) -> None:
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–åœæ­¢"""
        if not self.monitoring_active:
            return
        
        print("â¹ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–åœæ­¢ä¸­...")
        
        self.monitoring_active = False
        self.observer.stop()
        self.observer.join()
        
        if hasattr(self.base_monitor, 'stop_monitoring'):
            self.base_monitor.stop_monitoring()
        
        # æœ€çµ‚çµ±è¨ˆä¿å­˜
        self._save_performance_metrics()
        
        print("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç›£è¦–åœæ­¢å®Œäº†")
    
    def process_file_change(self, file_path: str, change_type: FileChangeType) -> None:
        """ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´å‡¦ç†"""
        start_time = time.time()
        
        try:
            print(f"ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æ¤œçŸ¥: {file_path} ({change_type.value})")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å“è³ªè©•ä¾¡
            snapshot = self._evaluate_file_quality(file_path, change_type)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
            previous_snapshot = self.file_quality_cache.get(file_path)
            self.file_quality_cache[file_path] = snapshot
            
            # æ”¹å–„/åŠ£åŒ–åˆ†æ
            if previous_snapshot:
                snapshot.previous_score = previous_snapshot.overall_score
                snapshot.improvement = snapshot.overall_score - previous_snapshot.overall_score
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆæ¤œå‡ºãƒ»é€šçŸ¥
            alerts = self._detect_realtime_alerts(snapshot, previous_snapshot)
            for alert in alerts:
                self._notify_subscribers(alert)
            
            # å±¥æ­´ä¿å­˜
            self._save_snapshot_to_history(snapshot)
            
            processing_time = time.time() - start_time
            self.performance_stats["files_processed"] += 1
            self.performance_stats["total_processing_time"] += processing_time
            self.performance_stats["average_processing_time"] = (
                self.performance_stats["total_processing_time"] / 
                self.performance_stats["files_processed"]
            )
            
            print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«è©•ä¾¡å®Œäº†: {snapshot.quality_level.value} "
                  f"(ã‚¹ã‚³ã‚¢: {snapshot.overall_score:.3f}, å‡¦ç†æ™‚é–“: {processing_time:.2f}s)")
            
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´å‡¦ç†ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
    
    def _evaluate_file_quality(self, file_path: str, change_type: FileChangeType) -> FileQualitySnapshot:
        """ãƒ•ã‚¡ã‚¤ãƒ«å“è³ªè©•ä¾¡"""
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
        file_hash = self._calculate_file_hash(file_path)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        cached_snapshot = self.file_quality_cache.get(file_path)
        if cached_snapshot and cached_snapshot.file_hash == file_hash:
            self.performance_stats["cache_hits"] += 1
            print(f"ğŸ“‹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {file_path}")
            cached_snapshot.change_type = change_type
            cached_snapshot.timestamp = datetime.datetime.now().isoformat()
            return cached_snapshot
        
        self.performance_stats["cache_misses"] += 1
        
        # å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
        try:
            if hasattr(self.quality_manager, 'run_comprehensive_check'):
                metrics = self.quality_manager.run_comprehensive_check([file_path], "realtime")
                
                quality_scores = {
                    "syntax": metrics.syntax_score,
                    "type_check": metrics.type_score,
                    "lint": metrics.lint_score,
                    "format": metrics.format_score,
                    "security": metrics.security_score,
                    "performance": metrics.performance_score
                }
                
                overall_score = metrics.overall_score
                errors = [f"ã‚¨ãƒ©ãƒ¼æ•°: {metrics.error_count}"]
                warnings = [f"è­¦å‘Šæ•°: {metrics.warning_count}"]
                
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…
                quality_scores = self._basic_quality_check(file_path)
                overall_score = sum(quality_scores.values()) / len(quality_scores)
                errors = []
                warnings = []
            
        except Exception as e:
            print(f"âš ï¸ å“è³ªãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            quality_scores = {"basic": 0.5}
            overall_score = 0.5
            errors = [f"å“è³ªãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}"]
            warnings = []
        
        # å“è³ªãƒ¬ãƒ™ãƒ«æ±ºå®š
        quality_level = self._determine_quality_level(overall_score)
        
        return FileQualitySnapshot(
            file_path=file_path,
            timestamp=datetime.datetime.now().isoformat(),
            file_hash=file_hash,
            quality_metrics=quality_scores,
            overall_score=overall_score,
            quality_level=quality_level,
            errors=errors,
            warnings=warnings,
            change_type=change_type
        )
    
    def _basic_quality_check(self, file_path: str) -> Dict[str, float]:
        """åŸºæœ¬çš„ãªå“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰"""
        scores = {}
        
        try:
            # æ§‹æ–‡ãƒã‚§ãƒƒã‚¯
            import subprocess
            result = subprocess.run(
                ["python3", "-m", "py_compile", file_path],
                capture_output=True,
                text=True
            )
            scores["syntax"] = 1.0 if result.returncode == 0 else 0.0
            
        except Exception:
            scores["syntax"] = 0.5
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ãƒ»åŸºæœ¬åˆ†æ
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            non_empty_lines = [line for line in lines if line.strip()]
            
            # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            scores["readability"] = min(1.0, 1.0 - (len(lines) / 1000))  # è¡Œæ•°ã«ã‚ˆã‚‹å¯èª­æ€§
            scores["basic_structure"] = 0.8 if any(line.strip().startswith('def ') for line in lines) else 0.6
            
        except Exception:
            scores["readability"] = 0.5
            scores["basic_structure"] = 0.5
        
        return scores
    
    def _determine_quality_level(self, overall_score: float) -> RealtimeQualityLevel:
        """å“è³ªãƒ¬ãƒ™ãƒ«æ±ºå®š"""
        if overall_score >= 0.95:
            return RealtimeQualityLevel.EXCELLENT
        elif overall_score >= 0.85:
            return RealtimeQualityLevel.GOOD
        elif overall_score >= 0.75:
            return RealtimeQualityLevel.ACCEPTABLE
        elif overall_score >= 0.65:
            return RealtimeQualityLevel.WARNING
        else:
            return RealtimeQualityLevel.CRITICAL
    
    def _calculate_file_hash(self, file_path: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—"""
        try:
            with open(file_path, 'rb') as f:
                content = f.read()
            return hashlib.md5(content).hexdigest()
        except Exception:
            return f"error_{int(time.time())}"
    
    def _detect_realtime_alerts(self, current_snapshot: FileQualitySnapshot, 
                              previous_snapshot: Optional[FileQualitySnapshot]) -> List[QualityAlert]:
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆæ¤œå‡º"""
        alerts = []
        current_time = datetime.datetime.now().isoformat()
        
        # å“è³ªãƒ¬ãƒ™ãƒ«ä½ä¸‹ã‚¢ãƒ©ãƒ¼ãƒˆ
        if current_snapshot.quality_level == RealtimeQualityLevel.CRITICAL:
            alerts.append(QualityAlert(
                timestamp=current_time,
                level=AlertLevel.CRITICAL,
                category="quality_critical",
                message=f"å“è³ªãƒ¬ãƒ™ãƒ«é‡å¤§: {current_snapshot.file_path}",
                details={"score": current_snapshot.overall_score},
                affected_files=[current_snapshot.file_path],
                ai_agent="realtime_monitor"
            ))
        
        # å“è³ªåŠ£åŒ–ã‚¢ãƒ©ãƒ¼ãƒˆ
        if (previous_snapshot and current_snapshot.improvement and 
            current_snapshot.improvement < -0.1):  # 10%ä»¥ä¸Šä½ä¸‹
            alerts.append(QualityAlert(
                timestamp=current_time,
                level=AlertLevel.WARNING,
                category="quality_degradation",
                message=f"å“è³ªåŠ£åŒ–æ¤œå‡º: {current_snapshot.file_path}",
                details={
                    "previous_score": previous_snapshot.overall_score,
                    "current_score": current_snapshot.overall_score,
                    "degradation": abs(current_snapshot.improvement)
                },
                affected_files=[current_snapshot.file_path],
                ai_agent="realtime_monitor"
            ))
        
        return alerts
    
    def _create_initial_snapshot(self) -> None:
        """åˆæœŸå“è³ªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆ"""
        print("ğŸ“¸ åˆæœŸå“è³ªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆä¸­...")
        
        initial_files = []
        for watch_dir in self.watch_directories:
            if os.path.exists(watch_dir):
                for root, dirs, files in os.walk(watch_dir):
                    for file in files:
                        if file.endswith('.py'):
                            initial_files.append(os.path.join(root, file))
        
        print(f"ğŸ“ åˆæœŸå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {len(initial_files)}ä»¶")
        
        # æœ€åˆã®10ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è€ƒæ…®ï¼‰
        for file_path in initial_files[:10]:
            try:
                self.process_file_change(file_path, FileChangeType.CREATED)
            except Exception as e:
                print(f"âš ï¸ åˆæœŸã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
        
        print("âœ… åˆæœŸå“è³ªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆå®Œäº†")
    
    def _save_snapshot_to_history(self, snapshot: FileQualitySnapshot) -> None:
        """ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å±¥æ­´ã«ä¿å­˜"""
        try:
            history = []
            if self.realtime_history_path.exists():
                with open(self.realtime_history_path, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            
            history.append(asdict(snapshot))
            
            # å±¥æ­´ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆæœ€æ–°1000ä»¶ï¼‰
            if len(history) > 1000:
                history = history[-1000:]
            
            with open(self.realtime_history_path, 'w', encoding='utf-8') as f:
                json.dump(history, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            print(f"âš ï¸ å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_performance_metrics(self) -> None:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆä¿å­˜"""
        try:
            metrics_data = {
                "timestamp": datetime.datetime.now().isoformat(),
                "performance_stats": self.performance_stats,
                "cache_efficiency": (
                    self.performance_stats["cache_hits"] / 
                    max(self.performance_stats["cache_hits"] + self.performance_stats["cache_misses"], 1)
                )
            }
            
            with open(self.performance_metrics_path, 'w', encoding='utf-8') as f:
                json.dump(metrics_data, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            print(f"âš ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _notify_subscribers(self, alert: QualityAlert) -> None:
        """è³¼èª­è€…ã¸ã®é€šçŸ¥"""
        for callback in self.subscribers:
            try:
                callback(alert)
            except Exception as e:
                print(f"âš ï¸ é€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
    
    def subscribe_to_realtime_alerts(self, callback: Callable[[QualityAlert], None]) -> None:
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆè³¼èª­"""
        self.subscribers.append(callback)
        print(f"ğŸ“¬ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆè³¼èª­è¿½åŠ : {len(self.subscribers)}ä»¶")
    
    def get_project_quality_overview(self) -> Dict[str, Any]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå“è³ªæ¦‚è¦å–å¾—"""
        if not self.file_quality_cache:
            return {"status": "no_data", "message": "å“è³ªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"}
        
        snapshots = list(self.file_quality_cache.values())
        
        # å“è³ªãƒ¬ãƒ™ãƒ«é›†è¨ˆ
        level_counts = {}
        for snapshot in snapshots:
            level = snapshot.quality_level.value
            level_counts[level] = level_counts.get(level, 0) + 1
        
        # å¹³å‡ã‚¹ã‚³ã‚¢è¨ˆç®—
        avg_score = sum(s.overall_score for s in snapshots) / len(snapshots)
        
        # æœ€è¿‘ã®å¤‰æ›´åˆ†æ
        recent_changes = [s for s in snapshots if s.improvement is not None]
        improved_count = len([s for s in recent_changes if s.improvement > 0])
        degraded_count = len([s for s in recent_changes if s.improvement < 0])
        
        return {
            "timestamp": datetime.datetime.now().isoformat(),
            "total_files": len(snapshots),
            "average_score": avg_score,
            "quality_distribution": level_counts,
            "recent_changes": {
                "improved": improved_count,
                "degraded": degraded_count,
                "stable": len(recent_changes) - improved_count - degraded_count
            },
            "performance": self.performance_stats,
            "monitoring_active": self.monitoring_active
        }

# Mock classes for testing without dependencies
class MockQualityManager:
    def run_comprehensive_check(self, files, agent):
        return type('MockMetrics', (), {
            'syntax_score': 0.9,
            'type_score': 0.8,
            'lint_score': 0.85,
            'format_score': 0.95,
            'security_score': 0.9,
            'performance_score': 0.8,
            'overall_score': 0.85,
            'error_count': 2,
            'warning_count': 5
        })()

class MockQualityMonitor:
    def start_monitoring(self): pass
    def stop_monitoring(self): pass

def realtime_console_alert_handler(alert: QualityAlert) -> None:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚¢ãƒ©ãƒ¼ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    level_icons = {
        AlertLevel.INFO: "â„¹ï¸",
        AlertLevel.WARNING: "âš ï¸",
        AlertLevel.ERROR: "âŒ",
        AlertLevel.CRITICAL: "ğŸš¨"
    }
    
    icon = level_icons.get(alert.level, "ğŸ“‹")
    print(f"ğŸ” REALTIME {icon} [{alert.level.value.upper()}] {alert.category}: {alert.message}")
    if alert.affected_files:
        print(f"    å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«: {alert.affected_files[0]}")

def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸ§ª EnhancedRealtimeQualityMonitor ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    monitor = EnhancedRealtimeQualityMonitor(["kumihan_formatter/core/utilities/"])
    
    # ã‚¢ãƒ©ãƒ¼ãƒˆè³¼èª­
    monitor.subscribe_to_realtime_alerts(realtime_console_alert_handler)
    
    # ç›£è¦–é–‹å§‹
    monitor.start_realtime_monitoring()
    
    print("ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ†ã‚¹ãƒˆä¸­... (10ç§’é–“)")
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    test_file = "kumihan_formatter/core/utilities/logger.py"
    if os.path.exists(test_file):
        print(f"ğŸ”„ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†: {test_file}")
        monitor.process_file_change(test_file, FileChangeType.MODIFIED)
    
    time.sleep(10)
    
    # æ¦‚è¦ç¢ºèª
    overview = monitor.get_project_quality_overview()
    print("\nğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå“è³ªæ¦‚è¦:")
    print(f"   ç›£è¦–ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {overview.get('total_files', 0)}")
    print(f"   å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {overview.get('average_score', 0):.3f}")
    print(f"   å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {overview.get('performance', {}).get('files_processed', 0)}")
    
    # ç›£è¦–åœæ­¢
    monitor.stop_realtime_monitoring()
    
    print("âœ… EnhancedRealtimeQualityMonitor ãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    main()