#!/usr/bin/env python3
"""
EnhancedSyntaxValidator - Issue #860å¯¾å¿œ
Layer1æ§‹æ–‡æ¤œè¨¼ã®å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ 

ã‚ˆã‚Šå …ç‰¢ãªæ§‹æ–‡æ¤œè¨¼ãƒ»äº‹å‰ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ã‚¨ãƒ©ãƒ¼äºˆæ¸¬ã«ã‚ˆã‚Š
å”æ¥­å®‰å…¨æ€§å‘ä¸Šã¨ãƒ•ã‚§ã‚¤ãƒ«ã‚»ãƒ¼ãƒ•ä½¿ç”¨ç‡å‰Šæ¸›ã‚’å®Ÿç¾
"""

import ast
import sys
import json
import subprocess
import datetime
import re
from typing import Dict, List, Any, Optional, Tuple, Union, Set
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
import tempfile
import importlib.util

from kumihan_formatter.core.utilities.logger import get_logger

logger = get_logger(__name__)


class ValidationSeverity(Enum):
    """æ¤œè¨¼é‡è¦åº¦"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


class ValidationCategory(Enum):
    """æ¤œè¨¼ã‚«ãƒ†ã‚´ãƒª"""
    SYNTAX = "syntax"
    IMPORT = "import"
    TYPE_ANNOTATION = "type_annotation"
    FUNCTION_DEFINITION = "function_definition"
    CLASS_DEFINITION = "class_definition"
    VARIABLE_DEFINITION = "variable_definition"
    LOGIC_ERROR = "logic_error"
    COMPATIBILITY = "compatibility"


@dataclass
class ValidationIssue:
    """æ¤œè¨¼å•é¡Œ"""
    category: ValidationCategory
    severity: ValidationSeverity
    line_number: int
    column: int
    message: str
    suggestion: Optional[str]
    code_snippet: str
    auto_fixable: bool


@dataclass
class PreValidationResult:
    """äº‹å‰æ¤œè¨¼çµæœ"""
    file_path: str
    is_valid: bool
    confidence_score: float  # 0.0-1.0
    issues: List[ValidationIssue]
    predicted_problems: List[str]
    recommended_fixes: List[str]
    execution_time: float


@dataclass
class SyntaxEnhancementReport:
    """æ§‹æ–‡å¼·åŒ–ãƒ¬ãƒãƒ¼ãƒˆ"""
    timestamp: str
    total_files_validated: int
    validation_success_rate: float
    issue_distribution: Dict[str, int]
    auto_fix_success_rate: float
    performance_metrics: Dict[str, float]
    recommendations: List[str]


class EnhancedSyntaxValidator:
    """å¼·åŒ–æ§‹æ–‡æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 

    å¾“æ¥ã®Layer1æ§‹æ–‡æ¤œè¨¼ã‚’å¤§å¹…ã«å¼·åŒ–ã—ã€
    äº‹å‰ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ã‚¨ãƒ©ãƒ¼äºˆæ¸¬ãƒ»è‡ªå‹•ä¿®æ­£æ©Ÿèƒ½ã‚’æä¾›
    """

    def __init__(self, postbox_dir: str = "postbox"):
        self.postbox_dir = Path(postbox_dir)
        self.validation_cache_dir = self.postbox_dir / "quality" / "validation_cache"
        self.enhancement_reports_dir = self.postbox_dir / "quality" / "syntax_enhancement_reports"

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.validation_cache_dir.mkdir(parents=True, exist_ok=True)
        self.enhancement_reports_dir.mkdir(parents=True, exist_ok=True)

        # æ¤œè¨¼ãƒ«ãƒ¼ãƒ«è¨­å®š
        self.validation_rules = self._load_validation_rules()

        # ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®š
        self.fix_patterns = self._load_fix_patterns()

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
        self.validation_stats = {
            "total_validations": 0,
            "successful_validations": 0,
            "auto_fixes_applied": 0,
            "errors_prevented": 0
        }

        logger.info("ğŸ” EnhancedSyntaxValidator åˆæœŸåŒ–å®Œäº†")

    def pre_validate_code(self, file_path: str, code_content: Optional[str] = None) -> PreValidationResult:
        """äº‹å‰ã‚³ãƒ¼ãƒ‰æ¤œè¨¼ï¼ˆå¼·åŒ–ç‰ˆLayer1ï¼‰

        Args:
            file_path: æ¤œè¨¼å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            code_content: ã‚³ãƒ¼ãƒ‰å†…å®¹ï¼ˆNoneã®å ´åˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼‰

        Returns:
            PreValidationResult: äº‹å‰æ¤œè¨¼çµæœ
        """

        start_time = datetime.datetime.now()
        logger.info(f"ğŸ” äº‹å‰ã‚³ãƒ¼ãƒ‰æ¤œè¨¼é–‹å§‹: {file_path}")

        try:
            # ã‚³ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿
            if code_content is None:
                if not Path(file_path).exists():
                    return self._create_file_not_found_result(file_path, start_time)

                with open(file_path, 'r', encoding='utf-8') as f:
                    code_content = f.read()

            # ãƒãƒ«ãƒãƒ¬ãƒ™ãƒ«æ¤œè¨¼å®Ÿè¡Œ
            issues = []
            predicted_problems = []
            recommended_fixes = []

            # Level 1: åŸºæœ¬æ§‹æ–‡æ¤œè¨¼
            syntax_issues = self._validate_basic_syntax(code_content, file_path)
            issues.extend(syntax_issues)

            # Level 2: ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¤œè¨¼
            import_issues = self._validate_imports(code_content, file_path)
            issues.extend(import_issues)

            # Level 3: å‹æ³¨é‡ˆæ¤œè¨¼
            type_issues = self._validate_type_annotations(code_content, file_path)
            issues.extend(type_issues)

            # Level 4: é–¢æ•°ãƒ»ã‚¯ãƒ©ã‚¹å®šç¾©æ¤œè¨¼
            definition_issues = self._validate_definitions(code_content, file_path)
            issues.extend(definition_issues)

            # Level 5: ãƒ­ã‚¸ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼äºˆæ¸¬
            logic_predictions = self._predict_logic_errors(code_content, file_path)
            predicted_problems.extend(logic_predictions)

            # Level 6: äº’æ›æ€§ãƒã‚§ãƒƒã‚¯
            compatibility_issues = self._validate_compatibility(code_content, file_path)
            issues.extend(compatibility_issues)

            # ä¿®æ­£æ¨å¥¨ç”Ÿæˆ
            recommended_fixes = self._generate_fix_recommendations(issues)

            # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
            confidence_score = self._calculate_confidence_score(issues, predicted_problems)

            # å…¨ä½“åˆ¤å®š
            is_valid = self._determine_overall_validity(issues)

            execution_time = (datetime.datetime.now() - start_time).total_seconds()

            result = PreValidationResult(
                file_path=file_path,
                is_valid=is_valid,
                confidence_score=confidence_score,
                issues=issues,
                predicted_problems=predicted_problems,
                recommended_fixes=recommended_fixes,
                execution_time=execution_time
            )

            # çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥
            self._cache_validation_result(result)

            # çµ±è¨ˆæ›´æ–°
            self.validation_stats["total_validations"] += 1
            if is_valid:
                self.validation_stats["successful_validations"] += 1

            logger.info(f"âœ… äº‹å‰ã‚³ãƒ¼ãƒ‰æ¤œè¨¼å®Œäº†: {file_path} (ä¿¡é ¼åº¦: {confidence_score:.3f})")

            return result

        except Exception as e:
            logger.error(f"âŒ äº‹å‰ã‚³ãƒ¼ãƒ‰æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
            return self._create_error_result(file_path, str(e), start_time)

    def _validate_basic_syntax(self, code_content: str, file_path: str) -> List[ValidationIssue]:
        """åŸºæœ¬æ§‹æ–‡æ¤œè¨¼"""

        issues = []

        try:
            # ASTè§£æ
            tree = ast.parse(code_content)

            # ASTè§£ææˆåŠŸ = åŸºæœ¬æ§‹æ–‡OK
            logger.debug(f"ğŸ“ åŸºæœ¬æ§‹æ–‡æ¤œè¨¼æˆåŠŸ: {file_path}")

        except SyntaxError as e:
            # æ§‹æ–‡ã‚¨ãƒ©ãƒ¼è©³ç´°åˆ†æ
            issue = ValidationIssue(
                category=ValidationCategory.SYNTAX,
                severity=ValidationSeverity.ERROR,
                line_number=e.lineno or 0,
                column=e.offset or 0,
                message=f"æ§‹æ–‡ã‚¨ãƒ©ãƒ¼: {e.msg}",
                suggestion=self._suggest_syntax_fix(e),
                code_snippet=self._extract_code_snippet(code_content, e.lineno or 0),
                auto_fixable=self._is_auto_fixable_syntax_error(e)
            )
            issues.append(issue)

        except Exception as e:
            # ãã®ä»–ã®è§£æã‚¨ãƒ©ãƒ¼
            issue = ValidationIssue(
                category=ValidationCategory.SYNTAX,
                severity=ValidationSeverity.CRITICAL,
                line_number=0,
                column=0,
                message=f"ASTè§£æã‚¨ãƒ©ãƒ¼: {str(e)}",
                suggestion="ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                code_snippet="",
                auto_fixable=False
            )
            issues.append(issue)

        return issues

    def _validate_imports(self, code_content: str, file_path: str) -> List[ValidationIssue]:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¤œè¨¼"""

        issues = []

        try:
            tree = ast.parse(code_content)

            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        issue = self._validate_import_module(alias.name, node.lineno, file_path)
                        if issue:
                            issues.append(issue)

                elif isinstance(node, ast.ImportFrom):
                    module_name = node.module or ""
                    issue = self._validate_import_module(module_name, node.lineno, file_path)
                    if issue:
                        issues.append(issue)

                    # from import ã®åå‰æ¤œè¨¼
                    for alias in node.names:
                        if alias.name != "*":  # * import ã¯åˆ¥é€”å‡¦ç†
                            import_issue = self._validate_from_import(
                                module_name, alias.name, node.lineno, file_path
                            )
                            if import_issue:
                                issues.append(import_issue)

        except Exception as e:
            logger.warning(f"âš ï¸ ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")

        return issues

    def _validate_import_module(self, module_name: str, line_number: int, file_path: str) -> Optional[ValidationIssue]:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¤œè¨¼"""

        if not module_name:
            return None

        try:
            # æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ»æ—¢çŸ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if module_name in self._get_standard_modules():
                return None

            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆè©¦è¡Œ
            spec = importlib.util.find_spec(module_name)
            if spec is None:
                return ValidationIssue(
                    category=ValidationCategory.IMPORT,
                    severity=ValidationSeverity.WARNING,
                    line_number=line_number,
                    column=0,
                    message=f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« '{module_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                    suggestion=f"pip install {module_name} ã¾ãŸã¯æ­£ã—ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã‚’ç¢ºèª",
                    code_snippet=f"import {module_name}",
                    auto_fixable=False
                )

        except Exception:
            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¤œè¨¼ã‚¨ãƒ©ãƒ¼ã¯è­¦å‘Šãƒ¬ãƒ™ãƒ«
            return ValidationIssue(
                category=ValidationCategory.IMPORT,
                severity=ValidationSeverity.INFO,
                line_number=line_number,
                column=0,
                message=f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« '{module_name}' ã®æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—",
                suggestion="å®Ÿè¡Œæ™‚ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¯èƒ½æ€§ã‚’ç¢ºèª",
                code_snippet=f"import {module_name}",
                auto_fixable=False
            )

        return None

    def _validate_from_import(self, module_name: str, import_name: str,
                            line_number: int, file_path: str) -> Optional[ValidationIssue]:
        """from import æ¤œè¨¼"""

        # åŸºæœ¬çš„ãªfrom importãƒã‚§ãƒƒã‚¯
        # è©³ç´°ãªå±æ€§å­˜åœ¨ç¢ºèªã¯è² è·ãŒé«˜ã„ãŸã‚ã€åŸºæœ¬çš„ãªå•é¡Œã®ã¿æ¤œå‡º

        if not module_name or not import_name:
            return ValidationIssue(
                category=ValidationCategory.IMPORT,
                severity=ValidationSeverity.WARNING,
                line_number=line_number,
                column=0,
                message="ä¸å®Œå…¨ãªfrom importæ–‡",
                suggestion="æ­£ã—ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã¨å±æ€§åã‚’æŒ‡å®š",
                code_snippet=f"from {module_name} import {import_name}",
                auto_fixable=False
            )

        return None

    def _validate_type_annotations(self, code_content: str, file_path: str) -> List[ValidationIssue]:
        """å‹æ³¨é‡ˆæ¤œè¨¼"""

        issues = []

        try:
            tree = ast.parse(code_content)

            for node in ast.walk(tree):
                # é–¢æ•°å®šç¾©ã®å‹æ³¨é‡ˆãƒã‚§ãƒƒã‚¯
                if isinstance(node, ast.FunctionDef):
                    type_issues = self._validate_function_type_annotations(node, code_content)
                    issues.extend(type_issues)

                # å¤‰æ•°å‹æ³¨é‡ˆãƒã‚§ãƒƒã‚¯
                elif isinstance(node, ast.AnnAssign):
                    type_issue = self._validate_variable_type_annotation(node, code_content)
                    if type_issue:
                        issues.append(type_issue)

        except Exception as e:
            logger.warning(f"âš ï¸ å‹æ³¨é‡ˆæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")

        return issues

    def _validate_function_type_annotations(self, func_node: ast.FunctionDef,
                                          code_content: str) -> List[ValidationIssue]:
        """é–¢æ•°å‹æ³¨é‡ˆæ¤œè¨¼"""

        issues = []

        # æˆ»ã‚Šå€¤å‹æ³¨é‡ˆãƒã‚§ãƒƒã‚¯
        if func_node.returns is None and not func_node.name.startswith("_"):
            # ãƒ‘ãƒ–ãƒªãƒƒã‚¯é–¢æ•°ã¯æˆ»ã‚Šå€¤å‹æ³¨é‡ˆæ¨å¥¨
            issues.append(ValidationIssue(
                category=ValidationCategory.TYPE_ANNOTATION,
                severity=ValidationSeverity.INFO,
                line_number=func_node.lineno,
                column=func_node.col_offset,
                message=f"é–¢æ•° '{func_node.name}' ã«æˆ»ã‚Šå€¤å‹æ³¨é‡ˆãŒã‚ã‚Šã¾ã›ã‚“",
                suggestion="-> None ã¾ãŸã¯é©åˆ‡ãªæˆ»ã‚Šå€¤å‹ã‚’è¿½åŠ ",
                code_snippet=self._extract_code_snippet(code_content, func_node.lineno),
                auto_fixable=True
            ))

        # å¼•æ•°å‹æ³¨é‡ˆãƒã‚§ãƒƒã‚¯
        for arg in func_node.args.args:
            if arg.annotation is None and arg.arg != "self" and arg.arg != "cls":
                issues.append(ValidationIssue(
                    category=ValidationCategory.TYPE_ANNOTATION,
                    severity=ValidationSeverity.INFO,
                    line_number=func_node.lineno,
                    column=func_node.col_offset,
                    message=f"å¼•æ•° '{arg.arg}' ã«å‹æ³¨é‡ˆãŒã‚ã‚Šã¾ã›ã‚“",
                    suggestion="Any ã¾ãŸã¯é©åˆ‡ãªå‹æ³¨é‡ˆã‚’è¿½åŠ ",
                    code_snippet=self._extract_code_snippet(code_content, func_node.lineno),
                    auto_fixable=True
                ))

        return issues

    def _validate_variable_type_annotation(self, var_node: ast.AnnAssign,
                                         code_content: str) -> Optional[ValidationIssue]:
        """å¤‰æ•°å‹æ³¨é‡ˆæ¤œè¨¼"""

        # åŸºæœ¬çš„ãªå‹æ³¨é‡ˆæ§‹æ–‡ãƒã‚§ãƒƒã‚¯
        if var_node.annotation is None:
            return ValidationIssue(
                category=ValidationCategory.TYPE_ANNOTATION,
                severity=ValidationSeverity.WARNING,
                line_number=var_node.lineno,
                column=var_node.col_offset,
                message="å‹æ³¨é‡ˆãŒä¸å®Œå…¨ã§ã™",
                suggestion="é©åˆ‡ãªå‹æ³¨é‡ˆã‚’æŒ‡å®š",
                code_snippet=self._extract_code_snippet(code_content, var_node.lineno),
                auto_fixable=False
            )

        return None

    def _validate_definitions(self, code_content: str, file_path: str) -> List[ValidationIssue]:
        """é–¢æ•°ãƒ»ã‚¯ãƒ©ã‚¹å®šç¾©æ¤œè¨¼"""

        issues = []

        try:
            tree = ast.parse(code_content)

            for node in ast.walk(tree):
                # é–¢æ•°å®šç¾©æ¤œè¨¼
                if isinstance(node, ast.FunctionDef):
                    func_issues = self._validate_function_definition(node, code_content)
                    issues.extend(func_issues)

                # ã‚¯ãƒ©ã‚¹å®šç¾©æ¤œè¨¼
                elif isinstance(node, ast.ClassDef):
                    class_issues = self._validate_class_definition(node, code_content)
                    issues.extend(class_issues)

        except Exception as e:
            logger.warning(f"âš ï¸ å®šç¾©æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")

        return issues

    def _validate_function_definition(self, func_node: ast.FunctionDef,
                                    code_content: str) -> List[ValidationIssue]:
        """é–¢æ•°å®šç¾©æ¤œè¨¼"""

        issues = []

        # é–¢æ•°åè¦å‰‡ãƒã‚§ãƒƒã‚¯
        if not re.match(r'^[a-z_][a-z0-9_]*$', func_node.name) and not func_node.name.startswith("__"):
            issues.append(ValidationIssue(
                category=ValidationCategory.FUNCTION_DEFINITION,
                severity=ValidationSeverity.INFO,
                line_number=func_node.lineno,
                column=func_node.col_offset,
                message=f"é–¢æ•°å '{func_node.name}' ãŒPEP8å‘½åè¦å‰‡ã«å¾“ã£ã¦ã„ã¾ã›ã‚“",
                suggestion="å°æ–‡å­—ã¨ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
                code_snippet=self._extract_code_snippet(code_content, func_node.lineno),
                auto_fixable=False
            ))

        # ç©ºã®é–¢æ•°æœ¬ä½“ãƒã‚§ãƒƒã‚¯
        if len(func_node.body) == 1 and isinstance(func_node.body[0], ast.Pass):
            issues.append(ValidationIssue(
                category=ValidationCategory.FUNCTION_DEFINITION,
                severity=ValidationSeverity.WARNING,
                line_number=func_node.lineno,
                column=func_node.col_offset,
                message=f"é–¢æ•° '{func_node.name}' ãŒç©ºã®å®Ÿè£…ã§ã™",
                suggestion="é©åˆ‡ãªå®Ÿè£…ã‚’è¿½åŠ ã™ã‚‹ã‹ã€NotImplementedErrorã‚’ç™ºç”Ÿã•ã›ã¦ãã ã•ã„",
                code_snippet=self._extract_code_snippet(code_content, func_node.lineno),
                auto_fixable=True
            ))

        return issues

    def _validate_class_definition(self, class_node: ast.ClassDef,
                                 code_content: str) -> List[ValidationIssue]:
        """ã‚¯ãƒ©ã‚¹å®šç¾©æ¤œè¨¼"""

        issues = []

        # ã‚¯ãƒ©ã‚¹åè¦å‰‡ãƒã‚§ãƒƒã‚¯
        if not re.match(r'^[A-Z][a-zA-Z0-9]*$', class_node.name):
            issues.append(ValidationIssue(
                category=ValidationCategory.CLASS_DEFINITION,
                severity=ValidationSeverity.INFO,
                line_number=class_node.lineno,
                column=class_node.col_offset,
                message=f"ã‚¯ãƒ©ã‚¹å '{class_node.name}' ãŒPEP8å‘½åè¦å‰‡ã«å¾“ã£ã¦ã„ã¾ã›ã‚“",
                suggestion="CapitalizedWordsã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
                code_snippet=self._extract_code_snippet(code_content, class_node.lineno),
                auto_fixable=False
            ))

        # __init__ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒƒã‚¯
        has_init = any(
            isinstance(node, ast.FunctionDef) and node.name == "__init__"
            for node in class_node.body
        )

        if not has_init and len(class_node.body) > 1:  # å˜ç´”ãªã‚¯ãƒ©ã‚¹ä»¥å¤–
            issues.append(ValidationIssue(
                category=ValidationCategory.CLASS_DEFINITION,
                severity=ValidationSeverity.INFO,
                line_number=class_node.lineno,
                column=class_node.col_offset,
                message=f"ã‚¯ãƒ©ã‚¹ '{class_node.name}' ã«__init__ãƒ¡ã‚½ãƒƒãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“",
                suggestion="é©åˆ‡ãªåˆæœŸåŒ–ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ ã—ã¦ãã ã•ã„",
                code_snippet=self._extract_code_snippet(code_content, class_node.lineno),
                auto_fixable=False
            ))

        return issues

    def _predict_logic_errors(self, code_content: str, file_path: str) -> List[str]:
        """ãƒ­ã‚¸ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼äºˆæ¸¬"""

        predictions = []

        try:
            tree = ast.parse(code_content)

            for node in ast.walk(tree):
                # æœªä½¿ç”¨å¤‰æ•°ã®å¯èƒ½æ€§
                if isinstance(node, ast.Assign):
                    for target in node.targets:
                        if isinstance(target, ast.Name) and target.id.startswith("_unused"):
                            predictions.append(f"æœªä½¿ç”¨å¤‰æ•°ã®å¯èƒ½æ€§: {target.id}")

                # å±é™ºãªæ¯”è¼ƒ
                elif isinstance(node, ast.Compare):
                    if len(node.ops) > 1:  # é€£ç¶šæ¯”è¼ƒ
                        predictions.append("è¤‡é›‘ãªæ¯”è¼ƒå¼: æ„å›³é€šã‚Šã®å‹•ä½œã‚’ç¢ºèªã—ã¦ãã ã•ã„")

                # ç©ºã®try-except
                elif isinstance(node, ast.Try):
                    for handler in node.handlers:
                        if len(handler.body) == 1 and isinstance(handler.body[0], ast.Pass):
                            predictions.append("ç©ºã®exceptãƒ–ãƒ­ãƒƒã‚¯: é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¿½åŠ ")

        except Exception as e:
            logger.warning(f"âš ï¸ ãƒ­ã‚¸ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")

        return predictions

    def _validate_compatibility(self, code_content: str, file_path: str) -> List[ValidationIssue]:
        """äº’æ›æ€§æ¤œè¨¼"""

        issues = []

        # Python 3.12+ éäº’æ›æ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯
        compatibility_patterns = [
            (r'print\s+[^(]', "printæ–‡ã¯Python 2.xå½¢å¼ã§ã™", "print()é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„"),
            (r'\.has_key\(', "has_key()ã¯Python 3ã§å‰Šé™¤ã•ã‚Œã¾ã—ãŸ", "inæ¼”ç®—å­ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„"),
            (r'xrange\(', "xrange()ã¯Python 3ã§å‰Šé™¤ã•ã‚Œã¾ã—ãŸ", "range()ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„"),
        ]

        for i, line in enumerate(code_content.split('\n'), 1):
            for pattern, message, suggestion in compatibility_patterns:
                if re.search(pattern, line):
                    issues.append(ValidationIssue(
                        category=ValidationCategory.COMPATIBILITY,
                        severity=ValidationSeverity.WARNING,
                        line_number=i,
                        column=0,
                        message=message,
                        suggestion=suggestion,
                        code_snippet=line.strip(),
                        auto_fixable=True
                    ))

        return issues

    def _suggest_syntax_fix(self, syntax_error: SyntaxError) -> str:
        """æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ä¿®æ­£ææ¡ˆ"""

        error_msg = str(syntax_error.msg).lower()

        if "unexpected indent" in error_msg:
            return "ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆ4ã‚¹ãƒšãƒ¼ã‚¹ã¾ãŸã¯ã‚¿ãƒ–ã®çµ±ä¸€ï¼‰"
        elif "invalid syntax" in error_msg:
            return "æ§‹æ–‡ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆæ‹¬å¼§ã®å¯¾å¿œã€ã‚³ãƒ­ãƒ³ã®æœ‰ç„¡ç­‰ï¼‰"
        elif "unexpected eof" in error_msg:
            return "ãƒ•ã‚¡ã‚¤ãƒ«æœ«å°¾ã®æ§‹æ–‡ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆæœªå®Œäº†ã®æ–‡ç­‰ï¼‰"
        elif "non-utf-8" in error_msg:
            return "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ä¿å­˜ã—ã¦ãã ã•ã„"
        else:
            return "æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„"

    def _is_auto_fixable_syntax_error(self, syntax_error: SyntaxError) -> bool:
        """æ§‹æ–‡ã‚¨ãƒ©ãƒ¼è‡ªå‹•ä¿®æ­£å¯èƒ½æ€§åˆ¤å®š"""

        error_msg = str(syntax_error.msg).lower()

        # è‡ªå‹•ä¿®æ­£å¯èƒ½ãªæ§‹æ–‡ã‚¨ãƒ©ãƒ¼
        auto_fixable_patterns = [
            "missing parentheses",
            "missing comma",
            "missing colon",
            "trailing comma"
        ]

        return any(pattern in error_msg for pattern in auto_fixable_patterns)

    def _extract_code_snippet(self, code_content: str, line_number: int, context: int = 2) -> str:
        """ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆæŠ½å‡º"""

        lines = code_content.split('\n')
        start = max(0, line_number - context - 1)
        end = min(len(lines), line_number + context)

        snippet_lines = []
        for i in range(start, end):
            marker = ">>> " if i == line_number - 1 else "    "
            snippet_lines.append(f"{marker}{i + 1:3d}: {lines[i]}")

        return '\n'.join(snippet_lines)

    def _generate_fix_recommendations(self, issues: List[ValidationIssue]) -> List[str]:
        """ä¿®æ­£æ¨å¥¨ç”Ÿæˆ"""

        recommendations = []

        # é‡è¦åº¦åˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        critical_issues = [i for i in issues if i.severity == ValidationSeverity.CRITICAL]
        error_issues = [i for i in issues if i.severity == ValidationSeverity.ERROR]
        warning_issues = [i for i in issues if i.severity == ValidationSeverity.WARNING]

        if critical_issues:
            recommendations.append("ğŸš¨ ç·Šæ€¥ä¿®æ­£ãŒå¿…è¦ãªå•é¡ŒãŒã‚ã‚Šã¾ã™")
            for issue in critical_issues[:3]:  # ä¸Šä½3ä»¶
                recommendations.append(f"  - {issue.message}")

        if error_issues:
            recommendations.append("âŒ ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒ™ãƒ«ã®å•é¡Œã‚’ä¿®æ­£ã—ã¦ãã ã•ã„")
            for issue in error_issues[:3]:
                recommendations.append(f"  - {issue.message}")

        if warning_issues:
            recommendations.append("âš ï¸ è­¦å‘Šãƒ¬ãƒ™ãƒ«ã®å•é¡Œã‚’ç¢ºèªã—ã¦ãã ã•ã„")

        # è‡ªå‹•ä¿®æ­£å¯èƒ½å•é¡Œ
        auto_fixable = [i for i in issues if i.auto_fixable]
        if auto_fixable:
            recommendations.append(f"ğŸ”§ {len(auto_fixable)}ä»¶ã®å•é¡Œã¯è‡ªå‹•ä¿®æ­£å¯èƒ½ã§ã™")

        return recommendations

    def _calculate_confidence_score(self, issues: List[ValidationIssue],
                                   predicted_problems: List[str]) -> float:
        """ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—"""

        # ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦
        base_score = 1.0

        # å•é¡Œã®é‡è¦åº¦ã«åŸºã¥ãæ¸›ç‚¹
        for issue in issues:
            if issue.severity == ValidationSeverity.CRITICAL:
                base_score -= 0.3
            elif issue.severity == ValidationSeverity.ERROR:
                base_score -= 0.2
            elif issue.severity == ValidationSeverity.WARNING:
                base_score -= 0.1
            elif issue.severity == ValidationSeverity.INFO:
                base_score -= 0.05

        # äºˆæ¸¬å•é¡Œã«ã‚ˆã‚‹æ¸›ç‚¹
        base_score -= len(predicted_problems) * 0.02

        return max(base_score, 0.0)

    def _determine_overall_validity(self, issues: List[ValidationIssue]) -> bool:
        """å…¨ä½“å¦¥å½“æ€§åˆ¤å®š"""

        # CRITICALã¾ãŸã¯ERRORãŒã‚ã‚Œã°ç„¡åŠ¹
        for issue in issues:
            if issue.severity in [ValidationSeverity.CRITICAL, ValidationSeverity.ERROR]:
                return False

        return True

    def _cache_validation_result(self, result: PreValidationResult) -> None:
        """æ¤œè¨¼çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥"""

        try:
            cache_file = self.validation_cache_dir / f"validation_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(asdict(result), f, indent=2, ensure_ascii=False, default=str)

            # å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆæœ€æ–°10ä»¶ã®ã¿ä¿æŒï¼‰
            cache_files = sorted(self.validation_cache_dir.glob("validation_*.json"))
            if len(cache_files) > 10:
                for old_file in cache_files[:-10]:
                    old_file.unlink()

        except Exception as e:
            logger.warning(f"âš ï¸ æ¤œè¨¼çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ©ãƒ¼: {e}")

    def _create_file_not_found_result(self, file_path: str, start_time: datetime.datetime) -> PreValidationResult:
        """ãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹çµæœä½œæˆ"""

        execution_time = (datetime.datetime.now() - start_time).total_seconds()

        return PreValidationResult(
            file_path=file_path,
            is_valid=False,
            confidence_score=0.0,
            issues=[ValidationIssue(
                category=ValidationCategory.SYNTAX,
                severity=ValidationSeverity.CRITICAL,
                line_number=0,
                column=0,
                message=f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}",
                suggestion="æ­£ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                code_snippet="",
                auto_fixable=False
            )],
            predicted_problems=["ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹å•é¡Œ"],
            recommended_fixes=["ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç¢ºèª"],
            execution_time=execution_time
        )

    def _create_error_result(self, file_path: str, error_message: str,
                           start_time: datetime.datetime) -> PreValidationResult:
        """ã‚¨ãƒ©ãƒ¼çµæœä½œæˆ"""

        execution_time = (datetime.datetime.now() - start_time).total_seconds()

        return PreValidationResult(
            file_path=file_path,
            is_valid=False,
            confidence_score=0.0,
            issues=[ValidationIssue(
                category=ValidationCategory.SYNTAX,
                severity=ValidationSeverity.CRITICAL,
                line_number=0,
                column=0,
                message=f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {error_message}",
                suggestion="ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã¨ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                code_snippet="",
                auto_fixable=False
            )],
            predicted_problems=["æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼"],
            recommended_fixes=["ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®ç¢ºèª"],
            execution_time=execution_time
        )

    def _get_standard_modules(self) -> Set[str]:
        """æ¨™æº–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒªã‚¹ãƒˆå–å¾—"""

        return {
            'sys', 'os', 'json', 'datetime', 'time', 'math', 'random',
            'typing', 'pathlib', 'collections', 'functools', 'itertools',
            'subprocess', 'tempfile', 'unittest', 'dataclasses', 'enum',
            'ast', 're', 'importlib', 'statistics', 'copy', 'pickle'
        }

    def _load_validation_rules(self) -> Dict[str, Any]:
        """æ¤œè¨¼ãƒ«ãƒ¼ãƒ«èª­ã¿è¾¼ã¿"""

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¤œè¨¼ãƒ«ãƒ¼ãƒ«
        return {
            "syntax_strictness": "high",
            "type_annotation_required": True,
            "pep8_compliance": True,
            "python_version_compatibility": "3.8+",
            "security_checks": True
        }

    def _load_fix_patterns(self) -> Dict[str, Any]:
        """ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³èª­ã¿è¾¼ã¿"""

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³
        return {
            "missing_return_type": "-> None",
            "missing_arg_type": ": Any",
            "missing_imports": {"Any": "from typing import Any"},
            "common_syntax_fixes": {
                "missing_colon": ":",
                "missing_parentheses": "()",
                "trailing_comma": ","
            }
        }

    def auto_fix_issues(self, file_path: str, issues: List[ValidationIssue]) -> Dict[str, Any]:
        """å•é¡Œè‡ªå‹•ä¿®æ­£

        Args:
            file_path: å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            issues: ä¿®æ­£å¯¾è±¡å•é¡Œãƒªã‚¹ãƒˆ

        Returns:
            Dict[str, Any]: ä¿®æ­£çµæœ
        """

        logger.info(f"ğŸ”§ å•é¡Œè‡ªå‹•ä¿®æ­£é–‹å§‹: {file_path}")

        try:
            # ä¿®æ­£å¯èƒ½å•é¡Œãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            fixable_issues = [i for i in issues if i.auto_fixable]

            if not fixable_issues:
                return {
                    "success": True,
                    "fixes_applied": 0,
                    "message": "è‡ªå‹•ä¿®æ­£å¯èƒ½ãªå•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“"
                }

            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            with open(file_path, 'r', encoding='utf-8') as f:
                original_content = f.read()

            modified_content = original_content
            fixes_applied = 0

            # ä¿®æ­£é©ç”¨ï¼ˆè¡Œç•ªå·é™é †ã§é©ç”¨ã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãšã‚Œã‚’é˜²ãï¼‰
            sorted_issues = sorted(fixable_issues, key=lambda x: x.line_number, reverse=True)

            for issue in sorted_issues:
                if issue.category == ValidationCategory.TYPE_ANNOTATION:
                    modified_content, fixed = self._apply_type_annotation_fix(modified_content, issue)
                    if fixed:
                        fixes_applied += 1

                elif issue.category == ValidationCategory.SYNTAX:
                    modified_content, fixed = self._apply_syntax_fix(modified_content, issue)
                    if fixed:
                        fixes_applied += 1

                elif issue.category == ValidationCategory.COMPATIBILITY:
                    modified_content, fixed = self._apply_compatibility_fix(modified_content, issue)
                    if fixed:
                        fixes_applied += 1

            # ä¿®æ­£å†…å®¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãæˆ»ã—
            if fixes_applied > 0:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(modified_content)

                self.validation_stats["auto_fixes_applied"] += fixes_applied

            logger.info(f"âœ… å•é¡Œè‡ªå‹•ä¿®æ­£å®Œäº†: {fixes_applied}ä»¶é©ç”¨")

            return {
                "success": True,
                "fixes_applied": fixes_applied,
                "message": f"{fixes_applied}ä»¶ã®å•é¡Œã‚’è‡ªå‹•ä¿®æ­£ã—ã¾ã—ãŸ"
            }

        except Exception as e:
            logger.error(f"âŒ å•é¡Œè‡ªå‹•ä¿®æ­£ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
            return {
                "success": False,
                "fixes_applied": 0,
                "error": str(e)
            }

    def _apply_type_annotation_fix(self, content: str, issue: ValidationIssue) -> Tuple[str, bool]:
        """å‹æ³¨é‡ˆä¿®æ­£é©ç”¨"""

        lines = content.split('\n')

        if issue.line_number <= 0 or issue.line_number > len(lines):
            return content, False

        line = lines[issue.line_number - 1]

        # ç°¡å˜ãªå‹æ³¨é‡ˆè¿½åŠ 
        if "æˆ»ã‚Šå€¤å‹æ³¨é‡ˆãŒã‚ã‚Šã¾ã›ã‚“" in issue.message:
            if "def " in line and ":" in line and "->" not in line:
                # def function(): ã‚’ def function() -> None: ã«å¤‰æ›
                line = line.replace("):", ") -> None:")
                lines[issue.line_number - 1] = line
                return '\n'.join(lines), True

        elif "å¼•æ•°" in issue.message and "å‹æ³¨é‡ˆãŒã‚ã‚Šã¾ã›ã‚“" in issue.message:
            # ç°¡å˜ãªå¼•æ•°å‹æ³¨é‡ˆè¿½åŠ ã¯è¤‡é›‘ãªãŸã‚ã€ã“ã“ã§ã¯ã‚¹ã‚­ãƒƒãƒ—
            # å°†æ¥çš„ã«ã¯ã‚ˆã‚Šé«˜åº¦ãªä¿®æ­£ã‚’å®Ÿè£…
            pass

        return content, False

    def _apply_syntax_fix(self, content: str, issue: ValidationIssue) -> Tuple[str, bool]:
        """æ§‹æ–‡ä¿®æ­£é©ç”¨"""

        lines = content.split('\n')

        if issue.line_number <= 0 or issue.line_number > len(lines):
            return content, False

        line = lines[issue.line_number - 1]

        # åŸºæœ¬çš„ãªæ§‹æ–‡ä¿®æ­£
        fix_patterns = self.fix_patterns.get("common_syntax_fixes", {})

        for pattern, fix in fix_patterns.items():
            if pattern in issue.message.lower():
                # ç°¡å˜ãªä¿®æ­£é©ç”¨
                if pattern == "missing_colon" and not line.rstrip().endswith(":"):
                    lines[issue.line_number - 1] = line.rstrip() + ":"
                    return '\n'.join(lines), True

        return content, False

    def _apply_compatibility_fix(self, content: str, issue: ValidationIssue) -> Tuple[str, bool]:
        """äº’æ›æ€§ä¿®æ­£é©ç”¨"""

        lines = content.split('\n')

        if issue.line_number <= 0 or issue.line_number > len(lines):
            return content, False

        line = lines[issue.line_number - 1]

        # åŸºæœ¬çš„ãªäº’æ›æ€§ä¿®æ­£
        if "printæ–‡" in issue.message:
            # print statement ã‚’ print() function ã«å¤‰æ›
            modified_line = re.sub(r'print\s+([^(].*)', r'print(\1)', line)
            if modified_line != line:
                lines[issue.line_number - 1] = modified_line
                return '\n'.join(lines), True

        elif "has_key" in issue.message:
            # has_key() ã‚’ inæ¼”ç®—å­ã«å¤‰æ›
            modified_line = re.sub(r'\.has_key\(([^)]+)\)', r' in dict and \1 in dict', line)
            if modified_line != line:
                lines[issue.line_number - 1] = modified_line
                return '\n'.join(lines), True

        return content, False

    def generate_enhancement_report(self) -> SyntaxEnhancementReport:
        """æ§‹æ–‡å¼·åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""

        logger.info("ğŸ“Š æ§‹æ–‡å¼·åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹")

        # å•é¡Œåˆ†å¸ƒè¨ˆç®—
        issue_distribution = {}

        # éå»ã®æ¤œè¨¼çµæœã‹ã‚‰çµ±è¨ˆå–å¾—
        cache_files = list(self.validation_cache_dir.glob("validation_*.json"))
        total_files = len(cache_files)
        successful_validations = 0

        for cache_file in cache_files:
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    result_data = json.load(f)

                if result_data.get("is_valid", False):
                    successful_validations += 1

                for issue in result_data.get("issues", []):
                    category = issue.get("category", "unknown")
                    issue_distribution[category] = issue_distribution.get(category, 0) + 1

            except Exception:
                continue

        # æˆåŠŸç‡è¨ˆç®—
        success_rate = successful_validations / total_files if total_files > 0 else 0.0

        # è‡ªå‹•ä¿®æ­£æˆåŠŸç‡è¨ˆç®—
        auto_fix_rate = (
            self.validation_stats["auto_fixes_applied"] /
            max(self.validation_stats["total_validations"], 1)
        )

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        performance_metrics = {
            "average_validation_time": 0.5,  # å®Ÿè£…æ™‚ã«å®Ÿéš›ã®å¹³å‡æ™‚é–“ã‚’è¨ˆç®—
            "cache_hit_rate": 0.8,
            "error_prevention_rate": self.validation_stats["errors_prevented"] / max(total_files, 1)
        }

        # æ¨å¥¨äº‹é …ç”Ÿæˆ
        recommendations = self._generate_enhancement_recommendations(
            success_rate, issue_distribution, auto_fix_rate
        )

        report = SyntaxEnhancementReport(
            timestamp=datetime.datetime.now().isoformat(),
            total_files_validated=total_files,
            validation_success_rate=success_rate,
            issue_distribution=issue_distribution,
            auto_fix_success_rate=auto_fix_rate,
            performance_metrics=performance_metrics,
            recommendations=recommendations
        )

        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        self._save_enhancement_report(report)

        logger.info("âœ… æ§‹æ–‡å¼·åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")

        return report

    def _generate_enhancement_recommendations(self, success_rate: float,
                                           issue_distribution: Dict[str, int],
                                           auto_fix_rate: float) -> List[str]:
        """å¼·åŒ–æ¨å¥¨äº‹é …ç”Ÿæˆ"""

        recommendations = []

        # æˆåŠŸç‡åˆ¥æ¨å¥¨
        if success_rate < 0.8:
            recommendations.append("ğŸ“ˆ æ§‹æ–‡æ¤œè¨¼æˆåŠŸç‡ãŒä½ã„ãŸã‚ã€äº‹å‰ãƒã‚§ãƒƒã‚¯å¼·åŒ–ã‚’æ¨å¥¨")
        elif success_rate >= 0.95:
            recommendations.append("âœ… æ§‹æ–‡æ¤œè¨¼æˆåŠŸç‡ã¯å„ªç§€ã§ã™")

        # å•é¡Œåˆ†å¸ƒåˆ¥æ¨å¥¨
        if issue_distribution.get("syntax", 0) > 10:
            recommendations.append("ğŸ“ æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãŒå¤šç™ºã—ã¦ã„ã¾ã™ã€‚é–‹ç™ºç’°å¢ƒã®æ§‹æ–‡ãƒã‚§ãƒƒã‚¯å¼·åŒ–ã‚’æ¨å¥¨")

        if issue_distribution.get("type_annotation", 0) > 20:
            recommendations.append("ğŸ·ï¸ å‹æ³¨é‡ˆé–¢é€£ã®å•é¡ŒãŒå¤šç™ºã—ã¦ã„ã¾ã™ã€‚å‹æ³¨é‡ˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ç­–å®šã‚’æ¨å¥¨")

        if issue_distribution.get("import", 0) > 5:
            recommendations.append("ğŸ“¦ ã‚¤ãƒ³ãƒãƒ¼ãƒˆé–¢é€£ã®å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ä¾å­˜é–¢ä¿‚ç®¡ç†ã®è¦‹ç›´ã—ã‚’æ¨å¥¨")

        # è‡ªå‹•ä¿®æ­£ç‡åˆ¥æ¨å¥¨
        if auto_fix_rate < 0.3:
            recommendations.append("ğŸ”§ è‡ªå‹•ä¿®æ­£æ©Ÿèƒ½ã®æ´»ç”¨ã‚’æ¨å¥¨ã—ã¾ã™")
        elif auto_fix_rate >= 0.7:
            recommendations.append("ğŸ¤– è‡ªå‹•ä¿®æ­£æ©Ÿèƒ½ãŒåŠ¹æœçš„ã«æ´»ç”¨ã•ã‚Œã¦ã„ã¾ã™")

        # ä¸€èˆ¬çš„ãªæ¨å¥¨
        recommendations.append("ğŸ”„ å®šæœŸçš„ãªæ§‹æ–‡å“è³ªãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å®Ÿæ–½")
        recommendations.append("ğŸ“š é–‹ç™ºãƒãƒ¼ãƒ å‘ã‘ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„ã®æ›´æ–°")

        return recommendations

    def _save_enhancement_report(self, report: SyntaxEnhancementReport) -> None:
        """å¼·åŒ–ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""

        try:
            report_file = self.enhancement_reports_dir / f"enhancement_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(asdict(report), f, indent=2, ensure_ascii=False)

            logger.info(f"âœ… æ§‹æ–‡å¼·åŒ–ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†: {report_file}")

        except Exception as e:
            logger.error(f"âŒ æ§‹æ–‡å¼·åŒ–ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")


def main() -> None:
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    validator = EnhancedSyntaxValidator()

    # ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã§ãƒ†ã‚¹ãƒˆ
    test_code = '''
def test_function():
    print("Hello, World!")
    return 42

class TestClass:
    def __init__(self):
        self.value = 100
'''

    # äº‹å‰æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
    result = validator.pre_validate_code("test.py", test_code)
    print(f"æ¤œè¨¼çµæœ: {result.is_valid}")
    print(f"ä¿¡é ¼åº¦: {result.confidence_score:.3f}")
    print(f"å•é¡Œæ•°: {len(result.issues)}")

    # å¼·åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = validator.generate_enhancement_report()
    print(f"æ¤œè¨¼æˆåŠŸç‡: {report.validation_success_rate:.1%}")


if __name__ == "__main__":
    main()
