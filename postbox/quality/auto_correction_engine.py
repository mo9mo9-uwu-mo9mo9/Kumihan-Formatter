#!/usr/bin/env python3
"""
AutoCorrection Engine
è‡ªå‹•ä¿®æ­£ææ¡ˆãƒ»é©ç”¨ã‚·ã‚¹ãƒ†ãƒ  - æ—¢å­˜Geminiå”æ¥­ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ
ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã«ã‚ˆã‚‹ä¿®æ­£ã‚¨ãƒ³ã‚¸ãƒ³ãƒ»æ®µéšçš„å“è³ªæ”¹å–„ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import json
import re
import ast
import time
import subprocess
import datetime
from typing import Dict, List, Any, Optional, Tuple, Union
from pathlib import Path
from dataclasses import dataclass, asdict
from enum import Enum

class CorrectionType(Enum):
    """ä¿®æ­£ã‚¿ã‚¤ãƒ—"""
    SYNTAX_FIX = "syntax_fix"           # æ§‹æ–‡ä¿®æ­£
    TYPE_ANNOTATION = "type_annotation" # å‹æ³¨é‡ˆè¿½åŠ 
    FORMAT_FIX = "format_fix"          # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¿®æ­£
    IMPORT_OPTIMIZATION = "import_opt"  # ã‚¤ãƒ³ãƒãƒ¼ãƒˆæœ€é©åŒ–
    SECURITY_FIX = "security_fix"      # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿®æ­£
    PERFORMANCE_OPT = "performance_opt" # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
    STYLE_IMPROVEMENT = "style_improve" # ã‚¹ã‚¿ã‚¤ãƒ«æ”¹å–„

class CorrectionComplexity(Enum):
    """ä¿®æ­£è¤‡é›‘åº¦"""
    SIMPLE = "simple"        # ç°¡å˜ï¼ˆè‡ªå‹•é©ç”¨å¯èƒ½ï¼‰
    MODERATE = "moderate"    # ä¸­ç¨‹åº¦ï¼ˆç¢ºèªå¾Œé©ç”¨ï¼‰
    COMPLEX = "complex"      # è¤‡é›‘ï¼ˆæ‰‹å‹•ä¿®æ­£æ¨å¥¨ï¼‰
    CRITICAL = "critical"    # é‡è¦ï¼ˆæ…é‡ãªç¢ºèªå¿…è¦ï¼‰

class CorrectionConfidence(Enum):
    """ä¿®æ­£ä¿¡é ¼åº¦"""
    HIGH = "high"        # é«˜ï¼ˆ95%ä»¥ä¸Šï¼‰
    MEDIUM = "medium"    # ä¸­ï¼ˆ80-94%ï¼‰
    LOW = "low"         # ä½ï¼ˆ60-79%ï¼‰
    UNCERTAIN = "uncertain" # ä¸ç¢ºå®Ÿï¼ˆ60%æœªæº€ï¼‰

@dataclass
class CorrectionSuggestion:
    """ä¿®æ­£ææ¡ˆ"""
    suggestion_id: str
    file_path: str
    line_number: int
    correction_type: CorrectionType
    complexity: CorrectionComplexity
    confidence: CorrectionConfidence
    
    original_code: str
    suggested_code: str
    explanation: str
    reasoning: str
    
    estimated_time: float  # æ¨å®šä¿®æ­£æ™‚é–“ï¼ˆåˆ†ï¼‰
    risk_level: str       # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«
    prerequisites: List[str] # å‰ææ¡ä»¶
    
    pattern_id: Optional[str] = None
    auto_applicable: bool = False
    gemini_recommended: bool = False

@dataclass
class CorrectionResult:
    """ä¿®æ­£çµæœ"""
    suggestion_id: str
    file_path: str
    applied: bool
    success: bool
    
    execution_time: float
    error_message: Optional[str] = None
    quality_improvement: Optional[float] = None
    
    before_metrics: Optional[Dict[str, float]] = None
    after_metrics: Optional[Dict[str, float]] = None

class PatternMatcher:
    """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ãƒ»èªè­˜ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.patterns = self._load_correction_patterns()
        self.statistics = {
            "patterns_matched": 0,
            "corrections_suggested": 0,
            "success_rate": 0.0
        }
    
    def _load_correction_patterns(self) -> Dict[str, Dict]:
        """ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³èª­ã¿è¾¼ã¿"""
        
        # åŸºæœ¬çš„ãªä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
        patterns = {
            "no_untyped_def": {
                "regex": r"def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\([^)]*\)\s*:",
                "type": CorrectionType.TYPE_ANNOTATION,
                "complexity": CorrectionComplexity.SIMPLE,
                "confidence": CorrectionConfidence.HIGH,
                "template": "def {func_name}({params}) -> {return_type}:",
                "auto_applicable": True
            },
            
            "missing_import": {
                "regex": r"from\s+typing\s+import",
                "type": CorrectionType.IMPORT_OPTIMIZATION,
                "complexity": CorrectionComplexity.SIMPLE,
                "confidence": CorrectionConfidence.HIGH,
                "template": "from typing import Any, Dict, List, Optional",
                "auto_applicable": True
            },
            
            "unused_import": {
                "regex": r"^import\s+([a-zA-Z_][a-zA-Z0-9_.]*)",
                "type": CorrectionType.IMPORT_OPTIMIZATION,
                "complexity": CorrectionComplexity.SIMPLE,
                "confidence": CorrectionConfidence.MEDIUM,
                "auto_applicable": True
            },
            
            "format_violation": {
                "regex": r"\s+$",  # è¡Œæœ«ç©ºç™½
                "type": CorrectionType.FORMAT_FIX,
                "complexity": CorrectionComplexity.SIMPLE,
                "confidence": CorrectionConfidence.HIGH,
                "template": "",
                "auto_applicable": True
            },
            
            "security_eval": {
                "regex": r"\beval\s*\(",
                "type": CorrectionType.SECURITY_FIX,
                "complexity": CorrectionComplexity.CRITICAL,
                "confidence": CorrectionConfidence.HIGH,
                "template": "# TODO: Replace eval() with safer alternative",
                "auto_applicable": False
            },
            
            "performance_loop": {
                "regex": r"for\s+\w+\s+in\s+range\(len\(",
                "type": CorrectionType.PERFORMANCE_OPT,
                "complexity": CorrectionComplexity.MODERATE,
                "confidence": CorrectionConfidence.MEDIUM,
                "template": "for i, item in enumerate({iterable}):",
                "auto_applicable": False
            }
        }
        
        return patterns
    
    def match_patterns(self, file_content: str, file_path: str) -> List[CorrectionSuggestion]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°å®Ÿè¡Œ"""
        suggestions = []
        lines = file_content.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            for pattern_id, pattern in self.patterns.items():
                match = re.search(pattern["regex"], line)
                if match:
                    suggestion = self._create_suggestion_from_pattern(
                        pattern_id, pattern, file_path, line_num, line, match
                    )
                    if suggestion:
                        suggestions.append(suggestion)
                        self.statistics["patterns_matched"] += 1
        
        self.statistics["corrections_suggested"] = len(suggestions)
        return suggestions
    
    def _create_suggestion_from_pattern(self, pattern_id: str, pattern: Dict, 
                                      file_path: str, line_num: int, 
                                      original_line: str, match: re.Match) -> Optional[CorrectionSuggestion]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ä¿®æ­£ææ¡ˆä½œæˆ"""
        
        try:
            suggestion_id = f"{pattern_id}_{file_path}_{line_num}_{int(time.time())}"
            
            # ä¿®æ­£ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
            suggested_code = self._generate_suggested_code(pattern, original_line, match)
            
            # èª¬æ˜ãƒ»æ¨è«–ç”Ÿæˆ
            explanation, reasoning = self._generate_explanation(pattern_id, pattern)
            
            return CorrectionSuggestion(
                suggestion_id=suggestion_id,
                file_path=file_path,
                line_number=line_num,
                correction_type=pattern["type"],
                complexity=pattern["complexity"],
                confidence=pattern["confidence"],
                original_code=original_line.strip(),
                suggested_code=suggested_code,
                explanation=explanation,
                reasoning=reasoning,
                estimated_time=self._estimate_correction_time(pattern),
                risk_level=self._assess_risk_level(pattern),
                prerequisites=self._get_prerequisites(pattern),
                pattern_id=pattern_id,
                auto_applicable=pattern.get("auto_applicable", False),
                gemini_recommended=self._should_recommend_gemini(pattern)
            )
            
        except Exception as e:
            print(f"âš ï¸ ä¿®æ­£ææ¡ˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _generate_suggested_code(self, pattern: Dict, original_line: str, match: re.Match) -> str:
        """ä¿®æ­£ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ"""
        
        template = pattern.get("template", original_line)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³å›ºæœ‰ã®ä¿®æ­£
        if pattern["type"] == CorrectionType.TYPE_ANNOTATION:
            return self._fix_type_annotation(original_line, match)
        elif pattern["type"] == CorrectionType.FORMAT_FIX:
            return original_line.rstrip()  # è¡Œæœ«ç©ºç™½é™¤å»
        elif pattern["type"] == CorrectionType.IMPORT_OPTIMIZATION:
            return self._optimize_import(original_line, match)
        else:
            return template
    
    def _fix_type_annotation(self, original_line: str, match: re.Match) -> str:
        """å‹æ³¨é‡ˆä¿®æ­£"""
        
        # é–¢æ•°å®šç¾©ãƒ‘ã‚¿ãƒ¼ãƒ³è§£æ
        func_match = re.search(r"def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\(([^)]*)\)\s*:", original_line)
        if not func_match:
            return original_line
        
        func_name = func_match.group(1)
        params = func_match.group(2).strip()
        
        # æˆ»ã‚Šå€¤å‹ã®æ¨å®š
        return_type = "None"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        if "return" in original_line.lower() or any(keyword in func_name.lower() for keyword in ["get", "create", "generate"]):
            return_type = "Any"
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‹æ³¨é‡ˆè¿½åŠ 
        if params and ":" not in params:
            # ç°¡å˜ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‹æ¨å®š
            typed_params = []
            for param in params.split(','):
                param = param.strip()
                if param and not param.startswith('*'):
                    typed_params.append(f"{param}: Any")
                else:
                    typed_params.append(param)
            params = ", ".join(typed_params)
        
        return f"def {func_name}({params}) -> {return_type}:"
    
    def _optimize_import(self, original_line: str, match: re.Match) -> str:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆæœ€é©åŒ–"""
        
        # æœªä½¿ç”¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¤œå‡ºã¯è¤‡é›‘ãªã®ã§ã€åŸºæœ¬çš„ãªæ•´ç†ã®ã¿
        if original_line.strip().startswith("import ") and "," in original_line:
            # è¤‡æ•°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’åˆ†å‰²
            imports = [imp.strip() for imp in original_line.replace("import ", "").split(",")]
            return "\n".join([f"import {imp}" for imp in imports if imp])
        
        return original_line
    
    def _generate_explanation(self, pattern_id: str, pattern: Dict) -> Tuple[str, str]:
        """èª¬æ˜ãƒ»æ¨è«–ç”Ÿæˆ"""
        
        explanations = {
            "no_untyped_def": (
                "å‹æ³¨é‡ˆãŒä¸è¶³ã—ã¦ã„ã‚‹é–¢æ•°ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚",
                "mypy strict modeã§ã¯å…¨ã¦ã®é–¢æ•°ã«å‹æ³¨é‡ˆãŒå¿…è¦ã§ã™ã€‚"
            ),
            "missing_import": (
                "typing ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã®å¿…è¦ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚",
                "å‹æ³¨é‡ˆã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã«ã¯é©åˆ‡ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå¿…è¦ã§ã™ã€‚"
            ),
            "unused_import": (
                "ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚",
                "ä¸è¦ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆã¯ã‚³ãƒ¼ãƒ‰ã®å¯èª­æ€§ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã—ã¾ã™ã€‚"
            ),
            "format_violation": (
                "ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé•åï¼ˆè¡Œæœ«ç©ºç™½ï¼‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚",
                "ä¸€è²«ã—ãŸã‚³ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯ä¿å®ˆæ€§ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚"
            ),
            "security_eval": (
                "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ï¼ˆevalä½¿ç”¨ï¼‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚",
                "eval()ã®ä½¿ç”¨ã¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
            ),
            "performance_loop": (
                "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„å¯èƒ½ãªãƒ«ãƒ¼ãƒ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚",
                "enumerate()ã®ä½¿ç”¨ã«ã‚ˆã‚ŠåŠ¹ç‡æ€§ã¨å¯èª­æ€§ãŒå‘ä¸Šã—ã¾ã™ã€‚"
            )
        }
        
        return explanations.get(pattern_id, ("ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚", "å“è³ªæ”¹å–„ã®ãŸã‚ä¿®æ­£ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"))
    
    def _estimate_correction_time(self, pattern: Dict) -> float:
        """ä¿®æ­£æ™‚é–“æ¨å®šï¼ˆåˆ†ï¼‰"""
        
        complexity_times = {
            CorrectionComplexity.SIMPLE: 0.5,
            CorrectionComplexity.MODERATE: 2.0,
            CorrectionComplexity.COMPLEX: 10.0,
            CorrectionComplexity.CRITICAL: 30.0
        }
        
        return complexity_times.get(pattern["complexity"], 5.0)
    
    def _assess_risk_level(self, pattern: Dict) -> str:
        """ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«è©•ä¾¡"""
        
        if pattern["complexity"] == CorrectionComplexity.CRITICAL:
            return "high"
        elif pattern["complexity"] == CorrectionComplexity.COMPLEX:
            return "medium"
        else:
            return "low"
    
    def _get_prerequisites(self, pattern: Dict) -> List[str]:
        """å‰ææ¡ä»¶å–å¾—"""
        
        prerequisites = {
            CorrectionType.TYPE_ANNOTATION: ["typing ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"],
            CorrectionType.SECURITY_FIX: ["ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ä»£æ›¿å®Ÿè£…ã®æ¤œè¨"],
            CorrectionType.PERFORMANCE_OPT: ["ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ", "ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"],
        }
        
        return prerequisites.get(pattern["type"], [])
    
    def _should_recommend_gemini(self, pattern: Dict) -> bool:
        """Geminiæ¨å¥¨åˆ¤å®š"""
        
        # ç°¡å˜ã§è‡ªå‹•é©ç”¨å¯èƒ½ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã¯Geminiæ¨å¥¨
        return (pattern["complexity"] in [CorrectionComplexity.SIMPLE, CorrectionComplexity.MODERATE] and
                pattern["confidence"] in [CorrectionConfidence.HIGH, CorrectionConfidence.MEDIUM])

class AutoCorrectionEngine:
    """è‡ªå‹•ä¿®æ­£ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.data_dir = Path("postbox/quality/corrections")
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        self.suggestions_path = self.data_dir / "suggestions.json"
        self.results_path = self.data_dir / "results.json"
        self.statistics_path = self.data_dir / "statistics.json"
        
        self.pattern_matcher = PatternMatcher()
        
        # çµ±è¨ˆæƒ…å ±
        self.statistics = {
            "total_suggestions": 0,
            "auto_applied": 0,
            "manual_applied": 0,
            "rejected": 0,
            "success_rate": 0.0,
            "gemini_delegated": 0,
            "quality_improvements": []
        }
        
        # Geminiå”æ¥­è¨­å®š
        self.gemini_integration = self._initialize_gemini_integration()
        
        print("ğŸ”§ AutoCorrectionEngine åˆæœŸåŒ–å®Œäº†")
    
    def _initialize_gemini_integration(self):
        """Geminiå”æ¥­ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        try:
            # æ—¢å­˜ã®DualAgentCoordinatorã‚’ä½¿ç”¨
            import sys
            sys.path.append('postbox')
            from workflow.dual_agent_coordinator import DualAgentCoordinator
            return DualAgentCoordinator()
        except ImportError:
            print("âš ï¸ Geminiå”æ¥­ã‚·ã‚¹ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™ã€‚")
            return None
    
    def analyze_file(self, file_path: str) -> List[CorrectionSuggestion]:
        """ãƒ•ã‚¡ã‚¤ãƒ«è§£æãƒ»ä¿®æ­£ææ¡ˆç”Ÿæˆ"""
        
        print(f"ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«è§£æé–‹å§‹: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚‹ææ¡ˆç”Ÿæˆ
        suggestions = self.pattern_matcher.match_patterns(content, file_path)
        
        # ææ¡ˆã®å„ªå…ˆåº¦ä»˜ã‘ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        suggestions = self._prioritize_suggestions(suggestions)
        
        # çµ±è¨ˆæ›´æ–°
        self.statistics["total_suggestions"] += len(suggestions)
        
        # ææ¡ˆä¿å­˜
        self._save_suggestions(suggestions)
        
        print(f"âœ… è§£æå®Œäº†: {len(suggestions)}ä»¶ã®ä¿®æ­£ææ¡ˆ")
        
        return suggestions
    
    def apply_corrections(self, suggestions: List[CorrectionSuggestion], 
                         auto_apply: bool = False, 
                         use_gemini: bool = True) -> List[CorrectionResult]:
        """ä¿®æ­£é©ç”¨"""
        
        results = []
        
        for suggestion in suggestions:
            print(f"ğŸ”§ ä¿®æ­£é©ç”¨: {suggestion.suggestion_id}")
            
            # é©ç”¨æ–¹æ³•æ±ºå®š
            if suggestion.auto_applicable and auto_apply:
                # è‡ªå‹•é©ç”¨
                result = self._apply_correction_direct(suggestion)
                if result.success:
                    self.statistics["auto_applied"] += 1
            elif suggestion.gemini_recommended and use_gemini and self.gemini_integration:
                # Geminié©ç”¨
                result = self._apply_correction_gemini(suggestion)
                if result.success:
                    self.statistics["gemini_delegated"] += 1
            else:
                # æ‰‹å‹•é©ç”¨æ¨å¥¨
                result = self._create_manual_correction_guide(suggestion)
                self.statistics["manual_applied"] += 1
            
            results.append(result)
            
            # å“è³ªæ”¹å–„æ¸¬å®š
            if result.success and result.quality_improvement:
                self.statistics["quality_improvements"].append(result.quality_improvement)
        
        # çµæœä¿å­˜
        self._save_results(results)
        
        # çµ±è¨ˆæ›´æ–°
        self._update_statistics(results)
        
        return results
    
    def _apply_correction_direct(self, suggestion: CorrectionSuggestion) -> CorrectionResult:
        """ç›´æ¥ä¿®æ­£é©ç”¨"""
        
        start_time = time.time()
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            with open(suggestion.file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # ä¿®æ­£é©ç”¨
            if suggestion.line_number <= len(lines):
                original_line = lines[suggestion.line_number - 1]
                lines[suggestion.line_number - 1] = suggestion.suggested_code + '\n'
                
                # ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿
                with open(suggestion.file_path, 'w', encoding='utf-8') as f:
                    f.writelines(lines)
                
                execution_time = time.time() - start_time
                
                print(f"âœ… ç›´æ¥ä¿®æ­£å®Œäº†: {suggestion.file_path}:{suggestion.line_number}")
                
                return CorrectionResult(
                    suggestion_id=suggestion.suggestion_id,
                    file_path=suggestion.file_path,
                    applied=True,
                    success=True,
                    execution_time=execution_time
                )
            else:
                raise ValueError(f"è¡Œç•ªå·ãŒç¯„å›²å¤–: {suggestion.line_number}")
                
        except Exception as e:
            execution_time = time.time() - start_time
            print(f"âŒ ç›´æ¥ä¿®æ­£ã‚¨ãƒ©ãƒ¼: {e}")
            
            return CorrectionResult(
                suggestion_id=suggestion.suggestion_id,
                file_path=suggestion.file_path,
                applied=False,
                success=False,
                execution_time=execution_time,
                error_message=str(e)
            )
    
    def _apply_correction_gemini(self, suggestion: CorrectionSuggestion) -> CorrectionResult:
        """Geminiä¿®æ­£é©ç”¨"""
        
        start_time = time.time()
        
        try:
            if not self.gemini_integration:
                raise ValueError("Geminiå”æ¥­ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            
            # Geminiã‚¿ã‚¹ã‚¯ä½œæˆ
            task_data = {
                'task_id': f"correction_{suggestion.suggestion_id}",
                'type': suggestion.correction_type.value,
                'target_files': [suggestion.file_path],
                'requirements': {
                    'line_number': suggestion.line_number,
                    'original_code': suggestion.original_code,
                    'suggested_code': suggestion.suggested_code,
                    'explanation': suggestion.explanation,
                    'complexity': suggestion.complexity.value
                }
            }
            
            # Geminiå®Ÿè¡Œ
            task_ids = self.gemini_integration.create_mypy_fix_task(
                [suggestion.file_path], 
                suggestion.correction_type.value, 
                auto_execute=True
            )
            
            execution_time = time.time() - start_time
            
            if task_ids:
                print(f"âœ… Geminiä¿®æ­£å®Œäº†: {suggestion.suggestion_id}")
                return CorrectionResult(
                    suggestion_id=suggestion.suggestion_id,
                    file_path=suggestion.file_path,
                    applied=True,
                    success=True,
                    execution_time=execution_time
                )
            else:
                raise ValueError("Geminiå®Ÿè¡Œå¤±æ•—")
                
        except Exception as e:
            execution_time = time.time() - start_time
            print(f"âŒ Geminiä¿®æ­£ã‚¨ãƒ©ãƒ¼: {e}")
            
            return CorrectionResult(
                suggestion_id=suggestion.suggestion_id,
                file_path=suggestion.file_path,
                applied=False,
                success=False,
                execution_time=execution_time,
                error_message=str(e)
            )
    
    def _create_manual_correction_guide(self, suggestion: CorrectionSuggestion) -> CorrectionResult:
        """æ‰‹å‹•ä¿®æ­£ã‚¬ã‚¤ãƒ‰ä½œæˆ"""
        
        guide_path = self.data_dir / f"manual_guide_{suggestion.suggestion_id}.md"
        
        guide_content = f"""# æ‰‹å‹•ä¿®æ­£ã‚¬ã‚¤ãƒ‰: {suggestion.suggestion_id}

## ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
- **ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: {suggestion.file_path}
- **è¡Œç•ªå·**: {suggestion.line_number}
- **ä¿®æ­£ã‚¿ã‚¤ãƒ—**: {suggestion.correction_type.value}
- **è¤‡é›‘åº¦**: {suggestion.complexity.value}
- **ä¿¡é ¼åº¦**: {suggestion.confidence.value}

## ä¿®æ­£å†…å®¹

### ä¿®æ­£å‰
```python
{suggestion.original_code}
```

### ä¿®æ­£å¾Œ
```python
{suggestion.suggested_code}
```

## èª¬æ˜
{suggestion.explanation}

## æ¨è«–
{suggestion.reasoning}

## å‰ææ¡ä»¶
{chr(10).join(f"- {prereq}" for prereq in suggestion.prerequisites)}

## æ¨å®šæ™‚é–“
ç´„ {suggestion.estimated_time} åˆ†

## ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«
{suggestion.risk_level}

## ä¿®æ­£æ‰‹é †
1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã: `{suggestion.file_path}`
2. {suggestion.line_number}è¡Œç›®ã‚’ç¢ºèª
3. ä¸Šè¨˜ã®ä¿®æ­£ã‚’é©ç”¨
4. æ§‹æ–‡ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ: `python3 -m py_compile {suggestion.file_path}`
5. å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ: `make lint`

---
Generated by AutoCorrectionEngine at {datetime.datetime.now().isoformat()}
"""
        
        try:
            with open(guide_path, 'w', encoding='utf-8') as f:
                f.write(guide_content)
            
            print(f"ğŸ“ æ‰‹å‹•ä¿®æ­£ã‚¬ã‚¤ãƒ‰ä½œæˆ: {guide_path}")
            
            return CorrectionResult(
                suggestion_id=suggestion.suggestion_id,
                file_path=suggestion.file_path,
                applied=False,
                success=True,
                execution_time=0.0
            )
            
        except Exception as e:
            print(f"âŒ æ‰‹å‹•ä¿®æ­£ã‚¬ã‚¤ãƒ‰ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return CorrectionResult(
                suggestion_id=suggestion.suggestion_id,
                file_path=suggestion.file_path,
                applied=False,
                success=False,
                execution_time=0.0,
                error_message=str(e)
            )
    
    def _prioritize_suggestions(self, suggestions: List[CorrectionSuggestion]) -> List[CorrectionSuggestion]:
        """ä¿®æ­£ææ¡ˆå„ªå…ˆåº¦ä»˜ã‘"""
        
        def priority_score(suggestion: CorrectionSuggestion) -> float:
            score = 0.0
            
            # ä¿¡é ¼åº¦ã«ã‚ˆã‚‹é‡ã¿
            confidence_weights = {
                CorrectionConfidence.HIGH: 1.0,
                CorrectionConfidence.MEDIUM: 0.8,
                CorrectionConfidence.LOW: 0.6,
                CorrectionConfidence.UNCERTAIN: 0.3
            }
            score += confidence_weights.get(suggestion.confidence, 0.5)
            
            # è¤‡é›‘åº¦ã«ã‚ˆã‚‹é‡ã¿ï¼ˆç°¡å˜ãªã‚‚ã®ã‚’å„ªå…ˆï¼‰
            complexity_weights = {
                CorrectionComplexity.SIMPLE: 1.0,
                CorrectionComplexity.MODERATE: 0.7,
                CorrectionComplexity.COMPLEX: 0.4,
                CorrectionComplexity.CRITICAL: 0.2
            }
            score += complexity_weights.get(suggestion.complexity, 0.5)
            
            # ä¿®æ­£ã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹é‡ã¿
            type_weights = {
                CorrectionType.SYNTAX_FIX: 1.0,
                CorrectionType.SECURITY_FIX: 0.9,
                CorrectionType.TYPE_ANNOTATION: 0.8,
                CorrectionType.FORMAT_FIX: 0.7,
                CorrectionType.IMPORT_OPTIMIZATION: 0.6,
                CorrectionType.PERFORMANCE_OPT: 0.5,
                CorrectionType.STYLE_IMPROVEMENT: 0.4
            }
            score += type_weights.get(suggestion.correction_type, 0.5)
            
            return score
        
        # å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆ
        return sorted(suggestions, key=priority_score, reverse=True)
    
    def _save_suggestions(self, suggestions: List[CorrectionSuggestion]) -> None:
        """ä¿®æ­£ææ¡ˆä¿å­˜"""
        try:
            suggestions_data = [asdict(suggestion) for suggestion in suggestions]
            
            with open(self.suggestions_path, 'w', encoding='utf-8') as f:
                json.dump(suggestions_data, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            print(f"âš ï¸ ææ¡ˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_results(self, results: List[CorrectionResult]) -> None:
        """ä¿®æ­£çµæœä¿å­˜"""
        try:
            # æ—¢å­˜çµæœèª­ã¿è¾¼ã¿
            existing_results = []
            if self.results_path.exists():
                with open(self.results_path, 'r', encoding='utf-8') as f:
                    existing_results = json.load(f)
            
            # æ–°ã—ã„çµæœè¿½åŠ 
            new_results_data = [asdict(result) for result in results]
            existing_results.extend(new_results_data)
            
            # ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆæœ€æ–°1000ä»¶ï¼‰
            if len(existing_results) > 1000:
                existing_results = existing_results[-1000:]
            
            with open(self.results_path, 'w', encoding='utf-8') as f:
                json.dump(existing_results, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            print(f"âš ï¸ çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _update_statistics(self, results: List[CorrectionResult]) -> None:
        """çµ±è¨ˆæ›´æ–°"""
        
        successful_results = [r for r in results if r.success]
        self.statistics["success_rate"] = len(successful_results) / len(results) if results else 0.0
        
        # çµ±è¨ˆä¿å­˜
        try:
            stats_data = {
                "timestamp": datetime.datetime.now().isoformat(),
                "statistics": self.statistics,
                "pattern_matcher_stats": self.pattern_matcher.statistics
            }
            
            with open(self.statistics_path, 'w', encoding='utf-8') as f:
                json.dump(stats_data, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            print(f"âš ï¸ çµ±è¨ˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_correction_summary(self) -> Dict[str, Any]:
        """ä¿®æ­£ã‚µãƒãƒªãƒ¼å–å¾—"""
        
        return {
            "timestamp": datetime.datetime.now().isoformat(),
            "statistics": self.statistics,
            "pattern_matcher_stats": self.pattern_matcher.statistics,
            "gemini_available": self.gemini_integration is not None,
            "data_files": {
                "suggestions": self.suggestions_path.exists(),
                "results": self.results_path.exists(),
                "statistics": self.statistics_path.exists()
            }
        }

def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸ§ª AutoCorrectionEngine ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    engine = AutoCorrectionEngine()
    
    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«è§£æ
    test_file = "kumihan_formatter/core/utilities/logger.py"
    if os.path.exists(test_file):
        print(f"ğŸ” ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«è§£æ: {test_file}")
        
        suggestions = engine.analyze_file(test_file)
        
        if suggestions:
            print(f"ğŸ“‹ ä¿®æ­£ææ¡ˆ: {len(suggestions)}ä»¶")
            
            for suggestion in suggestions[:3]:  # æœ€åˆã®3ä»¶è¡¨ç¤º
                print(f"  - {suggestion.correction_type.value}: {suggestion.explanation}")
            
            # ä¿®æ­£é©ç”¨ãƒ†ã‚¹ãƒˆï¼ˆæ‰‹å‹•ã‚¬ã‚¤ãƒ‰ã®ã¿ï¼‰
            print("\nğŸ”§ ä¿®æ­£é©ç”¨ãƒ†ã‚¹ãƒˆ...")
            results = engine.apply_corrections(suggestions[:1], auto_apply=False, use_gemini=False)
            
            print(f"ğŸ“Š é©ç”¨çµæœ: {len([r for r in results if r.success])}ä»¶æˆåŠŸ")
        else:
            print("ğŸ“‹ ä¿®æ­£ææ¡ˆãªã—")
    else:
        print(f"âš ï¸ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_file}")
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    summary = engine.get_correction_summary()
    print(f"\nğŸ“Š AutoCorrectionEngine ã‚µãƒãƒªãƒ¼:")
    print(f"   ç·ææ¡ˆæ•°: {summary['statistics']['total_suggestions']}")
    print(f"   æˆåŠŸç‡: {summary['statistics']['success_rate']:.1%}")
    print(f"   Geminiåˆ©ç”¨å¯èƒ½: {summary['gemini_available']}")
    
    print("âœ… AutoCorrectionEngine ãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    main()