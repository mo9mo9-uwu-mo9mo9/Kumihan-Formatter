#!/usr/bin/env python3
"""
QualityLearningSystem
å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ãƒ»è“„ç©ã‚·ã‚¹ãƒ†ãƒ  - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰å“è³ªåŸºæº–é€²åŒ–ãƒ»å“è³ªäºˆæ¸¬ãƒ»äº‹å‰æ”¹å–„ææ¡ˆ
æ©Ÿæ¢°å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®å“è³ªå‘ä¸Šãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ãƒ»è‡ªå‹•åŸºæº–èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import json
import pickle
import datetime
import time
import math
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, asdict
from enum import Enum
import collections

class LearningCategory(Enum):
    """å­¦ç¿’ã‚«ãƒ†ã‚´ãƒª"""
    QUALITY_PATTERNS = "quality_patterns"       # å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³
    ERROR_PATTERNS = "error_patterns"           # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³
    IMPROVEMENT_PATTERNS = "improvement_patterns" # æ”¹å–„ãƒ‘ã‚¿ãƒ¼ãƒ³
    PROJECT_STANDARDS = "project_standards"     # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºæº–
    DEVELOPER_PATTERNS = "developer_patterns"  # é–‹ç™ºè€…ãƒ‘ã‚¿ãƒ¼ãƒ³

class LearningConfidence(Enum):
    """å­¦ç¿’ä¿¡é ¼åº¦"""
    HIGH = "high"        # é«˜ï¼ˆååˆ†ãªãƒ‡ãƒ¼ã‚¿ï¼‰
    MEDIUM = "medium"    # ä¸­ï¼ˆã‚ã‚‹ç¨‹åº¦ã®ãƒ‡ãƒ¼ã‚¿ï¼‰
    LOW = "low"          # ä½ï¼ˆé™å®šçš„ãªãƒ‡ãƒ¼ã‚¿ï¼‰
    LEARNING = "learning" # å­¦ç¿’ä¸­

@dataclass
class QualityPattern:
    """å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³"""
    pattern_id: str
    category: LearningCategory
    pattern_type: str
    description: str
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿
    code_patterns: List[str]
    quality_indicators: Dict[str, float]
    success_conditions: Dict[str, Any]
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
    occurrence_count: int
    success_rate: float
    confidence: LearningConfidence
    
    # çµ±è¨ˆ
    first_seen: str
    last_updated: str
    effectiveness_score: float

@dataclass
class LearningEvent:
    """å­¦ç¿’ã‚¤ãƒ™ãƒ³ãƒˆ"""
    event_id: str
    timestamp: str
    category: LearningCategory
    
    # å“è³ªãƒ‡ãƒ¼ã‚¿
    before_metrics: Dict[str, float]
    after_metrics: Dict[str, float]
    improvement: float
    
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    file_path: str
    change_type: str
    ai_agent: str
    
    # å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿
    code_before: Optional[str] = None
    code_after: Optional[str] = None
    correction_applied: Optional[str] = None

@dataclass
class ProjectStandard:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰å“è³ªåŸºæº–"""
    standard_id: str
    name: str
    description: str
    
    # åŸºæº–å€¤
    thresholds: Dict[str, float]
    weights: Dict[str, float]
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
    adaptation_count: int
    effectiveness: float
    last_updated: str
    
    # é©ç”¨æ¡ä»¶
    applicable_files: List[str]
    applicable_phases: List[str]

class PatternMatcher:
    """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ãƒ»å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.patterns: Dict[str, QualityPattern] = {}
        self.pattern_stats = {
            "total_patterns": 0,
            "successful_matches": 0,
            "learning_accuracy": 0.0
        }
    
    def learn_from_quality_data(self, learning_event: LearningEvent) -> None:
        """å“è³ªãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®å­¦ç¿’"""
        
        print(f"ğŸ“š ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’: {learning_event.category.value}")
        
        # æ”¹å–„ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
        if learning_event.improvement > 0.1:  # 10%ä»¥ä¸Šã®æ”¹å–„
            self._extract_improvement_pattern(learning_event)
        
        # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
        if learning_event.improvement < -0.05:  # 5%ä»¥ä¸Šã®åŠ£åŒ–
            self._extract_error_pattern(learning_event)
        
        # ã‚³ãƒ¼ãƒ‰å¤‰æ›´ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
        if learning_event.code_before and learning_event.code_after:
            self._learn_code_change_pattern(learning_event)
    
    def _extract_improvement_pattern(self, event: LearningEvent) -> None:
        """æ”¹å–„ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º"""
        
        pattern_id = f"improve_{event.change_type}_{hash(event.file_path) % 1000}"
        
        if pattern_id in self.patterns:
            # æ—¢å­˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ›´æ–°
            pattern = self.patterns[pattern_id]
            pattern.occurrence_count += 1
            pattern.effectiveness_score = (
                pattern.effectiveness_score * (pattern.occurrence_count - 1) + event.improvement
            ) / pattern.occurrence_count
            pattern.last_updated = event.timestamp
            
            # ä¿¡é ¼åº¦æ›´æ–°
            if pattern.occurrence_count >= 10:
                pattern.confidence = LearningConfidence.HIGH
            elif pattern.occurrence_count >= 5:
                pattern.confidence = LearningConfidence.MEDIUM
            else:
                pattern.confidence = LearningConfidence.LOW
                
        else:
            # æ–°ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä½œæˆ
            pattern = QualityPattern(
                pattern_id=pattern_id,
                category=LearningCategory.IMPROVEMENT_PATTERNS,
                pattern_type=event.change_type,
                description=f"æ”¹å–„ãƒ‘ã‚¿ãƒ¼ãƒ³: {event.change_type}",
                code_patterns=[],
                quality_indicators=event.after_metrics,
                success_conditions={"min_improvement": 0.1},
                occurrence_count=1,
                success_rate=1.0,
                confidence=LearningConfidence.LEARNING,
                first_seen=event.timestamp,
                last_updated=event.timestamp,
                effectiveness_score=event.improvement
            )
            
            self.patterns[pattern_id] = pattern
            self.pattern_stats["total_patterns"] += 1
        
        print(f"   âœ… æ”¹å–„ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’å®Œäº†: {pattern_id} (åŠ¹æœ: {event.improvement:.3f})")
    
    def _extract_error_pattern(self, event: LearningEvent) -> None:
        """ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º"""
        
        pattern_id = f"error_{event.change_type}_{hash(event.file_path) % 1000}"
        
        if pattern_id in self.patterns:
            pattern = self.patterns[pattern_id]
            pattern.occurrence_count += 1
            pattern.last_updated = event.timestamp
        else:
            pattern = QualityPattern(
                pattern_id=pattern_id,
                category=LearningCategory.ERROR_PATTERNS,
                pattern_type=event.change_type,
                description=f"ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³: {event.change_type}",
                code_patterns=[],
                quality_indicators=event.before_metrics,
                success_conditions={"avoid_degradation": True},
                occurrence_count=1,
                success_rate=0.0,
                confidence=LearningConfidence.LEARNING,
                first_seen=event.timestamp,
                last_updated=event.timestamp,
                effectiveness_score=abs(event.improvement)
            )
            
            self.patterns[pattern_id] = pattern
        
        print(f"   âš ï¸ ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’: {pattern_id} (åŠ£åŒ–: {abs(event.improvement):.3f})")
    
    def _learn_code_change_pattern(self, event: LearningEvent) -> None:
        """ã‚³ãƒ¼ãƒ‰å¤‰æ›´ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’"""
        
        # ç°¡å˜ãªå·®åˆ†ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
        try:
            before_lines = event.code_before.split('\n')
            after_lines = event.code_after.split('\n')
            
            # å¤‰æ›´ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
            change_patterns = []
            for i, (before, after) in enumerate(zip(before_lines, after_lines)):
                if before.strip() != after.strip():
                    change_patterns.append({
                        "before": before.strip(),
                        "after": after.strip(),
                        "line": i + 1
                    })
            
            if change_patterns:
                pattern_id = f"code_change_{event.change_type}_{len(change_patterns)}"
                
                if pattern_id in self.patterns:
                    pattern = self.patterns[pattern_id]
                    pattern.occurrence_count += 1
                    # æˆåŠŸç‡æ›´æ–°
                    if event.improvement > 0:
                        pattern.success_rate = (
                            pattern.success_rate * (pattern.occurrence_count - 1) + 1
                        ) / pattern.occurrence_count
                    else:
                        pattern.success_rate = (
                            pattern.success_rate * (pattern.occurrence_count - 1)
                        ) / pattern.occurrence_count
                else:
                    pattern = QualityPattern(
                        pattern_id=pattern_id,
                        category=LearningCategory.QUALITY_PATTERNS,
                        pattern_type="code_change",
                        description=f"ã‚³ãƒ¼ãƒ‰å¤‰æ›´ãƒ‘ã‚¿ãƒ¼ãƒ³: {event.change_type}",
                        code_patterns=[json.dumps(change_patterns)],
                        quality_indicators=event.after_metrics,
                        success_conditions={"improvement_required": True},
                        occurrence_count=1,
                        success_rate=1.0 if event.improvement > 0 else 0.0,
                        confidence=LearningConfidence.LEARNING,
                        first_seen=event.timestamp,
                        last_updated=event.timestamp,
                        effectiveness_score=event.improvement
                    )
                    
                    self.patterns[pattern_id] = pattern
                
        except Exception as e:
            print(f"âš ï¸ ã‚³ãƒ¼ãƒ‰å¤‰æ›´ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
    
    def predict_quality_improvement(self, file_path: str, change_type: str) -> Dict[str, Any]:
        """å“è³ªæ”¹å–„äºˆæ¸¬"""
        
        # é–¢é€£ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œç´¢
        relevant_patterns = []
        for pattern in self.patterns.values():
            if (pattern.pattern_type == change_type and 
                pattern.category in [LearningCategory.IMPROVEMENT_PATTERNS, LearningCategory.QUALITY_PATTERNS]):
                relevant_patterns.append(pattern)
        
        if not relevant_patterns:
            return {
                "predicted_improvement": 0.0,
                "confidence": "low",
                "recommendations": ["ååˆ†ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"]
            }
        
        # äºˆæ¸¬è¨ˆç®—
        total_weight = 0
        weighted_improvement = 0
        
        for pattern in relevant_patterns:
            # ä¿¡é ¼åº¦ã«ã‚ˆã‚‹é‡ã¿
            confidence_weights = {
                LearningConfidence.HIGH: 1.0,
                LearningConfidence.MEDIUM: 0.7,
                LearningConfidence.LOW: 0.4,
                LearningConfidence.LEARNING: 0.2
            }
            
            weight = confidence_weights.get(pattern.confidence, 0.2) * pattern.occurrence_count
            weighted_improvement += pattern.effectiveness_score * weight
            total_weight += weight
        
        predicted_improvement = weighted_improvement / total_weight if total_weight > 0 else 0.0
        
        # ä¿¡é ¼åº¦è©•ä¾¡
        confidence = "high" if total_weight > 10 else "medium" if total_weight > 5 else "low"
        
        # æ¨å¥¨äº‹é …ç”Ÿæˆ
        recommendations = self._generate_improvement_recommendations(relevant_patterns)
        
        return {
            "predicted_improvement": predicted_improvement,
            "confidence": confidence,
            "supporting_patterns": len(relevant_patterns),
            "recommendations": recommendations
        }
    
    def _generate_improvement_recommendations(self, patterns: List[QualityPattern]) -> List[str]:
        """æ”¹å–„æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        
        recommendations = []
        
        # é«˜åŠ¹æœãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¨å¥¨
        high_effect_patterns = [p for p in patterns if p.effectiveness_score > 0.2]
        if high_effect_patterns:
            best_pattern = max(high_effect_patterns, key=lambda p: p.effectiveness_score)
            recommendations.append(f"é«˜åŠ¹æœãƒ‘ã‚¿ãƒ¼ãƒ³ '{best_pattern.pattern_type}' ã®é©ç”¨ã‚’æ¨å¥¨ã—ã¾ã™")
        
        # é«˜ä¿¡é ¼åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¨å¥¨
        high_confidence_patterns = [p for p in patterns if p.confidence == LearningConfidence.HIGH]
        if high_confidence_patterns:
            recommendations.append(f"å®Ÿç¸¾ã®ã‚ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ{len(high_confidence_patterns)}ä»¶ï¼‰ã‚’æ´»ç”¨ã—ã¦ãã ã•ã„")
        
        # æˆåŠŸç‡ã«ã‚ˆã‚‹æ¨å¥¨
        high_success_patterns = [p for p in patterns if p.success_rate > 0.8]
        if high_success_patterns:
            recommendations.append(f"æˆåŠŸç‡ã®é«˜ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆ{len(high_success_patterns)}ä»¶ï¼‰ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        return recommendations

class ProjectStandardsEvolver:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰å“è³ªåŸºæº–é€²åŒ–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.standards: Dict[str, ProjectStandard] = {}
        self.evolution_history: List[Dict[str, Any]] = []
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåŸºæº–ã‚’åˆæœŸåŒ–
        self._initialize_default_standards()
    
    def _initialize_default_standards(self) -> None:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå“è³ªåŸºæº–åˆæœŸåŒ–"""
        
        # åŸºæœ¬å“è³ªåŸºæº–
        basic_standard = ProjectStandard(
            standard_id="basic_quality",
            name="åŸºæœ¬å“è³ªåŸºæº–",
            description="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºæœ¬çš„ãªå“è³ªåŸºæº–",
            thresholds={
                "syntax": 0.95,
                "type_check": 0.8,
                "lint": 0.8,
                "format": 0.9,
                "security": 0.9,
                "performance": 0.7
            },
            weights={
                "syntax": 0.2,
                "type_check": 0.25,
                "lint": 0.2,
                "format": 0.1,
                "security": 0.15,
                "performance": 0.1
            },
            adaptation_count=0,
            effectiveness=0.8,
            last_updated=datetime.datetime.now().isoformat(),
            applicable_files=["*.py"],
            applicable_phases=["implementation", "integration"]
        )
        
        self.standards["basic_quality"] = basic_standard
    
    def evolve_standards(self, learning_events: List[LearningEvent]) -> Dict[str, Any]:
        """å“è³ªåŸºæº–é€²åŒ–"""
        
        print(f"ğŸ”„ å“è³ªåŸºæº–é€²åŒ–é–‹å§‹: {len(learning_events)}ã‚¤ãƒ™ãƒ³ãƒˆåˆ†æ")
        
        evolution_results = {}
        
        for standard_id, standard in self.standards.items():
            print(f"   ğŸ“Š åŸºæº–é€²åŒ–: {standard.name}")
            
            # é–¢é€£ã‚¤ãƒ™ãƒ³ãƒˆæŠ½å‡º
            relevant_events = self._filter_relevant_events(learning_events, standard)
            
            if len(relevant_events) < 3:
                print(f"   âš ï¸ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(relevant_events)}ä»¶")
                continue
            
            # åŸºæº–å€¤ã®æœ€é©åŒ–
            optimized_thresholds = self._optimize_thresholds(standard, relevant_events)
            optimized_weights = self._optimize_weights(standard, relevant_events)
            
            # åŠ¹æœè©•ä¾¡
            effectiveness = self._evaluate_effectiveness(standard, relevant_events)
            
            # åŸºæº–æ›´æ–°
            if effectiveness > standard.effectiveness:
                old_thresholds = standard.thresholds.copy()
                old_weights = standard.weights.copy()
                
                standard.thresholds = optimized_thresholds
                standard.weights = optimized_weights
                standard.effectiveness = effectiveness
                standard.adaptation_count += 1
                standard.last_updated = datetime.datetime.now().isoformat()
                
                evolution_results[standard_id] = {
                    "updated": True,
                    "old_effectiveness": standard.effectiveness,
                    "new_effectiveness": effectiveness,
                    "threshold_changes": self._calculate_changes(old_thresholds, optimized_thresholds),
                    "weight_changes": self._calculate_changes(old_weights, optimized_weights)
                }
                
                print(f"   âœ… åŸºæº–æ›´æ–°: åŠ¹æœ {standard.effectiveness:.3f} â†’ {effectiveness:.3f}")
            else:
                evolution_results[standard_id] = {
                    "updated": False,
                    "reason": "æ”¹å–„åŠ¹æœãªã—"
                }
                print(f"   ğŸ“‹ åŸºæº–ç¶­æŒ: ç¾åœ¨ã®åŠ¹æœ {effectiveness:.3f}")
        
        # é€²åŒ–å±¥æ­´è¨˜éŒ²
        self.evolution_history.append({
            "timestamp": datetime.datetime.now().isoformat(),
            "events_analyzed": len(learning_events),
            "standards_updated": len([r for r in evolution_results.values() if r.get("updated")]),
            "results": evolution_results
        })
        
        return evolution_results
    
    def _filter_relevant_events(self, events: List[LearningEvent], standard: ProjectStandard) -> List[LearningEvent]:
        """é–¢é€£ã‚¤ãƒ™ãƒ³ãƒˆæŠ½å‡º"""
        
        relevant_events = []
        
        for event in events:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ãƒã‚§ãƒƒã‚¯
            file_matches = any(
                event.file_path.endswith(pattern.replace("*", ""))
                for pattern in standard.applicable_files
            )
            
            if file_matches:
                relevant_events.append(event)
        
        return relevant_events
    
    def _optimize_thresholds(self, standard: ProjectStandard, events: List[LearningEvent]) -> Dict[str, float]:
        """é–¾å€¤æœ€é©åŒ–"""
        
        optimized = standard.thresholds.copy()
        
        # å„å“è³ªæŒ‡æ¨™ã®æˆåŠŸç‡åˆ†æ
        for metric_name in standard.thresholds.keys():
            metric_values = []
            improvements = []
            
            for event in events:
                if metric_name in event.after_metrics:
                    metric_values.append(event.after_metrics[metric_name])
                    improvements.append(event.improvement)
            
            if len(metric_values) < 2:
                continue
            
            # æ”¹å–„ã¨ã®ç›¸é–¢ã‹ã‚‰æœ€é©é–¾å€¤ã‚’æ¨å®š
            correlation = self._calculate_correlation(metric_values, improvements)
            
            if correlation > 0.3:  # æ­£ã®ç›¸é–¢ãŒã‚ã‚‹å ´åˆ
                # æˆåŠŸä¾‹ã®å¹³å‡å€¤ã‚’åŸºæº–ã«è¨­å®š
                successful_values = [
                    v for v, i in zip(metric_values, improvements) if i > 0
                ]
                if successful_values:
                    avg_successful = sum(successful_values) / len(successful_values)
                    # ç¾åœ¨å€¤ã¨ã®é‡ã¿ä»˜ãå¹³å‡ã§èª¿æ•´
                    optimized[metric_name] = (
                        standard.thresholds[metric_name] * 0.7 + avg_successful * 0.3
                    )
        
        return optimized
    
    def _optimize_weights(self, standard: ProjectStandard, events: List[LearningEvent]) -> Dict[str, float]:
        """é‡ã¿æœ€é©åŒ–"""
        
        # å„å“è³ªæŒ‡æ¨™ã®æ”¹å–„ã¸ã®å½±éŸ¿åº¦åˆ†æ
        influences = {}
        
        for metric_name in standard.weights.keys():
            metric_changes = []
            improvements = []
            
            for event in events:
                if (metric_name in event.before_metrics and 
                    metric_name in event.after_metrics):
                    change = event.after_metrics[metric_name] - event.before_metrics[metric_name]
                    metric_changes.append(change)
                    improvements.append(event.improvement)
            
            if len(metric_changes) >= 2:
                # å¤‰åŒ–é‡ã¨æ”¹å–„ã®ç›¸é–¢ã‹ã‚‰å½±éŸ¿åº¦è¨ˆç®—
                correlation = self._calculate_correlation(metric_changes, improvements)
                influences[metric_name] = max(0, correlation)
        
        # é‡ã¿ã®æ­£è¦åŒ–
        if influences:
            total_influence = sum(influences.values())
            if total_influence > 0:
                optimized_weights = {}
                for metric_name in standard.weights.keys():
                    influence = influences.get(metric_name, 0.1)
                    # ç¾åœ¨ã®é‡ã¿ã¨ã®é‡ã¿ä»˜ãå¹³å‡
                    new_weight = standard.weights[metric_name] * 0.8 + (influence / total_influence) * 0.2
                    optimized_weights[metric_name] = new_weight
                
                return optimized_weights
        
        return standard.weights.copy()
    
    def _evaluate_effectiveness(self, standard: ProjectStandard, events: List[LearningEvent]) -> float:
        """åŠ¹æœè©•ä¾¡"""
        
        if not events:
            return standard.effectiveness
        
        # å¹³å‡æ”¹å–„ç‡ã‚’åŠ¹æœã¨ã—ã¦è©•ä¾¡
        improvements = [event.improvement for event in events]
        avg_improvement = sum(improvements) / len(improvements)
        
        # æˆåŠŸç‡ã‚‚è€ƒæ…®
        successful_events = len([i for i in improvements if i > 0])
        success_rate = successful_events / len(improvements)
        
        # ç·åˆåŠ¹æœã‚¹ã‚³ã‚¢
        effectiveness = (avg_improvement + success_rate) / 2
        
        return max(0.0, min(1.0, effectiveness))
    
    def _calculate_correlation(self, x_values: List[float], y_values: List[float]) -> float:
        """ç›¸é–¢ä¿‚æ•°è¨ˆç®—"""
        
        if len(x_values) != len(y_values) or len(x_values) < 2:
            return 0.0
        
        n = len(x_values)
        x_mean = sum(x_values) / n
        y_mean = sum(y_values) / n
        
        numerator = sum((x - x_mean) * (y - y_mean) for x, y in zip(x_values, y_values))
        x_variance = sum((x - x_mean) ** 2 for x in x_values)
        y_variance = sum((y - y_mean) ** 2 for y in y_values)
        
        denominator = math.sqrt(x_variance * y_variance)
        
        if denominator == 0:
            return 0.0
        
        return numerator / denominator
    
    def _calculate_changes(self, old_values: Dict[str, float], new_values: Dict[str, float]) -> Dict[str, float]:
        """å¤‰æ›´é‡è¨ˆç®—"""
        
        changes = {}
        for key in old_values.keys():
            if key in new_values:
                changes[key] = new_values[key] - old_values[key]
        
        return changes
    
    def get_project_standards(self, file_path: str, phase: str) -> Optional[ProjectStandard]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºæº–å–å¾—"""
        
        for standard in self.standards.values():
            # ãƒ•ã‚¡ã‚¤ãƒ«é©ç”¨ãƒã‚§ãƒƒã‚¯
            file_matches = any(
                file_path.endswith(pattern.replace("*", ""))
                for pattern in standard.applicable_files
            )
            
            # ãƒ•ã‚§ãƒ¼ã‚ºé©ç”¨ãƒã‚§ãƒƒã‚¯
            phase_matches = phase in standard.applicable_phases
            
            if file_matches and phase_matches:
                return standard
        
        return None

class QualityLearningSystem:
    """å“è³ªå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ çµ±åˆç®¡ç†"""
    
    def __init__(self):
        self.pattern_matcher = PatternMatcher()
        self.standards_evolver = ProjectStandardsEvolver()
        
        self.data_dir = Path("postbox/quality/learning")
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        self.learning_events_path = self.data_dir / "learning_events.json"
        self.patterns_path = self.data_dir / "patterns.json"
        self.standards_path = self.data_dir / "standards.json"
        self.predictions_path = self.data_dir / "predictions.json"
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        self._load_learning_data()
        
        print("ğŸ“š QualityLearningSystem åˆæœŸåŒ–å®Œäº†")
    
    def learn_from_quality_change(self, file_path: str, change_type: str,
                                before_metrics: Dict[str, float], after_metrics: Dict[str, float],
                                ai_agent: str = "unknown", code_before: Optional[str] = None,
                                code_after: Optional[str] = None, correction_applied: Optional[str] = None) -> str:
        """å“è³ªå¤‰åŒ–ã‹ã‚‰ã®å­¦ç¿’"""
        
        improvement = self._calculate_improvement(before_metrics, after_metrics)
        
        # å­¦ç¿’ã‚¤ãƒ™ãƒ³ãƒˆä½œæˆ
        event = LearningEvent(
            event_id=f"learn_{int(time.time() * 1000)}",
            timestamp=datetime.datetime.now().isoformat(),
            category=LearningCategory.QUALITY_PATTERNS,
            before_metrics=before_metrics,
            after_metrics=after_metrics,
            improvement=improvement,
            file_path=file_path,
            change_type=change_type,
            ai_agent=ai_agent,
            code_before=code_before,
            code_after=code_after,
            correction_applied=correction_applied
        )
        
        print(f"ğŸ“š å“è³ªå­¦ç¿’é–‹å§‹: {file_path} ({change_type}) - æ”¹å–„: {improvement:.3f}")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
        self.pattern_matcher.learn_from_quality_data(event)
        
        # å­¦ç¿’ã‚¤ãƒ™ãƒ³ãƒˆä¿å­˜
        self._save_learning_event(event)
        
        # å®šæœŸçš„ãªåŸºæº–é€²åŒ–ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆæ•°ãŒä¸€å®šæ•°ã«é”ã—ãŸå ´åˆï¼‰
        if self._should_evolve_standards():
            self._trigger_standards_evolution()
        
        print(f"âœ… å­¦ç¿’å®Œäº†: {event.event_id}")
        
        return event.event_id
    
    def predict_quality_impact(self, file_path: str, change_type: str, 
                             current_metrics: Optional[Dict[str, float]] = None) -> Dict[str, Any]:
        """å“è³ªå½±éŸ¿äºˆæ¸¬"""
        
        print(f"ğŸ”® å“è³ªå½±éŸ¿äºˆæ¸¬: {file_path} ({change_type})")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹äºˆæ¸¬
        pattern_prediction = self.pattern_matcher.predict_quality_improvement(file_path, change_type)
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºæº–ãƒ™ãƒ¼ã‚¹äºˆæ¸¬
        standards_prediction = self._predict_from_standards(file_path, change_type, current_metrics)
        
        # çµ±åˆäºˆæ¸¬
        combined_prediction = self._combine_predictions(pattern_prediction, standards_prediction)
        
        # äºˆæ¸¬çµæœä¿å­˜
        self._save_prediction(file_path, change_type, combined_prediction)
        
        return combined_prediction
    
    def get_adaptive_quality_standards(self, file_path: str, phase: str = "implementation") -> Dict[str, Any]:
        """é©å¿œçš„å“è³ªåŸºæº–å–å¾—"""
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰åŸºæº–å–å¾—
        project_standard = self.standards_evolver.get_project_standards(file_path, phase)
        
        if project_standard:
            return {
                "standard_id": project_standard.standard_id,
                "name": project_standard.name,
                "thresholds": project_standard.thresholds,
                "weights": project_standard.weights,
                "effectiveness": project_standard.effectiveness,
                "adaptation_count": project_standard.adaptation_count,
                "last_updated": project_standard.last_updated,
                "is_adaptive": True
            }
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåŸºæº–
            return {
                "standard_id": "default",
                "name": "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå“è³ªåŸºæº–",
                "thresholds": {
                    "syntax": 0.95, "type_check": 0.8, "lint": 0.8,
                    "format": 0.9, "security": 0.9, "performance": 0.7
                },
                "weights": {
                    "syntax": 0.2, "type_check": 0.25, "lint": 0.2,
                    "format": 0.1, "security": 0.15, "performance": 0.1
                },
                "effectiveness": 0.7,
                "adaptation_count": 0,
                "last_updated": datetime.datetime.now().isoformat(),
                "is_adaptive": False
            }
    
    def generate_improvement_recommendations(self, file_path: str, 
                                           current_metrics: Dict[str, float]) -> List[Dict[str, Any]]:
        """æ”¹å–„æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        
        recommendations = []
        
        # ç¾åœ¨ã®å“è³ªåŸºæº–å–å¾—
        standards = self.get_adaptive_quality_standards(file_path)
        
        # åŸºæº–æœªé”æˆé …ç›®ã®ç‰¹å®š
        underperforming_metrics = []
        for metric, threshold in standards["thresholds"].items():
            if metric in current_metrics and current_metrics[metric] < threshold:
                underperforming_metrics.append({
                    "metric": metric,
                    "current": current_metrics[metric],
                    "threshold": threshold,
                    "gap": threshold - current_metrics[metric]
                })
        
        # å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨äº‹é …
        for metric_info in underperforming_metrics:
            metric = metric_info["metric"]
            
            # é–¢é€£ã™ã‚‹æ”¹å–„ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œç´¢
            relevant_patterns = [
                p for p in self.pattern_matcher.patterns.values()
                if (p.category == LearningCategory.IMPROVEMENT_PATTERNS and
                    metric in p.quality_indicators)
            ]
            
            if relevant_patterns:
                best_pattern = max(relevant_patterns, key=lambda p: p.effectiveness_score)
                
                recommendation = {
                    "metric": metric,
                    "current_score": metric_info["current"],
                    "target_score": metric_info["threshold"],
                    "recommended_action": f"{best_pattern.pattern_type}ã«ã‚ˆã‚‹æ”¹å–„",
                    "expected_improvement": best_pattern.effectiveness_score,
                    "confidence": best_pattern.confidence.value,
                    "pattern_id": best_pattern.pattern_id,
                    "evidence": f"{best_pattern.occurrence_count}å›ã®æˆåŠŸå®Ÿç¸¾"
                }
                
                recommendations.append(recommendation)
        
        # å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆ
        recommendations.sort(key=lambda r: r["expected_improvement"] * (r["target_score"] - r["current_score"]), reverse=True)
        
        return recommendations
    
    def _calculate_improvement(self, before: Dict[str, float], after: Dict[str, float]) -> float:
        """æ”¹å–„åº¦è¨ˆç®—"""
        
        common_metrics = set(before.keys()) & set(after.keys())
        if not common_metrics:
            return 0.0
        
        improvements = []
        for metric in common_metrics:
            if before[metric] > 0:  # ã‚¼ãƒ­é™¤ç®—å›é¿
                improvement = (after[metric] - before[metric]) / before[metric]
                improvements.append(improvement)
        
        return sum(improvements) / len(improvements) if improvements else 0.0
    
    def _should_evolve_standards(self) -> bool:
        """åŸºæº–é€²åŒ–ãƒˆãƒªã‚¬ãƒ¼åˆ¤å®š"""
        
        # å­¦ç¿’ã‚¤ãƒ™ãƒ³ãƒˆæ•°ãƒã‚§ãƒƒã‚¯
        try:
            if self.learning_events_path.exists():
                with open(self.learning_events_path, 'r', encoding='utf-8') as f:
                    events = json.load(f)
                return len(events) % 20 == 0  # 20ã‚¤ãƒ™ãƒ³ãƒˆã”ã¨ã«é€²åŒ–
        except:
            pass
        
        return False
    
    def _trigger_standards_evolution(self) -> None:
        """åŸºæº–é€²åŒ–å®Ÿè¡Œ"""
        
        print("ğŸ”„ å“è³ªåŸºæº–é€²åŒ–ãƒˆãƒªã‚¬ãƒ¼")
        
        try:
            # æœ€è¿‘ã®å­¦ç¿’ã‚¤ãƒ™ãƒ³ãƒˆå–å¾—
            recent_events = self._get_recent_learning_events()
            
            if len(recent_events) >= 5:
                # åŸºæº–é€²åŒ–å®Ÿè¡Œ
                evolution_results = self.standards_evolver.evolve_standards(recent_events)
                
                # é€²åŒ–çµæœä¿å­˜
                self._save_evolution_results(evolution_results)
                
                print(f"âœ… åŸºæº–é€²åŒ–å®Œäº†: {len(evolution_results)}åŸºæº–å‡¦ç†")
            else:
                print(f"âš ï¸ é€²åŒ–ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(recent_events)}ã‚¤ãƒ™ãƒ³ãƒˆ")
                
        except Exception as e:
            print(f"âŒ åŸºæº–é€²åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _predict_from_standards(self, file_path: str, change_type: str, 
                              current_metrics: Optional[Dict[str, float]]) -> Dict[str, Any]:
        """åŸºæº–ãƒ™ãƒ¼ã‚¹äºˆæ¸¬"""
        
        standards = self.get_adaptive_quality_standards(file_path)
        
        if not current_metrics:
            return {
                "predicted_improvement": 0.0,
                "confidence": "low",
                "recommendations": ["ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒä¸æ˜ã§ã™"]
            }
        
        # åŸºæº–ã¨ã®å·®åˆ†ã‹ã‚‰æ”¹å–„å¯èƒ½æ€§æ¨å®š
        potential_improvements = []
        for metric, threshold in standards["thresholds"].items():
            if metric in current_metrics:
                gap = threshold - current_metrics[metric]
                if gap > 0:
                    potential_improvements.append(gap)
        
        if potential_improvements:
            avg_potential = sum(potential_improvements) / len(potential_improvements)
            
            return {
                "predicted_improvement": min(avg_potential, 0.3),  # æœ€å¤§30%æ”¹å–„
                "confidence": "medium",
                "recommendations": [f"åŸºæº–æœªé”æˆé …ç›®ï¼ˆ{len(potential_improvements)}ä»¶ï¼‰ã®æ”¹å–„ã‚’æ¨å¥¨"]
            }
        else:
            return {
                "predicted_improvement": 0.05,  # å¾®å°æ”¹å–„
                "confidence": "high",
                "recommendations": ["ç¾åœ¨ã®å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã™"]
            }
    
    def _combine_predictions(self, pattern_pred: Dict[str, Any], 
                           standards_pred: Dict[str, Any]) -> Dict[str, Any]:
        """äºˆæ¸¬çµæœçµ±åˆ"""
        
        # é‡ã¿ä»˜ãå¹³å‡ã§çµ±åˆ
        pattern_weight = 0.7 if pattern_pred["confidence"] == "high" else 0.5
        standards_weight = 1.0 - pattern_weight
        
        combined_improvement = (
            pattern_pred["predicted_improvement"] * pattern_weight +
            standards_pred["predicted_improvement"] * standards_weight
        )
        
        # ä¿¡é ¼åº¦çµ±åˆ
        confidences = [pattern_pred["confidence"], standards_pred["confidence"]]
        if "high" in confidences:
            combined_confidence = "high"
        elif "medium" in confidences:
            combined_confidence = "medium"
        else:
            combined_confidence = "low"
        
        # æ¨å¥¨äº‹é …çµ±åˆ
        combined_recommendations = (
            pattern_pred["recommendations"] + standards_pred["recommendations"]
        )
        
        return {
            "predicted_improvement": combined_improvement,
            "confidence": combined_confidence,
            "recommendations": combined_recommendations,
            "pattern_contribution": pattern_weight,
            "standards_contribution": standards_weight,
            "timestamp": datetime.datetime.now().isoformat()
        }
    
    def _save_learning_event(self, event: LearningEvent) -> None:
        """å­¦ç¿’ã‚¤ãƒ™ãƒ³ãƒˆä¿å­˜"""
        
        try:
            events = []
            if self.learning_events_path.exists():
                with open(self.learning_events_path, 'r', encoding='utf-8') as f:
                    events = json.load(f)
            
            events.append(asdict(event))
            
            # ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆæœ€æ–°1000ä»¶ï¼‰
            if len(events) > 1000:
                events = events[-1000:]
            
            with open(self.learning_events_path, 'w', encoding='utf-8') as f:
                json.dump(events, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            print(f"âš ï¸ å­¦ç¿’ã‚¤ãƒ™ãƒ³ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_prediction(self, file_path: str, change_type: str, prediction: Dict[str, Any]) -> None:
        """äºˆæ¸¬çµæœä¿å­˜"""
        
        try:
            predictions = []
            if self.predictions_path.exists():
                with open(self.predictions_path, 'r', encoding='utf-8') as f:
                    predictions = json.load(f)
            
            prediction_entry = {
                "file_path": file_path,
                "change_type": change_type,
                "prediction": prediction,
                "timestamp": datetime.datetime.now().isoformat()
            }
            
            predictions.append(prediction_entry)
            
            # ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆæœ€æ–°500ä»¶ï¼‰
            if len(predictions) > 500:
                predictions = predictions[-500:]
            
            with open(self.predictions_path, 'w', encoding='utf-8') as f:
                json.dump(predictions, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            print(f"âš ï¸ äºˆæ¸¬çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _get_recent_learning_events(self) -> List[LearningEvent]:
        """æœ€è¿‘ã®å­¦ç¿’ã‚¤ãƒ™ãƒ³ãƒˆå–å¾—"""
        
        try:
            if self.learning_events_path.exists():
                with open(self.learning_events_path, 'r', encoding='utf-8') as f:
                    events_data = json.load(f)
                
                # æœ€æ–°20ä»¶ã‚’å–å¾—
                recent_data = events_data[-20:]
                
                # LearningEventã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
                events = []
                for data in recent_data:
                    event = LearningEvent(
                        event_id=data["event_id"],
                        timestamp=data["timestamp"],
                        category=LearningCategory(data["category"]),
                        before_metrics=data["before_metrics"],
                        after_metrics=data["after_metrics"],
                        improvement=data["improvement"],
                        file_path=data["file_path"],
                        change_type=data["change_type"],
                        ai_agent=data["ai_agent"],
                        code_before=data.get("code_before"),
                        code_after=data.get("code_after"),
                        correction_applied=data.get("correction_applied")
                    )
                    events.append(event)
                
                return events
        except Exception as e:
            print(f"âš ï¸ å­¦ç¿’ã‚¤ãƒ™ãƒ³ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        return []
    
    def _save_evolution_results(self, results: Dict[str, Any]) -> None:
        """é€²åŒ–çµæœä¿å­˜"""
        
        evolution_path = self.data_dir / "evolution_history.json"
        
        try:
            history = []
            if evolution_path.exists():
                with open(evolution_path, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            
            history.append({
                "timestamp": datetime.datetime.now().isoformat(),
                "results": results
            })
            
            # ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆæœ€æ–°100ä»¶ï¼‰
            if len(history) > 100:
                history = history[-100:]
            
            with open(evolution_path, 'w', encoding='utf-8') as f:
                json.dump(history, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            print(f"âš ï¸ é€²åŒ–çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _load_learning_data(self) -> None:
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        
        try:
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            if self.patterns_path.exists():
                with open(self.patterns_path, 'r', encoding='utf-8') as f:
                    patterns_data = json.load(f)
                # TODO: QualityPatternã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
                print("ğŸ“‹ å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³èª­ã¿è¾¼ã¿å®Œäº†")
            
            # åŸºæº–ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            if self.standards_path.exists():
                with open(self.standards_path, 'r', encoding='utf-8') as f:
                    standards_data = json.load(f)
                # TODO: ProjectStandardã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
                print("ğŸ“‹ å“è³ªåŸºæº–èª­ã¿è¾¼ã¿å®Œäº†")
                
        except Exception as e:
            print(f"âš ï¸ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_learning_summary(self) -> Dict[str, Any]:
        """å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã‚µãƒãƒªãƒ¼å–å¾—"""
        
        return {
            "patterns": {
                "total": len(self.pattern_matcher.patterns),
                "by_category": {
                    category.value: len([
                        p for p in self.pattern_matcher.patterns.values() 
                        if p.category == category
                    ])
                    for category in LearningCategory
                },
                "statistics": self.pattern_matcher.pattern_stats
            },
            "standards": {
                "total": len(self.standards_evolver.standards),
                "adaptation_counts": {
                    std_id: std.adaptation_count
                    for std_id, std in self.standards_evolver.standards.items()
                },
                "evolution_history": len(self.standards_evolver.evolution_history)
            },
            "learning_status": "active",
            "last_updated": datetime.datetime.now().isoformat()
        }

def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸ§ª QualityLearningSystem ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    learning_system = QualityLearningSystem()
    
    # å­¦ç¿’ãƒ†ã‚¹ãƒˆ
    print("\n=== å“è³ªå­¦ç¿’ãƒ†ã‚¹ãƒˆ ===")
    
    before_metrics = {"syntax": 0.8, "type_check": 0.7, "lint": 0.75}
    after_metrics = {"syntax": 0.95, "type_check": 0.85, "lint": 0.9}
    
    event_id = learning_system.learn_from_quality_change(
        file_path="test_file.py",
        change_type="type_annotation",
        before_metrics=before_metrics,
        after_metrics=after_metrics,
        ai_agent="test_agent"
    )
    
    print(f"âœ… å­¦ç¿’å®Œäº†: {event_id}")
    
    # äºˆæ¸¬ãƒ†ã‚¹ãƒˆ
    print("\n=== å“è³ªäºˆæ¸¬ãƒ†ã‚¹ãƒˆ ===")
    
    prediction = learning_system.predict_quality_impact(
        file_path="test_file.py",
        change_type="type_annotation",
        current_metrics={"syntax": 0.9, "type_check": 0.8}
    )
    
    print(f"ğŸ”® äºˆæ¸¬çµæœ:")
    print(f"   æ”¹å–„äºˆæ¸¬: {prediction['predicted_improvement']:.3f}")
    print(f"   ä¿¡é ¼åº¦: {prediction['confidence']}")
    
    # é©å¿œçš„åŸºæº–ãƒ†ã‚¹ãƒˆ
    print("\n=== é©å¿œçš„å“è³ªåŸºæº–ãƒ†ã‚¹ãƒˆ ===")
    
    standards = learning_system.get_adaptive_quality_standards("test_file.py")
    print(f"ğŸ“Š é©å¿œåŸºæº–: {standards['name']}")
    print(f"   åŠ¹æœ: {standards['effectiveness']:.3f}")
    print(f"   é©å¿œå›æ•°: {standards['adaptation_count']}")
    
    # æ¨å¥¨äº‹é …ãƒ†ã‚¹ãƒˆ
    print("\n=== æ”¹å–„æ¨å¥¨äº‹é …ãƒ†ã‚¹ãƒˆ ===")
    
    recommendations = learning_system.generate_improvement_recommendations(
        "test_file.py",
        {"syntax": 0.9, "type_check": 0.7, "lint": 0.8}
    )
    
    print(f"ğŸ’¡ æ¨å¥¨äº‹é …: {len(recommendations)}ä»¶")
    for rec in recommendations[:2]:
        print(f"   - {rec['metric']}: {rec['recommended_action']}")
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    summary = learning_system.get_learning_summary()
    print(f"\nğŸ“Š å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã‚µãƒãƒªãƒ¼:")
    print(f"   å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³: {summary['patterns']['total']}ä»¶")
    print(f"   å“è³ªåŸºæº–: {summary['standards']['total']}ä»¶")
    
    print("âœ… QualityLearningSystem ãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    main()