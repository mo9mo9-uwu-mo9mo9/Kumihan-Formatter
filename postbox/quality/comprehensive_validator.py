#!/usr/bin/env python3
"""
ComprehensiveQualityValidator
Áµ±ÂêàÂìÅË≥™Ê§úË®º„Ç∑„Çπ„ÉÜ„É† - „Çª„Ç≠„É•„É™„ÉÜ„Ç£„Éª„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„ÉªÁµ±Âêà„ÉÜ„Çπ„Éà„Éª‰ºÅÊ•≠„É¨„Éô„É´ÂìÅË≥™Âü∫Ê∫ñ
Ëá™Âãï„ÉÜ„Çπ„ÉàÁîüÊàê„ÉªÁµ±Âêà„ÉÜ„Çπ„ÉàÂÆüË°å„Éª„Çª„Ç≠„É•„É™„ÉÜ„Ç£Ê§úË®º„Éª„Éë„Éï„Ç©„Éº„Éû„É≥„ÇπË©ï‰æ°
"""

import os
import json
import time
import ast
import subprocess
import datetime
import tempfile
from typing import Dict, List, Any, Optional, Tuple, Union
from pathlib import Path
from dataclasses import dataclass, asdict
from enum import Enum
import concurrent.futures
import threading

class ValidationCategory(Enum):
    """Ê§úË®º„Ç´„ÉÜ„Ç¥„É™"""
    SECURITY = "security"          # „Çª„Ç≠„É•„É™„ÉÜ„Ç£Ê§úË®º
    PERFORMANCE = "performance"    # „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊ§úË®º
    INTEGRATION = "integration"    # Áµ±Âêà„ÉÜ„Çπ„Éà
    COMPLIANCE = "compliance"      # „Ç≥„É≥„Éó„É©„Ç§„Ç¢„É≥„ÇπÊ§úË®º
    RELIABILITY = "reliability"    # ‰ø°È†ºÊÄßÊ§úË®º
    SCALABILITY = "scalability"    # „Çπ„Ç±„Éº„É©„Éì„É™„ÉÜ„Ç£Ê§úË®º

class ValidationSeverity(Enum):
    """Ê§úË®ºÈáçË¶ÅÂ∫¶"""
    CRITICAL = "critical"   # ÈáçÂ§ß
    HIGH = "high"          # È´ò
    MEDIUM = "medium"      # ‰∏≠
    LOW = "low"           # ‰Ωé
    INFO = "info"         # ÊÉÖÂ†±

class ValidationStatus(Enum):
    """Ê§úË®º„Çπ„ÉÜ„Éº„Çø„Çπ"""
    PASSED = "passed"       # ÂêàÊ†º
    FAILED = "failed"       # ‰∏çÂêàÊ†º
    WARNING = "warning"     # Ë≠¶Âëä
    SKIPPED = "skipped"     # „Çπ„Ç≠„ÉÉ„Éó
    ERROR = "error"         # „Ç®„É©„Éº

@dataclass
class ValidationRule:
    """Ê§úË®º„É´„Éº„É´"""
    rule_id: str
    category: ValidationCategory
    severity: ValidationSeverity
    name: str
    description: str
    
    check_function: str  # ÂÆüË°å„Åô„ÇãÊ§úË®ºÈñ¢Êï∞Âêç
    parameters: Dict[str, Any]
    threshold: Optional[float] = None
    timeout_seconds: int = 60
    
    auto_fix_available: bool = False
    enterprise_required: bool = False

@dataclass
class ValidationResult:
    """Ê§úË®ºÁµêÊûú"""
    rule: ValidationRule
    status: ValidationStatus
    score: float
    execution_time: float
    
    details: Dict[str, Any]
    findings: List[str]
    recommendations: List[str]
    
    timestamp: str
    
    # „É°„Éà„É™„ÇØ„Çπ
    metrics: Optional[Dict[str, Any]] = None
    
    # ‰øÆÊ≠£ÊÉÖÂ†±
    auto_fix_applied: bool = False
    manual_action_required: bool = False

class SecurityValidator:
    """„Çª„Ç≠„É•„É™„ÉÜ„Ç£Ê§úË®º„Ç∑„Çπ„ÉÜ„É†"""
    
    def __init__(self):
        self.security_rules = self._load_security_rules()
        
    def _load_security_rules(self) -> List[ValidationRule]:
        """„Çª„Ç≠„É•„É™„ÉÜ„Ç£„É´„Éº„É´Ë™≠„ÅøËæº„Åø"""
        
        rules = [
            ValidationRule(
                rule_id="SEC001",
                category=ValidationCategory.SECURITY,
                severity=ValidationSeverity.CRITICAL,
                name="Âç±Èô∫„Å™Èñ¢Êï∞‰ΩøÁî®„ÉÅ„Çß„ÉÉ„ÇØ",
                description="eval, exec, subprocessÁ≠â„ÅÆÂç±Èô∫„Å™Èñ¢Êï∞„ÅÆ‰ΩøÁî®„ÇíÊ§úÂá∫",
                check_function="check_dangerous_functions",
                parameters={"patterns": [r"eval\s*\(", r"exec\s*\(", r"subprocess\.call.*shell=True"]},
                enterprise_required=True
            ),
            
            ValidationRule(
                rule_id="SEC002",
                category=ValidationCategory.SECURITY,
                severity=ValidationSeverity.HIGH,
                name="Ê©üÂØÜÊÉÖÂ†±„Éè„Éº„Éâ„Ç≥„Éº„Éá„Ç£„É≥„Ç∞",
                description="„Éë„Çπ„ÉØ„Éº„Éâ„ÄÅAPI„Ç≠„ÉºÁ≠â„ÅÆÊ©üÂØÜÊÉÖÂ†±„ÅÆ„Éè„Éº„Éâ„Ç≥„Éº„Éá„Ç£„É≥„Ç∞„ÇíÊ§úÂá∫",
                check_function="check_hardcoded_secrets",
                parameters={"patterns": [r"password\s*=\s*[\"']", r"api_key\s*=\s*[\"']", r"secret\s*=\s*[\"']"]},
                enterprise_required=True
            ),
            
            ValidationRule(
                rule_id="SEC003",
                category=ValidationCategory.SECURITY,
                severity=ValidationSeverity.MEDIUM,
                name="SQL„Ç§„É≥„Ç∏„Çß„ÇØ„Ç∑„Éß„É≥ËÑÜÂº±ÊÄß",
                description="SQL„Ç§„É≥„Ç∏„Çß„ÇØ„Ç∑„Éß„É≥ËÑÜÂº±ÊÄß„ÅÆÂèØËÉΩÊÄß„ÇíÊ§úÂá∫",
                check_function="check_sql_injection",
                parameters={"patterns": [r"execute\s*\(\s*[\"'].*%.*[\"']", r"query\s*\+\s*"]},
                enterprise_required=False
            ),
            
            ValidationRule(
                rule_id="SEC004",
                category=ValidationCategory.SECURITY,
                severity=ValidationSeverity.MEDIUM,
                name="ÊöóÂè∑ÂåñË®≠ÂÆöÊ§úË®º",
                description="ÈÅ©Âàá„Å™ÊöóÂè∑ÂåñË®≠ÂÆö„ÅÆ‰ΩøÁî®„ÇíÊ§úË®º",
                check_function="check_crypto_usage",
                parameters={"weak_algorithms": ["md5", "sha1", "des"]},
                enterprise_required=True
            )
        ]
        
        return rules
    
    def validate_security(self, file_paths: List[str]) -> List[ValidationResult]:
        """„Çª„Ç≠„É•„É™„ÉÜ„Ç£Ê§úË®ºÂÆüË°å"""
        
        results = []
        
        for rule in self.security_rules:
            print(f"üîí „Çª„Ç≠„É•„É™„ÉÜ„Ç£„ÉÅ„Çß„ÉÉ„ÇØ: {rule.name}")
            
            start_time = time.time()
            
            try:
                # Ê§úË®ºÈñ¢Êï∞ÂÆüË°å
                check_method = getattr(self, rule.check_function)
                findings = check_method(file_paths, rule.parameters)
                
                execution_time = time.time() - start_time
                
                # ÁµêÊûúÂà§ÂÆö
                if findings:
                    status = ValidationStatus.FAILED if rule.severity in [
                        ValidationSeverity.CRITICAL, ValidationSeverity.HIGH
                    ] else ValidationStatus.WARNING
                    score = 0.0 if status == ValidationStatus.FAILED else 0.5
                else:
                    status = ValidationStatus.PASSED
                    score = 1.0
                
                recommendations = self._generate_security_recommendations(rule, findings)
                
                result = ValidationResult(
                    rule=rule,
                    status=status,
                    score=score,
                    execution_time=execution_time,
                    details={"files_checked": len(file_paths)},
                    findings=findings,
                    recommendations=recommendations,
                    timestamp=datetime.datetime.now().isoformat(),
                    manual_action_required=len(findings) > 0
                )
                
                results.append(result)
                
            except Exception as e:
                execution_time = time.time() - start_time
                
                result = ValidationResult(
                    rule=rule,
                    status=ValidationStatus.ERROR,
                    score=0.0,
                    execution_time=execution_time,
                    details={"error": str(e)},
                    findings=[f"Ê§úË®º„Ç®„É©„Éº: {str(e)}"],
                    recommendations=["Ê§úË®º„Ç∑„Çπ„ÉÜ„É†„ÅÆÁ¢∫Ë™ç„ÅåÂøÖË¶Å„Åß„Åô"],
                    timestamp=datetime.datetime.now().isoformat()
                )
                
                results.append(result)
        
        return results
    
    def check_dangerous_functions(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """Âç±Èô∫„Å™Èñ¢Êï∞‰ΩøÁî®„ÉÅ„Çß„ÉÉ„ÇØ"""
        
        findings = []
        patterns = params.get("patterns", [])
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                for pattern in patterns:
                    matches = re.finditer(pattern, content)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        findings.append(f"{file_path}:{line_num} - Âç±Èô∫„Å™Èñ¢Êï∞‰ΩøÁî®: {match.group()}")
                        
            except Exception as e:
                findings.append(f"{file_path} - Ë™≠„ÅøËæº„Åø„Ç®„É©„Éº: {str(e)}")
        
        return findings
    
    def check_hardcoded_secrets(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """Ê©üÂØÜÊÉÖÂ†±„Éè„Éº„Éâ„Ç≥„Éº„Éá„Ç£„É≥„Ç∞„ÉÅ„Çß„ÉÉ„ÇØ"""
        
        findings = []
        patterns = params.get("patterns", [])
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                for pattern in patterns:
                    matches = re.finditer(pattern, content, re.IGNORECASE)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        findings.append(f"{file_path}:{line_num} - Ê©üÂØÜÊÉÖÂ†±„Éè„Éº„Éâ„Ç≥„Éº„Éá„Ç£„É≥„Ç∞Áñë„ÅÑ: {match.group()}")
                        
            except Exception as e:
                findings.append(f"{file_path} - Ë™≠„ÅøËæº„Åø„Ç®„É©„Éº: {str(e)}")
        
        return findings
    
    def check_sql_injection(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """SQL„Ç§„É≥„Ç∏„Çß„ÇØ„Ç∑„Éß„É≥ËÑÜÂº±ÊÄß„ÉÅ„Çß„ÉÉ„ÇØ"""
        
        findings = []
        patterns = params.get("patterns", [])
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                for pattern in patterns:
                    matches = re.finditer(pattern, content)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        findings.append(f"{file_path}:{line_num} - SQL„Ç§„É≥„Ç∏„Çß„ÇØ„Ç∑„Éß„É≥ËÑÜÂº±ÊÄßÁñë„ÅÑ: {match.group()}")
                        
            except Exception as e:
                findings.append(f"{file_path} - Ë™≠„ÅøËæº„Åø„Ç®„É©„Éº: {str(e)}")
        
        return findings
    
    def check_crypto_usage(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """ÊöóÂè∑ÂåñË®≠ÂÆöÊ§úË®º"""
        
        findings = []
        weak_algorithms = params.get("weak_algorithms", [])
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                for weak_algo in weak_algorithms:
                    if weak_algo.lower() in content.lower():
                        findings.append(f"{file_path} - Âº±„ÅÑÊöóÂè∑Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†‰ΩøÁî®Áñë„ÅÑ: {weak_algo}")
                        
            except Exception as e:
                findings.append(f"{file_path} - Ë™≠„ÅøËæº„Åø„Ç®„É©„Éº: {str(e)}")
        
        return findings
    
    def _generate_security_recommendations(self, rule: ValidationRule, findings: List[str]) -> List[str]:
        """„Çª„Ç≠„É•„É™„ÉÜ„Ç£Êé®Â•®‰∫ãÈ†ÖÁîüÊàê"""
        
        if not findings:
            return ["„Çª„Ç≠„É•„É™„ÉÜ„Ç£„ÉÅ„Çß„ÉÉ„ÇØÂêàÊ†º"]
        
        recommendations = []
        
        if rule.rule_id == "SEC001":
            recommendations.extend([
                "eval(), exec() „ÅÆ‰ΩøÁî®„ÇíÈÅø„Åë„ÄÅ„Çà„ÇäÂÆâÂÖ®„Å™‰ª£ÊõøÊâãÊÆµ„Çí‰ΩøÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                "subprocess.call() „Åß„ÅØ shell=False „Çí‰ΩøÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                "ÂÖ•ÂäõÂÄ§„ÅÆÈÅ©Âàá„Å™Ê§úË®º„Éª„Çµ„Éã„Çø„Ç§„Çº„Éº„Ç∑„Éß„É≥„ÇíÂÆüË£Ö„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
            ])
        elif rule.rule_id == "SEC002":
            recommendations.extend([
                "Ê©üÂØÜÊÉÖÂ†±„ÅØÁí∞Â¢ÉÂ§âÊï∞„ÇÑË®≠ÂÆö„Éï„Ç°„Ç§„É´„Åã„ÇâË™≠„ÅøËæº„Çì„Åß„Åè„Å†„Åï„ÅÑ",
                "Ë®≠ÂÆö„Éï„Ç°„Ç§„É´„ÅØ„Éê„Éº„Ç∏„Éß„É≥ÁÆ°ÁêÜ„Åã„ÇâÈô§Â§ñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                "Ê©üÂØÜÊÉÖÂ†±ÁÆ°ÁêÜ„Ç∑„Çπ„ÉÜ„É†ÔºàHashiCorp VaultÁ≠âÔºâ„ÅÆ‰ΩøÁî®„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
            ])
        elif rule.rule_id == "SEC003":
            recommendations.extend([
                "SQL„ÇØ„Ç®„É™„Å´„ÅØ„Éë„É©„É°„Éº„ÇøÂåñ„ÇØ„Ç®„É™„Çí‰ΩøÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                "ORMÔºàSQLAlchemyÁ≠âÔºâ„ÅÆ‰ΩøÁî®„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                "ÂÖ•ÂäõÂÄ§„ÅÆÈÅ©Âàá„Å™Ê§úË®º„Éª„Ç®„Çπ„Ç±„Éº„Éó„ÇíÂÆüË£Ö„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
            ])
        elif rule.rule_id == "SEC004":
            recommendations.extend([
                "SHA-256‰ª•‰∏ä„ÅÆÂº∑Âäõ„Å™„Éè„ÉÉ„Ç∑„É•„Ç¢„É´„Ç¥„É™„Ç∫„É†„Çí‰ΩøÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                "AES-256Á≠â„ÅÆÁèæ‰ª£ÁöÑ„Å™ÊöóÂè∑Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†„Çí‰ΩøÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                "ÊöóÂè∑Âåñ„É©„Ç§„Éñ„É©„É™ÔºàcryptographyÁ≠âÔºâ„ÅÆÊúÄÊñ∞Áâà„Çí‰ΩøÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
            ])
        
        return recommendations

class PerformanceValidator:
    """„Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊ§úË®º„Ç∑„Çπ„ÉÜ„É†"""
    
    def __init__(self):
        self.performance_rules = self._load_performance_rules()
        
    def _load_performance_rules(self) -> List[ValidationRule]:
        """„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„É´„Éº„É´Ë™≠„ÅøËæº„Åø"""
        
        rules = [
            ValidationRule(
                rule_id="PERF001",
                category=ValidationCategory.PERFORMANCE,
                severity=ValidationSeverity.MEDIUM,
                name="ÈùûÂäπÁéá„Å™„É´„Éº„Éó„Éë„Çø„Éº„É≥",
                description="range(len())Á≠â„ÅÆÈùûÂäπÁéá„Å™„É´„Éº„Éó„Éë„Çø„Éº„É≥„ÇíÊ§úÂá∫",
                check_function="check_inefficient_loops",
                parameters={"patterns": [r"for\s+\w+\s+in\s+range\(len\(", r"while.*len\(.*\)"]},
                auto_fix_available=True
            ),
            
            ValidationRule(
                rule_id="PERF002",
                category=ValidationCategory.PERFORMANCE,
                severity=ValidationSeverity.LOW,
                name="Â§ßÈáè„ÅÆ„Éï„Ç°„Ç§„É´I/O",
                description="„É´„Éº„ÉóÂÜÖ„Åß„ÅÆ„Éï„Ç°„Ç§„É´I/OÁ≠â„ÅÆ„Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÂïèÈ°å„ÇíÊ§úÂá∫",
                check_function="check_file_io_patterns",
                parameters={"patterns": [r"for.*open\(", r"while.*open\("]},
                auto_fix_available=False
            ),
            
            ValidationRule(
                rule_id="PERF003",
                category=ValidationCategory.PERFORMANCE,
                severity=ValidationSeverity.HIGH,
                name="„É°„É¢„É™„É™„Éº„ÇØÂèØËÉΩÊÄß",
                description="„É°„É¢„É™„É™„Éº„ÇØ„ÅÆÂèØËÉΩÊÄß„Åå„ÅÇ„Çã„Éë„Çø„Éº„É≥„ÇíÊ§úÂá∫",
                check_function="check_memory_leaks",
                parameters={"patterns": [r"global\s+\w+\s*=\s*\[\]", r".*\.append\(.*\)\s*$"]},
                enterprise_required=True
            ),
            
            ValidationRule(
                rule_id="PERF004",
                category=ValidationCategory.PERFORMANCE,
                severity=ValidationSeverity.MEDIUM,
                name="CPUÈõÜÁ¥ÑÁöÑÂá¶ÁêÜ",
                description="CPUÈõÜÁ¥ÑÁöÑ„Å™Âá¶ÁêÜ„Éë„Çø„Éº„É≥„ÇíÊ§úÂá∫",
                check_function="check_cpu_intensive",
                parameters={"time_threshold": 1.0},  # 1Áßí‰ª•‰∏ä
                threshold=1.0,
                timeout_seconds=30
            )
        ]
        
        return rules
    
    def validate_performance(self, file_paths: List[str]) -> List[ValidationResult]:
        """„Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊ§úË®ºÂÆüË°å"""
        
        results = []
        
        for rule in self.performance_rules:
            print(f"‚ö° „Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„ÉÅ„Çß„ÉÉ„ÇØ: {rule.name}")
            
            start_time = time.time()
            
            try:
                # Ê§úË®ºÈñ¢Êï∞ÂÆüË°å
                check_method = getattr(self, rule.check_function)
                findings = check_method(file_paths, rule.parameters)
                
                execution_time = time.time() - start_time
                
                # ÁµêÊûúÂà§ÂÆö
                if findings:
                    status = ValidationStatus.WARNING
                    score = 0.7  # „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÂïèÈ°å„ÅØË≠¶Âëä„É¨„Éô„É´
                else:
                    status = ValidationStatus.PASSED
                    score = 1.0
                
                recommendations = self._generate_performance_recommendations(rule, findings)
                
                result = ValidationResult(
                    rule=rule,
                    status=status,
                    score=score,
                    execution_time=execution_time,
                    details={"files_checked": len(file_paths)},
                    findings=findings,
                    recommendations=recommendations,
                    timestamp=datetime.datetime.now().isoformat(),
                    auto_fix_applied=False,
                    manual_action_required=len(findings) > 0
                )
                
                results.append(result)
                
            except Exception as e:
                execution_time = time.time() - start_time
                
                result = ValidationResult(
                    rule=rule,
                    status=ValidationStatus.ERROR,
                    score=0.0,
                    execution_time=execution_time,
                    details={"error": str(e)},
                    findings=[f"Ê§úË®º„Ç®„É©„Éº: {str(e)}"],
                    recommendations=["Ê§úË®º„Ç∑„Çπ„ÉÜ„É†„ÅÆÁ¢∫Ë™ç„ÅåÂøÖË¶Å„Åß„Åô"],
                    timestamp=datetime.datetime.now().isoformat()
                )
                
                results.append(result)
        
        return results
    
    def check_inefficient_loops(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """ÈùûÂäπÁéá„Å™„É´„Éº„Éó„Éë„Çø„Éº„É≥„ÉÅ„Çß„ÉÉ„ÇØ"""
        
        findings = []
        patterns = params.get("patterns", [])
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                for pattern in patterns:
                    matches = re.finditer(pattern, content)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        findings.append(f"{file_path}:{line_num} - ÈùûÂäπÁéá„Å™„É´„Éº„Éó: {match.group().strip()}")
                        
            except Exception as e:
                findings.append(f"{file_path} - Ë™≠„ÅøËæº„Åø„Ç®„É©„Éº: {str(e)}")
        
        return findings
    
    def check_file_io_patterns(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """„Éï„Ç°„Ç§„É´I/O„Éë„Çø„Éº„É≥„ÉÅ„Çß„ÉÉ„ÇØ"""
        
        findings = []
        patterns = params.get("patterns", [])
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                for pattern in patterns:
                    matches = re.finditer(pattern, content)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        findings.append(f"{file_path}:{line_num} - „É´„Éº„ÉóÂÜÖ„Éï„Ç°„Ç§„É´I/O: {match.group().strip()}")
                        
            except Exception as e:
                findings.append(f"{file_path} - Ë™≠„ÅøËæº„Åø„Ç®„É©„Éº: {str(e)}")
        
        return findings
    
    def check_memory_leaks(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """„É°„É¢„É™„É™„Éº„ÇØ„Éë„Çø„Éº„É≥„ÉÅ„Çß„ÉÉ„ÇØ"""
        
        findings = []
        patterns = params.get("patterns", [])
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                for pattern in patterns:
                    matches = re.finditer(pattern, content, re.MULTILINE)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        findings.append(f"{file_path}:{line_num} - „É°„É¢„É™„É™„Éº„ÇØÂèØËÉΩÊÄß: {match.group().strip()}")
                        
            except Exception as e:
                findings.append(f"{file_path} - Ë™≠„ÅøËæº„Åø„Ç®„É©„Éº: {str(e)}")
        
        return findings
    
    def check_cpu_intensive(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """CPUÈõÜÁ¥ÑÁöÑÂá¶ÁêÜ„ÉÅ„Çß„ÉÉ„ÇØ"""
        
        findings = []
        time_threshold = params.get("time_threshold", 1.0)
        
        # CPUÈõÜÁ¥ÑÁöÑ„Å™Âá¶ÁêÜ„Éë„Çø„Éº„É≥„ÇíÊ§úÂá∫
        cpu_patterns = [
            r"while\s+True:",
            r"for.*range\(\s*\d{4,}\s*\)",  # Â§ß„Åç„Å™range
            r"time\.sleep\s*\(\s*[0-9]+\s*\)"   # Èï∑„ÅÑsleep
        ]
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                for pattern in cpu_patterns:
                    matches = re.finditer(pattern, content)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        findings.append(f"{file_path}:{line_num} - CPUÈõÜÁ¥ÑÁöÑÂá¶ÁêÜÁñë„ÅÑ: {match.group().strip()}")
                        
            except Exception as e:
                findings.append(f"{file_path} - Ë™≠„ÅøËæº„Åø„Ç®„É©„Éº: {str(e)}")
        
        return findings
    
    def _generate_performance_recommendations(self, rule: ValidationRule, findings: List[str]) -> List[str]:
        """„Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊé®Â•®‰∫ãÈ†ÖÁîüÊàê"""
        
        if not findings:
            return ["„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„ÉÅ„Çß„ÉÉ„ÇØÂêàÊ†º"]
        
        recommendations = []
        
        if rule.rule_id == "PERF001":
            recommendations.extend([
                "enumerate() „Çí‰ΩøÁî®„Åó„Å¶„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„Å®ÂÄ§„ÇíÂêåÊôÇ„Å´ÂèñÂæó„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                "„É™„Çπ„ÉàÂÜÖÂåÖË°®Ë®ò„ÇÑmap(), filter()„ÅÆ‰ΩøÁî®„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                "NumPy„ÇÑPandas„ÅÆ„Éô„ÇØ„Éà„É´Âåñ„Åï„Çå„ÅüÊìç‰Ωú„ÇíÊ¥ªÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
            ])
        elif rule.rule_id == "PERF002":
            recommendations.extend([
                "„Éï„Ç°„Ç§„É´„ÅÆ‰∏ÄÊã¨Ë™≠„ÅøËæº„Åø„ÉªÊõ∏„ÅçËæº„Åø„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                "withÊñá„Çí‰ΩøÁî®„Åó„Åü„É™„ÇΩ„Éº„ÇπÁÆ°ÁêÜ„ÇíÂæπÂ∫ï„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                "„É°„É¢„É™„Éû„ÉÉ„Éó„Éâ„Éï„Ç°„Ç§„É´„ÅÆ‰ΩøÁî®„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
            ])
        elif rule.rule_id == "PERF003":
            recommendations.extend([
                "„Ç∞„É≠„Éº„Éê„É´Â§âÊï∞„ÅÆ‰ΩøÁî®„ÇíÊúÄÂ∞èÈôê„Å´Êäë„Åà„Å¶„Åè„Å†„Åï„ÅÑ",
                "ÈÅ©Âàá„Å™„Çπ„Ç≥„Éº„Éó„Åß„ÅÆÂ§âÊï∞ÂÆöÁæ©„ÇíÂøÉ„Åå„Åë„Å¶„Åè„Å†„Åï„ÅÑ",
                "„Ç¨„Éô„Éº„Ç∏„Ç≥„É¨„ÇØ„Ç∑„Éß„É≥„ÅÆÂãï‰Ωú„ÇíÁêÜËß£„Åó„Å¶Ë®≠Ë®à„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
            ])
        elif rule.rule_id == "PERF004":
            recommendations.extend([
                "ÈùûÂêåÊúüÂá¶ÁêÜÔºàasync/awaitÔºâ„ÅÆ‰ΩøÁî®„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                "„Éû„É´„ÉÅ„Éó„É≠„Çª„Ç∑„É≥„Ç∞„Éª„Éû„É´„ÉÅ„Çπ„É¨„ÉÉ„Éâ„ÅÆÊ¥ªÁî®„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
                "Âá¶ÁêÜ„ÅÆÂàÜÂâ≤„Éª„Éê„ÉÉ„ÉÅÂåñ„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
            ])
        
        return recommendations

class IntegrationTestGenerator:
    """Áµ±Âêà„ÉÜ„Çπ„ÉàËá™ÂãïÁîüÊàê„Ç∑„Çπ„ÉÜ„É†"""
    
    def __init__(self):
        self.test_templates = self._load_test_templates()
        
    def generate_integration_tests(self, file_paths: List[str]) -> List[ValidationResult]:
        """Áµ±Âêà„ÉÜ„Çπ„ÉàËá™ÂãïÁîüÊàê„ÉªÂÆüË°å"""
        
        results = []
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            print(f"üß™ Áµ±Âêà„ÉÜ„Çπ„ÉàÁîüÊàê: {file_path}")
            
            start_time = time.time()
            
            try:
                # „Éï„Ç°„Ç§„É´Ëß£Êûê
                module_info = self._analyze_module(file_path)
                
                # „ÉÜ„Çπ„Éà„Ç±„Éº„ÇπÁîüÊàê
                test_cases = self._generate_test_cases(module_info)
                
                # „ÉÜ„Çπ„ÉàÂÆüË°å
                test_results = self._execute_tests(test_cases, file_path)
                
                execution_time = time.time() - start_time
                
                # ÁµêÊûúË©ï‰æ°
                passed_tests = len([r for r in test_results if r["status"] == "passed"])
                total_tests = len(test_results)
                score = passed_tests / total_tests if total_tests > 0 else 1.0
                
                status = ValidationStatus.PASSED if score >= 0.8 else ValidationStatus.WARNING
                
                findings = []
                if score < 1.0:
                    failed_tests = [r for r in test_results if r["status"] != "passed"]
                    findings = [f"Â§±Êïó„ÉÜ„Çπ„Éà: {t['name']} - {t['error']}" for t in failed_tests]
                
                result = ValidationResult(
                    rule=ValidationRule(
                        rule_id="INT001",
                        category=ValidationCategory.INTEGRATION,
                        severity=ValidationSeverity.MEDIUM,
                        name="Áµ±Âêà„ÉÜ„Çπ„Éà",
                        description="Ëá™ÂãïÁîüÊàê„Åï„Çå„ÅüÁµ±Âêà„ÉÜ„Çπ„Éà",
                        check_function="generate_integration_tests",
                        parameters={}
                    ),
                    status=status,
                    score=score,
                    execution_time=execution_time,
                    details={
                        "total_tests": total_tests,
                        "passed_tests": passed_tests,
                        "functions_tested": len(module_info.get("functions", [])),
                        "classes_tested": len(module_info.get("classes", []))
                    },
                    findings=findings,
                    recommendations=self._generate_test_recommendations(score, module_info),
                    timestamp=datetime.datetime.now().isoformat(),
                    metrics={"test_coverage": score}
                )
                
                results.append(result)
                
            except Exception as e:
                execution_time = time.time() - start_time
                
                result = ValidationResult(
                    rule=ValidationRule(
                        rule_id="INT001",
                        category=ValidationCategory.INTEGRATION,
                        severity=ValidationSeverity.MEDIUM,
                        name="Áµ±Âêà„ÉÜ„Çπ„Éà",
                        description="Ëá™ÂãïÁîüÊàê„Åï„Çå„ÅüÁµ±Âêà„ÉÜ„Çπ„Éà",
                        check_function="generate_integration_tests",
                        parameters={}
                    ),
                    status=ValidationStatus.ERROR,
                    score=0.0,
                    execution_time=execution_time,
                    details={"error": str(e)},
                    findings=[f"„ÉÜ„Çπ„ÉàÁîüÊàê„Ç®„É©„Éº: {str(e)}"],
                    recommendations=["„É¢„Ç∏„É•„Éº„É´ÊßãÈÄ†„ÅÆÁ¢∫Ë™ç„ÅåÂøÖË¶Å„Åß„Åô"],
                    timestamp=datetime.datetime.now().isoformat()
                )
                
                results.append(result)
        
        return results
    
    def _analyze_module(self, file_path: str) -> Dict[str, Any]:
        """„É¢„Ç∏„É•„Éº„É´Ëß£Êûê"""
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ASTËß£Êûê
            tree = ast.parse(content)
            
            functions = []
            classes = []
            imports = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    functions.append({
                        "name": node.name,
                        "args": [arg.arg for arg in node.args.args],
                        "returns": ast.get_source_segment(content, node.returns) if node.returns else None,
                        "is_public": not node.name.startswith('_')
                    })
                elif isinstance(node, ast.ClassDef):
                    methods = [n.name for n in node.body if isinstance(n, ast.FunctionDef)]
                    classes.append({
                        "name": node.name,
                        "methods": methods,
                        "is_public": not node.name.startswith('_')
                    })
                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    if isinstance(node, ast.Import):
                        imports.extend([alias.name for alias in node.names])
                    else:
                        imports.append(node.module)
            
            return {
                "file_path": file_path,
                "functions": functions,
                "classes": classes,
                "imports": imports,
                "has_main": "if __name__ == '__main__':" in content
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è „É¢„Ç∏„É•„Éº„É´Ëß£Êûê„Ç®„É©„Éº: {e}")
            return {"file_path": file_path, "functions": [], "classes": [], "imports": []}
    
    def _generate_test_cases(self, module_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """„ÉÜ„Çπ„Éà„Ç±„Éº„ÇπÁîüÊàê"""
        
        test_cases = []
        
        # Èñ¢Êï∞„ÉÜ„Çπ„Éà„Ç±„Éº„ÇπÁîüÊàê
        for func in module_info.get("functions", []):
            if func["is_public"]:
                test_cases.append({
                    "type": "function",
                    "name": f"test_{func['name']}",
                    "target": func["name"],
                    "test_code": self._generate_function_test(func)
                })
        
        # „ÇØ„É©„Çπ„ÉÜ„Çπ„Éà„Ç±„Éº„ÇπÁîüÊàê
        for cls in module_info.get("classes", []):
            if cls["is_public"]:
                test_cases.append({
                    "type": "class",
                    "name": f"test_{cls['name']}",
                    "target": cls["name"],
                    "test_code": self._generate_class_test(cls)
                })
        
        # „Ç§„É≥„Éù„Éº„Éà„ÉÜ„Çπ„Éà
        if module_info.get("imports"):
            test_cases.append({
                "type": "import",
                "name": "test_imports",
                "target": "imports",
                "test_code": self._generate_import_test(module_info["imports"])
            })
        
        return test_cases
    
    def _generate_function_test(self, func_info: Dict[str, Any]) -> str:
        """Èñ¢Êï∞„ÉÜ„Çπ„Éà„Ç≥„Éº„ÉâÁîüÊàê"""
        
        func_name = func_info["name"]
        args = func_info["args"]
        
        # Á∞°Âçò„Å™„ÉÜ„Çπ„Éà„Ç≥„Éº„ÉâÁîüÊàê
        test_args = []
        for arg in args:
            if arg == "self":
                continue
            elif "file" in arg.lower() or "path" in arg.lower():
                test_args.append("'test_file.txt'")
            elif "num" in arg.lower() or "count" in arg.lower():
                test_args.append("10")
            elif "str" in arg.lower() or "text" in arg.lower():
                test_args.append("'test_string'")
            else:
                test_args.append("None")
        
        args_str = ", ".join(test_args)
        
        return f"""
def test_{func_name}():
    \"\"\"Ëá™ÂãïÁîüÊàê„Åï„Çå„Åü„ÉÜ„Çπ„Éà: {func_name}\"\"\"
    try:
        result = {func_name}({args_str})
        assert result is not None, "Èñ¢Êï∞„ÅØÂÄ§„ÇíËøî„Åô„Åπ„Åç„Åß„Åô"
        return True
    except Exception as e:
        print(f"„ÉÜ„Çπ„Éà„Ç®„É©„Éº: {{e}}")
        return False
"""
    
    def _generate_class_test(self, class_info: Dict[str, Any]) -> str:
        """„ÇØ„É©„Çπ„ÉÜ„Çπ„Éà„Ç≥„Éº„ÉâÁîüÊàê"""
        
        class_name = class_info["name"]
        
        return f"""
def test_{class_name}():
    \"\"\"Ëá™ÂãïÁîüÊàê„Åï„Çå„Åü„ÉÜ„Çπ„Éà: {class_name}\"\"\"
    try:
        instance = {class_name}()
        assert instance is not None, "„ÇØ„É©„Çπ„ÅÆ„Ç§„É≥„Çπ„Çø„É≥„ÇπÂåñ„Åå„Åß„Åç„Çã„Åπ„Åç„Åß„Åô"
        return True
    except Exception as e:
        print(f"„ÉÜ„Çπ„Éà„Ç®„É©„Éº: {{e}}")
        return False
"""
    
    def _generate_import_test(self, imports: List[str]) -> str:
        """„Ç§„É≥„Éù„Éº„Éà„ÉÜ„Çπ„Éà„Ç≥„Éº„ÉâÁîüÊàê"""
        
        import_statements = []
        for imp in imports:
            if imp:
                import_statements.append(f"import {imp}")
        
        imports_str = "; ".join(import_statements)
        
        return f"""
def test_imports():
    \"\"\"Ëá™ÂãïÁîüÊàê„Åï„Çå„Åü„ÉÜ„Çπ„Éà: „Ç§„É≥„Éù„Éº„Éà\"\"\"
    try:
        {imports_str}
        return True
    except ImportError as e:
        print(f"„Ç§„É≥„Éù„Éº„Éà„Ç®„É©„Éº: {{e}}")
        return False
"""
    
    def _execute_tests(self, test_cases: List[Dict[str, Any]], module_path: str) -> List[Dict[str, Any]]:
        """„ÉÜ„Çπ„ÉàÂÆüË°å"""
        
        results = []
        
        # ‰∏ÄÊôÇ„ÉÜ„Çπ„Éà„Éï„Ç°„Ç§„É´‰ΩúÊàê
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as temp_file:
            temp_file.write(f"import sys\n")
            temp_file.write(f"sys.path.append('{os.path.dirname(module_path)}')\n")
            temp_file.write(f"from {os.path.splitext(os.path.basename(module_path))[0]} import *\n\n")
            
            for test_case in test_cases:
                temp_file.write(test_case["test_code"])
                temp_file.write("\n")
            
            # „É°„Ç§„É≥ÂÆüË°åÈÉ®ÂàÜ
            temp_file.write("\nif __name__ == '__main__':\n")
            for test_case in test_cases:
                temp_file.write(f"    print('{test_case['name']}:', {test_case['name']}())\n")
            
            temp_file_path = temp_file.name
        
        try:
            # „ÉÜ„Çπ„ÉàÂÆüË°å
            result = subprocess.run(
                ["python3", temp_file_path],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            # ÁµêÊûúËß£Êûê
            if result.returncode == 0:
                output_lines = result.stdout.strip().split('\n')
                for line in output_lines:
                    if ':' in line:
                        test_name, test_result = line.split(':', 1)
                        status = "passed" if "True" in test_result else "failed"
                        results.append({
                            "name": test_name.strip(),
                            "status": status,
                            "output": test_result.strip(),
                            "error": None
                        })
            else:
                # „Ç®„É©„Éº„ÅÆÂ†¥Âêà
                for test_case in test_cases:
                    results.append({
                        "name": test_case["name"],
                        "status": "error",
                        "output": "",
                        "error": result.stderr
                    })
            
        except subprocess.TimeoutExpired:
            for test_case in test_cases:
                results.append({
                    "name": test_case["name"],
                    "status": "timeout",
                    "output": "",
                    "error": "„ÉÜ„Çπ„Éà„Çø„Ç§„É†„Ç¢„Ç¶„Éà"
                })
        
        except Exception as e:
            for test_case in test_cases:
                results.append({
                    "name": test_case["name"],
                    "status": "error",
                    "output": "",
                    "error": str(e)
                })
        
        finally:
            # ‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´ÂâäÈô§
            try:
                os.unlink(temp_file_path)
            except:
                pass
        
        return results
    
    def _generate_test_recommendations(self, score: float, module_info: Dict[str, Any]) -> List[str]:
        """„ÉÜ„Çπ„ÉàÊé®Â•®‰∫ãÈ†ÖÁîüÊàê"""
        
        recommendations = []
        
        if score < 0.5:
            recommendations.append("„ÉÜ„Çπ„Éà„ÅåÂ§öÊï∞Â§±Êïó„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Ç≥„Éº„Éâ„ÅÆÂü∫Êú¨ÊßãÈÄ†„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        elif score < 0.8:
            recommendations.append("‰∏ÄÈÉ®„ÅÆ„ÉÜ„Çπ„Éà„ÅåÂ§±Êïó„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        else:
            recommendations.append("Âü∫Êú¨ÁöÑ„Å™„ÉÜ„Çπ„Éà„ÅØÈÄöÈÅé„Åó„Å¶„ÅÑ„Åæ„Åô")
        
        if len(module_info.get("functions", [])) > 10:
            recommendations.append("Èñ¢Êï∞„ÅåÂ§öÊï∞„ÅÇ„Çä„Åæ„Åô„ÄÇÂçò‰Ωì„ÉÜ„Çπ„Éà„ÅÆ‰ΩúÊàê„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        
        if len(module_info.get("classes", [])) > 5:
            recommendations.append("„ÇØ„É©„Çπ„ÅåÂ§öÊï∞„ÅÇ„Çä„Åæ„Åô„ÄÇÁµ±Âêà„ÉÜ„Çπ„Éà„ÅÆË©≥Á¥∞Âåñ„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        
        return recommendations
    
    def _load_test_templates(self) -> Dict[str, str]:
        """„ÉÜ„Çπ„Éà„ÉÜ„É≥„Éó„É¨„Éº„ÉàË™≠„ÅøËæº„Åø"""
        # Âü∫Êú¨ÁöÑ„Å™„ÉÜ„Çπ„Éà„ÉÜ„É≥„Éó„É¨„Éº„Éà
        return {
            "function": "Âü∫Êú¨Èñ¢Êï∞„ÉÜ„Çπ„Éà„ÉÜ„É≥„Éó„É¨„Éº„Éà",
            "class": "Âü∫Êú¨„ÇØ„É©„Çπ„ÉÜ„Çπ„Éà„ÉÜ„É≥„Éó„É¨„Éº„Éà",
            "integration": "Áµ±Âêà„ÉÜ„Çπ„Éà„ÉÜ„É≥„Éó„É¨„Éº„Éà"
        }

class ComprehensiveQualityValidator:
    """ÂåÖÊã¨ÁöÑÂìÅË≥™Ê§úË®º„Ç∑„Çπ„ÉÜ„É†"""
    
    def __init__(self):
        self.security_validator = SecurityValidator()
        self.performance_validator = PerformanceValidator()
        self.integration_test_generator = IntegrationTestGenerator()
        
        self.data_dir = Path("postbox/quality/comprehensive")
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        self.results_path = self.data_dir / "validation_results.json"
        self.summary_path = self.data_dir / "validation_summary.json"
        
        print("üîç ComprehensiveQualityValidator ÂàùÊúüÂåñÂÆå‰∫Ü")
    
    def validate_comprehensive_quality(self, file_paths: List[str], 
                                     enterprise_mode: bool = False,
                                     categories: Optional[List[ValidationCategory]] = None) -> Dict[str, Any]:
        """ÂåÖÊã¨ÁöÑÂìÅË≥™Ê§úË®ºÂÆüË°å"""
        
        print(f"üîç ÂåÖÊã¨ÁöÑÂìÅË≥™Ê§úË®ºÈñãÂßã: {len(file_paths)}„Éï„Ç°„Ç§„É´")
        if enterprise_mode:
            print("üè¢ ‰ºÅÊ•≠„É¨„Éô„É´ÂìÅË≥™Âü∫Ê∫ñÈÅ©Áî®")
        
        start_time = time.time()
        all_results = []
        
        # „Ç´„ÉÜ„Ç¥„É™ÈÅ∏Êäû
        if categories is None:
            categories = [ValidationCategory.SECURITY, ValidationCategory.PERFORMANCE, ValidationCategory.INTEGRATION]
        
        # ‰∏¶ÂàóÂÆüË°å„Åß„Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÂêë‰∏ä
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            futures = {}
            
            if ValidationCategory.SECURITY in categories:
                futures["security"] = executor.submit(self.security_validator.validate_security, file_paths)
            
            if ValidationCategory.PERFORMANCE in categories:
                futures["performance"] = executor.submit(self.performance_validator.validate_performance, file_paths)
            
            if ValidationCategory.INTEGRATION in categories:
                futures["integration"] = executor.submit(self.integration_test_generator.generate_integration_tests, file_paths)
            
            # ÁµêÊûúÂèñÂæó
            category_results = {}
            for category, future in futures.items():
                try:
                    results = future.result(timeout=300)  # 5ÂàÜ„Çø„Ç§„É†„Ç¢„Ç¶„Éà
                    category_results[category] = results
                    all_results.extend(results)
                    print(f"‚úÖ {category} Ê§úË®ºÂÆå‰∫Ü: {len(results)}‰ª∂")
                except concurrent.futures.TimeoutError:
                    print(f"‚è∞ {category} Ê§úË®º„Çø„Ç§„É†„Ç¢„Ç¶„Éà")
                    category_results[category] = []
                except Exception as e:
                    print(f"‚ùå {category} Ê§úË®º„Ç®„É©„Éº: {e}")
                    category_results[category] = []
        
        total_execution_time = time.time() - start_time
        
        # Á∑èÂêàË©ï‰æ°
        summary = self._generate_comprehensive_summary(all_results, enterprise_mode, total_execution_time)
        
        # ÁµêÊûú‰øùÂ≠ò
        self._save_validation_results(all_results, summary)
        
        return {
            "summary": summary,
            "results_by_category": category_results,
            "all_results": all_results,
            "execution_time": total_execution_time
        }
    
    def _generate_comprehensive_summary(self, results: List[ValidationResult], 
                                      enterprise_mode: bool, execution_time: float) -> Dict[str, Any]:
        """ÂåÖÊã¨ÁöÑ„Çµ„Éû„É™„ÉºÁîüÊàê"""
        
        if not results:
            return {
                "overall_status": ValidationStatus.ERROR.value,
                "overall_score": 0.0,
                "message": "Ê§úË®ºÁµêÊûú„Å™„Åó"
            }
        
        # „Ç´„ÉÜ„Ç¥„É™Âà•ÈõÜË®à
        category_scores = {}
        category_status = {}
        
        for category in ValidationCategory:
            category_results = [r for r in results if r.rule.category == category]
            if category_results:
                scores = [r.score for r in category_results]
                category_scores[category.value] = sum(scores) / len(scores)
                
                # ÊúÄ„ÇÇÂé≥„Åó„ÅÑ„Çπ„ÉÜ„Éº„Çø„Çπ„ÇíÊé°Áî®
                statuses = [r.status for r in category_results]
                if ValidationStatus.FAILED in statuses:
                    category_status[category.value] = ValidationStatus.FAILED.value
                elif ValidationStatus.ERROR in statuses:
                    category_status[category.value] = ValidationStatus.ERROR.value
                elif ValidationStatus.WARNING in statuses:
                    category_status[category.value] = ValidationStatus.WARNING.value
                else:
                    category_status[category.value] = ValidationStatus.PASSED.value
        
        # Á∑èÂêà„Çπ„Ç≥„Ç¢Ë®àÁÆóÔºàÈáç„Åø‰ªò„ÅçÔºâ
        weights = {
            ValidationCategory.SECURITY.value: 0.4,
            ValidationCategory.PERFORMANCE.value: 0.3,
            ValidationCategory.INTEGRATION.value: 0.3
        }
        
        weighted_score = 0.0
        total_weight = 0.0
        
        for category, score in category_scores.items():
            weight = weights.get(category, 0.2)
            weighted_score += score * weight
            total_weight += weight
        
        overall_score = weighted_score / total_weight if total_weight > 0 else 0.0
        
        # ‰ºÅÊ•≠„É¨„Éô„É´ÂìÅË≥™Âü∫Ê∫ñÈÅ©Áî®
        if enterprise_mode:
            enterprise_threshold = 0.9
            overall_status = ValidationStatus.PASSED if overall_score >= enterprise_threshold else ValidationStatus.FAILED
        else:
            if overall_score >= 0.8:
                overall_status = ValidationStatus.PASSED
            elif overall_score >= 0.6:
                overall_status = ValidationStatus.WARNING
            else:
                overall_status = ValidationStatus.FAILED
        
        # Áµ±Ë®à
        total_rules = len(results)
        passed_rules = len([r for r in results if r.status == ValidationStatus.PASSED])
        failed_rules = len([r for r in results if r.status == ValidationStatus.FAILED])
        warning_rules = len([r for r in results if r.status == ValidationStatus.WARNING])
        
        # Êé®Â•®‰∫ãÈ†Ö
        recommendations = self._generate_comprehensive_recommendations(
            results, overall_score, enterprise_mode
        )
        
        return {
            "overall_status": overall_status.value,
            "overall_score": overall_score,
            "enterprise_mode": enterprise_mode,
            "execution_time": execution_time,
            "category_scores": category_scores,
            "category_status": category_status,
            "statistics": {
                "total_rules": total_rules,
                "passed_rules": passed_rules,
                "failed_rules": failed_rules,
                "warning_rules": warning_rules,
                "success_rate": passed_rules / total_rules if total_rules > 0 else 0.0
            },
            "recommendations": recommendations,
            "timestamp": datetime.datetime.now().isoformat()
        }
    
    def _generate_comprehensive_recommendations(self, results: List[ValidationResult], 
                                             overall_score: float, enterprise_mode: bool) -> List[str]:
        """ÂåÖÊã¨ÁöÑÊé®Â•®‰∫ãÈ†ÖÁîüÊàê"""
        
        recommendations = []
        
        # Á∑èÂêà„Çπ„Ç≥„Ç¢„Å´Âü∫„Å•„ÅèÊé®Â•®‰∫ãÈ†Ö
        if overall_score < 0.5:
            recommendations.append("ÂìÅË≥™„ÅåÂü∫Ê∫ñ„ÇíÂ§ßÂπÖ„Å´‰∏ãÂõû„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇÁ∑äÊÄ•„ÅÆÊîπÂñÑ„ÅåÂøÖË¶Å„Åß„Åô")
        elif overall_score < 0.7:
            recommendations.append("ÂìÅË≥™ÊîπÂñÑ„ÅåÂøÖË¶Å„Åß„Åô„ÄÇÈáçË¶Å„Å™ÂïèÈ°å„Åã„ÇâÂÑ™ÂÖàÁöÑ„Å´ÂØæÂøú„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        elif overall_score < 0.9:
            recommendations.append("Âü∫Êú¨ÁöÑ„Å™ÂìÅË≥™„ÅØÁ¢∫‰øù„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇÁ¥∞„Åã„ÅÑÊîπÂñÑ„ÇíÁ∂ôÁ∂ö„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        else:
            recommendations.append("ÂÑ™ÁßÄ„Å™ÂìÅË≥™„É¨„Éô„É´„Åß„Åô„ÄÇÁèæÂú®„ÅÆÊ∞¥Ê∫ñ„ÇíÁ∂≠ÊåÅ„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        
        # „Ç´„ÉÜ„Ç¥„É™Âà•Êé®Â•®‰∫ãÈ†Ö
        security_results = [r for r in results if r.rule.category == ValidationCategory.SECURITY]
        if any(r.status == ValidationStatus.FAILED for r in security_results):
            recommendations.append("„Çª„Ç≠„É•„É™„ÉÜ„Ç£ÂïèÈ°å„ÅåÊ§úÂá∫„Åï„Çå„Åæ„Åó„Åü„ÄÇÊó©ÊÄ•„Å™ÂØæÂøú„ÅåÂøÖË¶Å„Åß„Åô")
        
        performance_results = [r for r in results if r.rule.category == ValidationCategory.PERFORMANCE]
        if any(r.status == ValidationStatus.WARNING for r in performance_results):
            recommendations.append("„Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊîπÂñÑ„ÅÆ‰ΩôÂú∞„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇÊúÄÈÅ©Âåñ„ÇíÊ§úË®é„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        
        integration_results = [r for r in results if r.rule.category == ValidationCategory.INTEGRATION]
        if any(r.status == ValidationStatus.FAILED for r in integration_results):
            recommendations.append("Áµ±Âêà„ÉÜ„Çπ„Éà„ÅåÂ§±Êïó„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Ç≥„É≥„Éù„Éº„Éç„É≥„ÉàÈñì„ÅÆÈÄ£Êê∫„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        
        # ‰ºÅÊ•≠„É¢„Éº„ÉâÂõ∫Êúâ„ÅÆÊé®Â•®‰∫ãÈ†Ö
        if enterprise_mode and overall_score < 0.9:
            recommendations.append("‰ºÅÊ•≠„É¨„Éô„É´ÂìÅË≥™Âü∫Ê∫ñ„Å´Âà∞ÈÅî„Åó„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ„Ç≥„É≥„Éó„É©„Ç§„Ç¢„É≥„ÇπË¶Å‰ª∂„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        
        return recommendations
    
    def _save_validation_results(self, results: List[ValidationResult], summary: Dict[str, Any]) -> None:
        """Ê§úË®ºÁµêÊûú‰øùÂ≠ò"""
        
        try:
            # Ë©≥Á¥∞ÁµêÊûú‰øùÂ≠òÔºàÊúÄÊñ∞„ÅÆ„ÅøÔºâ
            results_data = []
            for result in results:
                result_dict = asdict(result)
                # ValidationRuleÂÜÖ„ÅÆEnumÂÄ§„ÇíÊñáÂ≠óÂàó„Å´Â§âÊèõ
                result_dict["rule"]["category"] = result.rule.category.value
                result_dict["rule"]["severity"] = result.rule.severity.value
                result_dict["status"] = result.status.value
                results_data.append(result_dict)
            
            with open(self.results_path, 'w', encoding='utf-8') as f:
                json.dump(results_data, f, indent=2, ensure_ascii=False)
            
            # „Çµ„Éû„É™„ÉºÂ±•Ê≠¥‰øùÂ≠ò
            summaries = []
            if self.summary_path.exists():
                with open(self.summary_path, 'r', encoding='utf-8') as f:
                    summaries = json.load(f)
            
            summaries.append(summary)
            
            # Â±•Ê≠¥„Çµ„Ç§„Ç∫Âà∂ÈôêÔºàÊúÄÊñ∞100‰ª∂Ôºâ
            if len(summaries) > 100:
                summaries = summaries[-100:]
            
            with open(self.summary_path, 'w', encoding='utf-8') as f:
                json.dump(summaries, f, indent=2, ensure_ascii=False)
            
            print(f"üìä Ê§úË®ºÁµêÊûú‰øùÂ≠òÂÆå‰∫Ü: {self.results_path}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è ÁµêÊûú‰øùÂ≠ò„Ç®„É©„Éº: {e}")

def main():
    """„ÉÜ„Çπ„ÉàÂÆüË°å"""
    print("üß™ ComprehensiveQualityValidator „ÉÜ„Çπ„ÉàÈñãÂßã")
    
    validator = ComprehensiveQualityValidator()
    
    # „ÉÜ„Çπ„Éà„Éï„Ç°„Ç§„É´
    test_files = [
        "kumihan_formatter/core/utilities/logger.py",
        "postbox/quality/quality_manager.py"
    ]
    
    # ÂåÖÊã¨ÁöÑÂìÅË≥™Ê§úË®ºÂÆüË°å
    print("\n=== Âü∫Êú¨ÂìÅË≥™Ê§úË®º ===")
    result = validator.validate_comprehensive_quality(test_files)
    
    summary = result["summary"]
    print(f"\nüìä Ê§úË®ºÁµêÊûú„Çµ„Éû„É™„Éº:")
    print(f"   Á∑èÂêà„Çπ„ÉÜ„Éº„Çø„Çπ: {summary['overall_status']}")
    print(f"   Á∑èÂêà„Çπ„Ç≥„Ç¢: {summary['overall_score']:.3f}")
    print(f"   ÂÆüË°åÊôÇÈñì: {summary['execution_time']:.2f}Áßí")
    print(f"   ÊàêÂäüÁéá: {summary['statistics']['success_rate']:.1%}")
    
    # ‰ºÅÊ•≠„É¨„Éô„É´ÂìÅË≥™Ê§úË®º
    print("\n=== ‰ºÅÊ•≠„É¨„Éô„É´ÂìÅË≥™Ê§úË®º ===")
    enterprise_result = validator.validate_comprehensive_quality(
        test_files, 
        enterprise_mode=True
    )
    
    enterprise_summary = enterprise_result["summary"]
    print(f"   ‰ºÅÊ•≠„É¨„Éô„É´„Çπ„ÉÜ„Éº„Çø„Çπ: {enterprise_summary['overall_status']}")
    print(f"   ‰ºÅÊ•≠„É¨„Éô„É´„Çπ„Ç≥„Ç¢: {enterprise_summary['overall_score']:.3f}")
    
    # Êé®Â•®‰∫ãÈ†ÖË°®Á§∫
    if summary.get("recommendations"):
        print(f"\nüí° Êé®Â•®‰∫ãÈ†Ö:")
        for rec in summary["recommendations"][:3]:
            print(f"   - {rec}")
    
    print("‚úÖ ComprehensiveQualityValidator „ÉÜ„Çπ„ÉàÂÆå‰∫Ü")

if __name__ == "__main__":
    main()