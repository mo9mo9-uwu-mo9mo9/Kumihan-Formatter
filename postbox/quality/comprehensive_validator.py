#!/usr/bin/env python3
"""
ComprehensiveQualityValidator
çµ±åˆå“è³ªæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ  - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»çµ±åˆãƒ†ã‚¹ãƒˆãƒ»ä¼æ¥­ãƒ¬ãƒ™ãƒ«å“è³ªåŸºæº–
è‡ªå‹•ãƒ†ã‚¹ãƒˆç”Ÿæˆãƒ»çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
"""

import os
import json
import time
import ast
import subprocess
import datetime
import tempfile
from typing import Dict, List, Any, Optional, Tuple, Union
from pathlib import Path
from dataclasses import dataclass, asdict
from enum import Enum
import concurrent.futures
import threading

class ValidationCategory(Enum):
    """æ¤œè¨¼ã‚«ãƒ†ã‚´ãƒª"""
    SECURITY = "security"          # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼
    PERFORMANCE = "performance"    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼
    INTEGRATION = "integration"    # çµ±åˆãƒ†ã‚¹ãƒˆ
    COMPLIANCE = "compliance"      # ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹æ¤œè¨¼
    RELIABILITY = "reliability"    # ä¿¡é ¼æ€§æ¤œè¨¼
    SCALABILITY = "scalability"    # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£æ¤œè¨¼

class ValidationSeverity(Enum):
    """æ¤œè¨¼é‡è¦åº¦"""
    CRITICAL = "critical"   # é‡å¤§
    HIGH = "high"          # é«˜
    MEDIUM = "medium"      # ä¸­
    LOW = "low"           # ä½
    INFO = "info"         # æƒ…å ±

class ValidationStatus(Enum):
    """æ¤œè¨¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"""
    PASSED = "passed"       # åˆæ ¼
    FAILED = "failed"       # ä¸åˆæ ¼
    WARNING = "warning"     # è­¦å‘Š
    SKIPPED = "skipped"     # ã‚¹ã‚­ãƒƒãƒ—
    ERROR = "error"         # ã‚¨ãƒ©ãƒ¼

@dataclass
class ValidationRule:
    """æ¤œè¨¼ãƒ«ãƒ¼ãƒ«"""
    rule_id: str
    category: ValidationCategory
    severity: ValidationSeverity
    name: str
    description: str
    
    check_function: str  # å®Ÿè¡Œã™ã‚‹æ¤œè¨¼é–¢æ•°å
    parameters: Dict[str, Any]
    threshold: Optional[float] = None
    timeout_seconds: int = 60
    
    auto_fix_available: bool = False
    enterprise_required: bool = False

@dataclass
class ValidationResult:
    """æ¤œè¨¼çµæœ"""
    rule: ValidationRule
    status: ValidationStatus
    score: float
    execution_time: float
    
    details: Dict[str, Any]
    findings: List[str]
    recommendations: List[str]
    
    timestamp: str
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    metrics: Optional[Dict[str, Any]] = None
    
    # ä¿®æ­£æƒ…å ±
    auto_fix_applied: bool = False
    manual_action_required: bool = False

class SecurityValidator:
    """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.security_rules = self._load_security_rules()
        
    def _load_security_rules(self) -> List[ValidationRule]:
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ«ãƒ¼ãƒ«èª­ã¿è¾¼ã¿"""
        
        rules = [
            ValidationRule(
                rule_id="SEC001",
                category=ValidationCategory.SECURITY,
                severity=ValidationSeverity.CRITICAL,
                name="å±é™ºãªé–¢æ•°ä½¿ç”¨ãƒã‚§ãƒƒã‚¯",
                description="eval, exec, subprocessç­‰ã®å±é™ºãªé–¢æ•°ã®ä½¿ç”¨ã‚’æ¤œå‡º",
                check_function="check_dangerous_functions",
                parameters={"patterns": [r"eval\s*\(", r"exec\s*\(", r"subprocess\.call.*shell=True"]},
                enterprise_required=True
            ),
            
            ValidationRule(
                rule_id="SEC002",
                category=ValidationCategory.SECURITY,
                severity=ValidationSeverity.HIGH,
                name="æ©Ÿå¯†æƒ…å ±ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°",
                description="ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã€APIã‚­ãƒ¼ç­‰ã®æ©Ÿå¯†æƒ…å ±ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¤œå‡º",
                check_function="check_hardcoded_secrets",
                parameters={"patterns": [r"password\s*=\s*[\"']", r"api_key\s*=\s*[\"']", r"secret\s*=\s*[\"']"]},
                enterprise_required=True
            ),
            
            ValidationRule(
                rule_id="SEC003",
                category=ValidationCategory.SECURITY,
                severity=ValidationSeverity.MEDIUM,
                name="SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³è„†å¼±æ€§",
                description="SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³è„†å¼±æ€§ã®å¯èƒ½æ€§ã‚’æ¤œå‡º",
                check_function="check_sql_injection",
                parameters={"patterns": [r"execute\s*\(\s*[\"'].*%.*[\"']", r"query\s*\+\s*"]},
                enterprise_required=False
            ),
            
            ValidationRule(
                rule_id="SEC004",
                category=ValidationCategory.SECURITY,
                severity=ValidationSeverity.MEDIUM,
                name="æš—å·åŒ–è¨­å®šæ¤œè¨¼",
                description="é©åˆ‡ãªæš—å·åŒ–è¨­å®šã®ä½¿ç”¨ã‚’æ¤œè¨¼",
                check_function="check_crypto_usage",
                parameters={"weak_algorithms": ["md5", "sha1", "des"]},
                enterprise_required=True
            )
        ]
        
        return rules
    
    def validate_security(self, file_paths: List[str]) -> List[ValidationResult]:
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼å®Ÿè¡Œ"""
        
        results = []
        
        for rule in self.security_rules:
            print(f"ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯: {rule.name}")
            
            start_time = time.time()
            
            try:
                # æ¤œè¨¼é–¢æ•°å®Ÿè¡Œ
                check_method = getattr(self, rule.check_function)
                findings = check_method(file_paths, rule.parameters)
                
                execution_time = time.time() - start_time
                
                # çµæœåˆ¤å®š
                if findings:
                    status = ValidationStatus.FAILED if rule.severity in [
                        ValidationSeverity.CRITICAL, ValidationSeverity.HIGH
                    ] else ValidationStatus.WARNING
                    score = 0.0 if status == ValidationStatus.FAILED else 0.5
                else:
                    status = ValidationStatus.PASSED
                    score = 1.0
                
                recommendations = self._generate_security_recommendations(rule, findings)
                
                result = ValidationResult(
                    rule=rule,
                    status=status,
                    score=score,
                    execution_time=execution_time,
                    details={"files_checked": len(file_paths)},
                    findings=findings,
                    recommendations=recommendations,
                    timestamp=datetime.datetime.now().isoformat(),
                    manual_action_required=len(findings) > 0
                )
                
                results.append(result)
                
            except Exception as e:
                execution_time = time.time() - start_time
                
                result = ValidationResult(
                    rule=rule,
                    status=ValidationStatus.ERROR,
                    score=0.0,
                    execution_time=execution_time,
                    details={"error": str(e)},
                    findings=[f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}"],
                    recommendations=["æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ã®ç¢ºèªãŒå¿…è¦ã§ã™"],
                    timestamp=datetime.datetime.now().isoformat()
                )
                
                results.append(result)
        
        return results
    
    def check_dangerous_functions(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """å±é™ºãªé–¢æ•°ä½¿ç”¨ãƒã‚§ãƒƒã‚¯"""
        
        findings = []
        patterns = params.get("patterns", [])
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                for pattern in patterns:
                    matches = re.finditer(pattern, content)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        findings.append(f"{file_path}:{line_num} - å±é™ºãªé–¢æ•°ä½¿ç”¨: {match.group()}")
                        
            except Exception as e:
                findings.append(f"{file_path} - èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return findings
    
    def check_hardcoded_secrets(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """æ©Ÿå¯†æƒ…å ±ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒã‚§ãƒƒã‚¯"""
        
        findings = []
        patterns = params.get("patterns", [])
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                for pattern in patterns:
                    matches = re.finditer(pattern, content, re.IGNORECASE)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        findings.append(f"{file_path}:{line_num} - æ©Ÿå¯†æƒ…å ±ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç–‘ã„: {match.group()}")
                        
            except Exception as e:
                findings.append(f"{file_path} - èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return findings
    
    def check_sql_injection(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³è„†å¼±æ€§ãƒã‚§ãƒƒã‚¯"""
        
        findings = []
        patterns = params.get("patterns", [])
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                for pattern in patterns:
                    matches = re.finditer(pattern, content)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        findings.append(f"{file_path}:{line_num} - SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³è„†å¼±æ€§ç–‘ã„: {match.group()}")
                        
            except Exception as e:
                findings.append(f"{file_path} - èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return findings
    
    def check_crypto_usage(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """æš—å·åŒ–è¨­å®šæ¤œè¨¼"""
        
        findings = []
        weak_algorithms = params.get("weak_algorithms", [])
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                for weak_algo in weak_algorithms:
                    if weak_algo.lower() in content.lower():
                        findings.append(f"{file_path} - å¼±ã„æš—å·åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ä½¿ç”¨ç–‘ã„: {weak_algo}")
                        
            except Exception as e:
                findings.append(f"{file_path} - èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return findings
    
    def _generate_security_recommendations(self, rule: ValidationRule, findings: List[str]) -> List[str]:
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        
        if not findings:
            return ["ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯åˆæ ¼"]
        
        recommendations = []
        
        if rule.rule_id == "SEC001":
            recommendations.extend([
                "eval(), exec() ã®ä½¿ç”¨ã‚’é¿ã‘ã€ã‚ˆã‚Šå®‰å…¨ãªä»£æ›¿æ‰‹æ®µã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
                "subprocess.call() ã§ã¯ shell=False ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
                "å…¥åŠ›å€¤ã®é©åˆ‡ãªæ¤œè¨¼ãƒ»ã‚µãƒ‹ã‚¿ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„"
            ])
        elif rule.rule_id == "SEC002":
            recommendations.extend([
                "æ©Ÿå¯†æƒ…å ±ã¯ç’°å¢ƒå¤‰æ•°ã‚„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚“ã§ãã ã•ã„",
                "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‹ã‚‰é™¤å¤–ã—ã¦ãã ã•ã„",
                "æ©Ÿå¯†æƒ…å ±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆHashiCorp Vaultç­‰ï¼‰ã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„"
            ])
        elif rule.rule_id == "SEC003":
            recommendations.extend([
                "SQLã‚¯ã‚¨ãƒªã«ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
                "ORMï¼ˆSQLAlchemyç­‰ï¼‰ã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
                "å…¥åŠ›å€¤ã®é©åˆ‡ãªæ¤œè¨¼ãƒ»ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„"
            ])
        elif rule.rule_id == "SEC004":
            recommendations.extend([
                "SHA-256ä»¥ä¸Šã®å¼·åŠ›ãªãƒãƒƒã‚·ãƒ¥ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
                "AES-256ç­‰ã®ç¾ä»£çš„ãªæš—å·åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
                "æš—å·åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆcryptographyç­‰ï¼‰ã®æœ€æ–°ç‰ˆã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„"
            ])
        
        return recommendations

class PerformanceValidator:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.performance_rules = self._load_performance_rules()
        
    def _load_performance_rules(self) -> List[ValidationRule]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ«ãƒ¼ãƒ«èª­ã¿è¾¼ã¿"""
        
        rules = [
            ValidationRule(
                rule_id="PERF001",
                category=ValidationCategory.PERFORMANCE,
                severity=ValidationSeverity.MEDIUM,
                name="éåŠ¹ç‡ãªãƒ«ãƒ¼ãƒ—ãƒ‘ã‚¿ãƒ¼ãƒ³",
                description="range(len())ç­‰ã®éåŠ¹ç‡ãªãƒ«ãƒ¼ãƒ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º",
                check_function="check_inefficient_loops",
                parameters={"patterns": [r"for\s+\w+\s+in\s+range\(len\(", r"while.*len\(.*\)"]},
                auto_fix_available=True
            ),
            
            ValidationRule(
                rule_id="PERF002",
                category=ValidationCategory.PERFORMANCE,
                severity=ValidationSeverity.LOW,
                name="å¤§é‡ã®ãƒ•ã‚¡ã‚¤ãƒ«I/O",
                description="ãƒ«ãƒ¼ãƒ—å†…ã§ã®ãƒ•ã‚¡ã‚¤ãƒ«I/Oç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã‚’æ¤œå‡º",
                check_function="check_file_io_patterns",
                parameters={"patterns": [r"for.*open\(", r"while.*open\("]},
                auto_fix_available=False
            ),
            
            ValidationRule(
                rule_id="PERF003",
                category=ValidationCategory.PERFORMANCE,
                severity=ValidationSeverity.HIGH,
                name="ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯å¯èƒ½æ€§",
                description="ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º",
                check_function="check_memory_leaks",
                parameters={"patterns": [r"global\s+\w+\s*=\s*\[\]", r".*\.append\(.*\)\s*$"]},
                enterprise_required=True
            ),
            
            ValidationRule(
                rule_id="PERF004",
                category=ValidationCategory.PERFORMANCE,
                severity=ValidationSeverity.MEDIUM,
                name="CPUé›†ç´„çš„å‡¦ç†",
                description="CPUé›†ç´„çš„ãªå‡¦ç†ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º",
                check_function="check_cpu_intensive",
                parameters={"time_threshold": 1.0},  # 1ç§’ä»¥ä¸Š
                threshold=1.0,
                timeout_seconds=30
            )
        ]
        
        return rules
    
    def validate_performance(self, file_paths: List[str]) -> List[ValidationResult]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼å®Ÿè¡Œ"""
        
        results = []
        
        for rule in self.performance_rules:
            print(f"âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯: {rule.name}")
            
            start_time = time.time()
            
            try:
                # æ¤œè¨¼é–¢æ•°å®Ÿè¡Œ
                check_method = getattr(self, rule.check_function)
                findings = check_method(file_paths, rule.parameters)
                
                execution_time = time.time() - start_time
                
                # çµæœåˆ¤å®š
                if findings:
                    status = ValidationStatus.WARNING
                    score = 0.7  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã¯è­¦å‘Šãƒ¬ãƒ™ãƒ«
                else:
                    status = ValidationStatus.PASSED
                    score = 1.0
                
                recommendations = self._generate_performance_recommendations(rule, findings)
                
                result = ValidationResult(
                    rule=rule,
                    status=status,
                    score=score,
                    execution_time=execution_time,
                    details={"files_checked": len(file_paths)},
                    findings=findings,
                    recommendations=recommendations,
                    timestamp=datetime.datetime.now().isoformat(),
                    auto_fix_applied=False,
                    manual_action_required=len(findings) > 0
                )
                
                results.append(result)
                
            except Exception as e:
                execution_time = time.time() - start_time
                
                result = ValidationResult(
                    rule=rule,
                    status=ValidationStatus.ERROR,
                    score=0.0,
                    execution_time=execution_time,
                    details={"error": str(e)},
                    findings=[f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}"],
                    recommendations=["æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ã®ç¢ºèªãŒå¿…è¦ã§ã™"],
                    timestamp=datetime.datetime.now().isoformat()
                )
                
                results.append(result)
        
        return results
    
    def check_inefficient_loops(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """éåŠ¹ç‡ãªãƒ«ãƒ¼ãƒ—ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯"""
        
        findings = []
        patterns = params.get("patterns", [])
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                for pattern in patterns:
                    matches = re.finditer(pattern, content)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        findings.append(f"{file_path}:{line_num} - éåŠ¹ç‡ãªãƒ«ãƒ¼ãƒ—: {match.group().strip()}")
                        
            except Exception as e:
                findings.append(f"{file_path} - èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return findings
    
    def check_file_io_patterns(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«I/Oãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯"""
        
        findings = []
        patterns = params.get("patterns", [])
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                for pattern in patterns:
                    matches = re.finditer(pattern, content)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        findings.append(f"{file_path}:{line_num} - ãƒ«ãƒ¼ãƒ—å†…ãƒ•ã‚¡ã‚¤ãƒ«I/O: {match.group().strip()}")
                        
            except Exception as e:
                findings.append(f"{file_path} - èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return findings
    
    def check_memory_leaks(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯"""
        
        findings = []
        patterns = params.get("patterns", [])
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                for pattern in patterns:
                    matches = re.finditer(pattern, content, re.MULTILINE)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        findings.append(f"{file_path}:{line_num} - ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯å¯èƒ½æ€§: {match.group().strip()}")
                        
            except Exception as e:
                findings.append(f"{file_path} - èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return findings
    
    def check_cpu_intensive(self, file_paths: List[str], params: Dict[str, Any]) -> List[str]:
        """CPUé›†ç´„çš„å‡¦ç†ãƒã‚§ãƒƒã‚¯"""
        
        findings = []
        time_threshold = params.get("time_threshold", 1.0)
        
        # CPUé›†ç´„çš„ãªå‡¦ç†ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
        cpu_patterns = [
            r"while\s+True:",
            r"for.*range\(\s*\d{4,}\s*\)",  # å¤§ããªrange
            r"time\.sleep\s*\(\s*[0-9]+\s*\)"   # é•·ã„sleep
        ]
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                import re
                for pattern in cpu_patterns:
                    matches = re.finditer(pattern, content)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        findings.append(f"{file_path}:{line_num} - CPUé›†ç´„çš„å‡¦ç†ç–‘ã„: {match.group().strip()}")
                        
            except Exception as e:
                findings.append(f"{file_path} - èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return findings
    
    def _generate_performance_recommendations(self, rule: ValidationRule, findings: List[str]) -> List[str]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        
        if not findings:
            return ["ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯åˆæ ¼"]
        
        recommendations = []
        
        if rule.rule_id == "PERF001":
            recommendations.extend([
                "enumerate() ã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨å€¤ã‚’åŒæ™‚ã«å–å¾—ã—ã¦ãã ã•ã„",
                "ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜ã‚„map(), filter()ã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
                "NumPyã‚„Pandasã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸæ“ä½œã‚’æ´»ç”¨ã—ã¦ãã ã•ã„"
            ])
        elif rule.rule_id == "PERF002":
            recommendations.extend([
                "ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€æ‹¬èª­ã¿è¾¼ã¿ãƒ»æ›¸ãè¾¼ã¿ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
                "withæ–‡ã‚’ä½¿ç”¨ã—ãŸãƒªã‚½ãƒ¼ã‚¹ç®¡ç†ã‚’å¾¹åº•ã—ã¦ãã ã•ã„",
                "ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ—ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„"
            ])
        elif rule.rule_id == "PERF003":
            recommendations.extend([
                "ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã®ä½¿ç”¨ã‚’æœ€å°é™ã«æŠ‘ãˆã¦ãã ã•ã„",
                "é©åˆ‡ãªã‚¹ã‚³ãƒ¼ãƒ—ã§ã®å¤‰æ•°å®šç¾©ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„",
                "ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å‹•ä½œã‚’ç†è§£ã—ã¦è¨­è¨ˆã—ã¦ãã ã•ã„"
            ])
        elif rule.rule_id == "PERF004":
            recommendations.extend([
                "éåŒæœŸå‡¦ç†ï¼ˆasync/awaitï¼‰ã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
                "ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚·ãƒ³ã‚°ãƒ»ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã®æ´»ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
                "å‡¦ç†ã®åˆ†å‰²ãƒ»ãƒãƒƒãƒåŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„"
            ])
        
        return recommendations

class IntegrationTestGenerator:
    """çµ±åˆãƒ†ã‚¹ãƒˆè‡ªå‹•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.test_templates = self._load_test_templates()
        
    def generate_integration_tests(self, file_paths: List[str]) -> List[ValidationResult]:
        """çµ±åˆãƒ†ã‚¹ãƒˆè‡ªå‹•ç”Ÿæˆãƒ»å®Ÿè¡Œ"""
        
        results = []
        
        for file_path in file_paths:
            if not file_path.endswith('.py'):
                continue
                
            print(f"ğŸ§ª çµ±åˆãƒ†ã‚¹ãƒˆç”Ÿæˆ: {file_path}")
            
            start_time = time.time()
            
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«è§£æ
                module_info = self._analyze_module(file_path)
                
                # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ
                test_cases = self._generate_test_cases(module_info)
                
                # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
                test_results = self._execute_tests(test_cases, file_path)
                
                execution_time = time.time() - start_time
                
                # çµæœè©•ä¾¡
                passed_tests = len([r for r in test_results if r["status"] == "passed"])
                total_tests = len(test_results)
                score = passed_tests / total_tests if total_tests > 0 else 1.0
                
                status = ValidationStatus.PASSED if score >= 0.8 else ValidationStatus.WARNING
                
                findings = []
                if score < 1.0:
                    failed_tests = [r for r in test_results if r["status"] != "passed"]
                    findings = [f"å¤±æ•—ãƒ†ã‚¹ãƒˆ: {t['name']} - {t['error']}" for t in failed_tests]
                
                result = ValidationResult(
                    rule=ValidationRule(
                        rule_id="INT001",
                        category=ValidationCategory.INTEGRATION,
                        severity=ValidationSeverity.MEDIUM,
                        name="çµ±åˆãƒ†ã‚¹ãƒˆ",
                        description="è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸçµ±åˆãƒ†ã‚¹ãƒˆ",
                        check_function="generate_integration_tests",
                        parameters={}
                    ),
                    status=status,
                    score=score,
                    execution_time=execution_time,
                    details={
                        "total_tests": total_tests,
                        "passed_tests": passed_tests,
                        "functions_tested": len(module_info.get("functions", [])),
                        "classes_tested": len(module_info.get("classes", []))
                    },
                    findings=findings,
                    recommendations=self._generate_test_recommendations(score, module_info),
                    timestamp=datetime.datetime.now().isoformat(),
                    metrics={"test_coverage": score}
                )
                
                results.append(result)
                
            except Exception as e:
                execution_time = time.time() - start_time
                
                result = ValidationResult(
                    rule=ValidationRule(
                        rule_id="INT001",
                        category=ValidationCategory.INTEGRATION,
                        severity=ValidationSeverity.MEDIUM,
                        name="çµ±åˆãƒ†ã‚¹ãƒˆ",
                        description="è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸçµ±åˆãƒ†ã‚¹ãƒˆ",
                        check_function="generate_integration_tests",
                        parameters={}
                    ),
                    status=ValidationStatus.ERROR,
                    score=0.0,
                    execution_time=execution_time,
                    details={"error": str(e)},
                    findings=[f"ãƒ†ã‚¹ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"],
                    recommendations=["ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ ã®ç¢ºèªãŒå¿…è¦ã§ã™"],
                    timestamp=datetime.datetime.now().isoformat()
                )
                
                results.append(result)
        
        return results
    
    def _analyze_module(self, file_path: str) -> Dict[str, Any]:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è§£æ"""
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ASTè§£æ
            tree = ast.parse(content)
            
            functions = []
            classes = []
            imports = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    functions.append({
                        "name": node.name,
                        "args": [arg.arg for arg in node.args.args],
                        "returns": ast.get_source_segment(content, node.returns) if node.returns else None,
                        "is_public": not node.name.startswith('_')
                    })
                elif isinstance(node, ast.ClassDef):
                    methods = [n.name for n in node.body if isinstance(n, ast.FunctionDef)]
                    classes.append({
                        "name": node.name,
                        "methods": methods,
                        "is_public": not node.name.startswith('_')
                    })
                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    if isinstance(node, ast.Import):
                        imports.extend([alias.name for alias in node.names])
                    else:
                        imports.append(node.module)
            
            return {
                "file_path": file_path,
                "functions": functions,
                "classes": classes,
                "imports": imports,
                "has_main": "if __name__ == '__main__':" in content
            }
            
        except Exception as e:
            print(f"âš ï¸ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return {"file_path": file_path, "functions": [], "classes": [], "imports": []}
    
    def _generate_test_cases(self, module_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ"""
        
        test_cases = []
        
        # é–¢æ•°ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ
        for func in module_info.get("functions", []):
            if func["is_public"]:
                test_cases.append({
                    "type": "function",
                    "name": f"test_{func['name']}",
                    "target": func["name"],
                    "test_code": self._generate_function_test(func)
                })
        
        # ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆ
        for cls in module_info.get("classes", []):
            if cls["is_public"]:
                test_cases.append({
                    "type": "class",
                    "name": f"test_{cls['name']}",
                    "target": cls["name"],
                    "test_code": self._generate_class_test(cls)
                })
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
        if module_info.get("imports"):
            test_cases.append({
                "type": "import",
                "name": "test_imports",
                "target": "imports",
                "test_code": self._generate_import_test(module_info["imports"])
            })
        
        return test_cases
    
    def _generate_function_test(self, func_info: Dict[str, Any]) -> str:
        """é–¢æ•°ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ç”Ÿæˆ"""
        
        func_name = func_info["name"]
        args = func_info["args"]
        
        # ç°¡å˜ãªãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
        test_args = []
        for arg in args:
            if arg == "self":
                continue
            elif "file" in arg.lower() or "path" in arg.lower():
                test_args.append("'test_file.txt'")
            elif "num" in arg.lower() or "count" in arg.lower():
                test_args.append("10")
            elif "str" in arg.lower() or "text" in arg.lower():
                test_args.append("'test_string'")
            else:
                test_args.append("None")
        
        args_str = ", ".join(test_args)
        
        return f"""
def test_{func_name}():
    \"\"\"è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚¹ãƒˆ: {func_name}\"\"\"
    try:
        result = {func_name}({args_str})
        assert result is not None, "é–¢æ•°ã¯å€¤ã‚’è¿”ã™ã¹ãã§ã™"
        return True
    except Exception as e:
        print(f"ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {{e}}")
        return False
"""
    
    def _generate_class_test(self, class_info: Dict[str, Any]) -> str:
        """ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ç”Ÿæˆ"""
        
        class_name = class_info["name"]
        
        return f"""
def test_{class_name}():
    \"\"\"è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚¹ãƒˆ: {class_name}\"\"\"
    try:
        instance = {class_name}()
        assert instance is not None, "ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ãŒã§ãã‚‹ã¹ãã§ã™"
        return True
    except Exception as e:
        print(f"ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {{e}}")
        return False
"""
    
    def _generate_import_test(self, imports: List[str]) -> str:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ç”Ÿæˆ"""
        
        import_statements = []
        for imp in imports:
            if imp:
                import_statements.append(f"import {imp}")
        
        imports_str = "; ".join(import_statements)
        
        return f"""
def test_imports():
    \"\"\"è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚¹ãƒˆ: ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\"\"\"
    try:
        {imports_str}
        return True
    except ImportError as e:
        print(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {{e}}")
        return False
"""
    
    def _execute_tests(self, test_cases: List[Dict[str, Any]], module_path: str) -> List[Dict[str, Any]]:
        """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        
        results = []
        
        # ä¸€æ™‚ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as temp_file:
            temp_file.write(f"import sys\n")
            temp_file.write(f"sys.path.append('{os.path.dirname(module_path)}')\n")
            temp_file.write(f"from {os.path.splitext(os.path.basename(module_path))[0]} import *\n\n")
            
            for test_case in test_cases:
                temp_file.write(test_case["test_code"])
                temp_file.write("\n")
            
            # ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨åˆ†
            temp_file.write("\nif __name__ == '__main__':\n")
            for test_case in test_cases:
                temp_file.write(f"    print('{test_case['name']}:', {test_case['name']}())\n")
            
            temp_file_path = temp_file.name
        
        try:
            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            result = subprocess.run(
                ["python3", temp_file_path],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            # çµæœè§£æ
            if result.returncode == 0:
                output_lines = result.stdout.strip().split('\n')
                for line in output_lines:
                    if ':' in line:
                        test_name, test_result = line.split(':', 1)
                        status = "passed" if "True" in test_result else "failed"
                        results.append({
                            "name": test_name.strip(),
                            "status": status,
                            "output": test_result.strip(),
                            "error": None
                        })
            else:
                # ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
                for test_case in test_cases:
                    results.append({
                        "name": test_case["name"],
                        "status": "error",
                        "output": "",
                        "error": result.stderr
                    })
            
        except subprocess.TimeoutExpired:
            for test_case in test_cases:
                results.append({
                    "name": test_case["name"],
                    "status": "timeout",
                    "output": "",
                    "error": "ãƒ†ã‚¹ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ"
                })
        
        except Exception as e:
            for test_case in test_cases:
                results.append({
                    "name": test_case["name"],
                    "status": "error",
                    "output": "",
                    "error": str(e)
                })
        
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            try:
                os.unlink(temp_file_path)
            except:
                pass
        
        return results
    
    def _generate_test_recommendations(self, score: float, module_info: Dict[str, Any]) -> List[str]:
        """ãƒ†ã‚¹ãƒˆæ¨å¥¨äº‹é …ç”Ÿæˆ"""
        
        recommendations = []
        
        if score < 0.5:
            recommendations.append("ãƒ†ã‚¹ãƒˆãŒå¤šæ•°å¤±æ•—ã—ã¦ã„ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã®åŸºæœ¬æ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        elif score < 0.8:
            recommendations.append("ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¦ã„ã¾ã™ã€‚ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        else:
            recommendations.append("åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆã¯é€šéã—ã¦ã„ã¾ã™")
        
        if len(module_info.get("functions", [])) > 10:
            recommendations.append("é–¢æ•°ãŒå¤šæ•°ã‚ã‚Šã¾ã™ã€‚å˜ä½“ãƒ†ã‚¹ãƒˆã®ä½œæˆã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if len(module_info.get("classes", [])) > 5:
            recommendations.append("ã‚¯ãƒ©ã‚¹ãŒå¤šæ•°ã‚ã‚Šã¾ã™ã€‚çµ±åˆãƒ†ã‚¹ãƒˆã®è©³ç´°åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        return recommendations
    
    def _load_test_templates(self) -> Dict[str, str]:
        """ãƒ†ã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿"""
        # åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        return {
            "function": "åŸºæœ¬é–¢æ•°ãƒ†ã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ",
            "class": "åŸºæœ¬ã‚¯ãƒ©ã‚¹ãƒ†ã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ",
            "integration": "çµ±åˆãƒ†ã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ"
        }

class ComprehensiveQualityValidator:
    """åŒ…æ‹¬çš„å“è³ªæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.security_validator = SecurityValidator()
        self.performance_validator = PerformanceValidator()
        self.integration_test_generator = IntegrationTestGenerator()
        
        self.data_dir = Path("postbox/quality/comprehensive")
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        self.results_path = self.data_dir / "validation_results.json"
        self.summary_path = self.data_dir / "validation_summary.json"
        
        print("ğŸ” ComprehensiveQualityValidator åˆæœŸåŒ–å®Œäº†")
    
    def validate_comprehensive_quality(self, file_paths: List[str], 
                                     enterprise_mode: bool = False,
                                     categories: Optional[List[ValidationCategory]] = None) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„å“è³ªæ¤œè¨¼å®Ÿè¡Œ"""
        
        print(f"ğŸ” åŒ…æ‹¬çš„å“è³ªæ¤œè¨¼é–‹å§‹: {len(file_paths)}ãƒ•ã‚¡ã‚¤ãƒ«")
        if enterprise_mode:
            print("ğŸ¢ ä¼æ¥­ãƒ¬ãƒ™ãƒ«å“è³ªåŸºæº–é©ç”¨")
        
        start_time = time.time()
        all_results = []
        
        # ã‚«ãƒ†ã‚´ãƒªé¸æŠ
        if categories is None:
            categories = [ValidationCategory.SECURITY, ValidationCategory.PERFORMANCE, ValidationCategory.INTEGRATION]
        
        # ä¸¦åˆ—å®Ÿè¡Œã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            futures = {}
            
            if ValidationCategory.SECURITY in categories:
                futures["security"] = executor.submit(self.security_validator.validate_security, file_paths)
            
            if ValidationCategory.PERFORMANCE in categories:
                futures["performance"] = executor.submit(self.performance_validator.validate_performance, file_paths)
            
            if ValidationCategory.INTEGRATION in categories:
                futures["integration"] = executor.submit(self.integration_test_generator.generate_integration_tests, file_paths)
            
            # çµæœå–å¾—
            category_results = {}
            for category, future in futures.items():
                try:
                    results = future.result(timeout=300)  # 5åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                    category_results[category] = results
                    all_results.extend(results)
                    print(f"âœ… {category} æ¤œè¨¼å®Œäº†: {len(results)}ä»¶")
                except concurrent.futures.TimeoutError:
                    print(f"â° {category} æ¤œè¨¼ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
                    category_results[category] = []
                except Exception as e:
                    print(f"âŒ {category} æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
                    category_results[category] = []
        
        total_execution_time = time.time() - start_time
        
        # ç·åˆè©•ä¾¡
        summary = self._generate_comprehensive_summary(all_results, enterprise_mode, total_execution_time)
        
        # çµæœä¿å­˜
        self._save_validation_results(all_results, summary)
        
        return {
            "summary": summary,
            "results_by_category": category_results,
            "all_results": all_results,
            "execution_time": total_execution_time
        }
    
    def _generate_comprehensive_summary(self, results: List[ValidationResult], 
                                      enterprise_mode: bool, execution_time: float) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        
        if not results:
            return {
                "overall_status": ValidationStatus.ERROR.value,
                "overall_score": 0.0,
                "message": "æ¤œè¨¼çµæœãªã—"
            }
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
        category_scores = {}
        category_status = {}
        
        for category in ValidationCategory:
            category_results = [r for r in results if r.rule.category == category]
            if category_results:
                scores = [r.score for r in category_results]
                category_scores[category.value] = sum(scores) / len(scores)
                
                # æœ€ã‚‚å³ã—ã„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ¡ç”¨
                statuses = [r.status for r in category_results]
                if ValidationStatus.FAILED in statuses:
                    category_status[category.value] = ValidationStatus.FAILED.value
                elif ValidationStatus.ERROR in statuses:
                    category_status[category.value] = ValidationStatus.ERROR.value
                elif ValidationStatus.WARNING in statuses:
                    category_status[category.value] = ValidationStatus.WARNING.value
                else:
                    category_status[category.value] = ValidationStatus.PASSED.value
        
        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆé‡ã¿ä»˜ãï¼‰
        weights = {
            ValidationCategory.SECURITY.value: 0.4,
            ValidationCategory.PERFORMANCE.value: 0.3,
            ValidationCategory.INTEGRATION.value: 0.3
        }
        
        weighted_score = 0.0
        total_weight = 0.0
        
        for category, score in category_scores.items():
            weight = weights.get(category, 0.2)
            weighted_score += score * weight
            total_weight += weight
        
        overall_score = weighted_score / total_weight if total_weight > 0 else 0.0
        
        # ä¼æ¥­ãƒ¬ãƒ™ãƒ«å“è³ªåŸºæº–é©ç”¨
        if enterprise_mode:
            enterprise_threshold = 0.9
            overall_status = ValidationStatus.PASSED if overall_score >= enterprise_threshold else ValidationStatus.FAILED
        else:
            if overall_score >= 0.8:
                overall_status = ValidationStatus.PASSED
            elif overall_score >= 0.6:
                overall_status = ValidationStatus.WARNING
            else:
                overall_status = ValidationStatus.FAILED
        
        # çµ±è¨ˆ
        total_rules = len(results)
        passed_rules = len([r for r in results if r.status == ValidationStatus.PASSED])
        failed_rules = len([r for r in results if r.status == ValidationStatus.FAILED])
        warning_rules = len([r for r in results if r.status == ValidationStatus.WARNING])
        
        # æ¨å¥¨äº‹é …
        recommendations = self._generate_comprehensive_recommendations(
            results, overall_score, enterprise_mode
        )
        
        return {
            "overall_status": overall_status.value,
            "overall_score": overall_score,
            "enterprise_mode": enterprise_mode,
            "execution_time": execution_time,
            "category_scores": category_scores,
            "category_status": category_status,
            "statistics": {
                "total_rules": total_rules,
                "passed_rules": passed_rules,
                "failed_rules": failed_rules,
                "warning_rules": warning_rules,
                "success_rate": passed_rules / total_rules if total_rules > 0 else 0.0
            },
            "recommendations": recommendations,
            "timestamp": datetime.datetime.now().isoformat()
        }
    
    def _generate_comprehensive_recommendations(self, results: List[ValidationResult], 
                                             overall_score: float, enterprise_mode: bool) -> List[str]:
        """åŒ…æ‹¬çš„æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        
        recommendations = []
        
        # ç·åˆã‚¹ã‚³ã‚¢ã«åŸºã¥ãæ¨å¥¨äº‹é …
        if overall_score < 0.5:
            recommendations.append("å“è³ªãŒåŸºæº–ã‚’å¤§å¹…ã«ä¸‹å›ã£ã¦ã„ã¾ã™ã€‚ç·Šæ€¥ã®æ”¹å–„ãŒå¿…è¦ã§ã™")
        elif overall_score < 0.7:
            recommendations.append("å“è³ªæ”¹å–„ãŒå¿…è¦ã§ã™ã€‚é‡è¦ãªå•é¡Œã‹ã‚‰å„ªå…ˆçš„ã«å¯¾å¿œã—ã¦ãã ã•ã„")
        elif overall_score < 0.9:
            recommendations.append("åŸºæœ¬çš„ãªå“è³ªã¯ç¢ºä¿ã•ã‚Œã¦ã„ã¾ã™ã€‚ç´°ã‹ã„æ”¹å–„ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„")
        else:
            recommendations.append("å„ªç§€ãªå“è³ªãƒ¬ãƒ™ãƒ«ã§ã™ã€‚ç¾åœ¨ã®æ°´æº–ã‚’ç¶­æŒã—ã¦ãã ã•ã„")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥æ¨å¥¨äº‹é …
        security_results = [r for r in results if r.rule.category == ValidationCategory.SECURITY]
        if any(r.status == ValidationStatus.FAILED for r in security_results):
            recommendations.append("ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚æ—©æ€¥ãªå¯¾å¿œãŒå¿…è¦ã§ã™")
        
        performance_results = [r for r in results if r.rule.category == ValidationCategory.PERFORMANCE]
        if any(r.status == ValidationStatus.WARNING for r in performance_results):
            recommendations.append("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚æœ€é©åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        integration_results = [r for r in results if r.rule.category == ValidationCategory.INTEGRATION]
        if any(r.status == ValidationStatus.FAILED for r in integration_results):
            recommendations.append("çµ±åˆãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¦ã„ã¾ã™ã€‚ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé–“ã®é€£æºã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
        # ä¼æ¥­ãƒ¢ãƒ¼ãƒ‰å›ºæœ‰ã®æ¨å¥¨äº‹é …
        if enterprise_mode and overall_score < 0.9:
            recommendations.append("ä¼æ¥­ãƒ¬ãƒ™ãƒ«å“è³ªåŸºæº–ã«åˆ°é”ã—ã¦ã„ã¾ã›ã‚“ã€‚ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è¦ä»¶ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
        return recommendations
    
    def _save_validation_results(self, results: List[ValidationResult], summary: Dict[str, Any]) -> None:
        """æ¤œè¨¼çµæœä¿å­˜"""
        
        try:
            # è©³ç´°çµæœä¿å­˜ï¼ˆæœ€æ–°ã®ã¿ï¼‰
            results_data = []
            for result in results:
                result_dict = asdict(result)
                # ValidationRuleå†…ã®Enumå€¤ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
                result_dict["rule"]["category"] = result.rule.category.value
                result_dict["rule"]["severity"] = result.rule.severity.value
                result_dict["status"] = result.status.value
                results_data.append(result_dict)
            
            with open(self.results_path, 'w', encoding='utf-8') as f:
                json.dump(results_data, f, indent=2, ensure_ascii=False)
            
            # ã‚µãƒãƒªãƒ¼å±¥æ­´ä¿å­˜
            summaries = []
            if self.summary_path.exists():
                with open(self.summary_path, 'r', encoding='utf-8') as f:
                    summaries = json.load(f)
            
            summaries.append(summary)
            
            # å±¥æ­´ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆæœ€æ–°100ä»¶ï¼‰
            if len(summaries) > 100:
                summaries = summaries[-100:]
            
            with open(self.summary_path, 'w', encoding='utf-8') as f:
                json.dump(summaries, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ“Š æ¤œè¨¼çµæœä¿å­˜å®Œäº†: {self.results_path}")
            
        except Exception as e:
            print(f"âš ï¸ çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸ§ª ComprehensiveQualityValidator ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    validator = ComprehensiveQualityValidator()
    
    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
    test_files = [
        "kumihan_formatter/core/utilities/logger.py",
        "postbox/quality/quality_manager.py"
    ]
    
    # åŒ…æ‹¬çš„å“è³ªæ¤œè¨¼å®Ÿè¡Œ
    print("\n=== åŸºæœ¬å“è³ªæ¤œè¨¼ ===")
    result = validator.validate_comprehensive_quality(test_files)
    
    summary = result["summary"]
    print(f"\nğŸ“Š æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼:")
    print(f"   ç·åˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {summary['overall_status']}")
    print(f"   ç·åˆã‚¹ã‚³ã‚¢: {summary['overall_score']:.3f}")
    print(f"   å®Ÿè¡Œæ™‚é–“: {summary['execution_time']:.2f}ç§’")
    print(f"   æˆåŠŸç‡: {summary['statistics']['success_rate']:.1%}")
    
    # ä¼æ¥­ãƒ¬ãƒ™ãƒ«å“è³ªæ¤œè¨¼
    print("\n=== ä¼æ¥­ãƒ¬ãƒ™ãƒ«å“è³ªæ¤œè¨¼ ===")
    enterprise_result = validator.validate_comprehensive_quality(
        test_files, 
        enterprise_mode=True
    )
    
    enterprise_summary = enterprise_result["summary"]
    print(f"   ä¼æ¥­ãƒ¬ãƒ™ãƒ«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {enterprise_summary['overall_status']}")
    print(f"   ä¼æ¥­ãƒ¬ãƒ™ãƒ«ã‚¹ã‚³ã‚¢: {enterprise_summary['overall_score']:.3f}")
    
    # æ¨å¥¨äº‹é …è¡¨ç¤º
    if summary.get("recommendations"):
        print(f"\nğŸ’¡ æ¨å¥¨äº‹é …:")
        for rec in summary["recommendations"][:3]:
            print(f"   - {rec}")
    
    print("âœ… ComprehensiveQualityValidator ãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    main()