"""Document Classification System
æ–‡æ›¸åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ  - Issue #118å¯¾å¿œ
ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã¨é–‹ç™ºè€…å‘ã‘æ–‡æ›¸ã‚’é©åˆ‡ã«åˆ†é¡ãƒ»å‡¦ç†ã™ã‚‹
"""

from pathlib import Path

from .classification_rules import build_classification_rules, get_conversion_strategies
from .document_types import DocumentType, get_type_display_names

__all__ = ["DocumentClassifier", "DocumentType"]


class DocumentClassifier:
    """æ–‡æ›¸åˆ†é¡å™¨
    ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦æ–‡æ›¸ã‚’é©åˆ‡ã«åˆ†é¡ã™ã‚‹
    """

    def __init__(self) -> None:
        """åˆ†é¡å™¨ã‚’åˆæœŸåŒ–"""
        self.classification_rules = build_classification_rules()

    def classify_file(self, file_path: Path, base_path: Path) -> DocumentType:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†é¡
        Args:
            file_path: åˆ†é¡ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            base_path: ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
        Returns:
            DocumentType: åˆ†é¡çµæœ
        """
        # ãƒ‘ã‚¹ãƒ™ãƒ¼ã‚¹åˆ†é¡ãƒ«ãƒ¼ãƒ«å®Ÿè£…
        import os

        ext = os.path.splitext(file_path.name)[1].lower()
        # æ‹¡å¼µå­ã«ã‚ˆã‚‹åˆ†é¡
        if ext in [".md", ".markdown"]:
            return (
                DocumentType.MARKDOWN
                if hasattr(DocumentType, "MARKDOWN")
                else DocumentType.GENERAL
            )
        elif ext in [".txt"]:
            return (
                DocumentType.TEXT
                if hasattr(DocumentType, "TEXT")
                else DocumentType.GENERAL
            )

        filename = file_path.name.lower()
        # ãƒ•ã‚¡ã‚¤ãƒ«åã«ã‚ˆã‚‹ç›´æ¥ãƒãƒƒãƒãƒ³ã‚°ï¼ˆæœ€é«˜å„ªå…ˆåº¦ï¼‰
        for doc_type, rules in self.classification_rules.items():
            if "filenames" in rules:
                for target_filename in rules["filenames"]:
                    if filename == target_filename.lower():
                        return doc_type

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ†é¡
        return DocumentType.GENERAL

    def classify_directory(self, directory: Path) -> dict[DocumentType, list[Path]]:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬åˆ†é¡
        Args:
            directory: åˆ†é¡ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        Returns:
            Dict: åˆ†é¡çµæœï¼ˆã‚¿ã‚¤ãƒ—åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆï¼‰
        """
        result = {doc_type: [] for doc_type in DocumentType}  # type: ignore
        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ­ãƒ¼ãƒ‰
        exclude_patterns = self._load_exclude_patterns(directory)
        for file_path in directory.rglob("*"):
            if file_path.is_file():
                # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
                if self._should_exclude_by_patterns(
                    file_path, directory, exclude_patterns
                ):
                    continue
                doc_type = self.classify_file(file_path, directory)
                result[doc_type].append(file_path)
        return result

    def _load_exclude_patterns(self, directory: Path) -> list[str]:
        """é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’.distignoreã‹ã‚‰èª­ã¿è¾¼ã¿"""
        distignore_file = directory / ".distignore"
        patterns = []
        if distignore_file.exists():
            try:
                with open(distignore_file, "r", encoding="utf-8") as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith("#"):
                            patterns.append(line)
            except Exception:
                pass  # ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
        return patterns

    def _should_exclude_by_patterns(
        self, file_path: Path, base_path: Path, patterns: list[str]
    ) -> bool:
        """é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹ãƒã‚§ãƒƒã‚¯"""
        # çµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµŒç”±ã§å®Ÿè¡Œ
        from .file_path_utilities import FilePathUtilities

        return FilePathUtilities.should_exclude(file_path, patterns, base_path)

    def get_conversion_strategy(self, doc_type: DocumentType) -> tuple[str, str]:
        """æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã«å¯¾ã™ã‚‹å¤‰æ›æˆ¦ç•¥ã‚’å–å¾—
        Args:
            doc_type: æ–‡æ›¸ã‚¿ã‚¤ãƒ—
        Returns:
            tuple[str, str]: (å¤‰æ›æ–¹æ³•, å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª)
        """
        strategies = get_conversion_strategies()
        return strategies.get(doc_type, ("exclude", ""))

    def generate_document_summary(
        self, classified_files: dict[DocumentType, list[Path]]
    ) -> str:
        """åˆ†é¡çµæœã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        summary_lines = ["ğŸ“š æ–‡æ›¸åˆ†é¡çµæœ", "=" * 40, ""]
        type_names = get_type_display_names()
        for doc_type, files in classified_files.items():
            if files:
                summary_lines.append(
                    f"{type_names.get(doc_type, str(doc_type))} ({len(files)}ä»¶)"
                )
                for file_path in sorted(files)[:5]:  # æœ€åˆã®5ä»¶ã®ã¿è¡¨ç¤º
                    summary_lines.append(f"  - {file_path}")
                if len(files) > 5:
                    summary_lines.append(f"  ... ä»–{len(files) - 5}ä»¶")
                summary_lines.append("")
        return "\n".join(summary_lines)


def classify_document(file_path: Path, base_path: Path) -> DocumentType:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†é¡ï¼ˆå¤–éƒ¨APIï¼‰
    Args:
        file_path: åˆ†é¡ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
        base_path: ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    Returns:
        DocumentType: åˆ†é¡çµæœ
    """
    classifier = DocumentClassifier()
    return classifier.classify_file(file_path, base_path)


def classify_project_documents(project_dir: Path) -> dict[DocumentType, list[Path]]:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ–‡æ›¸ã‚’ä¸€æ‹¬åˆ†é¡ï¼ˆå¤–éƒ¨APIï¼‰
    Args:
        project_dir: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    Returns:
        Dict: åˆ†é¡çµæœ
    """
    classifier = DocumentClassifier()
    return classifier.classify_directory(project_dir)
