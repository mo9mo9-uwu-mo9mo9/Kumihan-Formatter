#!/usr/bin/env python3
"""
Issue #759å¯¾å¿œ: å¤§è¦æ¨¡ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

ä¸¦åˆ—å‡¦ç†Ã—çœŸã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµ±åˆå®Ÿè£…ã®æ€§èƒ½æ¸¬å®š
ç›®æ¨™: 300Kè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã‚’23.41ç§’ â†’ 5ç§’ä»¥ä¸‹ (78.6%æ”¹å–„)
"""

import time
import traceback
from pathlib import Path
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent))

from kumihan_formatter.parser import Parser
from kumihan_formatter.core.utilities.logger import get_logger


class PerformanceBenchmark:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.logger = get_logger(__name__)
        self.results = {}
        
    def run_comprehensive_benchmark(self):
        """åŒ…æ‹¬çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        
        print("=" * 80)
        print("Issue #759: å¤§è¦æ¨¡ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç† ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        print("=" * 80)
        print(f"ç›®æ¨™: 300Kè¡Œãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ™‚é–“ 23.41ç§’ â†’ 5ç§’ä»¥ä¸‹ (78.6%æ”¹å–„)")
        print()
        
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å®šç¾©
        test_files = [
            ("1k_test_file.kumihan", "1Kè¡Œ", "baseline"),
            ("10k_test_file.kumihan", "10Kè¡Œ", "medium"),
            ("50k_test_file.kumihan", "50Kè¡Œ", "large"),
            ("300k_test_file.kumihan", "300Kè¡Œ", "target")
        ]
        
        # ãƒ‘ãƒ¼ã‚µãƒ¼æ–¹å¼å®šç¾©
        parsing_methods = [
            ("traditional", "å¾“æ¥æ–¹å¼", self.test_traditional_parse),
            ("optimized", "æœ€é©åŒ–ç‰ˆ", self.test_optimized_parse),
            ("streaming", "ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°", self.test_streaming_parse),
            ("parallel_streaming", "ä¸¦åˆ—ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°", self.test_parallel_streaming),
            ("hybrid", "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰", self.test_hybrid_parse)
        ]
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
        for file_path, file_desc, file_category in test_files:
            if not Path(file_path).exists():
                print(f"âš ï¸  ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹: {file_path}")
                continue
                
            print(f"\nğŸ“ {file_desc} ãƒ•ã‚¡ã‚¤ãƒ«: {file_path}")
            print("-" * 60)
            
            file_size = Path(file_path).stat().st_size / 1024 / 1024  # MB
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.1f} MB")
            
            file_results = {}
            
            for method_id, method_name, test_func in parsing_methods:
                try:
                    print(f"\nğŸ”„ {method_name} ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
                    
                    result = test_func(file_path)
                    file_results[method_id] = result
                    
                    # çµæœè¡¨ç¤º
                    self.display_result(method_name, result)
                    
                    # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
                    import gc
                    gc.collect()
                    
                except Exception as e:
                    print(f"âŒ {method_name} ã‚¨ãƒ©ãƒ¼: {e}")
                    self.logger.error(f"Benchmark error in {method_name}: {e}")
                    file_results[method_id] = {"error": str(e)}
            
            self.results[file_path] = file_results
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
            self.analyze_file_performance(file_desc, file_results)
        
        # å…¨ä½“çµæœåˆ†æ
        self.generate_comprehensive_report()

    def test_traditional_parse(self, file_path: str) -> dict:
        """å¾“æ¥æ–¹å¼ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        start_memory = self.get_memory_usage()
        
        parser = Parser()
        
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
            
        nodes = list(parser.parse(content))
        
        end_time = time.time()
        end_memory = self.get_memory_usage()
        
        return {
            "method": "traditional",
            "duration": end_time - start_time,
            "nodes_count": len(nodes),
            "memory_start": start_memory,
            "memory_end": end_memory,
            "memory_delta": end_memory - start_memory
        }

    def test_optimized_parse(self, file_path: str) -> dict:
        """æœ€é©åŒ–ç‰ˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        start_memory = self.get_memory_usage()
        
        parser = Parser()
        
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
            
        nodes = list(parser.parse_optimized(content))
        
        end_time = time.time()
        end_memory = self.get_memory_usage()
        
        return {
            "method": "optimized",
            "duration": end_time - start_time,
            "nodes_count": len(nodes),
            "memory_start": start_memory,
            "memory_end": end_memory,
            "memory_delta": end_memory - start_memory
        }

    def test_streaming_parse(self, file_path: str) -> dict:
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç‰ˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        start_memory = self.get_memory_usage()
        
        parser = Parser()
        
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
            
        nodes = list(parser.parse_streaming_from_text(content))
        
        end_time = time.time()
        end_memory = self.get_memory_usage()
        
        return {
            "method": "streaming",
            "duration": end_time - start_time,
            "nodes_count": len(nodes),
            "memory_start": start_memory,
            "memory_end": end_memory,
            "memory_delta": end_memory - start_memory
        }

    def test_parallel_streaming(self, file_path: str) -> dict:
        """ä¸¦åˆ—ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç‰ˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        start_memory = self.get_memory_usage()
        
        parser = Parser()
        
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
            
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æƒ…å ±ã‚’åé›†
        progress_info = []
        def progress_callback(info):
            progress_info.append(info)
            
        nodes = list(parser.parse_parallel_streaming(content, progress_callback))
        
        end_time = time.time()
        end_memory = self.get_memory_usage()
        
        return {
            "method": "parallel_streaming",
            "duration": end_time - start_time,
            "nodes_count": len(nodes),
            "memory_start": start_memory,
            "memory_end": end_memory,
            "memory_delta": end_memory - start_memory,
            "progress_updates": len(progress_info)
        }

    def test_hybrid_parse(self, file_path: str) -> dict:
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç‰ˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        start_memory = self.get_memory_usage()
        
        parser = Parser()
        
        nodes = list(parser.parse_hybrid_optimized(file_path))
        
        end_time = time.time()
        end_memory = self.get_memory_usage()
        
        return {
            "method": "hybrid",
            "duration": end_time - start_time,
            "nodes_count": len(nodes),
            "memory_start": start_memory,
            "memory_end": end_memory,
            "memory_delta": end_memory - start_memory
        }

    def get_memory_usage(self) -> float:
        """ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’MBã§å–å¾—"""
        try:
            import psutil
            process = psutil.Process()
            return process.memory_info().rss / 1024 / 1024  # MB
        except ImportError:
            return 0.0  # psutilæœªåˆ©ç”¨ç’°å¢ƒ

    def display_result(self, method_name: str, result: dict):
        """çµæœè¡¨ç¤º"""
        if "error" in result:
            print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
            return
            
        duration = result['duration']
        nodes = result['nodes_count']
        memory_delta = result.get('memory_delta', 0)
        
        print(f"   â±ï¸  å‡¦ç†æ™‚é–“: {duration:.2f}ç§’")
        print(f"   ğŸ“Š ãƒãƒ¼ãƒ‰æ•°: {nodes:,}")
        print(f"   ğŸ’¾ ãƒ¡ãƒ¢ãƒªå·®åˆ†: {memory_delta:.1f}MB")
        print(f"   âš¡ å‡¦ç†é€Ÿåº¦: {nodes/duration:.0f} nodes/sec")

    def analyze_file_performance(self, file_desc: str, results: dict):
        """ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        print(f"\nğŸ“ˆ {file_desc} ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ:")
        print("-" * 40)
        
        # ã‚¨ãƒ©ãƒ¼ã®ãªã„çµæœã®ã¿ã‚’åˆ†æ
        valid_results = {k: v for k, v in results.items() if "error" not in v}
        
        if not valid_results:
            print("   âš ï¸  æœ‰åŠ¹ãªçµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
            
        # æœ€é€Ÿãƒ»æœ€é…ã®ç‰¹å®š
        fastest = min(valid_results.items(), key=lambda x: x[1]['duration'])
        slowest = max(valid_results.items(), key=lambda x: x[1]['duration'])
        
        print(f"   ğŸ† æœ€é€Ÿ: {fastest[0]} ({fastest[1]['duration']:.2f}ç§’)")
        print(f"   ğŸŒ æœ€é…: {slowest[0]} ({slowest[1]['duration']:.2f}ç§’)")
        
        # æ”¹å–„ç‡è¨ˆç®—
        if len(valid_results) >= 2:
            improvement = (slowest[1]['duration'] - fastest[1]['duration']) / slowest[1]['duration'] * 100
            print(f"   ğŸ“Š æœ€å¤§æ”¹å–„ç‡: {improvement:.1f}%")

    def generate_comprehensive_report(self):
        """åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\n" + "=" * 80)
        print("ğŸ“‹ ç·åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 80)
        
        # 300Kè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã®çµæœã«ç„¦ç‚¹
        target_file = "300k_test_file.kumihan"
        if target_file in self.results:
            target_results = self.results[target_file]
            print(f"\nğŸ¯ 300Kè¡Œãƒ•ã‚¡ã‚¤ãƒ« (ç›®æ¨™ãƒ•ã‚¡ã‚¤ãƒ«) çµæœ:")
            print("-" * 50)
            
            baseline_time = 23.41  # å¾“æ¥ã®å‡¦ç†æ™‚é–“
            
            for method, result in target_results.items():
                if "error" in result:
                    continue
                    
                duration = result['duration']
                improvement = (baseline_time - duration) / baseline_time * 100
                
                print(f"   {method:20}: {duration:6.2f}ç§’ ({improvement:+5.1f}%)")
                
                # ç›®æ¨™é”æˆãƒã‚§ãƒƒã‚¯
                if duration <= 5.0:
                    print(f"      âœ… ç›®æ¨™é”æˆï¼ (5ç§’ä»¥ä¸‹)")
                else:
                    remaining = (duration - 5.0) / duration * 100
                    print(f"      â³ ç›®æ¨™ã¾ã§: {remaining:.1f}%æ”¹å–„ãŒå¿…è¦")
        
        # å…¨ä½“çš„ãªå‚¾å‘åˆ†æ
        print(f"\nğŸ“Š å…¨ä½“å‚¾å‘:")
        print("-" * 30)
        
        method_performance = {}
        for file_path, file_results in self.results.items():
            for method, result in file_results.items():
                if "error" not in result:
                    if method not in method_performance:
                        method_performance[method] = []
                    method_performance[method].append(result['duration'])
        
        for method, durations in method_performance.items():
            avg_duration = sum(durations) / len(durations)
            print(f"   {method:20}: å¹³å‡ {avg_duration:.2f}ç§’")
        
        print(f"\nğŸ‰ Issue #759 å®Ÿè£…å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ!")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    
    # å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    required_files = [
        "1k_test_file.kumihan",
        "10k_test_file.kumihan", 
        "50k_test_file.kumihan",
        "300k_test_file.kumihan"
    ]
    
    missing_files = [f for f in required_files if not Path(f).exists()]
    if missing_files:
        print("âŒ å¿…è¦ãªãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:")
        for f in missing_files:
            print(f"   - {f}")
        print("\nå…ˆã« generate_large_test_file.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return 1
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    benchmark = PerformanceBenchmark()
    try:
        benchmark.run_comprehensive_benchmark()
        return 0
    except Exception as e:
        print(f"\nâŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)