#!/usr/bin/env python3
"""
Kumihan-Formatter å“è³ªç®¡ç†çµ±åˆãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ

å“è³ªç®¡ç†ã€ãƒˆãƒ¬ãƒ³ãƒ‰ç›£è¦–ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚’çµ±åˆã—ãŸãƒ„ãƒ¼ãƒ«ã€‚
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å“è³ªã‚’åŒ…æ‹¬çš„ã«ç®¡ç†ãƒ»ç›£è¦–ã™ã‚‹ã€‚

ä½¿ç”¨æ–¹æ³•:
    # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ãƒ»åˆ†æ
    python dev/tools/quality_toolkit.py --analyze
    
    # å“è³ªã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
    python dev/tools/quality_toolkit.py --gate-check
    
    # å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    python dev/tools/quality_toolkit.py --report
    
    # å“è³ªä¿å®ˆï¼ˆæ¸…æƒãƒ»æœ€é©åŒ–ï¼‰
    python dev/tools/quality_toolkit.py --maintenance
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰ç›£è¦–ãƒ»å±¥æ­´è¨˜éŒ²
    python dev/tools/quality_toolkit.py --trend-snapshot
    
    # çµ±åˆå“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆæ¨å¥¨ï¼‰
    python dev/tools/quality_toolkit.py --full-check
"""

import sys
import json
import argparse
import sqlite3
import subprocess
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict


@dataclass
class QualityMetrics:
    """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    total_score: float
    syntax_pass_rate: float
    test_pass_rate: float
    test_coverage: float
    performance_score: float
    file_count: int
    test_count: int
    complexity_score: float


@dataclass
class QualitySnapshot:
    """å“è³ªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼ˆå±¥æ­´è¨˜éŒ²ç”¨ï¼‰"""
    timestamp: str
    commit_hash: str
    branch_name: str
    metrics: QualityMetrics


@dataclass
class QualityGateResult:
    """å“è³ªã‚²ãƒ¼ãƒˆçµæœ"""
    passed: bool
    failed_checks: List[str]
    warnings: List[str]
    metrics: QualityMetrics


class QualityToolkit:
    """å“è³ªç®¡ç†çµ±åˆãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ"""
    
    # å“è³ªã‚²ãƒ¼ãƒˆåŸºæº–å€¤
    QUALITY_GATES = {
        'min_test_coverage': 70.0,
        'min_test_pass_rate': 95.0,
        'min_syntax_pass_rate': 98.0,
        'max_complexity_score': 50.0,
        'min_total_score': 75.0
    }
    
    def __init__(self, project_root: Optional[Path] = None):
        """åˆæœŸåŒ–"""
        self.project_root = project_root or Path.cwd()
        self.history_db = self.project_root / "dev" / "data" / "quality_history.db"
        self.history_db.parent.mkdir(parents=True, exist_ok=True)
        self._init_history_db()
    
    def _init_history_db(self):
        """å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–"""
        with sqlite3.connect(self.history_db) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS quality_snapshots (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    commit_hash TEXT,
                    branch_name TEXT,
                    total_score REAL,
                    syntax_pass_rate REAL,
                    test_pass_rate REAL,
                    test_coverage REAL,
                    performance_score REAL,
                    complexity_score REAL,
                    file_count INTEGER,
                    test_count INTEGER
                )
            """)
            conn.commit()
    
    def collect_metrics(self) -> QualityMetrics:
        """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†"""
        print("å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†ä¸­...")
        
        # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        file_count = len(list(self.project_root.glob("**/*.py")))
        test_count = len(list(self.project_root.glob("**/test_*.py")))
        
        # ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸å–å¾—
        test_coverage = self._get_test_coverage()
        
        # ãƒ†ã‚¹ãƒˆæˆåŠŸç‡å–å¾—
        test_pass_rate = self._get_test_pass_rate()
        
        # æ§‹æ–‡ãƒã‚§ãƒƒã‚¯æˆåŠŸç‡
        syntax_pass_rate = self._get_syntax_pass_rate()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        performance_score = self._get_performance_score()
        
        # è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢
        complexity_score = self._get_complexity_score()
        
        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        total_score = (
            test_coverage * 0.3 +
            test_pass_rate * 0.25 +
            syntax_pass_rate * 0.2 +
            performance_score * 0.15 +
            max(0, 100 - complexity_score) * 0.1
        )
        
        return QualityMetrics(
            total_score=total_score,
            syntax_pass_rate=syntax_pass_rate,
            test_pass_rate=test_pass_rate,
            test_coverage=test_coverage,
            performance_score=performance_score,
            file_count=file_count,
            test_count=test_count,
            complexity_score=complexity_score
        )
    
    def _get_test_coverage(self) -> float:
        """ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’å–å¾—"""
        try:
            result = subprocess.run([
                sys.executable, "-m", "pytest",
                "--cov=kumihan_formatter",
                "--cov-report=json:coverage.json",
                "-q"
            ], cwd=self.project_root, capture_output=True, text=True, timeout=120)
            
            coverage_file = self.project_root / "coverage.json"
            if coverage_file.exists():
                with open(coverage_file, 'r') as f:
                    coverage_data = json.load(f)
                coverage = coverage_data['totals']['percent_covered']
                coverage_file.unlink()  # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                return coverage
        except Exception as e:
            print(f"ã‚«ãƒãƒ¬ãƒƒã‚¸å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        return 0.0
    
    def _get_test_pass_rate(self) -> float:
        """ãƒ†ã‚¹ãƒˆæˆåŠŸç‡ã‚’å–å¾—"""
        try:
            result = subprocess.run([
                sys.executable, "-m", "pytest",
                "--tb=no", "-q"
            ], cwd=self.project_root, capture_output=True, text=True, timeout=120)
            
            output = result.stdout + result.stderr
            
            # æˆåŠŸ/å¤±æ•—ã®æ•°ã‚’è§£æ
            import re
            passed_match = re.search(r'(\d+) passed', output)
            failed_match = re.search(r'(\d+) failed', output)
            
            passed = int(passed_match.group(1)) if passed_match else 0
            failed = int(failed_match.group(1)) if failed_match else 0
            
            total = passed + failed
            return (passed / total * 100) if total > 0 else 100.0
            
        except Exception as e:
            print(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def _get_syntax_pass_rate(self) -> float:
        """æ§‹æ–‡ãƒã‚§ãƒƒã‚¯æˆåŠŸç‡ã‚’å–å¾—"""
        try:
            # Pythonæ§‹æ–‡ãƒã‚§ãƒƒã‚¯
            python_files = list(self.project_root.glob("**/*.py"))
            if not python_files:
                return 100.0
            
            valid_files = 0
            for py_file in python_files:
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        compile(f.read(), str(py_file), 'exec')
                    valid_files += 1
                except SyntaxError:
                    pass
                except Exception:
                    pass  # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã¯æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã§ã¯ãªã„
            
            return (valid_files / len(python_files)) * 100
            
        except Exception:
            return 0.0
    
    def _get_performance_score(self) -> float:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢å–å¾—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        try:
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®å¤‰æ›æ™‚é–“æ¸¬å®š
            sample_file = self.project_root / "examples" / "sample.txt"
            if not sample_file.exists():
                return 75.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
            start_time = time.time()
            result = subprocess.run([
                sys.executable, "-m", "kumihan_formatter.cli",
                str(sample_file), "-o", "/tmp"
            ], cwd=self.project_root, capture_output=True, timeout=30)
            
            execution_time = time.time() - start_time
            
            # 5ç§’ä»¥å†…ãªã‚‰100ç‚¹ã€10ç§’ã§50ç‚¹ã€ãã‚Œä»¥ä¸Šã¯0ç‚¹
            if execution_time <= 5:
                return 100.0
            elif execution_time <= 10:
                return 100 - ((execution_time - 5) * 10)
            else:
                return 0.0
                
        except Exception:
            return 50.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    def _get_complexity_score(self) -> float:
        """è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢å–å¾—"""
        try:
            # å˜ç´”ãªè¤‡é›‘åº¦æŒ‡æ¨™ï¼ˆé–¢æ•°ã®å¹³å‡è¡Œæ•°ï¼‰
            python_files = list(self.project_root.glob("kumihan_formatter/**/*.py"))
            
            total_functions = 0
            total_lines = 0
            
            for py_file in python_files:
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    import re
                    functions = re.findall(r'def \w+\([^)]*\):', content)
                    total_functions += len(functions)
                    total_lines += len(content.splitlines())
                    
                except Exception:
                    continue
            
            if total_functions == 0:
                return 0.0
            
            avg_lines_per_function = total_lines / total_functions
            
            # 15è¡Œä»¥ä¸‹ãªã‚‰è¤‡é›‘åº¦0ã€25è¡Œã§50ã€50è¡Œã§100
            if avg_lines_per_function <= 15:
                return 0.0
            elif avg_lines_per_function <= 50:
                return (avg_lines_per_function - 15) * (100 / 35)
            else:
                return 100.0
                
        except Exception:
            return 25.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    def check_quality_gates(self, metrics: QualityMetrics) -> QualityGateResult:
        """å“è³ªã‚²ãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯"""
        failed_checks = []
        warnings = []
        
        # å¿…é ˆãƒã‚§ãƒƒã‚¯
        if metrics.test_coverage < self.QUALITY_GATES['min_test_coverage']:
            failed_checks.append(f"ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ä¸è¶³: {metrics.test_coverage:.1f}% < {self.QUALITY_GATES['min_test_coverage']}%")
        
        if metrics.test_pass_rate < self.QUALITY_GATES['min_test_pass_rate']:
            failed_checks.append(f"ãƒ†ã‚¹ãƒˆæˆåŠŸç‡ä¸è¶³: {metrics.test_pass_rate:.1f}% < {self.QUALITY_GATES['min_test_pass_rate']}%")
        
        if metrics.syntax_pass_rate < self.QUALITY_GATES['min_syntax_pass_rate']:
            failed_checks.append(f"æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ç‡é«˜: {metrics.syntax_pass_rate:.1f}% < {self.QUALITY_GATES['min_syntax_pass_rate']}%")
        
        if metrics.total_score < self.QUALITY_GATES['min_total_score']:
            failed_checks.append(f"ç·åˆã‚¹ã‚³ã‚¢ä¸è¶³: {metrics.total_score:.1f} < {self.QUALITY_GATES['min_total_score']}")
        
        # è­¦å‘Šãƒ¬ãƒ™ãƒ«ãƒã‚§ãƒƒã‚¯
        if metrics.complexity_score > self.QUALITY_GATES['max_complexity_score']:
            warnings.append(f"è¤‡é›‘åº¦é«˜: {metrics.complexity_score:.1f} > {self.QUALITY_GATES['max_complexity_score']}")
        
        if metrics.performance_score < 70:
            warnings.append(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ³¨æ„: {metrics.performance_score:.1f}")
        
        passed = len(failed_checks) == 0
        return QualityGateResult(passed, failed_checks, warnings, metrics)
    
    def save_snapshot(self, metrics: QualityMetrics) -> QualitySnapshot:
        """å“è³ªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜"""
        # Gitæƒ…å ±å–å¾—
        try:
            commit_hash = subprocess.run([
                "git", "rev-parse", "HEAD"
            ], capture_output=True, text=True, cwd=self.project_root).stdout.strip()
            
            branch_name = subprocess.run([
                "git", "branch", "--show-current"
            ], capture_output=True, text=True, cwd=self.project_root).stdout.strip()
        except Exception:
            commit_hash = "unknown"
            branch_name = "unknown"
        
        snapshot = QualitySnapshot(
            timestamp=datetime.now().isoformat(),
            commit_hash=commit_hash,
            branch_name=branch_name,
            metrics=metrics
        )
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        with sqlite3.connect(self.history_db) as conn:
            conn.execute("""
                INSERT INTO quality_snapshots 
                (timestamp, commit_hash, branch_name, total_score, syntax_pass_rate,
                 test_pass_rate, test_coverage, performance_score, complexity_score,
                 file_count, test_count)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                snapshot.timestamp,
                snapshot.commit_hash,
                snapshot.branch_name,
                metrics.total_score,
                metrics.syntax_pass_rate,
                metrics.test_pass_rate,
                metrics.test_coverage,
                metrics.performance_score,
                metrics.complexity_score,
                metrics.file_count,
                metrics.test_count
            ))
            conn.commit()
        
        return snapshot
    
    def get_trend_analysis(self, days: int = 30) -> Dict[str, Any]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’å®Ÿè¡Œ"""
        cutoff_date = (datetime.now() - timedelta(days=days)).isoformat()
        
        with sqlite3.connect(self.history_db) as conn:
            cursor = conn.execute("""
                SELECT timestamp, total_score, test_coverage, complexity_score
                FROM quality_snapshots 
                WHERE timestamp > ?
                ORDER BY timestamp
            """, (cutoff_date,))
            
            rows = cursor.fetchall()
        
        if len(rows) < 2:
            return {"trend": "insufficient_data", "message": "å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"}
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—
        first_score = rows[0][1]
        last_score = rows[-1][1]
        score_change = last_score - first_score
        
        first_coverage = rows[0][2]
        last_coverage = rows[-1][2]
        coverage_change = last_coverage - first_coverage
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š
        if score_change > 5:
            trend = "improving"
        elif score_change < -5:
            trend = "declining"
        else:
            trend = "stable"
        
        return {
            "trend": trend,
            "score_change": score_change,
            "coverage_change": coverage_change,
            "data_points": len(rows),
            "period_days": days
        }
    
    def perform_maintenance(self) -> Dict[str, Any]:
        """å“è³ªä¿å®ˆã‚’å®Ÿè¡Œ"""
        results = {}
        
        # å¤ã„ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        test_artifacts = list(self.project_root.glob("**/.pytest_cache"))
        test_artifacts.extend(self.project_root.glob("**/__pycache__"))
        
        cleaned_dirs = 0
        for artifact in test_artifacts:
            if artifact.is_dir():
                try:
                    import shutil
                    shutil.rmtree(artifact)
                    cleaned_dirs += 1
                except Exception:
                    pass
        
        results['cleaned_cache_dirs'] = cleaned_dirs
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        temp_files = list(self.project_root.glob("**/*.tmp"))
        temp_files.extend(self.project_root.glob("**/.coverage"))
        temp_files.extend(self.project_root.glob("**/coverage.json"))
        
        cleaned_files = 0
        for temp_file in temp_files:
            try:
                temp_file.unlink()
                cleaned_files += 1
            except Exception:
                pass
        
        results['cleaned_temp_files'] = cleaned_files
        
        # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€é©åŒ–
        try:
            with sqlite3.connect(self.history_db) as conn:
                conn.execute("VACUUM")
                conn.commit()
            results['db_optimized'] = True
        except Exception:
            results['db_optimized'] = False
        
        return results
    
    def generate_report(self, metrics: QualityMetrics, gate_result: QualityGateResult,
                       trend_analysis: Optional[Dict] = None) -> str:
        """å“è³ªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = []
        report.append("# å“è³ªç®¡ç†ãƒ¬ãƒãƒ¼ãƒˆ\n")
        
        # ç·åˆã‚¹ã‚³ã‚¢
        status = "âœ… åˆæ ¼" if gate_result.passed else "âŒ ä¸åˆæ ¼"
        report.append(f"## å“è³ªã‚²ãƒ¼ãƒˆ: {status}")
        report.append(f"**ç·åˆã‚¹ã‚³ã‚¢**: {metrics.total_score:.1f}/100\n")
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è©³ç´°
        report.append("## å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹")
        report.append("| é …ç›® | å€¤ | åŸºæº– | çŠ¶æ…‹ |")
        report.append("|------|----|----- |------|")
        
        metrics_data = [
            ("ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸", f"{metrics.test_coverage:.1f}%", "â‰¥70%", 
             "âœ…" if metrics.test_coverage >= 70 else "âŒ"),
            ("ãƒ†ã‚¹ãƒˆæˆåŠŸç‡", f"{metrics.test_pass_rate:.1f}%", "â‰¥95%",
             "âœ…" if metrics.test_pass_rate >= 95 else "âŒ"),
            ("æ§‹æ–‡æ­£ç¢ºæ€§", f"{metrics.syntax_pass_rate:.1f}%", "â‰¥98%",
             "âœ…" if metrics.syntax_pass_rate >= 98 else "âŒ"),
            ("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", f"{metrics.performance_score:.1f}", "â‰¥70",
             "âœ…" if metrics.performance_score >= 70 else "âš ï¸"),
            ("è¤‡é›‘åº¦", f"{metrics.complexity_score:.1f}", "â‰¤50",
             "âœ…" if metrics.complexity_score <= 50 else "âš ï¸"),
        ]
        
        for name, value, threshold, status in metrics_data:
            report.append(f"| {name} | {value} | {threshold} | {status} |")
        
        report.append("")
        
        # å•é¡Œã¨è­¦å‘Š
        if gate_result.failed_checks:
            report.append("## âŒ å“è³ªã‚²ãƒ¼ãƒˆå¤±æ•—é …ç›®")
            for check in gate_result.failed_checks:
                report.append(f"- {check}")
            report.append("")
        
        if gate_result.warnings:
            report.append("## âš ï¸ è­¦å‘Šé …ç›®")
            for warning in gate_result.warnings:
                report.append(f"- {warning}")
            report.append("")
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        if trend_analysis:
            trend_emoji = {
                "improving": "ğŸ“ˆ",
                "declining": "ğŸ“‰", 
                "stable": "â¡ï¸",
                "insufficient_data": "â“"
            }
            
            emoji = trend_emoji.get(trend_analysis["trend"], "â“")
            report.append(f"## {emoji} ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æï¼ˆéå»{trend_analysis.get('period_days', 30)}æ—¥ï¼‰")
            
            if trend_analysis["trend"] != "insufficient_data":
                report.append(f"- **ã‚¹ã‚³ã‚¢å¤‰åŒ–**: {trend_analysis['score_change']:+.1f}")
                report.append(f"- **ã‚«ãƒãƒ¬ãƒƒã‚¸å¤‰åŒ–**: {trend_analysis['coverage_change']:+.1f}%")
                report.append(f"- **ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ**: {trend_analysis['data_points']}å€‹")
            else:
                report.append(f"- {trend_analysis['message']}")
            
            report.append("")
        
        # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        report.append("## æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
        if gate_result.passed:
            report.append("- âœ… å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã™ã€‚ç¾åœ¨ã®é–‹ç™ºãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„ã€‚")
        else:
            report.append("- â— å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®æ”¹å–„ãŒå¿…è¦ã§ã™ï¼š")
            for check in gate_result.failed_checks[:3]:  # ä¸Šä½3ã¤ã®å•é¡Œ
                report.append(f"  - {check}")
        
        if gate_result.warnings:
            report.append("- âš ï¸ ä»¥ä¸‹ã®è­¦å‘Šã¸ã®å¯¾å¿œã‚’æ¤œè¨ã—ã¦ãã ã•ã„ï¼š")
            for warning in gate_result.warnings[:2]:  # ä¸Šä½2ã¤ã®è­¦å‘Š
                report.append(f"  - {warning}")
        
        return "\n".join(report)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description="å“è³ªç®¡ç†çµ±åˆãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ")
    parser.add_argument("--analyze", action="store_true", help="å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æ")
    parser.add_argument("--gate-check", action="store_true", help="å“è³ªã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯")
    parser.add_argument("--report", action="store_true", help="å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
    parser.add_argument("--maintenance", action="store_true", help="å“è³ªä¿å®ˆå®Ÿè¡Œ")
    parser.add_argument("--trend-snapshot", action="store_true", help="å“è³ªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜")
    parser.add_argument("--full-check", action="store_true", help="çµ±åˆå“è³ªãƒã‚§ãƒƒã‚¯")
    parser.add_argument("--output", "-o", type=Path, help="ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--project-root", type=Path, default=Path.cwd(),
                       help="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    
    args = parser.parse_args()
    
    if not any([args.analyze, args.gate_check, args.report, args.maintenance,
                args.trend_snapshot, args.full_check]):
        parser.print_help()
        return
    
    toolkit = QualityToolkit(args.project_root)
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
    if any([args.analyze, args.gate_check, args.report, args.full_check, args.trend_snapshot]):
        metrics = toolkit.collect_metrics()
        print(f"å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å®Œäº†: ç·åˆã‚¹ã‚³ã‚¢ {metrics.total_score:.1f}/100")
    
    # å“è³ªã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
    if any([args.gate_check, args.report, args.full_check]):
        gate_result = toolkit.check_quality_gates(metrics)
        status = "åˆæ ¼" if gate_result.passed else "ä¸åˆæ ¼"
        print(f"å“è³ªã‚²ãƒ¼ãƒˆçµæœ: {status}")
    
    # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜
    if args.trend_snapshot or args.full_check:
        snapshot = toolkit.save_snapshot(metrics)
        print(f"å“è³ªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜: {snapshot.timestamp}")
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    if args.report or args.full_check:
        trend_analysis = toolkit.get_trend_analysis()
    else:
        trend_analysis = None
    
    # ä¿å®ˆå®Ÿè¡Œ
    if args.maintenance or args.full_check:
        maintenance_result = toolkit.perform_maintenance()
        print(f"ä¿å®ˆå®Ÿè¡Œå®Œäº†: {maintenance_result}")
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    if args.report or args.full_check:
        report = toolkit.generate_report(metrics, gate_result, trend_analysis)
        
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {args.output}")
        else:
            print("\n" + report)
    
    # çµ‚äº†ã‚³ãƒ¼ãƒ‰
    if any([args.gate_check, args.full_check]):
        sys.exit(0 if gate_result.passed else 1)


if __name__ == "__main__":
    main()