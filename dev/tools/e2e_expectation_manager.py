#!/usr/bin/env python3
"""
E2Eãƒ†ã‚¹ãƒˆæœŸå¾…å€¤è‡ªå‹•ç®¡ç†ãƒ„ãƒ¼ãƒ«

ä½¿ç”¨æ–¹æ³•:
    # æœŸå¾…å€¤ã®è‡ªå‹•æ›´æ–°ï¼ˆå“è³ªã‚²ãƒ¼ãƒˆé€šéæ™‚ã®ã¿ï¼‰
    python dev/tools/e2e_expectation_manager.py --update-if-quality-pass
    
    # å¼·åˆ¶çš„ãªæœŸå¾…å€¤æ›´æ–°
    python dev/tools/e2e_expectation_manager.py --force-update
    
    # æœŸå¾…å€¤ã®æ¤œè¨¼ï¼ˆå¤‰æ›´ç¢ºèªï¼‰
    python dev/tools/e2e_expectation_manager.py --validate
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©å…ƒ
    python dev/tools/e2e_expectation_manager.py --restore-backup=2024-01-15
"""

import os
import sys
import json
import shutil
import argparse
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import difflib
import hashlib

# å“è³ªã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚«ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from quality_gates import QualityGateChecker
except ImportError:
    sys.path.append(str(Path(__file__).parent))
    from quality_gates import QualityGateChecker


@dataclass
class ExpectationFile:
    """æœŸå¾…å€¤ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±"""
    path: Path
    content_hash: str
    last_modified: datetime
    size_bytes: int


@dataclass
class ExpectationUpdate:
    """æœŸå¾…å€¤æ›´æ–°æƒ…å ±"""
    file_path: Path
    old_hash: str
    new_hash: str
    changed: bool
    backup_path: Optional[Path] = None


@dataclass
class ExpectationReport:
    """æœŸå¾…å€¤ç®¡ç†ãƒ¬ãƒãƒ¼ãƒˆ"""
    timestamp: str
    operation: str  # 'update', 'validate', 'restore'
    quality_gate_passed: bool
    total_files: int
    updated_files: int
    unchanged_files: int
    backup_created: bool
    updates: List[ExpectationUpdate]
    summary: str


class E2EExpectationManager:
    """E2Eãƒ†ã‚¹ãƒˆæœŸå¾…å€¤ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, project_root: Path = None):
        self.project_root = project_root or Path.cwd()
        self.expectations_dir = self.project_root / "dev" / "tests" / "e2e_expected"
        self.backup_dir = self.project_root / "dev" / "tests" / "e2e_backups"
        self.temp_dir = self.project_root / "temp" / "e2e_generation"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.expectations_dir.mkdir(parents=True, exist_ok=True)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        self.temp_dir.mkdir(parents=True, exist_ok=True)
        
        self.quality_checker = QualityGateChecker()
    
    def update_expectations_if_quality_pass(self) -> ExpectationReport:
        """å“è³ªã‚²ãƒ¼ãƒˆé€šéæ™‚ã®ã¿æœŸå¾…å€¤ã‚’æ›´æ–°"""
        print("ğŸ” å“è³ªã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­...")
        
        # å“è³ªã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
        gate_report = self.quality_checker.check_quality_gates(self.project_root)
        
        if not gate_report.overall_passed:
            print("âŒ å“è³ªã‚²ãƒ¼ãƒˆãŒå¤±æ•—ã—ãŸãŸã‚ã€æœŸå¾…å€¤ã¯æ›´æ–°ã•ã‚Œã¾ã›ã‚“")
            return ExpectationReport(
                timestamp=datetime.now().isoformat(),
                operation="update_conditional",
                quality_gate_passed=False,
                total_files=0,
                updated_files=0,
                unchanged_files=0,
                backup_created=False,
                updates=[],
                summary="å“è³ªã‚²ãƒ¼ãƒˆå¤±æ•—ã«ã‚ˆã‚ŠæœŸå¾…å€¤æ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ"
            )
        
        print("âœ… å“è³ªã‚²ãƒ¼ãƒˆã‚’é€šéã—ã¾ã—ãŸã€‚æœŸå¾…å€¤ã‚’æ›´æ–°ã—ã¾ã™...")
        return self.force_update_expectations()
    
    def force_update_expectations(self) -> ExpectationReport:
        """å¼·åˆ¶çš„ã«æœŸå¾…å€¤ã‚’æ›´æ–°"""
        print("ğŸ“ E2Eãƒ†ã‚¹ãƒˆæœŸå¾…å€¤ã®å¼·åˆ¶æ›´æ–°ã‚’é–‹å§‹...")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_path = self._create_backup()
        print(f"ğŸ’¾ æ—¢å­˜æœŸå¾…å€¤ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ: {backup_path}")
        
        # æ–°ã—ã„æœŸå¾…å€¤ç”Ÿæˆ
        updates = self._generate_new_expectations()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        updated_count = sum(1 for update in updates if update.changed)
        
        report = ExpectationReport(
            timestamp=datetime.now().isoformat(),
            operation="force_update",
            quality_gate_passed=True,
            total_files=len(updates),
            updated_files=updated_count,
            unchanged_files=len(updates) - updated_count,
            backup_created=True,
            updates=updates,
            summary=f"{updated_count}/{len(updates)} ãƒ•ã‚¡ã‚¤ãƒ«ã®æœŸå¾…å€¤ã‚’æ›´æ–°ã—ã¾ã—ãŸ"
        )
        
        print(f"âœ… æœŸå¾…å€¤æ›´æ–°å®Œäº†: {updated_count}/{len(updates)} ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°")
        return report
    
    def validate_expectations(self) -> ExpectationReport:
        """æœŸå¾…å€¤ã®æ¤œè¨¼ï¼ˆå¤‰æ›´ç¢ºèªï¼‰"""
        print("ğŸ” æœŸå¾…å€¤ã®æ¤œè¨¼ã‚’é–‹å§‹...")
        
        current_expectations = self._get_current_expectations()
        generated_expectations = self._generate_expectations_for_validation()
        
        updates = []
        for file_path in current_expectations:
            current_hash = current_expectations[file_path].content_hash
            generated_hash = generated_expectations.get(file_path, {}).get('hash', '')
            
            update = ExpectationUpdate(
                file_path=file_path,
                old_hash=current_hash,
                new_hash=generated_hash,
                changed=current_hash != generated_hash
            )
            updates.append(update)
        
        changed_count = sum(1 for update in updates if update.changed)
        
        report = ExpectationReport(
            timestamp=datetime.now().isoformat(),
            operation="validate",
            quality_gate_passed=True,
            total_files=len(updates),
            updated_files=0,
            unchanged_files=len(updates) - changed_count,
            backup_created=False,
            updates=updates,
            summary=f"{changed_count}/{len(updates)} ãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›´ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
        )
        
        if changed_count > 0:
            print(f"âš ï¸ {changed_count}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›´ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
        else:
            print("âœ… å…¨ã¦ã®æœŸå¾…å€¤ãŒæœ€æ–°ã§ã™")
        
        return report
    
    def restore_backup(self, backup_date: str) -> ExpectationReport:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰æœŸå¾…å€¤ã‚’å¾©å…ƒ"""
        backup_path = self.backup_dir / f"expectations_{backup_date}"
        
        if not backup_path.exists():
            raise FileNotFoundError(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {backup_path}")
        
        print(f"ğŸ”„ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒä¸­: {backup_path}")
        
        # ç¾åœ¨ã®æœŸå¾…å€¤ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆå¾©å…ƒå‰ï¼‰
        restore_backup_path = self._create_backup(suffix="_before_restore")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ
        if self.expectations_dir.exists():
            shutil.rmtree(self.expectations_dir)
        shutil.copytree(backup_path, self.expectations_dir)
        
        # å¾©å…ƒã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’è¨ˆç®—
        restored_files = list(self.expectations_dir.rglob("*.html"))
        
        report = ExpectationReport(
            timestamp=datetime.now().isoformat(),
            operation="restore",
            quality_gate_passed=True,
            total_files=len(restored_files),
            updated_files=len(restored_files),
            unchanged_files=0,
            backup_created=True,
            updates=[],
            summary=f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— {backup_date} ã‹ã‚‰ {len(restored_files)} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¾©å…ƒã—ã¾ã—ãŸ"
        )
        
        print(f"âœ… å¾©å…ƒå®Œäº†: {len(restored_files)} ãƒ•ã‚¡ã‚¤ãƒ«")
        return report
    
    def _create_backup(self, suffix: str = "") -> Path:
        """ç¾åœ¨ã®æœŸå¾…å€¤ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"expectations_{timestamp}{suffix}"
        backup_path = self.backup_dir / backup_name
        
        if self.expectations_dir.exists():
            shutil.copytree(self.expectations_dir, backup_path)
        
        return backup_path
    
    def _generate_new_expectations(self) -> List[ExpectationUpdate]:
        """æ–°ã—ã„æœŸå¾…å€¤ã‚’ç”Ÿæˆ"""
        updates = []
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        sample_files = self._get_sample_files()
        print(f"ğŸ“ {len(sample_files)} å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†...")
        
        for sample_file in sample_files:
            try:
                update = self._process_sample_file(sample_file)
                updates.append(update)
            except Exception as e:
                print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ {sample_file}: {e}")
                # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã‚‚è¨˜éŒ²
                updates.append(ExpectationUpdate(
                    file_path=sample_file,
                    old_hash="",
                    new_hash="",
                    changed=False
                ))
        
        return updates
    
    def _process_sample_file(self, sample_file: Path) -> ExpectationUpdate:
        """å€‹åˆ¥ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†"""
        print(f"   å‡¦ç†ä¸­: {sample_file.name}")
        
        # æ—¢å­˜ã®æœŸå¾…å€¤ãƒãƒƒã‚·ãƒ¥ã‚’å–å¾—
        expected_file = self.expectations_dir / f"{sample_file.stem}.html"
        old_hash = ""
        if expected_file.exists():
            with open(expected_file, 'r', encoding='utf-8') as f:
                old_hash = hashlib.md5(f.read().encode()).hexdigest()
        
        # æ–°ã—ã„HTMLã‚’ç”Ÿæˆ
        output_file = self.temp_dir / f"{sample_file.stem}.html"
        self._run_conversion(sample_file, output_file)
        
        # æ–°ã—ã„ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—
        new_hash = ""
        if output_file.exists():
            with open(output_file, 'r', encoding='utf-8') as f:
                content = f.read()
                new_hash = hashlib.md5(content.encode()).hexdigest()
            
            # æœŸå¾…å€¤ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒ”ãƒ¼
            shutil.copy2(output_file, expected_file)
        
        return ExpectationUpdate(
            file_path=sample_file,
            old_hash=old_hash,
            new_hash=new_hash,
            changed=old_hash != new_hash
        )
    
    def _run_conversion(self, input_file: Path, output_file: Path):
        """å¤‰æ›ã‚’å®Ÿè¡Œ"""
        cmd = [
            sys.executable,
            '-m', 'kumihan_formatter.cli',
            str(input_file),
            '--no-preview',
            '-o', str(output_file.parent)
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        
        if result.returncode != 0:
            raise RuntimeError(f"å¤‰æ›å¤±æ•—: {result.stderr}")
    
    def _get_sample_files(self) -> List[Path]:
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        sample_dirs = [
            self.project_root / "examples",
            self.project_root / "examples" / "templates",
            self.project_root / "examples" / "showcase"
        ]
        
        sample_files = []
        for sample_dir in sample_dirs:
            if sample_dir.exists():
                sample_files.extend(sample_dir.glob("*.txt"))
        
        # ã‚¨ãƒ©ãƒ¼ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¯é™¤å¤–
        sample_files = [f for f in sample_files if "ã‚¨ãƒ©ãƒ¼ã‚µãƒ³ãƒ—ãƒ«" not in f.name and "error-" not in f.name]
        
        return sorted(sample_files)
    
    def _get_current_expectations(self) -> Dict[Path, ExpectationFile]:
        """ç¾åœ¨ã®æœŸå¾…å€¤ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—"""
        expectations = {}
        
        for html_file in self.expectations_dir.glob("*.html"):
            with open(html_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            expectation = ExpectationFile(
                path=html_file,
                content_hash=hashlib.md5(content.encode()).hexdigest(),
                last_modified=datetime.fromtimestamp(html_file.stat().st_mtime),
                size_bytes=html_file.stat().st_size
            )
            expectations[html_file] = expectation
        
        return expectations
    
    def _generate_expectations_for_validation(self) -> Dict[Path, Dict[str, str]]:
        """æ¤œè¨¼ç”¨ã®æœŸå¾…å€¤ã‚’ä¸€æ™‚ç”Ÿæˆ"""
        expectations = {}
        sample_files = self._get_sample_files()
        
        for sample_file in sample_files:
            try:
                output_file = self.temp_dir / f"validation_{sample_file.stem}.html"
                self._run_conversion(sample_file, output_file)
                
                if output_file.exists():
                    with open(output_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    expected_path = self.expectations_dir / f"{sample_file.stem}.html"
                    expectations[expected_path] = {
                        'hash': hashlib.md5(content.encode()).hexdigest(),
                        'content': content
                    }
            except Exception:
                pass  # ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
        
        return expectations
    
    def list_backups(self) -> List[Dict[str, Any]]:
        """åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        backups = []
        
        for backup_dir in self.backup_dir.glob("expectations_*"):
            if backup_dir.is_dir():
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‹ã‚‰æ—¥æ™‚ã‚’æŠ½å‡º
                timestamp_str = backup_dir.name.replace("expectations_", "").split("_")[0]
                try:
                    timestamp = datetime.strptime(timestamp_str, "%Y%m%d")
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’è¨ˆç®—
                    file_count = len(list(backup_dir.glob("*.html")))
                    
                    backups.append({
                        'name': backup_dir.name,
                        'date': timestamp.strftime("%Y-%m-%d"),
                        'path': backup_dir,
                        'file_count': file_count,
                        'size_mb': sum(f.stat().st_size for f in backup_dir.rglob("*")) / 1024 / 1024
                    })
                except ValueError:
                    pass  # æ—¥æ™‚è§£æå¤±æ•—ã¯ç„¡è¦–
        
        return sorted(backups, key=lambda x: x['date'], reverse=True)


def format_expectation_report(report: ExpectationReport, format_type: str = 'detailed') -> str:
    """æœŸå¾…å€¤ç®¡ç†ãƒ¬ãƒãƒ¼ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if format_type == 'json':
        # dataclassã‚’è¾æ›¸ã«å¤‰æ›ï¼ˆPathã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’strIngã«å¤‰æ›ï¼‰
        report_dict = {
            'timestamp': report.timestamp,
            'operation': report.operation,
            'quality_gate_passed': report.quality_gate_passed,
            'total_files': report.total_files,
            'updated_files': report.updated_files,
            'unchanged_files': report.unchanged_files,
            'backup_created': report.backup_created,
            'updates': [
                {
                    'file_path': str(update.file_path),
                    'old_hash': update.old_hash,
                    'new_hash': update.new_hash,
                    'changed': update.changed,
                    'backup_path': str(update.backup_path) if update.backup_path else None
                }
                for update in report.updates
            ],
            'summary': report.summary
        }
        return json.dumps(report_dict, indent=2, ensure_ascii=False)
    
    elif format_type == 'summary':
        operation_names = {
            'update_conditional': 'æ¡ä»¶ä»˜ãæ›´æ–°',
            'force_update': 'å¼·åˆ¶æ›´æ–°',
            'validate': 'æ¤œè¨¼',
            'restore': 'å¾©å…ƒ'
        }
        
        operation_name = operation_names.get(report.operation, report.operation)
        
        return f"""
ğŸ“ E2Eãƒ†ã‚¹ãƒˆæœŸå¾…å€¤ç®¡ç†çµæœ
========================
æ“ä½œ: {operation_name}
æ™‚åˆ»: {report.timestamp}

ğŸ“Š çµæœ:
- å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {report.total_files}
- æ›´æ–°ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {report.updated_files}
- æœªå¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {report.unchanged_files}
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {'âœ… Yes' if report.backup_created else 'âŒ No'}

ğŸ’¬ ã‚µãƒãƒªãƒ¼: {report.summary}
"""
    
    else:  # detailed
        operation_names = {
            'update_conditional': 'æ¡ä»¶ä»˜ãæœŸå¾…å€¤æ›´æ–°',
            'force_update': 'å¼·åˆ¶æœŸå¾…å€¤æ›´æ–°',
            'validate': 'æœŸå¾…å€¤æ¤œè¨¼',
            'restore': 'æœŸå¾…å€¤å¾©å…ƒ'
        }
        
        operation_name = operation_names.get(report.operation, report.operation)
        
        # å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°
        changed_files = [update for update in report.updates if update.changed]
        unchanged_files = [update for update in report.updates if not update.changed]
        
        change_details = []
        if changed_files:
            change_details.append("ğŸ”„ å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
            for update in changed_files[:10]:  # æœ€å¤§10ä»¶è¡¨ç¤º
                file_name = update.file_path.name if hasattr(update.file_path, 'name') else str(update.file_path)
                change_details.append(f"   â€¢ {file_name}")
            
            if len(changed_files) > 10:
                change_details.append(f"   ... ä»– {len(changed_files) - 10} ãƒ•ã‚¡ã‚¤ãƒ«")
        
        if unchanged_files and report.operation in ['validate', 'update_conditional', 'force_update']:
            change_details.append(f"\nâœ… æœªå¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«: {len(unchanged_files)} å€‹")
        
        return f"""
ğŸ“ Kumihan-Formatter E2Eãƒ†ã‚¹ãƒˆæœŸå¾…å€¤ç®¡ç†è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
================================================
æ“ä½œ: {operation_name}
å®Ÿè¡Œæ™‚åˆ»: {report.timestamp}

ğŸ¯ å®Ÿè¡Œçµæœ: {'âœ… æˆåŠŸ' if report.quality_gate_passed else 'âŒ å¤±æ•—'}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š çµ±è¨ˆæƒ…å ±:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {report.total_files}
â€¢ æ›´æ–°ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {report.updated_files}
â€¢ æœªå¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {report.unchanged_files}
â€¢ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {'âœ… Yes' if report.backup_created else 'âŒ No'}

{chr(10).join(change_details) if change_details else ''}

ğŸ’¬ ã‚µãƒãƒªãƒ¼:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{report.summary}

{'ğŸŒŸ æœŸå¾…å€¤ç®¡ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸã€‚' if report.quality_gate_passed else 'âš ï¸ å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚'}
"""


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="Kumihan-Formatter E2Eãƒ†ã‚¹ãƒˆæœŸå¾…å€¤è‡ªå‹•ç®¡ç†ãƒ„ãƒ¼ãƒ«",
        epilog="ä¾‹: python dev/tools/e2e_expectation_manager.py --update-if-quality-pass"
    )
    
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        '--update-if-quality-pass',
        action='store_true',
        help='å“è³ªã‚²ãƒ¼ãƒˆé€šéæ™‚ã®ã¿æœŸå¾…å€¤ã‚’æ›´æ–°'
    )
    group.add_argument(
        '--force-update',
        action='store_true',
        help='å¼·åˆ¶çš„ã«æœŸå¾…å€¤ã‚’æ›´æ–°'
    )
    group.add_argument(
        '--validate',
        action='store_true',
        help='æœŸå¾…å€¤ã®æ¤œè¨¼ï¼ˆå¤‰æ›´ç¢ºèªï¼‰'
    )
    group.add_argument(
        '--restore-backup',
        type=str,
        help='ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒï¼ˆæ—¥ä»˜æŒ‡å®š: YYYY-MM-DDï¼‰'
    )
    group.add_argument(
        '--list-backups',
        action='store_true',
        help='åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ãƒªã‚¹ãƒˆè¡¨ç¤º'
    )
    
    parser.add_argument(
        '--format',
        choices=['detailed', 'summary', 'json'],
        default='detailed',
        help='ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼'
    )
    parser.add_argument(
        '--output', '-o',
        type=Path,
        help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹'
    )
    
    args = parser.parse_args()
    
    try:
        manager = E2EExpectationManager()
        
        if args.list_backups:
            backups = manager.list_backups()
            print("ğŸ“¦ åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—:")
            print("=" * 50)
            for backup in backups:
                print(f"ğŸ“… {backup['date']} - {backup['file_count']}ãƒ•ã‚¡ã‚¤ãƒ« ({backup['size_mb']:.1f}MB)")
                print(f"   ğŸ“ {backup['name']}")
            return
        
        # æ“ä½œå®Ÿè¡Œ
        if args.update_if_quality_pass:
            report = manager.update_expectations_if_quality_pass()
        elif args.force_update:
            report = manager.force_update_expectations()
        elif args.validate:
            report = manager.validate_expectations()
        elif args.restore_backup:
            report = manager.restore_backup(args.restore_backup)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ»å‡ºåŠ›
        formatted_report = format_expectation_report(report, args.format)
        
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(formatted_report)
            print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {args.output}")
        else:
            print(formatted_report)
    
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()