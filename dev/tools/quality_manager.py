#!/usr/bin/env python3
"""
Kumihan-Formatter å“è³ªç®¡ç†ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ - çµ±åˆç‰ˆ

ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’çµ±åˆã—ã¦ã„ã¾ã™:
- quality_gates.py: å“è³ªã‚²ãƒ¼ãƒˆè‡ªå‹•åˆ¤å®š
- quality_maintenance.py: å“è³ªä¿å®ˆãƒ»ç›£è¦–
- quality_metrics.py: å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ãƒ»åˆ†æ
- quality_report_generator.py: å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

ä½¿ç”¨æ–¹æ³•:
    # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ãƒ»åˆ†æ
    python dev/tools/quality_manager.py --analyze
    
    # å“è³ªã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
    python dev/tools/quality_manager.py --gate-check
    
    # å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    python dev/tools/quality_manager.py --report
    
    # å“è³ªä¿å®ˆï¼ˆæ¸…æƒãƒ»æœ€é©åŒ–ï¼‰
    python dev/tools/quality_manager.py --maintenance
    
    # çµ±åˆå“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆæ¨å¥¨ï¼‰
    python dev/tools/quality_manager.py --full-check
"""

import sys
import json
import argparse
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import time

try:
    import yaml
except ImportError:
    yaml = None


@dataclass
class QualityMetrics:
    """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    # ã‚³ãƒ¼ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    total_files: int
    total_lines: int
    code_coverage: float
    test_pass_rate: float
    
    # è¤‡é›‘åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    cyclomatic_complexity: float
    maintainability_index: float
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå¥å…¨æ€§
    dead_code_ratio: float
    duplication_ratio: float
    technical_debt_hours: float
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
    build_time_seconds: float
    test_time_seconds: float
    
    # å“è³ªã‚¹ã‚³ã‚¢ï¼ˆç·åˆï¼‰
    quality_score: float
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    timestamp: str = ""
    
    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = datetime.now().isoformat()


@dataclass
class QualityGateRule:
    """å“è³ªã‚²ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«"""
    name: str
    metric: str
    operator: str  # '>=', '<=', '==', '>', '<'
    threshold: float
    weight: float = 1.0
    critical: bool = False
    description: str = ""


@dataclass
class QualityGateResult:
    """å“è³ªã‚²ãƒ¼ãƒˆçµæœ"""
    rule: QualityGateRule
    actual_value: float
    passed: bool
    score: float
    message: str


class QualityAnalyzer:
    """å“è³ªåˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.data_dir = project_root / "dev" / "data"
        self.data_dir.mkdir(parents=True, exist_ok=True)
    
    def collect_metrics(self) -> QualityMetrics:
        """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†"""
        print("ğŸ“Š å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ä¸­...")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆ
        total_files, total_lines = self._count_source_files()
        
        # ãƒ†ã‚¹ãƒˆé–¢é€£ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        code_coverage, test_pass_rate, test_time = self._analyze_tests()
        
        # ã‚³ãƒ¼ãƒ‰è¤‡é›‘åº¦åˆ†æ
        complexity, maintainability = self._analyze_complexity()
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå¥å…¨æ€§
        dead_code_ratio, duplication_ratio = self._analyze_code_health()
        
        # ãƒ“ãƒ«ãƒ‰æ™‚é–“
        build_time = self._measure_build_time()
        
        # æŠ€è¡“çš„è² å‚µæ¨å®š
        tech_debt = self._estimate_technical_debt(
            total_lines, complexity, duplication_ratio
        )
        
        # ç·åˆå“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
        quality_score = self._calculate_quality_score(
            code_coverage, test_pass_rate, complexity, 
            maintainability, dead_code_ratio, duplication_ratio
        )
        
        return QualityMetrics(
            total_files=total_files,
            total_lines=total_lines,
            code_coverage=code_coverage,
            test_pass_rate=test_pass_rate,
            cyclomatic_complexity=complexity,
            maintainability_index=maintainability,
            dead_code_ratio=dead_code_ratio,
            duplication_ratio=duplication_ratio,
            technical_debt_hours=tech_debt,
            build_time_seconds=build_time,
            test_time_seconds=test_time,
            quality_score=quality_score
        )
    
    def _count_source_files(self) -> Tuple[int, int]:
        """ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆ"""
        python_files = list(self.project_root.glob("**/*.py"))
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒ“ãƒ«ãƒ‰æˆæœç‰©ã‚’é™¤å¤–
        source_files = [
            f for f in python_files 
            if not any(part in str(f) for part in [
                "__pycache__", ".egg-info", "dist/", "build/",
                ".venv", ".tox"
            ])
        ]
        
        total_lines = 0
        for file_path in source_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    # ç©ºè¡Œã¨ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚’é™¤ã„ãŸå®Ÿè¡Œå¯èƒ½è¡Œæ•°
                    code_lines = [
                        line for line in lines 
                        if line.strip() and not line.strip().startswith('#')
                    ]
                    total_lines += len(code_lines)
            except Exception:
                pass
        
        return len(source_files), total_lines
    
    def _analyze_tests(self) -> Tuple[float, float, float]:
        """ãƒ†ã‚¹ãƒˆåˆ†æ"""
        start_time = time.time()
        
        try:
            # pytestå®Ÿè¡Œï¼ˆã‚«ãƒãƒ¬ãƒƒã‚¸ä»˜ãï¼‰
            result = subprocess.run([
                sys.executable, "-m", "pytest", 
                "--cov=kumihan_formatter", "--cov-report=term-missing",
                "--tb=short", "-q"
            ], cwd=self.project_root, capture_output=True, text=True, timeout=300)
            
            test_time = time.time() - start_time
            
            # ã‚«ãƒãƒ¬ãƒƒã‚¸è§£æ
            coverage = 0.0
            if "TOTAL" in result.stdout:
                for line in result.stdout.split('\n'):
                    if "TOTAL" in line:
                        parts = line.split()
                        if len(parts) >= 4 and parts[-1].endswith('%'):
                            coverage = float(parts[-1].rstrip('%'))
                            break
            
            # ãƒ†ã‚¹ãƒˆæˆåŠŸç‡
            pass_rate = 100.0 if result.returncode == 0 else 0.0
            
            # éƒ¨åˆ†çš„æˆåŠŸã®å ´åˆã®ãƒ‘ãƒ¼ã‚¹
            if result.returncode != 0 and "failed" in result.stdout:
                # "X failed, Y passed" ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è§£æ
                import re
                match = re.search(r'(\d+) failed.*?(\d+) passed', result.stdout)
                if match:
                    failed = int(match.group(1))
                    passed = int(match.group(2))
                    total = failed + passed
                    pass_rate = (passed / total * 100) if total > 0 else 0.0
            
            return coverage, pass_rate, test_time
            
        except Exception as e:
            print(f"âš ï¸  ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0, 0.0, 0.0
    
    def _analyze_complexity(self) -> Tuple[float, float]:
        """ã‚³ãƒ¼ãƒ‰è¤‡é›‘åº¦åˆ†æï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        total_complexity = 0
        file_count = 0
        
        for py_file in self.project_root.glob("kumihan_formatter/**/*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ç°¡æ˜“çš„ãªå¾ªç’°çš„è¤‡é›‘åº¦è¨ˆç®—
                complexity = content.count('if ') + content.count('elif ') + \
                           content.count('for ') + content.count('while ') + \
                           content.count('except ') + content.count('and ') + \
                           content.count('or ')
                
                total_complexity += complexity
                file_count += 1
                
            except Exception:
                pass
        
        avg_complexity = total_complexity / file_count if file_count > 0 else 0
        
        # ä¿å®ˆæ€§æŒ‡æ•°ï¼ˆç°¡æ˜“è¨ˆç®—ï¼‰
        # é«˜ã„è¤‡é›‘åº¦ = ä½ã„ä¿å®ˆæ€§
        maintainability = max(0, 100 - (avg_complexity * 2))
        
        return avg_complexity, maintainability
    
    def _analyze_code_health(self) -> Tuple[float, float]:
        """ã‚³ãƒ¼ãƒ‰å¥å…¨æ€§åˆ†æ"""
        # ç°¡æ˜“çš„ãªãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ãƒ»é‡è¤‡æ¤œå‡º
        python_files = list(self.project_root.glob("kumihan_formatter/**/*.py"))
        
        total_functions = 0
        unused_functions = 0
        total_lines = 0
        duplicate_lines = 0
        
        function_calls = set()
        function_definitions = set()
        line_hashes = {}
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    total_lines += len(lines)
                
                for line in lines:
                    line = line.strip()
                    
                    # é–¢æ•°å®šç¾©
                    if line.startswith('def '):
                        func_name = line.split('(')[0].replace('def ', '')
                        function_definitions.add(func_name)
                        total_functions += 1
                    
                    # é–¢æ•°å‘¼ã³å‡ºã—ï¼ˆç°¡æ˜“æ¤œå‡ºï¼‰
                    if '(' in line and ')' in line:
                        for func in function_definitions:
                            if f'{func}(' in line:
                                function_calls.add(func)
                    
                    # é‡è¤‡è¡Œæ¤œå‡º
                    if line and not line.startswith('#'):
                        line_hash = hash(line)
                        if line_hash in line_hashes:
                            duplicate_lines += 1
                        else:
                            line_hashes[line_hash] = 1
                            
            except Exception:
                pass
        
        # æœªä½¿ç”¨é–¢æ•°ã®æ¨å®š
        for func in function_definitions:
            if func not in function_calls and not func.startswith('_'):
                unused_functions += 1
        
        dead_code_ratio = (unused_functions / total_functions * 100) if total_functions > 0 else 0
        duplication_ratio = (duplicate_lines / total_lines * 100) if total_lines > 0 else 0
        
        return dead_code_ratio, duplication_ratio
    
    def _measure_build_time(self) -> float:
        """ãƒ“ãƒ«ãƒ‰æ™‚é–“æ¸¬å®š"""
        start_time = time.time()
        
        try:
            # ç°¡å˜ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆã§ãƒ“ãƒ«ãƒ‰æ™‚é–“ã‚’ä»£æ›¿
            result = subprocess.run([
                sys.executable, "-c", "import kumihan_formatter; print('OK')"
            ], cwd=self.project_root, capture_output=True, timeout=60)
            
            return time.time() - start_time
            
        except Exception:
            return 0.0
    
    def _estimate_technical_debt(self, total_lines: int, complexity: float, duplication: float) -> float:
        """æŠ€è¡“çš„è² å‚µæ¨å®šï¼ˆæ™‚é–“ï¼‰"""
        # ç°¡æ˜“çš„ãªè² å‚µæ™‚é–“è¨ˆç®—
        # è¤‡é›‘åº¦ã¨é‡è¤‡ç‡ã‹ã‚‰æ¨å®š
        complexity_debt = (complexity - 10) * 0.1 if complexity > 10 else 0
        duplication_debt = duplication * 0.05
        line_debt = total_lines * 0.001
        
        return max(0, complexity_debt + duplication_debt + line_debt)
    
    def _calculate_quality_score(self, coverage: float, pass_rate: float, 
                                complexity: float, maintainability: float,
                                dead_code: float, duplication: float) -> float:
        """ç·åˆå“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—"""
        # é‡ã¿ä»˜ãå¹³å‡ã§å“è³ªã‚¹ã‚³ã‚¢ç®—å‡º
        weights = {
            'coverage': 0.25,
            'pass_rate': 0.25,
            'maintainability': 0.20,
            'complexity': 0.15,  # ä½ã„ã»ã©è‰¯ã„ï¼ˆé€†è»¢ï¼‰
            'dead_code': 0.10,   # ä½ã„ã»ã©è‰¯ã„ï¼ˆé€†è»¢ï¼‰
            'duplication': 0.05  # ä½ã„ã»ã©è‰¯ã„ï¼ˆé€†è»¢ï¼‰
        }
        
        # ã‚¹ã‚³ã‚¢æ­£è¦åŒ–ï¼ˆ0-100ï¼‰
        normalized_scores = {
            'coverage': coverage,
            'pass_rate': pass_rate,
            'maintainability': maintainability,
            'complexity': max(0, 100 - complexity * 2),  # è¤‡é›‘åº¦ã‚’é€†è»¢
            'dead_code': max(0, 100 - dead_code * 2),    # ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ã‚’é€†è»¢
            'duplication': max(0, 100 - duplication * 2) # é‡è¤‡ã‚’é€†è»¢
        }
        
        # é‡ã¿ä»˜ãåˆè¨ˆ
        quality_score = sum(
            normalized_scores[metric] * weight 
            for metric, weight in weights.items()
        )
        
        return min(100, max(0, quality_score))


class QualityGateManager:
    """å“è³ªã‚²ãƒ¼ãƒˆç®¡ç†"""
    
    def __init__(self):
        self.default_rules = [
            QualityGateRule("ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸", "code_coverage", ">=", 70.0, 2.0, True, "ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ70%ä»¥ä¸Šå¿…è¦"),
            QualityGateRule("ãƒ†ã‚¹ãƒˆæˆåŠŸç‡", "test_pass_rate", ">=", 95.0, 2.0, True, "ãƒ†ã‚¹ãƒˆæˆåŠŸç‡ãŒ95%ä»¥ä¸Šå¿…è¦"),
            QualityGateRule("å“è³ªã‚¹ã‚³ã‚¢", "quality_score", ">=", 80.0, 1.5, False, "ç·åˆå“è³ªã‚¹ã‚³ã‚¢ãŒ80ç‚¹ä»¥ä¸Šæ¨å¥¨"),
            QualityGateRule("å¾ªç’°çš„è¤‡é›‘åº¦", "cyclomatic_complexity", "<=", 15.0, 1.0, False, "å¹³å‡è¤‡é›‘åº¦ãŒ15ä»¥ä¸‹æ¨å¥¨"),
            QualityGateRule("ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ç‡", "dead_code_ratio", "<=", 5.0, 1.0, False, "ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ç‡ãŒ5%ä»¥ä¸‹æ¨å¥¨"),
            QualityGateRule("é‡è¤‡ç‡", "duplication_ratio", "<=", 3.0, 0.5, False, "ã‚³ãƒ¼ãƒ‰é‡è¤‡ç‡ãŒ3%ä»¥ä¸‹æ¨å¥¨"),
        ]
    
    def evaluate_gates(self, metrics: QualityMetrics, rules: Optional[List[QualityGateRule]] = None) -> List[QualityGateResult]:
        """å“è³ªã‚²ãƒ¼ãƒˆè©•ä¾¡"""
        if rules is None:
            rules = self.default_rules
        
        results = []
        
        for rule in rules:
            actual_value = getattr(metrics, rule.metric, 0)
            passed = self._evaluate_rule(actual_value, rule.operator, rule.threshold)
            
            # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆåˆæ ¼ãªã‚‰æº€ç‚¹ã€ä¸åˆæ ¼ãªã‚‰é‡ã¿ã«å¿œã˜ãŸæ¸›ç‚¹ï¼‰
            score = rule.weight if passed else 0
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
            status = "âœ… åˆæ ¼" if passed else "âŒ ä¸åˆæ ¼"
            message = f"{status}: {rule.name} = {actual_value:.1f} (é–¾å€¤: {rule.operator} {rule.threshold})"
            
            results.append(QualityGateResult(
                rule=rule,
                actual_value=actual_value,
                passed=passed,
                score=score,
                message=message
            ))
        
        return results
    
    def _evaluate_rule(self, value: float, operator: str, threshold: float) -> bool:
        """ãƒ«ãƒ¼ãƒ«è©•ä¾¡"""
        if operator == ">=":
            return value >= threshold
        elif operator == "<=":
            return value <= threshold
        elif operator == ">":
            return value > threshold
        elif operator == "<":
            return value < threshold
        elif operator == "==":
            return abs(value - threshold) < 0.01
        else:
            return False


class QualityReportGenerator:
    """å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    
    def generate_comprehensive_report(self, metrics: QualityMetrics, 
                                    gate_results: List[QualityGateResult]) -> str:
        """åŒ…æ‹¬çš„å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report_lines = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        report_lines.append("=" * 60)
        report_lines.append("ğŸ” Kumihan-Formatter å“è³ªãƒ¬ãƒãƒ¼ãƒˆ")
        report_lines.append("=" * 60)
        report_lines.append(f"ç”Ÿæˆæ—¥æ™‚: {metrics.timestamp}")
        report_lines.append("")
        
        # ç·åˆå“è³ªã‚¹ã‚³ã‚¢
        report_lines.append("ğŸ“Š ç·åˆå“è³ªã‚¹ã‚³ã‚¢")
        report_lines.append("-" * 30)
        score_emoji = "ğŸŸ¢" if metrics.quality_score >= 80 else "ğŸŸ¡" if metrics.quality_score >= 60 else "ğŸ”´"
        report_lines.append(f"{score_emoji} å“è³ªã‚¹ã‚³ã‚¢: {metrics.quality_score:.1f}/100")
        report_lines.append("")
        
        # ã‚³ãƒ¼ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        report_lines.append("ğŸ“ˆ ã‚³ãƒ¼ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹")
        report_lines.append("-" * 30)
        report_lines.append(f"ğŸ“ ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {metrics.total_files:,}")
        report_lines.append(f"ğŸ“ ç·è¡Œæ•°: {metrics.total_lines:,}")
        report_lines.append(f"ğŸ§ª ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸: {metrics.code_coverage:.1f}%")
        report_lines.append(f"âœ… ãƒ†ã‚¹ãƒˆæˆåŠŸç‡: {metrics.test_pass_rate:.1f}%")
        report_lines.append("")
        
        # è¤‡é›‘åº¦ãƒ»ä¿å®ˆæ€§
        report_lines.append("ğŸ”§ è¤‡é›‘åº¦ãƒ»ä¿å®ˆæ€§")
        report_lines.append("-" * 30)
        report_lines.append(f"ğŸŒ€ å¾ªç’°çš„è¤‡é›‘åº¦: {metrics.cyclomatic_complexity:.1f}")
        report_lines.append(f"ğŸ› ï¸  ä¿å®ˆæ€§æŒ‡æ•°: {metrics.maintainability_index:.1f}")
        report_lines.append(f"ğŸ’€ ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ç‡: {metrics.dead_code_ratio:.1f}%")
        report_lines.append(f"ğŸ“„ é‡è¤‡ã‚³ãƒ¼ãƒ‰ç‡: {metrics.duplication_ratio:.1f}%")
        report_lines.append("")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        report_lines.append("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
        report_lines.append("-" * 30)
        report_lines.append(f"ğŸ—ï¸  ãƒ“ãƒ«ãƒ‰æ™‚é–“: {metrics.build_time_seconds:.2f}ç§’")
        report_lines.append(f"ğŸ§ª ãƒ†ã‚¹ãƒˆæ™‚é–“: {metrics.test_time_seconds:.2f}ç§’")
        report_lines.append(f"ğŸ’³ æŠ€è¡“çš„è² å‚µ: {metrics.technical_debt_hours:.1f}æ™‚é–“")
        report_lines.append("")
        
        # å“è³ªã‚²ãƒ¼ãƒˆçµæœ
        report_lines.append("ğŸš¦ å“è³ªã‚²ãƒ¼ãƒˆçµæœ")
        report_lines.append("-" * 30)
        
        passed_count = sum(1 for result in gate_results if result.passed)
        total_count = len(gate_results)
        critical_failed = any(result.rule.critical and not result.passed for result in gate_results)
        
        report_lines.append(f"åˆæ ¼ç‡: {passed_count}/{total_count} ({passed_count/total_count*100:.1f}%)")
        
        if critical_failed:
            report_lines.append("ğŸš¨ é‡è¦ãªå“è³ªã‚²ãƒ¼ãƒˆãŒä¸åˆæ ¼ã§ã™ï¼")
        
        report_lines.append("")
        
        for result in gate_results:
            report_lines.append(result.message)
            if result.rule.description:
                report_lines.append(f"   ğŸ’¡ {result.rule.description}")
        
        report_lines.append("")
        
        # æ¨å¥¨äº‹é …
        report_lines.append("ğŸ’¡ æ¨å¥¨äº‹é …")
        report_lines.append("-" * 30)
        
        recommendations = self._generate_recommendations(metrics, gate_results)
        for rec in recommendations:
            report_lines.append(f"â€¢ {rec}")
        
        return "\n".join(report_lines)
    
    def _generate_recommendations(self, metrics: QualityMetrics, 
                                gate_results: List[QualityGateResult]) -> List[str]:
        """æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []
        
        # å“è³ªã‚¹ã‚³ã‚¢ãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨
        if metrics.quality_score < 70:
            recommendations.append("ç·åˆå“è³ªã‚¹ã‚³ã‚¢ãŒä½ã„ã§ã™ã€‚ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã¨ä¿å®ˆæ€§ã®å‘ä¸Šã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        # å€‹åˆ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ¨å¥¨
        if metrics.code_coverage < 70:
            recommendations.append("ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®è¿½åŠ ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if metrics.cyclomatic_complexity > 15:
            recommendations.append("ã‚³ãƒ¼ãƒ‰ãŒè¤‡é›‘ã§ã™ã€‚é–¢æ•°ã®åˆ†å‰²ã‚„ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if metrics.dead_code_ratio > 5:
            recommendations.append("æœªä½¿ç”¨ã‚³ãƒ¼ãƒ‰ãŒå¤šã„ã§ã™ã€‚ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ã®å‰Šé™¤ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if metrics.duplication_ratio > 3:
            recommendations.append("é‡è¤‡ã‚³ãƒ¼ãƒ‰ãŒå¤šã„ã§ã™ã€‚å…±é€šåŒ–ã§ãã‚‹éƒ¨åˆ†ãŒãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„")
        
        if metrics.technical_debt_hours > 10:
            recommendations.append("æŠ€è¡“çš„è² å‚µãŒè“„ç©ã—ã¦ã„ã¾ã™ã€‚å®šæœŸçš„ãªãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚’è¨ˆç”»ã—ã¦ãã ã•ã„")
        
        # å“è³ªã‚²ãƒ¼ãƒˆä¸åˆæ ¼ã¸ã®å¯¾å¿œ
        failed_critical = [r for r in gate_results if r.rule.critical and not r.passed]
        if failed_critical:
            recommendations.append("é‡è¦ãªå“è³ªã‚²ãƒ¼ãƒˆãŒä¸åˆæ ¼ã§ã™ã€‚ãƒªãƒªãƒ¼ã‚¹å‰ã«å¿…ãšä¿®æ­£ã—ã¦ãã ã•ã„")
        
        if not recommendations:
            recommendations.append("å“è³ªçŠ¶æ…‹ã¯è‰¯å¥½ã§ã™ã€‚ç¾åœ¨ã®ãƒ¬ãƒ™ãƒ«ã‚’ç¶­æŒã—ã¦ãã ã•ã„")
        
        return recommendations


class QualityMaintenanceManager:
    """å“è³ªä¿å®ˆç®¡ç†"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
    
    def perform_maintenance(self) -> Dict[str, Any]:
        """å“è³ªä¿å®ˆå®Ÿè¡Œ"""
        results = {}
        
        print("ğŸ§¹ å“è³ªä¿å®ˆä½œæ¥­é–‹å§‹...")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        results['cache_cleanup'] = self._cleanup_caches()
        
        # æœªä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º
        results['unused_files'] = self._detect_unused_files()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
        results['optimization'] = self._optimize_performance()
        
        return results
    
    def _cleanup_caches(self) -> Dict[str, int]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        removed_items = 0
        
        cache_patterns = [
            "**/__pycache__",
            "**/*.pyc",
            "**/*.pyo",
            ".pytest_cache",
            ".hypothesis",
            ".coverage",
            "*.egg-info"
        ]
        
        for pattern in cache_patterns:
            for item in self.project_root.glob(pattern):
                try:
                    if item.is_file():
                        item.unlink()
                        removed_items += 1
                    elif item.is_dir():
                        import shutil
                        shutil.rmtree(item)
                        removed_items += 1
                except Exception:
                    pass
        
        return {"removed_items": removed_items}
    
    def _detect_unused_files(self) -> List[str]:
        """æœªä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º"""
        # ç°¡æ˜“çš„ãªæœªä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º
        # TODO: ã‚ˆã‚Šè©³ç´°ãªä¾å­˜é–¢ä¿‚åˆ†æã‚’å®Ÿè£…
        unused_files = []
        
        return unused_files
    
    def _optimize_performance(self) -> Dict[str, str]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–"""
        optimizations = []
        
        # å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å®š
        large_files = []
        for py_file in self.project_root.glob("**/*.py"):
            if py_file.stat().st_size > 50000:  # 50KBä»¥ä¸Š
                large_files.append(str(py_file))
        
        if large_files:
            optimizations.append(f"å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«({len(large_files)}å€‹)ã®åˆ†å‰²ã‚’æ¤œè¨")
        
        return {"suggestions": optimizations}


def main():
    parser = argparse.ArgumentParser(
        description="Kumihan-Formatter å“è³ªç®¡ç†ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('--analyze', action='store_true', help='å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æ')
    parser.add_argument('--gate-check', action='store_true', help='å“è³ªã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯')
    parser.add_argument('--report', action='store_true', help='å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ')
    parser.add_argument('--maintenance', action='store_true', help='å“è³ªä¿å®ˆå®Ÿè¡Œ')
    parser.add_argument('--full-check', action='store_true', help='çµ±åˆå“è³ªãƒã‚§ãƒƒã‚¯')
    parser.add_argument('--output', help='çµæœå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«')
    
    args = parser.parse_args()
    
    project_root = Path(__file__).parent.parent.parent
    
    # ä½•ã‚‚æŒ‡å®šã•ã‚Œãªã„å ´åˆã¯ãƒ•ãƒ«ãƒã‚§ãƒƒã‚¯
    if not any([args.analyze, args.gate_check, args.report, args.maintenance]):
        args.full_check = True
    
    # å“è³ªåˆ†æ
    if args.analyze or args.full_check:
        analyzer = QualityAnalyzer(project_root)
        metrics = analyzer.collect_metrics()
        
        print("ğŸ“Š å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å®Œäº†")
        print(f"å“è³ªã‚¹ã‚³ã‚¢: {metrics.quality_score:.1f}/100")
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜
        metrics_file = project_root / "dev" / "data" / "current_metrics.json"
        with open(metrics_file, 'w') as f:
            json.dump(asdict(metrics), f, indent=2)
    
    # å“è³ªã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
    if args.gate_check or args.full_check:
        if 'metrics' not in locals():
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒæœªåé›†ã®å ´åˆã¯èª­ã¿è¾¼ã¿
            metrics_file = project_root / "dev" / "data" / "current_metrics.json"
            if metrics_file.exists():
                with open(metrics_file, 'r') as f:
                    data = json.load(f)
                    metrics = QualityMetrics(**data)
            else:
                print("âŒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚--analyze ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„")
                return 1
        
        gate_manager = QualityGateManager()
        gate_results = gate_manager.evaluate_gates(metrics)
        
        print("\nğŸš¦ å“è³ªã‚²ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯çµæœ:")
        passed_count = sum(1 for r in gate_results if r.passed)
        critical_failed = any(r.rule.critical and not r.passed for r in gate_results)
        
        for result in gate_results:
            print(f"  {result.message}")
        
        print(f"\nåˆæ ¼ç‡: {passed_count}/{len(gate_results)}")
        
        if critical_failed:
            print("ğŸš¨ é‡è¦ãªå“è³ªã‚²ãƒ¼ãƒˆãŒä¸åˆæ ¼ã§ã™ï¼")
            return 1
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    if args.report or args.full_check:
        if 'metrics' not in locals() or 'gate_results' not in locals():
            print("âŒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ»ã‚²ãƒ¼ãƒˆçµæœãŒå¿…è¦ã§ã™ã€‚--analyze --gate-check ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return 1
        
        report_generator = QualityReportGenerator()
        report = report_generator.generate_comprehensive_report(metrics, gate_results)
        
        if args.output:
            with open(args.output, 'w') as f:
                f.write(report)
            print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’ {args.output} ã«å‡ºåŠ›ã—ã¾ã—ãŸ")
        else:
            print("\n" + report)
    
    # ä¿å®ˆä½œæ¥­
    if args.maintenance or args.full_check:
        maintenance_manager = QualityMaintenanceManager(project_root)
        maintenance_results = maintenance_manager.perform_maintenance()
        
        print("\nğŸ§¹ å“è³ªä¿å®ˆå®Œäº†:")
        print(f"  ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {maintenance_results['cache_cleanup']['removed_items']}é …ç›®å‰Šé™¤")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())