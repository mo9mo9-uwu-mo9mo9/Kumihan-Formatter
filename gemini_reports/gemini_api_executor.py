#!/usr/bin/env python3
"""Gemini APIçµ±åˆå®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ 

å®Ÿéš›ã®Gemini APIã‚’ä½¿ç”¨ã—ã¦Claudeä½œæˆã®ä½œæ¥­æŒ‡ç¤ºæ›¸ã«åŸºã¥ãå®Ÿè£…ã‚’å®Ÿè¡Œã€‚
çœŸã®Claude-Geminiã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä½“åˆ¶ã‚’å®Ÿç¾ã€‚

Created: 2025-08-15 (çœŸã®APIçµ±åˆç‰ˆ)
"""

import asyncio
import json
import logging
import os
import re
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸ google-generativeai not installed. Run: pip install google-generativeai")


class GeminiAPIExecutor:
    """å®Ÿéš›ã®Gemini APIã‚’ä½¿ç”¨ã—ãŸå®Ÿè£…å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, api_key: Optional[str] = None, config_path: Optional[str] = None):
        """åˆæœŸåŒ–

        Args:
            api_key: Gemini API ã‚­ãƒ¼ï¼ˆç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ã‹ã‚‰ã‚‚å–å¾—å¯èƒ½ï¼‰
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: gemini_reports/config.jsonï¼‰
        """
        if not GEMINI_AVAILABLE:
            raise ImportError("google-generativeai library is required")

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        self.config = self._load_config(config_path)

        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("Gemini API key is required. Set GEMINI_API_KEY environment variable or pass api_key parameter")

        # Gemini APIè¨­å®š
        genai.configure(api_key=self.api_key)  # type: ignore
        model_name = self.config["gemini_api"]["model_name"]
        self.model = genai.GenerativeModel(model_name)  # type: ignore

        # è¨­å®šã‹ã‚‰èª­ã¿è¾¼ã¿
        self.generation_config = self.config["gemini_api"]["generation_config"]

        # ãƒªãƒˆãƒ©ã‚¤è¨­å®š
        retry_config = self.config["gemini_api"]["retry_config"]
        self.max_retries = retry_config["max_retries"]
        self.retry_delays = retry_config["retry_delays"]
        self.quota_retry_delay = retry_config["quota_retry_delay"]

        # ãƒ­ã‚°è¨­å®š
        logging_config = self.config["logging"]
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(getattr(logging, logging_config["level"]))
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(logging_config["format"])
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)

        # çµ±è¨ˆãƒ»ã‚¨ãƒ©ãƒ¼è©³ç´°ãƒ­ã‚°
        self.execution_stats: Dict[str, Any] = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "retry_attempts": 0,
            "quota_errors": 0,
            "network_errors": 0,
            "parsing_errors": 0,
            "timeout_errors": 0,
            "error_details": [],  # è©³ç´°ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
            "total_tokens_used": 0
        }

        # è¨­å®šä¿å­˜
        self.max_error_entries = logging_config["max_error_entries"]

    def _load_config(self, config_path: Optional[str] = None) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿

        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            è¨­å®šè¾æ›¸
        """
        if config_path is None:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            current_dir = Path(__file__).parent
            config_path = str(current_dir / "config.json")

        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config_data: Dict[str, Any] = json.load(f)
                return config_data
        except FileNotFoundError:
            # loggeræœªåˆæœŸåŒ–ã®ãŸã‚ç›´æ¥print
            print(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return self._get_default_config()
        except json.JSONDecodeError as e:
            print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æã‚¨ãƒ©ãƒ¼: {e}. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return self._get_default_config()

    def _get_default_config(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’å–å¾—"""
        return {
            "gemini_api": {
                "model_name": "gemini-2.0-flash-exp",
                "generation_config": {
                    "temperature": 0.1,
                    "top_p": 0.8,
                    "top_k": 40,
                    "max_output_tokens": 8192
                },
                "retry_config": {
                    "max_retries": 3,
                    "retry_delays": [1, 5, 15],
                    "quota_retry_delay": 60,
                    "timeout_seconds": 120
                }
            },
            "logging": {
                "level": "INFO",
                "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
                "max_error_entries": 100
            },
            "file_output": {
                "temp_directory": "tmp",
                "encoding": "utf-8",
                "create_backup": True
            },
            "quality_checks": {
                "enable_syntax_check": True,
                "enable_mypy_check": False,
                "enable_flake8_check": False
            }
        }

    def _log_error_details(self, error_type: str, error_message: str, task_id: str, context: Optional[Dict[str, Any]] = None) -> None:
        """è©³ç´°ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’è¨˜éŒ²

        Args:
            error_type: ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—
            error_message: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            task_id: ã‚¿ã‚¹ã‚¯ID
            context: è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
        """
        error_entry = {
            "timestamp": datetime.now().isoformat(),
            "task_id": task_id,
            "error_type": error_type,
            "error_message": str(error_message),
            "context": context or {}
        }

        self.execution_stats["error_details"].append(error_entry)

        # è¨­å®šã•ã‚ŒãŸæœ€å¤§ä»¶æ•°ã®ã¿ä¿æŒ
        if len(self.execution_stats["error_details"]) > self.max_error_entries:
            self.execution_stats["error_details"] = self.execution_stats["error_details"][-self.max_error_entries:]

        self.logger.error(f"[{error_type}] Task {task_id}: {error_message}")
        if context:
            self.logger.debug(f"Error context: {context}")

    def _determine_task_type(self, work_instruction: str) -> str:
        """ä½œæ¥­æŒ‡ç¤ºæ›¸ã‹ã‚‰ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã‚’è‡ªå‹•åˆ¤å®š

        Args:
            work_instruction: ä½œæ¥­æŒ‡ç¤ºæ›¸ã®å†…å®¹

        Returns:
            ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ— ('modification', 'creation', 'enhancement')
        """
        instruction_lower = work_instruction.lower()

        # ä¿®æ­£ã‚¿ã‚¹ã‚¯ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        modification_keywords = [
            'ä¿®æ­£', 'fix', 'error', 'ã‚¨ãƒ©ãƒ¼', 'mypy', 'flake8', 'lint',
            'å‹æ³¨é‡ˆ', 'type annotation', 'ãƒã‚°', 'bug', 'æ”¹ä¿®'
        ]

        # æ–°è¦ä½œæˆã‚¿ã‚¹ã‚¯ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        creation_keywords = [
            'tmp/', 'æ–°è¦', 'ä½œæˆ', 'create', 'å®Ÿè£…', 'implement',
            'ã‚·ã‚¹ãƒ†ãƒ ', 'dashboard', 'ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰'
        ]

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£ã®æ˜ç¤ºçš„æŒ‡å®šãƒã‚§ãƒƒã‚¯
        if any(keyword in instruction_lower for keyword in modification_keywords):
            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨€åŠã‚’ãƒã‚§ãƒƒã‚¯
            existing_dirs = ['gemini_reports/', 'kumihan_formatter/', 'docs/', 'core/']
            if any(dir_name in work_instruction for dir_name in existing_dirs):
                return 'modification'

        # æ˜ç¤ºçš„ã«tmp/æŒ‡å®šã‚„ã‚·ã‚¹ãƒ†ãƒ ä½œæˆ
        if any(keyword in instruction_lower for keyword in creation_keywords):
            return 'creation'

        # æ©Ÿèƒ½è¿½åŠ ãƒ»æ‹¡å¼µ
        enhancement_keywords = ['è¿½åŠ ', 'add', 'æ©Ÿèƒ½', 'feature', 'æ‹¡å¼µ', 'extend']
        if any(keyword in instruction_lower for keyword in enhancement_keywords):
            return 'enhancement'

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ–°è¦ä½œæˆï¼ˆå®‰å…¨å´ï¼‰
        return 'creation'

    async def execute_task(self, work_instruction: str, task_id: str) -> Dict[str, Any]:
        """Gemini APIã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ

        Args:
            work_instruction: Claudeä½œæˆã®è©³ç´°ä½œæ¥­æŒ‡ç¤ºæ›¸
            task_id: ã‚¿ã‚¹ã‚¯ID

        Returns:
            å®Ÿè¡Œçµæœè¾æ›¸
        """
        print(f"ğŸ¤– Gemini APIå®Ÿè¡Œé–‹å§‹: {task_id}")

        start_time = datetime.now()

        # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—è‡ªå‹•åˆ¤å®š
        task_type = self._determine_task_type(work_instruction)

        result: Dict[str, Any] = {
            "task_id": task_id,
            "status": "failed",
            "implemented_files": [],
            "modified_lines": 0,
            "gemini_response": "",
            "extracted_code": {},
            "execution_time": 0,
            "token_usage": {"input_tokens": 0, "output_tokens": 0},
            "errors": [],
            "warnings": []
        }

        try:
            # Gemini APIã«é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
            prompt = self._create_gemini_prompt(work_instruction)

            # APIå®Ÿè¡Œ
            print("ğŸ“¡ Gemini APIã«é€ä¿¡ä¸­...")
            response = await self._call_gemini_api(prompt)

            result["gemini_response"] = response
            self.execution_stats["total_requests"] += 1

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
            extracted_code = self._extract_code_blocks(response)
            result["extracted_code"] = extracted_code

            if extracted_code:
                # ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒ»ä¿®æ­£å®Ÿè¡Œ
                implemented_files = await self._implement_code(extracted_code, task_id, task_type)
                result["implemented_files"] = implemented_files
                result["modified_lines"] = self._count_total_lines(implemented_files)

                # Phase 4: å“è³ªæ¤œè¨¼ãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å¼·åŒ–
                quality_check_result = await self._perform_quality_verification(
                    implemented_files, task_id, work_instruction
                )
                result["quality_checks"] = quality_check_result["checks"]
                result["quality_feedback"] = quality_check_result["feedback"]

                # å“è³ªæ¤œè¨¼çµæœã«åŸºã¥ãçŠ¶æ…‹åˆ¤å®š
                if quality_check_result["overall_pass"]:
                    result["status"] = "completed"
                    print(f"âœ… Geminiå®Ÿè£…å®Œäº†: {len(implemented_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
                    self.execution_stats["successful_requests"] += 1
                else:
                    result["status"] = "quality_failed"
                    result["errors"].extend(quality_check_result["errors"])
                    print(f"âš ï¸ Geminiå®Ÿè£…å“è³ªä¸é©åˆ: {quality_check_result['errors']}")
                    self.execution_stats["failed_requests"] += 1
                    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«è¨˜éŒ²
                    await self._record_failure_pattern(work_instruction, quality_check_result)
            else:
                error_msg = "Geminiãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ"
                result["errors"].append(error_msg)
                self.execution_stats["failed_requests"] += 1
                self.execution_stats["parsing_errors"] += 1
                self._log_error_details("PARSING_ERROR", error_msg, task_id, {
                    "response_length": len(response),
                    "response_preview": response[:500] if response else "No response"
                })

        except asyncio.TimeoutError as e:
            error_msg = f"Gemini API ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {str(e)}"
            result["errors"].append(error_msg)
            self.execution_stats["failed_requests"] += 1
            self.execution_stats["timeout_errors"] += 1
            self._log_error_details("TIMEOUT_ERROR", error_msg, task_id, {
                "timeout_duration": "120s",
                "instruction_length": len(work_instruction)
            })
            print(f"â° {error_msg}")

        except Exception as e:
            error_msg = f"Gemini APIå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}"
            result["errors"].append(error_msg)
            self.execution_stats["failed_requests"] += 1

            # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—åˆ¥ã®åˆ†é¡
            if "quota" in str(e).lower() or "429" in str(e):
                self.execution_stats["quota_errors"] += 1
                error_type = "QUOTA_ERROR"
            elif "network" in str(e).lower() or "connection" in str(e).lower():
                self.execution_stats["network_errors"] += 1
                error_type = "NETWORK_ERROR"
            else:
                error_type = "UNKNOWN_ERROR"

            self._log_error_details(error_type, error_msg, task_id, {
                "exception_type": type(e).__name__,
                "instruction_length": len(work_instruction)
            })
            print(f"âŒ Gemini APIå®Ÿè¡Œå¤±æ•—: {e}")

        # å®Ÿè¡Œæ™‚é–“è¨ˆç®—
        end_time = datetime.now()
        result["execution_time"] = int((end_time - start_time).total_seconds())

        return result

    def _create_gemini_prompt(self, work_instruction: str) -> str:
        """Gemini APIã«é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
        prompt = f"""ã‚ãªãŸã¯å„ªç§€ãªPythonãƒ‡ãƒ™ãƒ­ãƒƒãƒ‘ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®ä½œæ¥­æŒ‡ç¤ºæ›¸ã«å¾“ã£ã¦å®Ÿè£…ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

# ä½œæ¥­æŒ‡ç¤ºæ›¸
{work_instruction}

# å®Ÿè£…è¦ä»¶
1. **å®Œå…¨ãªãƒ•ã‚¡ã‚¤ãƒ«å®Ÿè£…**: ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«å®Œå…¨ãªã‚³ãƒ¼ãƒ‰ã‚’æä¾›ã—ã¦ãã ã•ã„
2. **å“è³ªåŸºæº–éµå®ˆ**: MyPyã€Flake8ã€Blackã®åŸºæº–ã«æº–æ‹ ã—ã¦ãã ã•ã„
3. **ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å½¢å¼**: ä»¥ä¸‹ã®å½¢å¼ã§ã‚³ãƒ¼ãƒ‰ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„

```python
# ãƒ•ã‚¡ã‚¤ãƒ«: path/to/file.py
ã‚³ãƒ¼ãƒ‰å†…å®¹
```

4. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: é©åˆ‡ãªä¾‹å¤–å‡¦ç†ã‚’å«ã‚ã¦ãã ã•ã„
5. **å‹æ³¨é‡ˆ**: å…¨ã¦ã®é–¢æ•°ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰ã«å‹æ³¨é‡ˆã‚’è¿½åŠ ã—ã¦ãã ã•ã„
6. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: docstringã‚’é©åˆ‡ã«è¨˜è¿°ã—ã¦ãã ã•ã„

# ç¦æ­¢äº‹é …
- ä¸å®Œå…¨ãªã‚³ãƒ¼ãƒ‰ç‰‡ã®æä¾›
- å“è³ªåŸºæº–ã«æº–æ‹ ã—ãªã„ã‚³ãƒ¼ãƒ‰
- æŒ‡ç¤ºæ›¸ã«ãªã„æ©Ÿèƒ½ã®è¿½åŠ 
- æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç ´å£Šçš„å¤‰æ›´

æŒ‡ç¤ºæ›¸ã®è¦ä»¶ã‚’100%æº€ãŸã™å®Ÿè£…ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"""

        return prompt

    async def _call_gemini_api(self, prompt: str) -> str:
        """Gemini APIã‚’å‘¼ã³å‡ºã—ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰"""
        last_error = None

        for attempt in range(self.max_retries + 1):
            try:
                self.logger.info(f"Gemini APIå‘¼ã³å‡ºã—è©¦è¡Œ {attempt + 1}/{self.max_retries + 1}")

                response = await asyncio.to_thread(
                    self.model.generate_content,
                    prompt,
                    generation_config=self.generation_config
                )

                if response.candidates and len(response.candidates) > 0:
                    candidate = response.candidates[0]
                    if candidate.content and candidate.content.parts and len(candidate.content.parts) > 0:
                        self.logger.info("Gemini APIå‘¼ã³å‡ºã—æˆåŠŸ")
                        return str(candidate.content.parts[0].text)
                    else:
                        raise Exception(f"Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã‚¨ãƒ©ãƒ¼: content={candidate.content}")
                else:
                    raise Exception(f"Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¨ãƒ©ãƒ¼: candidates={response.candidates}")

            except Exception as e:
                last_error = e
                error_str = str(e).lower()

                # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆæ›´æ–°
                if "429" in error_str or "quota" in error_str:
                    self.execution_stats["quota_errors"] += 1
                    self.logger.warning(f"ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}): {e}")

                    if attempt < self.max_retries:
                        wait_time = self.quota_retry_delay
                        self.logger.info(f"ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã®ãŸã‚ {wait_time}ç§’å¾…æ©Ÿ")
                        await asyncio.sleep(wait_time)
                        continue

                elif "network" in error_str or "connection" in error_str or "timeout" in error_str:
                    self.execution_stats["network_errors"] += 1
                    self.logger.warning(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}): {e}")

                else:
                    self.logger.error(f"APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}): {e}")

                # ãƒªãƒˆãƒ©ã‚¤å®Ÿè¡Œ
                if attempt < self.max_retries:
                    self.execution_stats["retry_attempts"] += 1
                    wait_time = self.retry_delays[min(attempt, len(self.retry_delays) - 1)]
                    self.logger.info(f"ãƒªãƒˆãƒ©ã‚¤ã¾ã§ {wait_time}ç§’å¾…æ©Ÿ")
                    await asyncio.sleep(wait_time)
                else:
                    self.logger.error(f"æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸã€‚æœ€å¾Œã®ã‚¨ãƒ©ãƒ¼: {e}")

        raise Exception(f"Gemini APIå‘¼ã³å‡ºã—å¤±æ•— (æœ€å¤§{self.max_retries + 1}å›è©¦è¡Œ): {str(last_error)}")

    def _extract_code_blocks(self, response: str) -> Dict[str, str]:
        """Geminiãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºï¼ˆãƒ•ã‚§ã‚¤ãƒ«ã‚»ãƒ¼ãƒ•ä»˜ãï¼‰"""
        extracted_code = {}

        try:
            self.logger.info("ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯æŠ½å‡ºé–‹å§‹")

            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ä»˜ãã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
            pattern = r'```python\s*\n#\s*ãƒ•ã‚¡ã‚¤ãƒ«:\s*([^\n]+)\n(.*?)```'
            matches = re.findall(pattern, response, re.DOTALL)

            for file_path, code in matches:
                file_path = file_path.strip()
                code = code.strip()

                # ã‚³ãƒ¼ãƒ‰æ¤œè¨¼
                if len(code) < 10:
                    self.logger.warning(f"ã‚³ãƒ¼ãƒ‰ãŒçŸ­ã™ãã¾ã™: {file_path} ({len(code)}æ–‡å­—)")
                    continue

                extracted_code[file_path] = code
                self.logger.info(f"ğŸ“„ ã‚³ãƒ¼ãƒ‰æŠ½å‡º: {file_path} ({len(code)}æ–‡å­—)")

            # é€šå¸¸ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚‚æŠ½å‡ºï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æ¨å®šï¼‰
            if not extracted_code:
                self.logger.info("ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ä»˜ãã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€æ±ç”¨æŠ½å‡ºã‚’å®Ÿè¡Œ")
                pattern = r'```python\n(.*?)```'
                matches = re.findall(pattern, response, re.DOTALL)

                for i, code in enumerate(matches):
                    code = code.strip()
                    if len(code) < 10:  # æœ€å°ã‚³ãƒ¼ãƒ‰é•·ãƒã‚§ãƒƒã‚¯
                        continue

                    file_path = f"tmp/gemini_generated_{i+1}.py"
                    extracted_code[file_path] = code
                    self.logger.info(f"ğŸ“„ æ±ç”¨ã‚³ãƒ¼ãƒ‰æŠ½å‡º: {file_path}")

            # æŠ½å‡ºçµæœã®æœ€çµ‚æ¤œè¨¼
            if not extracted_code:
                self.logger.error("ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
                self.logger.debug(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ (å…ˆé ­500æ–‡å­—): {response[:500]}")

                # ãƒ•ã‚§ã‚¤ãƒ«ã‚»ãƒ¼ãƒ•: ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãªã—ã®å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯
                if "def " in response or "class " in response or "import " in response:
                    self.logger.info("ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãªã—ã®ã‚³ãƒ¼ãƒ‰ã‚’æ¤œå‡ºã€ãã®ã¾ã¾ä½¿ç”¨")
                    extracted_code["tmp/fallback_code.py"] = response.strip()

        except Exception as e:
            self.logger.error(f"ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯æŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            # å®Œå…¨ãƒ•ã‚§ã‚¤ãƒ«ã‚»ãƒ¼ãƒ•
            if response.strip():
                extracted_code["tmp/emergency_fallback.py"] = response.strip()
                self.logger.warning("ç·Šæ€¥ãƒ•ã‚§ã‚¤ãƒ«ã‚»ãƒ¼ãƒ•: ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’ã‚³ãƒ¼ãƒ‰ã¨ã—ã¦ä¿å­˜")

        self.logger.info(f"ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯æŠ½å‡ºå®Œäº†: {len(extracted_code)}ãƒ•ã‚¡ã‚¤ãƒ«")
        return extracted_code

    def _resolve_file_path(self, file_path: str, task_type: str) -> str:
        """ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è§£æ±º

        Args:
            file_path: å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            task_type: ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—

        Returns:
            è§£æ±ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # çµ¶å¯¾ãƒ‘ã‚¹ã®å ´åˆ
        if file_path.startswith('/'):
            return file_path.lstrip('/')

        # æ—¢ã«é©åˆ‡ãªãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒã‚ã‚‹å ´åˆ
        if file_path.startswith(('kumihan_formatter/', 'tmp/', 'docs/', 'gemini_reports/')):
            return file_path

        # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—åˆ¥ã®å‡¦ç†
        if task_type == 'modification':
            # ä¿®æ­£ã‚¿ã‚¹ã‚¯ã®å ´åˆï¼šæ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã‚’æ¨å®š

            # gemini_reportsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£
            if any(hint in file_path.lower() for hint in ['gemini', 'api', 'orchestrator', 'config']):
                return f"gemini_reports/{file_path}"

            # kumihan_formatterãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£
            if any(hint in file_path.lower() for hint in ['core', 'parser', 'formatter', 'cli']):
                return f"kumihan_formatter/{file_path}"

            # docsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£
            if any(hint in file_path.lower() for hint in ['doc', 'guide', 'readme', 'md']):
                return f"docs/{file_path}"

            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            import os
            possible_paths = [
                f"gemini_reports/{file_path}",
                f"kumihan_formatter/{file_path}",
                f"docs/{file_path}",
                file_path  # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹
            ]

            for path in possible_paths:
                if os.path.exists(path):
                    self.logger.info(f"æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {path}")
                    return path

            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯è­¦å‘Šã—ã¦tmp/é…ä¸‹ã«
            self.logger.warning(f"ä¿®æ­£å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}, tmp/é…ä¸‹ã«ä½œæˆã—ã¾ã™")
            return f"tmp/{file_path}"

        elif task_type == 'enhancement':
            # æ©Ÿèƒ½è¿½åŠ ã®å ´åˆï¼šæ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã«è¿½åŠ 
            if 'gemini' in file_path.lower():
                return f"gemini_reports/{file_path}"
            else:
                return f"kumihan_formatter/{file_path}"

        else:  # task_type == 'creation' or default
            # æ–°è¦ä½œæˆã®å ´åˆï¼štmp/é…ä¸‹ã«ä½œæˆ
            return f"tmp/{file_path}"

    async def _implement_code(self, extracted_code: Dict[str, str], task_id: str, task_type: str = 'creation') -> List[str]:
        """æŠ½å‡ºã—ãŸã‚³ãƒ¼ãƒ‰ã‚’å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å®Ÿè£…

        Args:
            extracted_code: æŠ½å‡ºã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰è¾æ›¸
            task_id: ã‚¿ã‚¹ã‚¯ID
            task_type: ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ— ('modification', 'creation', 'enhancement')
        """
        implemented_files = []

        for file_path, code in extracted_code.items():
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æ­£è¦åŒ–ï¼ˆã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—è€ƒæ…®ï¼‰
                full_path = self._resolve_file_path(file_path, task_type)

                self.logger.info(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«å®Ÿè£…é–‹å§‹: {file_path} â†’ {full_path} (type: {task_type})")

                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
                Path(full_path).parent.mkdir(parents=True, exist_ok=True)

                # ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                with open(full_path, 'w', encoding='utf-8') as f:
                    f.write(code)

                implemented_files.append(full_path)
                print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {full_path}")

                # åŸºæœ¬çš„ãªæ§‹æ–‡ãƒã‚§ãƒƒã‚¯
                if await self._basic_syntax_check(full_path):
                    print(f"âœ… æ§‹æ–‡ãƒã‚§ãƒƒã‚¯é€šé: {full_path}")
                else:
                    print(f"âš ï¸ æ§‹æ–‡ãƒã‚§ãƒƒã‚¯å¤±æ•—: {full_path}")

            except Exception as e:
                print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¤±æ•— {file_path}: {e}")

        return implemented_files

    async def _basic_syntax_check(self, file_path: str) -> bool:
        """åŸºæœ¬çš„ãªæ§‹æ–‡ãƒã‚§ãƒƒã‚¯"""
        try:
            result = subprocess.run(
                [sys.executable, "-m", "py_compile", file_path],
                capture_output=True,
                text=True,
                timeout=30
            )
            return result.returncode == 0
        except Exception:
            return False

    def _count_total_lines(self, files: List[str]) -> int:
        """å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«ã®ç·è¡Œæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        total_lines = 0
        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    total_lines += len(f.readlines())
            except Exception:
                pass
        return total_lines

    async def _perform_quality_verification(self, implemented_files: List[str], task_id: str, work_instruction: str) -> Dict[str, Any]:
        """å“è³ªæ¤œè¨¼ãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ 

        Args:
            implemented_files: å®Ÿè£…æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
            task_id: ã‚¿ã‚¹ã‚¯ID
            work_instruction: å…ƒã®ä½œæ¥­æŒ‡ç¤ºæ›¸

        Returns:
            å“è³ªæ¤œè¨¼çµæœã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
        """
        self.logger.info(f"ğŸ” å“è³ªæ¤œè¨¼é–‹å§‹: {task_id}")

        verification_result: Dict[str, Any] = {
            "checks": {
                "syntax_pass": True,
                "mypy_pass": True,
                "flake8_pass": True,
                "file_location_correct": True
            },
            "feedback": [],
            "errors": [],
            "overall_pass": True
        }

        try:
            # 1. ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®ç¢ºèªï¼ˆé‡è¦ãªæ”¹å–„ç‚¹ï¼‰
            location_check = await self._verify_file_locations(implemented_files, work_instruction)
            verification_result["checks"]["file_location_correct"] = location_check["correct"]
            if not location_check["correct"]:
                verification_result["errors"].extend(location_check["errors"])
                verification_result["feedback"].append("ä¿®æ­£ãƒ•ã‚¡ã‚¤ãƒ«ãŒtmp/é…ä¸‹ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£ã®å ´åˆã¯å…ƒã®å ´æ‰€ã«ä¿å­˜ã™ã¹ãã§ã™ã€‚")

            # 2. MyPyå‹æ³¨é‡ˆä¿®æ­£ã®å®ŸåŠ¹æ€§ç¢ºèª
            if "mypy" in work_instruction.lower() or "å‹æ³¨é‡ˆ" in work_instruction:
                mypy_check = await self._verify_mypy_fixes(implemented_files)
                verification_result["checks"]["mypy_pass"] = mypy_check["pass"]
                if not mypy_check["pass"]:
                    verification_result["errors"].extend(mypy_check["errors"])
                    verification_result["feedback"].append("MyPyä¿®æ­£ãŒä¸å®Œå…¨ã§ã™ã€‚å†ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")

            # 3. æ§‹æ–‡ãƒã‚§ãƒƒã‚¯å¼·åŒ–
            for file_path in implemented_files:
                if file_path.endswith('.py'):
                    syntax_ok = await self._enhanced_syntax_check(file_path)
                    if not syntax_ok:
                        verification_result["checks"]["syntax_pass"] = False
                        verification_result["errors"].append(f"æ§‹æ–‡ã‚¨ãƒ©ãƒ¼: {file_path}")

            # 4. ç·åˆåˆ¤å®š
            verification_result["overall_pass"] = all(verification_result["checks"].values())

            # 5. æ”¹å–„ææ¡ˆç”Ÿæˆ
            if not verification_result["overall_pass"]:
                improvement_suggestions = await self._generate_improvement_suggestions(
                    verification_result["errors"], work_instruction
                )
                verification_result["improvement_suggestions"] = improvement_suggestions

        except Exception as e:
            self.logger.error(f"å“è³ªæ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            verification_result["errors"].append(f"å“è³ªæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            verification_result["overall_pass"] = False

        self.logger.info(f"å“è³ªæ¤œè¨¼å®Œäº†: {task_id} (åˆæ ¼: {verification_result['overall_pass']})")
        return verification_result

    async def _verify_file_locations(self, implemented_files: List[str], work_instruction: str) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®ã®æ­£ç¢ºæ€§ã‚’æ¤œè¨¼"""
        result: Dict[str, Any] = {"correct": True, "errors": []}

        # ä¿®æ­£ã‚¿ã‚¹ã‚¯ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        is_modification_task = any(
            keyword in work_instruction.lower()
            for keyword in ['ä¿®æ­£', 'fix', 'error', 'ã‚¨ãƒ©ãƒ¼', 'mypy', 'flake8']
        )

        if is_modification_task:
            for file_path in implemented_files:
                if file_path.startswith('tmp/') and not 'tmp/' in work_instruction:
                    result["correct"] = False
                    result["errors"].append(f"ä¿®æ­£å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒtmp/é…ä¸‹ã«ä¿å­˜: {file_path}")

        return result

    async def _verify_mypy_fixes(self, implemented_files: List[str]) -> Dict[str, Any]:
        """MyPyä¿®æ­£ã®å®ŸåŠ¹æ€§ã‚’æ¤œè¨¼"""
        result: Dict[str, Any] = {"pass": True, "errors": []}

        try:
            for file_path in implemented_files:
                if file_path.endswith('.py'):
                    # MyPyãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
                    mypy_result = subprocess.run(
                        [sys.executable, "-m", "mypy", file_path, "--strict"],
                        capture_output=True,
                        text=True,
                        timeout=60
                    )

                    if mypy_result.returncode != 0:
                        result["pass"] = False
                        result["errors"].append(f"MyPyã‚¨ãƒ©ãƒ¼ ({file_path}): {mypy_result.stdout}")

        except Exception as e:
            result["pass"] = False
            result["errors"].append(f"MyPyæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")

        return result

    async def _enhanced_syntax_check(self, file_path: str) -> bool:
        """å¼·åŒ–ã•ã‚ŒãŸæ§‹æ–‡ãƒã‚§ãƒƒã‚¯"""
        try:
            # åŸºæœ¬æ§‹æ–‡ãƒã‚§ãƒƒã‚¯
            result = subprocess.run(
                [sys.executable, "-c", f"import ast; ast.parse(open('{file_path}').read())"],
                capture_output=True,
                text=True,
                timeout=30
            )
            return result.returncode == 0
        except Exception:
            return False

    async def _generate_improvement_suggestions(self, errors: List[str], work_instruction: str) -> List[str]:
        """å“è³ªæ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ"""
        suggestions = []

        # ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã®æ”¹å–„ææ¡ˆ
        for error in errors:
            if "tmp/é…ä¸‹ã«ä¿å­˜" in error:
                suggestions.append("æŒ‡ç¤ºæ›¸ã«ãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£ã®å ´åˆã¯ 'æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ç›´æ¥ä¿®æ­£' ã‚’æ˜è¨˜ã™ã‚‹")
            elif "MyPyã‚¨ãƒ©ãƒ¼" in error:
                suggestions.append("å‹æ³¨é‡ˆä¿®æ­£æ™‚ã¯ã‚ˆã‚Šå…·ä½“çš„ãªå‹æŒ‡å®šä¾‹ã‚’æä¾›ã™ã‚‹")
            elif "æ§‹æ–‡ã‚¨ãƒ©ãƒ¼" in error:
                suggestions.append("å®Œå…¨ãªãƒ•ã‚¡ã‚¤ãƒ«å®Ÿè£…ã‚’è¦æ±‚ã—ã€ã‚³ãƒ¼ãƒ‰ç‰‡ã®æä¾›ã‚’ç¦æ­¢ã™ã‚‹")

        return suggestions

    async def _record_failure_pattern(self, work_instruction: str, quality_result: Dict[str, Any]) -> None:
        """å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è¨˜éŒ²"""
        try:
            failure_pattern = {
                "timestamp": datetime.now().isoformat(),
                "instruction_type": self._determine_task_type(work_instruction),
                "instruction_length": len(work_instruction),
                "failure_reasons": quality_result["errors"],
                "improvement_suggestions": quality_result.get("improvement_suggestions", []),
                "quality_checks": quality_result["checks"]
            }

            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
            learning_file = Path("gemini_reports/failure_patterns.json")
            if learning_file.exists():
                with open(learning_file, 'r', encoding='utf-8') as f:
                    patterns = json.load(f)
            else:
                patterns = []

            patterns.append(failure_pattern)

            # æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
            if len(patterns) > 100:
                patterns = patterns[-100:]

            with open(learning_file, 'w', encoding='utf-8') as f:
                json.dump(patterns, f, indent=2, ensure_ascii=False)

            self.logger.info(f"å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨˜éŒ²: {learning_file}")

        except Exception as e:
            self.logger.error(f"å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

    def get_execution_stats(self) -> Dict[str, Any]:
        """å®Ÿè¡Œçµ±è¨ˆã‚’å–å¾—"""
        success_rate = 0
        retry_rate = 0

        if self.execution_stats["total_requests"] > 0:
            success_rate = (
                self.execution_stats["successful_requests"] /
                self.execution_stats["total_requests"]
            )
            retry_rate = (
                self.execution_stats["retry_attempts"] /
                self.execution_stats["total_requests"]
            )

        return {
            **self.execution_stats,
            "success_rate": success_rate,
            "retry_rate": retry_rate,
            "avg_tokens_per_request": (
                self.execution_stats["total_tokens_used"] /
                max(1, self.execution_stats["total_requests"])
            ),
            "error_breakdown": {
                "quota_errors": self.execution_stats["quota_errors"],
                "network_errors": self.execution_stats["network_errors"],
                "parsing_errors": self.execution_stats["parsing_errors"],
                "timeout_errors": self.execution_stats["timeout_errors"],
                "other_errors": (
                    self.execution_stats["failed_requests"] -
                    self.execution_stats["quota_errors"] -
                    self.execution_stats["network_errors"] -
                    self.execution_stats["parsing_errors"] -
                    self.execution_stats["timeout_errors"]
                )
            },
            "recent_errors": self.execution_stats["error_details"][-10:],  # æœ€æ–°10ä»¶ã®ã‚¨ãƒ©ãƒ¼
            "error_summary": self._get_error_summary()
        }

    def _get_error_summary(self) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        error_types: Dict[str, int] = {}
        recent_errors = self.execution_stats["error_details"][-50:]  # æœ€æ–°50ä»¶ã‚’åˆ†æ

        for error in recent_errors:
            error_type = error["error_type"]
            error_types[error_type] = error_types.get(error_type, 0) + 1

        return {
            "most_common_errors": sorted(error_types.items(), key=lambda x: x[1], reverse=True)[:5],
            "total_logged_errors": len(self.execution_stats["error_details"]),
            "error_rate_trend": self._calculate_error_trend()
        }

    def _calculate_error_trend(self) -> str:
        """æœ€è¿‘ã®ã‚¨ãƒ©ãƒ¼ç‡ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¨ˆç®—"""
        recent_errors = self.execution_stats["error_details"][-20:]  # æœ€æ–°20ä»¶
        if len(recent_errors) < 5:
            return "insufficient_data"

        # å‰åŠã¨å¾ŒåŠã§ã‚¨ãƒ©ãƒ¼æ•°æ¯”è¼ƒ
        half_point = len(recent_errors) // 2
        first_half = recent_errors[:half_point]
        second_half = recent_errors[half_point:]

        if len(second_half) > len(first_half):
            return "increasing"
        elif len(second_half) < len(first_half):
            return "decreasing"
        else:
            return "stable"

    async def test_connection(self) -> Dict[str, Any]:
        """APIæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        try:
            test_prompt = "Hello, are you working? Please respond with 'API connection successful'."
            response = await self._call_gemini_api(test_prompt)

            return {
                "status": "success",
                "response": response,
                "api_available": True
            }
        except Exception as e:
            return {
                "status": "failed",
                "error": str(e),
                "api_available": False
            }


# CLIå®Ÿè¡Œç”¨
async def main() -> None:
    """CLIå®Ÿè¡Œ"""
    import argparse

    parser = argparse.ArgumentParser(description="Gemini APIçµ±åˆå®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("--test", action="store_true", help="APIæ¥ç¶šãƒ†ã‚¹ãƒˆ")
    parser.add_argument("--instruction", help="ä½œæ¥­æŒ‡ç¤ºæ›¸ãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--task-id", help="ã‚¿ã‚¹ã‚¯ID")
    parser.add_argument("--stats", action="store_true", help="å®Ÿè¡Œçµ±è¨ˆè¡¨ç¤º")

    args = parser.parse_args()

    try:
        executor = GeminiAPIExecutor()

        if args.test:
            print("ğŸ§ª Gemini APIæ¥ç¶šãƒ†ã‚¹ãƒˆ...")
            result = await executor.test_connection()
            if result["status"] == "success":
                print("âœ… APIæ¥ç¶šæˆåŠŸ")
                print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {result['response']}")
            else:
                print("âŒ APIæ¥ç¶šå¤±æ•—")
                print(f"ã‚¨ãƒ©ãƒ¼: {result['error']}")
            return

        if args.stats:
            stats = executor.get_execution_stats()
            print("ğŸ“Š Gemini APIå®Ÿè¡Œçµ±è¨ˆ")
            print("=" * 30)
            for key, value in stats.items():
                print(f"{key}: {value}")
            return

        if args.instruction and args.task_id:
            with open(args.instruction, 'r', encoding='utf-8') as f:
                instruction = f.read()

            result = await executor.execute_task(instruction, args.task_id)
            print(f"\nğŸ¯ å®Ÿè¡Œçµæœ:")
            print(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {result['status']}")
            print(f"å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(result['implemented_files'])}")
            print(f"å®Ÿè£…è¡Œæ•°: {result['modified_lines']}")
            print(f"å®Ÿè¡Œæ™‚é–“: {result['execution_time']}ç§’")

            if result['errors']:
                print(f"\nã‚¨ãƒ©ãƒ¼: {result['errors']}")

            return

        parser.print_help()

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
