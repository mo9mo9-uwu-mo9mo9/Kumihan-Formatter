#!/usr/bin/env python3
"""
Issue #769 çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

å®Ÿéš›ã®Kumihanè¨˜æ³•ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½¿ç”¨ã—ãŸ300Kè¡Œãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®æ€§èƒ½æ¸¬å®š
ç›®æ¨™: 29.17ç§’ â†’ 5ç§’ä»¥ä¸‹ï¼ˆ83%é«˜é€ŸåŒ–ï¼‰
"""

import asyncio
import time
import sys
import tempfile
from pathlib import Path
from typing import Dict, Any

# Kumihan-Formatter components
sys.path.insert(0, str(Path(__file__).parent))
from kumihan_formatter.core.keyword_parser import KeywordParser
from kumihan_formatter.core.utilities.performance_metrics import (
    PerformanceMonitor,
    SIMDOptimizer,
    AsyncIOOptimizer,
    RegexOptimizer,
    MemoryOptimizer
)
from kumihan_formatter.core.utilities.parallel_processor import ParallelChunkProcessor
from kumihan_formatter.core.utilities.logger import get_logger


class IntegratedPerformanceTest:
    """çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ - å®Ÿéš›ã®Kumihanè¨˜æ³•å‡¦ç†"""

    def __init__(self):
        self.logger = get_logger(__name__)

        # ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.keyword_parser = KeywordParser()
        self.parallel_processor = ParallelChunkProcessor()

        # æœ€é©åŒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.simd_optimizer = SIMDOptimizer()
        self.async_optimizer = AsyncIOOptimizer()
        self.regex_optimizer = RegexOptimizer()
        self.memory_optimizer = MemoryOptimizer()

        self.logger.info("Integrated performance test system initialized")

    def create_realistic_test_file(self, lines_count: int = 300000) -> Path:
        """ç¾å®Ÿçš„ãªKumihanè¨˜æ³•ã‚’å«ã‚€ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
        test_file = Path(tempfile.mktemp(suffix=".kumihan"))

        self.logger.info(f"Creating realistic Kumihan test file: {lines_count:,} lines")

        # å®Ÿéš›ã®Kumihanè¨˜æ³•ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä½¿ç”¨é »åº¦ã‚’è€ƒæ…®ï¼‰
        patterns = [
            "# å¤ªå­— #é‡è¦ãªæƒ…å ±##",
            "# ã‚¤ã‚¿ãƒªãƒƒã‚¯ #å¼·èª¿ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ##",
            "# ãƒã‚¤ãƒ©ã‚¤ãƒˆ color=yellow #æ³¨æ„äº‹é …##",
            "# ãƒã‚¤ãƒ©ã‚¤ãƒˆ color=#ff0000 #è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸##",
            "# è¦‹å‡ºã—1 #ç¬¬1ç«  ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦##",
            "# è¦‹å‡ºã—2 #2.1 åŸºæœ¬æ©Ÿèƒ½##",
            "# è¦‹å‡ºã—3 #2.1.1 è©³ç´°ä»•æ§˜##",
            "# å¤ªå­— ã‚¤ã‚¿ãƒªãƒƒã‚¯ #è¤‡åˆã‚¹ã‚¿ã‚¤ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ##",
            "# ã‚³ãƒ¼ãƒ‰ #print('Hello, Kumihan!')##",
            "# ä¸‹ç·š #ä¸‹ç·šä»˜ããƒ†ã‚­ã‚¹ãƒˆ##",
            "é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆè¡Œã§ã™ã€‚ã“ã®è¡Œã«ã¯ç‰¹åˆ¥ãªè¨˜æ³•ã¯å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
            "æ—¥æœ¬èªã®è¤‡é›‘ãªæ–‡ç« ã€‚æ¼¢å­—ã€ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠãŒæ··åœ¨ã—ã¦ã„ã‚‹ä¾‹ã§ã™ã€‚",
            "English mixed text with Japanese. è‹±èªã¨æ—¥æœ¬èªã®æ··åˆä¾‹ã€‚",
            "æ•°å€¤ãƒ‡ãƒ¼ã‚¿: 123, 456.789, -987.654, 3.14159265359",
            "# å¤ªå­— #ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå: Kumihan-Formatter##",
            "# ã‚¤ã‚¿ãƒªãƒƒã‚¯ #ãƒãƒ¼ã‚¸ãƒ§ãƒ³: v2.0.0-alpha##",
            "# ãƒã‚¤ãƒ©ã‚¤ãƒˆ color=lightblue #ãƒªãƒªãƒ¼ã‚¹äºˆå®š: 2024å¹´12æœˆ##",
            "# è¦‹å‡ºã—2 #æ©Ÿèƒ½ä¸€è¦§##",
            "- åŸºæœ¬è¨˜æ³•ã‚µãƒãƒ¼ãƒˆ",
            "- é«˜é€Ÿå‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³",
            "- ä¸¦åˆ—å‡¦ç†å¯¾å¿œ",
            "è¤‡æ•°ã®# å¤ªå­— #ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰##ã‚’å«ã‚€è¡Œã¨# ã‚¤ã‚¿ãƒªãƒƒã‚¯ #ä»–ã®ã‚¹ã‚¿ã‚¤ãƒ«##ã®çµ„ã¿åˆã‚ã›",
            "# å¤ªå­— #ãƒã‚¹ãƒˆã—ãŸ# ã‚¤ã‚¿ãƒªãƒƒã‚¯ #è¨˜æ³•## test##",
            "ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€è¡Œ: !@#$%^&*()_+-=[]{}|;':\",./<>?",
            "é•·ã„è¡Œã®ãƒ†ã‚¹ãƒˆ: " + "ã‚" * 200,  # é•·ã„è¡Œ
            "",  # ç©ºè¡Œ
            "# è¦‹å‡ºã—1 #ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ##",
            "# å¤ªå­— #å‡¦ç†é€Ÿåº¦: 300,000è¡Œ/ç§’##",
            "# ãƒã‚¤ãƒ©ã‚¤ãƒˆ color=green #ãƒ†ã‚¹ãƒˆçµæœ: æˆåŠŸ##",
        ]

        with open(test_file, 'w', encoding='utf-8') as f:
            for i in range(lines_count):
                # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦å¤šæ§˜æ€§ã‚’ç¢ºä¿
                pattern = patterns[i % len(patterns)]
                # è¡Œç•ªå·ã‚’è¿½åŠ 
                line = f"L{i:06d}: {pattern}\n"
                f.write(line)

        file_size_mb = test_file.stat().st_size / 1024 / 1024
        self.logger.info(f"Test file created: {file_size_mb:.2f}MB")

        return test_file

    def process_kumihan_content_traditional(self, content: str) -> str:
        """å¾“æ¥æ‰‹æ³•ã§ã®Kumihanè¨˜æ³•å‡¦ç† - å®Ÿéš›ã®Kumihanå‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨"""
        # æœ€é©åŒ–ãªã—ã®å¾“æ¥ã®KeywordParserã‚’ä½¿ç”¨ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒã®åŸºæº–ï¼‰
        from kumihan_formatter.core.keyword_parser import KeywordParser

        # æœ€é©åŒ–ã‚’ç„¡åŠ¹ã«ã—ãŸå¾“æ¥ã®ãƒ‘ãƒ¼ã‚µãƒ¼
        traditional_parser = KeywordParser()

        # _regex_optimizerã®å‰Šé™¤ã§æœ€é©åŒ–ã‚’ç„¡åŠ¹åŒ–
        if hasattr(traditional_parser, '_regex_optimizer'):
            delattr(traditional_parser, '_regex_optimizer')

        # å¾“æ¥ã®å‡¦ç†ï¼ˆæœ€é©åŒ–ãªã—ï¼‰
        processed = traditional_parser._process_inline_keywords(content)

        if isinstance(processed, list):
            # ãƒªã‚¹ãƒˆçµæœã‚’æ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆç°¡ç•¥åŒ–ï¼‰
            result = ""
            for item in processed:
                if hasattr(item, 'tag'):  # Node object
                    result += f"<{item.tag}>{item.content}</{item.tag}>"
                else:
                    result += str(item)
            return result
        else:
            return str(processed)

    def process_kumihan_content_optimized(self, content: str) -> str:
        """æœ€é©åŒ–æ‰‹æ³•ã§ã®Kumihanè¨˜æ³•å‡¦ç†"""
        # KeywordParserã®æœ€é©åŒ–ã•ã‚ŒãŸå‡¦ç†ã‚’ä½¿ç”¨
        processed = self.keyword_parser._process_inline_keywords(content)

        if isinstance(processed, list):
            # ãƒªã‚¹ãƒˆçµæœã‚’æ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆç°¡ç•¥åŒ–ï¼‰
            result = ""
            for item in processed:
                if hasattr(item, 'tag'):  # Node object
                    result += f"<{item.tag}>{item.content}</{item.tag}>"
                else:
                    result += str(item)
            return result
        else:
            return str(processed)

    async def run_performance_comparison(self, lines_count: int = 300000) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
        self.logger.info(f"Starting integrated performance test: {lines_count:,} lines")

        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
        test_file = self.create_realistic_test_file(lines_count)

        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            with open(test_file, 'r', encoding='utf-8') as f:
                content = f.read()

            self.logger.info(f"Test file loaded: {len(content):,} characters")

            # 1. å¾“æ¥æ‰‹æ³•ã§ã®ãƒ†ã‚¹ãƒˆ
            self.logger.info("Testing traditional approach...")
            perf_monitor_traditional = PerformanceMonitor()
            perf_monitor_traditional.start_monitoring(lines_count, "traditional_processing")

            start_time = time.time()
            traditional_result = self.process_kumihan_content_traditional(content)
            traditional_time = time.time() - start_time

            perf_monitor_traditional.stop_monitoring()

            # 2. æœ€é©åŒ–æ‰‹æ³•ã§ã®ãƒ†ã‚¹ãƒˆ
            self.logger.info("Testing optimized approach...")
            perf_monitor_optimized = PerformanceMonitor()
            perf_monitor_optimized.start_monitoring(lines_count, "optimized_processing")

            start_time = time.time()
            optimized_result = self.process_kumihan_content_optimized(content)
            optimized_time = time.time() - start_time

            perf_monitor_optimized.stop_monitoring()

            # 3. ä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆå¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ï¼‰
            self.logger.info("Testing parallel processing...")
            lines = content.split('\n')

            # ãƒãƒ£ãƒ³ã‚¯ä½œæˆ
            chunks = self.parallel_processor.create_chunks_adaptive(lines[:50000])  # 50Kè¡Œã§ãƒ†ã‚¹ãƒˆ

            def process_chunk_parallel(chunk):
                chunk_content = '\n'.join(chunk.lines)
                return self.process_kumihan_content_optimized(chunk_content)

            start_time = time.time()
            parallel_results = list(
                self.parallel_processor.process_chunks_parallel_optimized(
                    chunks,
                    process_chunk_parallel
                )
            )
            parallel_time = time.time() - start_time

            # 4. éåŒæœŸI/O + æœ€é©åŒ–å‡¦ç†ãƒ†ã‚¹ãƒˆ
            self.logger.info("Testing async I/O + optimization...")

            start_time = time.time()
            async_results = []
            async for batch in self.async_optimizer.async_read_lines_batched(test_file, batch_size=5000):
                batch_content = '\n'.join(batch)
                batch_result = self.process_kumihan_content_optimized(batch_content)
                async_results.append(batch_result)
            async_time = time.time() - start_time

            # çµæœåˆ†æ
            speedup_factor = traditional_time / optimized_time if optimized_time > 0 else float('inf')
            parallel_speedup = traditional_time / parallel_time if parallel_time > 0 else float('inf')
            async_speedup = traditional_time / async_time if async_time > 0 else float('inf')

            results = {
                "traditional_time": traditional_time,
                "optimized_time": optimized_time,
                "parallel_time": parallel_time,
                "async_time": async_time,
                "speedup_factor": speedup_factor,
                "parallel_speedup": parallel_speedup,
                "async_speedup": async_speedup,
                "lines_processed": lines_count,
                "characters_processed": len(content),
                "target_time": 5.0,  # ç›®æ¨™: 5ç§’ä»¥ä¸‹
                "original_time": 29.17,  # å…ƒã®å‡¦ç†æ™‚é–“
                "target_achieved": optimized_time <= 5.0,
                "performance_improvement": ((29.17 - optimized_time) / 29.17) * 100,
                "traditional_report": perf_monitor_traditional.generate_performance_report(),
                "optimized_report": perf_monitor_optimized.generate_performance_report(),
            }

            self.logger.info(f"Performance test completed:")
            self.logger.info(f"  Traditional: {traditional_time:.2f}s")
            self.logger.info(f"  Optimized: {optimized_time:.2f}s")
            self.logger.info(f"  Speedup: {speedup_factor:.2f}x")
            self.logger.info(f"  Target achieved: {results['target_achieved']}")

            return results

        finally:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if test_file.exists():
                test_file.unlink()
                self.logger.info(f"Test file cleaned up: {test_file}")

    def print_performance_report(self, results: Dict[str, Any]):
        """çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆ"""
        print("\n" + "="*80)
        print("ğŸš€ Issue #769 çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆçµæœ")
        print("="*80)
        print(f"ç›®æ¨™: 300Kè¡Œãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç† 29.17ç§’ â†’ 5ç§’ä»¥ä¸‹")
        print()

        print("ğŸ“Š å‡¦ç†æ™‚é–“æ¯”è¼ƒ")
        print("-" * 40)
        print(f"  å¾“æ¥æ‰‹æ³•:     {results['traditional_time']:8.2f}ç§’")
        print(f"  æœ€é©åŒ–æ‰‹æ³•:   {results['optimized_time']:8.2f}ç§’")
        print(f"  ä¸¦åˆ—å‡¦ç†:     {results['parallel_time']:8.2f}ç§’")
        print(f"  éåŒæœŸI/O:    {results['async_time']:8.2f}ç§’")
        print()

        print("âš¡ é«˜é€ŸåŒ–çµæœ")
        print("-" * 40)
        print(f"  åŸºæœ¬æœ€é©åŒ–:   {results['speedup_factor']:8.2f}x")
        print(f"  ä¸¦åˆ—å‡¦ç†:     {results['parallel_speedup']:8.2f}x")
        print(f"  éåŒæœŸI/O:    {results['async_speedup']:8.2f}x")
        print()

        print("ğŸ¯ ç›®æ¨™é”æˆçŠ¶æ³")
        print("-" * 40)
        print(f"  ç›®æ¨™æ™‚é–“:     {results['target_time']:8.2f}ç§’")
        print(f"  å®Ÿéš›ã®æ™‚é–“:   {results['optimized_time']:8.2f}ç§’")
        print(f"  ç›®æ¨™é”æˆ:     {'âœ… YES' if results['target_achieved'] else 'âŒ NO'}")
        print(f"  æ€§èƒ½å‘ä¸Š:     {results['performance_improvement']:8.1f}%")
        print()

        if results['target_achieved']:
            print("ğŸ‰ Issue #769 å®Œå…¨é”æˆ!")
            print(f"   29.17ç§’ â†’ {results['optimized_time']:.2f}ç§’")
            print(f"   {results['speedup_factor']:.1f}å€é«˜é€ŸåŒ–ã‚’å®Ÿç¾")
        else:
            remaining_improvement = (results['optimized_time'] / results['target_time'] - 1) * 100
            print(f"âš ï¸  ç›®æ¨™ã¾ã§ã‚ã¨ {remaining_improvement:.1f}% ã®æ”¹å–„ãŒå¿…è¦")

        print()
        print("ğŸ“ˆ è©³ç´°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ:")
        print("å¾“æ¥æ‰‹æ³•:")
        print(results['traditional_report'])
        print("\næœ€é©åŒ–æ‰‹æ³•:")
        print(results['optimized_report'])


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("Issue #769 çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")

    test_system = IntegratedPerformanceTest()

    # çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    results = await test_system.run_performance_comparison(lines_count=300000)

    # çµæœãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
    test_system.print_performance_report(results)

    print("\nçµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº† ğŸ‰")

    # Issue #769å®Œäº†åˆ¤å®š
    if results['target_achieved']:
        print("\nğŸ† Issue #769 å®Œå…¨å®Œäº†!")
        print("   300Kè¡Œãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãŒ5ç§’ä»¥ä¸‹ã§å®Œäº†ã—ã¾ã—ãŸ")
    else:
        print(f"\nâš ï¸  Issue #769 æœªå®Œäº†")
        print(f"   ç¾åœ¨: {results['optimized_time']:.2f}ç§’")
        print(f"   ç›®æ¨™: {results['target_time']:.2f}ç§’ä»¥ä¸‹")


if __name__ == "__main__":
    asyncio.run(main())
