"""
ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

Issue #772 - ãƒ¡ãƒ¢ãƒªãƒ»ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†ã®å¼·åŒ–ã¨é•·æ™‚é–“å®Ÿè¡Œæ™‚ã®å®‰å®šæ€§å‘ä¸Š
ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºæ©Ÿæ§‹ã®ç²¾åº¦ã¨ä¿¡é ¼æ€§ã‚’ãƒ†ã‚¹ãƒˆ
"""

import gc
import tempfile
import threading
import time
from pathlib import Path
from typing import Any, Dict, List, Optional

import pytest

from kumihan_formatter.core.utilities.logger import get_logger
from kumihan_formatter.core.performance import MemoryOptimizer


class MemoryLeakDetectionTest:
    """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.logger = get_logger(__name__)
        self.memory_optimizer = MemoryOptimizer(enable_gc_optimization=True)

    def create_intentional_memory_leak(
        self, leak_type: str, size_mb: float = 5.0
    ) -> List[Any]:
        """
        æ„å›³çš„ãªãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ä½œæˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰

        Args:
            leak_type: ãƒªãƒ¼ã‚¯ã‚¿ã‚¤ãƒ—ï¼ˆ'circular', 'growing_list', 'unclosed_files'ï¼‰
            size_mb: ãƒªãƒ¼ã‚¯ã‚µã‚¤ã‚ºï¼ˆMBï¼‰

        Returns:
            List[Any]: ãƒªãƒ¼ã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå‚ç…§ï¼ˆãƒ†ã‚¹ãƒˆå¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ç”¨ï¼‰
        """
        leak_objects = []
        size_bytes = int(size_mb * 1024 * 1024)

        if leak_type == "circular":
            # å¾ªç’°å‚ç…§ã«ã‚ˆã‚‹ãƒªãƒ¼ã‚¯
            class CircularNode:
                def __init__(self, data: str):
                    self.data = data
                    self.ref = None

            # å¾ªç’°å‚ç…§ãƒã‚§ãƒ¼ãƒ³ä½œæˆ
            nodes = []
            chunk_size = 1024  # 1KB per node
            node_count = size_bytes // chunk_size

            for i in range(node_count):
                node = CircularNode("x" * chunk_size)
                if nodes:
                    nodes[-1].ref = node
                nodes.append(node)

            # æœ€å¾Œã®ãƒãƒ¼ãƒ‰ã‹ã‚‰æœ€åˆã®ãƒãƒ¼ãƒ‰ã¸ã®å¾ªç’°å‚ç…§
            if nodes:
                nodes[-1].ref = nodes[0]

            leak_objects.extend(nodes)

        elif leak_type == "growing_list":
            # æˆé•·ã—ç¶šã‘ã‚‹ãƒªã‚¹ãƒˆã«ã‚ˆã‚‹ãƒªãƒ¼ã‚¯
            growing_list = []
            chunk_size = 1024
            chunk_count = size_bytes // chunk_size

            for i in range(chunk_count):
                growing_list.append("x" * chunk_size)

            leak_objects.append(growing_list)

        elif leak_type == "unclosed_files":
            # ã‚¯ãƒ­ãƒ¼ã‚ºã•ã‚Œãªã„ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ«ã«ã‚ˆã‚‹ãƒªãƒ¼ã‚¯
            temp_files = []

            try:
                # è¤‡æ•°ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã„ãŸã¾ã¾ä¿æŒ
                for i in range(50):  # 50å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ«
                    temp_file = tempfile.NamedTemporaryFile(delete=False)
                    temp_file.write(b"x" * (size_bytes // 50))
                    temp_files.append(temp_file)  # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒ­ãƒ¼ã‚ºã›ãšã«ä¿æŒ

            except Exception as e:
                self.logger.warning(f"Failed to create file leak: {e}")

            leak_objects.extend(temp_files)

        self.logger.info(
            f"Created intentional {leak_type} memory leak (~{size_mb:.1f} MB)"
        )
        return leak_objects

    def test_leak_detection_accuracy(
        self, leak_types: List[str] = None
    ) -> Dict[str, Any]:
        """
        ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºç²¾åº¦ãƒ†ã‚¹ãƒˆ

        Args:
            leak_types: ãƒ†ã‚¹ãƒˆã™ã‚‹ãƒªãƒ¼ã‚¯ã‚¿ã‚¤ãƒ—

        Returns:
            Dict[str, Any]: ãƒ†ã‚¹ãƒˆçµæœ
        """
        if leak_types is None:
            leak_types = ["circular", "growing_list", "unclosed_files"]

        self.logger.info(f"Starting leak detection accuracy test for: {leak_types}")

        results = {
            "test_name": "leak_detection_accuracy",
            "leak_tests": [],
            "detection_accuracy": 0.0,
            "false_positives": 0,
            "false_negatives": 0,
        }

        for leak_type in leak_types:
            self.logger.info(f"Testing {leak_type} leak detection...")

            # åˆæœŸçŠ¶æ…‹æ¸¬å®š
            initial_memory = self.memory_optimizer.get_memory_stats()[
                "process_memory_mb"
            ]

            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®šï¼ˆãƒªãƒ¼ã‚¯ãªã—ï¼‰
            baseline_result = self.memory_optimizer.detect_memory_leaks(
                threshold_mb=2.0, sample_interval=2
            )

            leak_test_result = {
                "leak_type": leak_type,
                "baseline_leak_detected": baseline_result["leak_detected"],
                "leak_created": False,
                "leak_detected_after_creation": False,
                "detection_time_ms": 0.0,
                "cleanup_effective": False,
            }

            # æ„å›³çš„ãƒªãƒ¼ã‚¯ä½œæˆ
            leak_objects = []
            try:
                start_time = time.time()
                leak_objects = self.create_intentional_memory_leak(
                    leak_type, size_mb=8.0
                )
                leak_test_result["leak_created"] = True

                # ãƒªãƒ¼ã‚¯æ¤œå‡ºå®Ÿè¡Œ
                detection_start = time.time()
                leak_result = self.memory_optimizer.detect_memory_leaks(
                    threshold_mb=3.0, sample_interval=3
                )
                leak_test_result["detection_time_ms"] = (
                    time.time() - detection_start
                ) * 1000

                leak_test_result["leak_detected_after_creation"] = leak_result[
                    "leak_detected"
                ]
                leak_test_result["memory_growth_mb"] = leak_result["memory_growth_mb"]
                leak_test_result["gc_effect_mb"] = leak_result.get("gc_effect_mb", 0)

                self.logger.info(
                    f"{leak_type} leak: Created={leak_test_result['leak_created']}, "
                    f"Detected={leak_test_result['leak_detected_after_creation']}"
                )

            except Exception as e:
                self.logger.error(f"Error during {leak_type} leak test: {e}")
                leak_test_result["error"] = str(e)

            finally:
                # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                cleanup_start_memory = self.memory_optimizer.get_memory_stats()[
                    "process_memory_mb"
                ]

                # ãƒªãƒ¼ã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                if leak_type == "unclosed_files":
                    for temp_file in leak_objects:
                        try:
                            temp_file.close()
                            Path(temp_file.name).unlink(missing_ok=True)
                        except Exception:
                            pass

                leak_objects.clear()

                # å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
                self.memory_optimizer.force_garbage_collection()
                time.sleep(0.5)

                cleanup_end_memory = self.memory_optimizer.get_memory_stats()[
                    "process_memory_mb"
                ]
                memory_recovered = cleanup_start_memory - cleanup_end_memory
                leak_test_result["cleanup_effective"] = (
                    memory_recovered > 1.0
                )  # 1MBä»¥ä¸Šå›å

            results["leak_tests"].append(leak_test_result)

        # ç²¾åº¦è¨ˆç®—
        correct_detections = 0
        total_tests = len(results["leak_tests"])

        for test in results["leak_tests"]:
            # æ­£ã—ã„æ¤œå‡º: ãƒªãƒ¼ã‚¯ä½œæˆå¾Œã«æ¤œå‡ºã•ã‚Œã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã§ã¯æ¤œå‡ºã•ã‚Œãªã„
            if (
                test["leak_created"]
                and test["leak_detected_after_creation"]
                and not test["baseline_leak_detected"]
            ):
                correct_detections += 1

            # å½é™½æ€§: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã§ãƒªãƒ¼ã‚¯æ¤œå‡º
            if test["baseline_leak_detected"]:
                results["false_positives"] += 1

            # å½é™°æ€§: ãƒªãƒ¼ã‚¯ä½œæˆå¾Œã«æ¤œå‡ºã•ã‚Œãªã„
            if test["leak_created"] and not test["leak_detected_after_creation"]:
                results["false_negatives"] += 1

        results["detection_accuracy"] = (
            (correct_detections / total_tests * 100) if total_tests > 0 else 0
        )

        self.logger.info(
            f"Leak detection accuracy: {results['detection_accuracy']:.1f}%"
        )
        return results

    def test_leak_detection_sensitivity(
        self, threshold_levels: List[float] = None
    ) -> Dict[str, Any]:
        """
        ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºæ„Ÿåº¦ãƒ†ã‚¹ãƒˆ

        Args:
            threshold_levels: ãƒ†ã‚¹ãƒˆã™ã‚‹é–¾å€¤ãƒ¬ãƒ™ãƒ«ï¼ˆMBï¼‰

        Returns:
            Dict[str, Any]: ãƒ†ã‚¹ãƒˆçµæœ
        """
        if threshold_levels is None:
            threshold_levels = [1.0, 2.5, 5.0, 10.0, 20.0]

        self.logger.info(
            f"Starting leak detection sensitivity test with thresholds: {threshold_levels}"
        )

        results = {
            "test_name": "leak_detection_sensitivity",
            "threshold_tests": [],
            "optimal_threshold_mb": 0.0,
            "sensitivity_curve": [],
        }

        # æ®µéšçš„ã«ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’ä½œæˆ
        leak_sizes = [1.0, 3.0, 7.0, 15.0]  # MB

        for leak_size in leak_sizes:
            self.logger.info(f"Testing leak size: {leak_size} MB")

            # ãƒªãƒ¼ã‚¯ä½œæˆ
            leak_objects = self.create_intentional_memory_leak(
                "growing_list", size_mb=leak_size
            )

            try:
                threshold_results = []

                for threshold in threshold_levels:
                    detection_result = self.memory_optimizer.detect_memory_leaks(
                        threshold_mb=threshold, sample_interval=2
                    )

                    threshold_results.append(
                        {
                            "threshold_mb": threshold,
                            "leak_detected": detection_result["leak_detected"],
                            "memory_growth_mb": detection_result["memory_growth_mb"],
                            "detection_confidence": self._calculate_detection_confidence(
                                detection_result
                            ),
                        }
                    )

                sensitivity_point = {
                    "leak_size_mb": leak_size,
                    "threshold_results": threshold_results,
                    "min_detection_threshold": self._find_min_detection_threshold(
                        threshold_results
                    ),
                }

                results["sensitivity_curve"].append(sensitivity_point)

            finally:
                # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                leak_objects.clear()
                self.memory_optimizer.force_garbage_collection()
                time.sleep(0.5)

        # æœ€é©é–¾å€¤è¨ˆç®—
        results["optimal_threshold_mb"] = self._calculate_optimal_threshold(
            results["sensitivity_curve"]
        )

        self.logger.info(
            f"Optimal detection threshold: {results['optimal_threshold_mb']:.1f} MB"
        )
        return results

    def test_leak_detection_under_load(
        self, concurrent_threads: int = 4, duration_minutes: int = 5
    ) -> Dict[str, Any]:
        """
        è² è·ä¸‹ã§ã®ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆ

        Args:
            concurrent_threads: ä¸¦è¡Œã‚¹ãƒ¬ãƒƒãƒ‰æ•°
            duration_minutes: ãƒ†ã‚¹ãƒˆç¶™ç¶šæ™‚é–“ï¼ˆåˆ†ï¼‰

        Returns:
            Dict[str, Any]: ãƒ†ã‚¹ãƒˆçµæœ
        """
        self.logger.info(
            f"Starting leak detection under load test: {concurrent_threads} threads, {duration_minutes} min"
        )

        results = {
            "test_name": "leak_detection_under_load",
            "concurrent_threads": concurrent_threads,
            "duration_minutes": duration_minutes,
            "detection_attempts": 0,
            "successful_detections": 0,
            "detection_times_ms": [],
            "load_impact_factor": 0.0,
        }

        test_active = threading.Event()
        test_active.set()

        detection_results = []
        detection_lock = threading.Lock()

        def load_generator_thread(thread_id: int):
            """è² è·ç”Ÿæˆã‚¹ãƒ¬ãƒƒãƒ‰"""
            local_objects = []

            while test_active.is_set():
                try:
                    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                    temp_data = ["x" * 10000] * 100  # 1MBç¨‹åº¦
                    local_objects.append(temp_data)

                    # å®šæœŸçš„ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    if len(local_objects) > 10:
                        local_objects.clear()

                    time.sleep(0.1)

                except Exception as e:
                    self.logger.warning(f"Load generator thread {thread_id} error: {e}")

        def leak_detection_thread():
            """ãƒªãƒ¼ã‚¯æ¤œå‡ºã‚¹ãƒ¬ãƒƒãƒ‰"""
            while test_active.is_set():
                try:
                    start_time = time.time()

                    leak_result = self.memory_optimizer.detect_memory_leaks(
                        threshold_mb=5.0, sample_interval=2
                    )

                    detection_time = (time.time() - start_time) * 1000

                    with detection_lock:
                        detection_results.append(
                            {
                                "timestamp": time.time(),
                                "detection_time_ms": detection_time,
                                "leak_detected": leak_result["leak_detected"],
                                "memory_growth_mb": leak_result["memory_growth_mb"],
                            }
                        )

                    time.sleep(2)  # 2ç§’é–“éš”ã§æ¤œå‡ºå®Ÿè¡Œ

                except Exception as e:
                    self.logger.warning(f"Leak detection thread error: {e}")

        # ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        load_threads = []
        for i in range(concurrent_threads):
            thread = threading.Thread(target=load_generator_thread, args=(i,))
            thread.start()
            load_threads.append(thread)

        detection_thread = threading.Thread(target=leak_detection_thread)
        detection_thread.start()

        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        time.sleep(duration_minutes * 60)

        # çµ‚äº†å‡¦ç†
        test_active.clear()

        for thread in load_threads:
            thread.join(timeout=2)

        detection_thread.join(timeout=5)

        # çµæœåˆ†æ
        results["detection_attempts"] = len(detection_results)
        results["successful_detections"] = sum(
            1 for r in detection_results if r["leak_detected"]
        )
        results["detection_times_ms"] = [
            r["detection_time_ms"] for r in detection_results
        ]

        if results["detection_times_ms"]:
            avg_detection_time = sum(results["detection_times_ms"]) / len(
                results["detection_times_ms"]
            )
            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¤œå‡ºæ™‚é–“ã¨æ¯”è¼ƒï¼ˆè² è·ãªã—ã§ã®æ¤œå‡ºæ™‚é–“ï¼‰
            baseline_time = 100  # ä»®å®šå€¤ï¼ˆmsï¼‰
            results["load_impact_factor"] = avg_detection_time / baseline_time

        self.logger.info(
            f"Load test completed. Detection rate: {results['successful_detections']}/{results['detection_attempts']}"
        )
        return results

    def _calculate_detection_confidence(
        self, detection_result: Dict[str, Any]
    ) -> float:
        """æ¤œå‡ºä¿¡é ¼åº¦è¨ˆç®—"""
        if not detection_result["leak_detected"]:
            return 0.0

        growth = detection_result.get("memory_growth_mb", 0)
        gc_effect = detection_result.get("gc_effect_mb", 0)

        # GCåŠ¹æœãŒä½ã„ã»ã©ä¿¡é ¼åº¦ãŒé«˜ã„
        confidence = (
            max(0, min(100, (growth - gc_effect) / growth * 100)) if growth > 0 else 0
        )
        return confidence

    def _find_min_detection_threshold(
        self, threshold_results: List[Dict[str, Any]]
    ) -> float:
        """æœ€å°æ¤œå‡ºé–¾å€¤ã‚’è¦‹ã¤ã‘ã‚‹"""
        for result in sorted(threshold_results, key=lambda x: x["threshold_mb"]):
            if result["leak_detected"]:
                return result["threshold_mb"]
        return float("inf")

    def _calculate_optimal_threshold(
        self, sensitivity_curve: List[Dict[str, Any]]
    ) -> float:
        """æœ€é©é–¾å€¤è¨ˆç®—"""
        if not sensitivity_curve:
            return 5.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

        # å„ãƒªãƒ¼ã‚¯ã‚µã‚¤ã‚ºã«å¯¾ã™ã‚‹æœ€å°æ¤œå‡ºé–¾å€¤ã®å¹³å‡
        min_thresholds = []
        for point in sensitivity_curve:
            min_threshold = point["min_detection_threshold"]
            if min_threshold != float("inf"):
                min_thresholds.append(min_threshold)

        return sum(min_thresholds) / len(min_thresholds) if min_thresholds else 5.0


# Pytestãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
class TestMemoryLeakDetection:
    """Pytestç”¨ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""

    def setup_method(self):
        """å„ãƒ†ã‚¹ãƒˆå‰ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.test_suite = MemoryLeakDetectionTest()

    @pytest.mark.performance
    def test_basic_leak_detection(self):
        """åŸºæœ¬çš„ãªãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        result = self.test_suite.test_leak_detection_accuracy(
            leak_types=["growing_list"]
        )

        # æ¤œè¨¼æ¡ä»¶
        assert len(result["leak_tests"]) > 0, "ãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“"
        assert result["detection_accuracy"] > 50.0, "æ¤œå‡ºç²¾åº¦ãŒ50%ã‚’ä¸‹å›ã‚Šã¾ã—ãŸ"

    @pytest.mark.performance
    def test_sensitivity_basic(self):
        """åŸºæœ¬çš„ãªæ¤œå‡ºæ„Ÿåº¦ãƒ†ã‚¹ãƒˆ"""
        result = self.test_suite.test_leak_detection_sensitivity(
            threshold_levels=[2.0, 5.0, 10.0]
        )

        # æ¤œè¨¼æ¡ä»¶
        assert len(result["sensitivity_curve"]) > 0, "æ„Ÿåº¦ãƒ†ã‚¹ãƒˆçµæœãŒç©ºã§ã™"
        assert result["optimal_threshold_mb"] > 0, "æœ€é©é–¾å€¤ãŒè¨ˆç®—ã•ã‚Œã¦ã„ã¾ã›ã‚“"

    @pytest.mark.performance
    @pytest.mark.slow
    def test_load_detection_basic(self):
        """åŸºæœ¬çš„ãªè² è·ä¸‹æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        result = self.test_suite.test_leak_detection_under_load(
            concurrent_threads=2, duration_minutes=1
        )

        # æ¤œè¨¼æ¡ä»¶
        assert result["detection_attempts"] > 0, "æ¤œå‡ºè©¦è¡ŒãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        assert result["load_impact_factor"] > 0, "è² è·å½±éŸ¿ä¿‚æ•°ãŒè¨ˆç®—ã•ã‚Œã¦ã„ã¾ã›ã‚“"


if __name__ == "__main__":
    # ç›´æ¥å®Ÿè¡Œæ™‚ã®ãƒ†ã‚¹ãƒˆ
    print("ğŸ” ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆé–‹å§‹...")

    test_suite = MemoryLeakDetectionTest()

    # å„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("1. ãƒªãƒ¼ã‚¯æ¤œå‡ºç²¾åº¦ãƒ†ã‚¹ãƒˆ...")
    result1 = test_suite.test_leak_detection_accuracy()
    print(f"   æ¤œå‡ºç²¾åº¦: {result1['detection_accuracy']:.1f}%")

    print("2. æ¤œå‡ºæ„Ÿåº¦ãƒ†ã‚¹ãƒˆ...")
    result2 = test_suite.test_leak_detection_sensitivity()
    print(f"   æœ€é©é–¾å€¤: {result2['optimal_threshold_mb']:.1f} MB")

    print("3. è² è·ä¸‹æ¤œå‡ºãƒ†ã‚¹ãƒˆ...")
    result3 = test_suite.test_leak_detection_under_load(
        concurrent_threads=2, duration_minutes=2
    )
    print(
        f"   æ¤œå‡ºè©¦è¡Œ: {result3['detection_attempts']}, æˆåŠŸ: {result3['successful_detections']}"
    )

    print("âœ… å…¨ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
