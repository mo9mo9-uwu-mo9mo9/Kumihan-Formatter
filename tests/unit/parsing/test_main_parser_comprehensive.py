"""
MainParseråŠ¹ç‡åŒ–ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

Issue #1113: 701â†’200ãƒ†ã‚¹ãƒˆå‰Šæ¸›ã«ã‚ˆã‚‹70%å®Ÿè¡Œæ™‚é–“çŸ­ç¸®

çµ±åˆã•ã‚ŒãŸãƒ†ã‚¹ãƒˆé ˜åŸŸï¼š
- åŸºæœ¬æ©Ÿèƒ½ï¼ˆåˆæœŸåŒ–ãƒ»ãƒ‘ãƒ¼ã‚¹ãƒ»çµ±è¨ˆï¼‰
- Kumihanè¨˜æ³•è§£æï¼ˆçµ±åˆãƒ†ã‚¹ãƒˆï¼‰
- çµ±åˆæ©Ÿèƒ½ï¼ˆãƒ‘ãƒ¼ã‚µãƒ¼é€£æºï¼‰
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆä¾‹å¤–ãƒ»ä¸æ­£å…¥åŠ›ï¼‰
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆå¤§å®¹é‡ãƒ»ä¸¦åˆ—ï¼‰
"""

import os
import time
from concurrent.futures import ThreadPoolExecutor
from typing import Iterator
from unittest.mock import Mock, patch

import pytest

from kumihan_formatter.core.ast_nodes import Node, create_node, error_node
from kumihan_formatter.core.parsing.main_parser import MainParser
from kumihan_formatter.core.utilities.logger import get_logger


class TestMainParserCore:
    """MainParseråŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        self.parser = MainParser()
        self.logger = get_logger(self.__class__.__name__)

    @pytest.mark.parametrize("config,expected_type", [
        (None, "main"),
        ({"test": "value"}, "main"),
        ({}, "main"),
    ])
    def test_initialization_variants(self, config, expected_type):
        """åˆæœŸåŒ–ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""
        parser = MainParser(config=config)
        assert parser.parser_type == expected_type
        assert hasattr(parser, "parsers")

        # å°‚é–€ãƒ‘ãƒ¼ã‚µãƒ¼ã®å­˜åœ¨ç¢ºèª
        expected_parsers = ["keyword", "list", "block", "markdown"]
        for parser_name in expected_parsers:
            assert parser_name in parser.parsers

    @pytest.mark.parametrize("input_text,expected_type", [
        ("åŸºæœ¬ãƒ†ã‚­ã‚¹ãƒˆ", "text"),
        ("", "error"),
        ("   \n\t  \n  ", "error"),
        (None, "error"),
        (123, "error"),
    ])
    def test_parse_inputs(self, input_text, expected_type):
        """ãƒ‘ãƒ¼ã‚¹å…¥åŠ›ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""
        result = self.parser.parse(input_text)
        assert isinstance(result, list)
        assert len(result) >= 1
        if expected_type == "error":
            assert result[0].type == "error"
        else:
            assert all(isinstance(node, Node) for node in result)

    def test_statistics_and_state_management(self):
        """çµ±è¨ˆã¨çŠ¶æ…‹ç®¡ç†çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # åˆæœŸçµ±è¨ˆç¢ºèª
        initial_stats = self.parser.get_performance_stats()
        assert initial_stats["total_parses"] == 0

        # è¤‡æ•°ãƒ‘ãƒ¼ã‚¹å®Ÿè¡Œ
        texts = ["ãƒ†ã‚¹ãƒˆ1", "ãƒ†ã‚¹ãƒˆ2", "ãƒ†ã‚¹ãƒˆ3"]
        for i, text in enumerate(texts, 1):
            result = self.parser.parse(text)
            assert len(result) > 0
            stats = self.parser.get_performance_stats()
            assert stats["total_parses"] == i
            assert stats["total_time"] > 0

        # çµ±è¨ˆãƒªã‚»ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
        self.parser.reset_statistics()
        reset_stats = self.parser.get_performance_stats()
        assert reset_stats["total_parses"] == 0
        assert reset_stats["total_time"] == 0.0


class TestMainParserKumihanNotation:
    """Kumihanè¨˜æ³•è§£æçµ±åˆãƒ†ã‚¹ãƒˆ"""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        self.parser = MainParser()

    @pytest.mark.parametrize("notation_text,description", [
        ("#å¤ªå­—#\né‡è¦ãªæƒ…å ±\n##", "åŸºæœ¬ãƒ–ãƒ­ãƒƒã‚¯è¨˜æ³•"),
        ("ã“ã‚Œã¯ #å¼·èª¿# ã•ã‚ŒãŸæ–‡ç« ã§ã™ã€‚", "ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³è¨˜æ³•"),
        ("#è¦‹å‡ºã—#\nã‚¿ã‚¤ãƒˆãƒ«\n##\n\né€šå¸¸ãƒ†ã‚­ã‚¹ãƒˆ", "æ··åˆè¨˜æ³•"),
        ("#å¤–éƒ¨#\n#å†…éƒ¨#\nå†…å®¹\n##\n##", "ãƒã‚¹ãƒˆæ§‹é€ "),
        ("#ä¸å®Œå…¨ãªãƒ–ãƒ­ãƒƒã‚¯", "ä¸æ­£å½¢å¼è¨˜æ³•"),
    ])
    def test_kumihan_notation_parsing(self, notation_text, description):
        """Kumihanè¨˜æ³•çµ±åˆãƒ‘ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ"""
        result = self.parser.parse(notation_text)
        assert isinstance(result, list)
        assert len(result) > 0
        # å…¨ã¦ã®ãƒãƒ¼ãƒ‰ãŒé©åˆ‡ãªå‹ã‚’æŒã¤ã“ã¨ã‚’ç¢ºèª
        for node in result:
            assert hasattr(node, "type")

    def test_complex_document_structure(self):
        """è¤‡é›‘æ–‡æ›¸æ§‹é€ ãƒ†ã‚¹ãƒˆ"""
        complex_text = """#æ–‡æ›¸ã‚¿ã‚¤ãƒˆãƒ«#
ãƒ¡ã‚¤ãƒ³æ–‡æ›¸
##

#ã‚»ã‚¯ã‚·ãƒ§ãƒ³1#
å†…å®¹
##

- ãƒªã‚¹ãƒˆé …ç›®1
- ãƒªã‚¹ãƒˆé …ç›®2

#çµè«–#
ã¾ã¨ã‚
##"""

        result = self.parser.parse(complex_text)
        assert isinstance(result, list)
        assert len(result) > 0


class TestMainParserIntegration:
    """çµ±åˆãƒ»å”èª¿æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        self.parser = MainParser()

    def test_specialized_parsers_availability(self):
        """å°‚é–€ãƒ‘ãƒ¼ã‚µãƒ¼åˆ©ç”¨å¯èƒ½æ€§ãƒ†ã‚¹ãƒˆ"""
        expected_parsers = ["keyword", "list", "block", "markdown"]
        for parser_name in expected_parsers:
            assert parser_name in self.parser.parsers
            assert self.parser.parsers[parser_name] is not None

    @pytest.mark.parametrize("parser_type,test_text", [
        ("keyword", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ"),
        ("list", "- é …ç›®1\n- é …ç›®2"),
        ("markdown", "# Heading\n**Bold**"),
    ])
    def test_parser_integration_execution(self, parser_type, test_text):
        """ãƒ‘ãƒ¼ã‚µãƒ¼çµ±åˆå®Ÿè¡Œãƒ†ã‚¹ãƒˆ"""
        assert parser_type in self.parser.parsers
        result = self.parser.parse(test_text)
        assert isinstance(result, list)
        assert len(result) > 0

    def test_parser_management_operations(self):
        """ãƒ‘ãƒ¼ã‚µãƒ¼ç®¡ç†æ“ä½œçµ±åˆãƒ†ã‚¹ãƒˆ"""
        # ãƒ‘ãƒ¼ã‚µãƒ¼æƒ…å ±å–å¾—
        info = self.parser.get_parser_info()
        assert isinstance(info, dict)
        assert "main_parser" in info
        assert "specialized_parsers" in info

        # ãƒ‘ãƒ¼ã‚µãƒ¼ç™»éŒ²ãƒ»è§£é™¤
        mock_parser = Mock()
        mock_parser.can_parse.return_value = True
        mock_parser.parse.return_value = [create_node("test", content="test")]

        self.parser.register_parser("test_parser", mock_parser)
        assert "test_parser" in self.parser.parsers

        success = self.parser.unregister_parser("test_parser")
        assert success is True
        assert "test_parser" not in self.parser.parsers

        # å­˜åœ¨ã—ãªã„ãƒ‘ãƒ¼ã‚µãƒ¼ã®è§£é™¤
        success = self.parser.unregister_parser("nonexistent")
        assert success is False

    def test_parser_selection_mechanism(self):
        """ãƒ‘ãƒ¼ã‚µãƒ¼é¸æŠæ©Ÿæ§‹ãƒ†ã‚¹ãƒˆ"""
        selected_parsers = self.parser._select_parsers("ãƒ†ã‚¹ãƒˆ")
        assert isinstance(selected_parsers, list)
        assert len(selected_parsers) >= 0


class TestMainParserErrorHandling:
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°çµ±åˆãƒ†ã‚¹ãƒˆ"""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        self.parser = MainParser()

    @pytest.mark.parametrize("invalid_input,expected_error", [
        (None, "error"),
        (123, "error"),
        (["test"], "error"),
        ("", "error"),
        ("   \n\t\n   ", "error"),
    ])
    def test_invalid_input_handling(self, invalid_input, expected_error):
        """ä¸æ­£å…¥åŠ›çµ±åˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        result = self.parser.parse(invalid_input)
        assert isinstance(result, list)
        assert len(result) >= 1
        assert result[0].type == expected_error

    def test_special_and_large_input_handling(self):
        """ç‰¹æ®Šãƒ»å¤§å®¹é‡å…¥åŠ›ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        test_cases = [
            "ğŸ¯ğŸ“‹âœ…âŒ",  # çµµæ–‡å­—
            "ãƒ†ã‚¹ãƒˆ\x00\x01\x02",  # åˆ¶å¾¡æ–‡å­—
            "a" * 100000,  # å¤§å®¹é‡
            "ãƒ†ã‚¹ãƒˆ\n" * 1000,  # å¤§é‡æ”¹è¡Œ
        ]

        for text in test_cases:
            try:
                result = self.parser.parse(text)
                assert isinstance(result, list)
                assert len(result) > 0
            except Exception:
                # ä¾‹å¤–ç™ºç”Ÿæ™‚ã‚‚å‡¦ç†ç¶™ç¶š
                pass

    def test_graceful_degradation_and_concurrency(self):
        """å„ªé›…ãªåŠ£åŒ–ã¨ä¸¦è¡Œå‡¦ç†çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # ãƒ‘ãƒ¼ã‚µãƒ¼ç„¡åŠ¹åŒ–ãƒ†ã‚¹ãƒˆ
        original = self.parser.parsers["keyword"]
        self.parser.parsers["keyword"] = None

        try:
            result = self.parser.parse("åŠ£åŒ–ãƒ†ã‚¹ãƒˆ")
            assert isinstance(result, list)
        finally:
            self.parser.parsers["keyword"] = original

        # ä¸¦è¡Œå‡¦ç†ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        def concurrent_parse():
            return self.parser.parse("ä¸¦è¡Œãƒ†ã‚¹ãƒˆ" * 100)

        with ThreadPoolExecutor(max_workers=2) as executor:
            futures = [executor.submit(concurrent_parse) for _ in range(2)]
            for future in futures:
                try:
                    result = future.result(timeout=3)
                    assert isinstance(result, list)
                except Exception:
                    pass


class TestMainParserPerformance:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆ"""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        self.parser = MainParser()

    def test_large_document_processing(self):
        """å¤§å®¹é‡æ–‡æ›¸å‡¦ç†çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # å¤§å®¹é‡ãƒ†ã‚­ã‚¹ãƒˆï¼ˆç´„50KBï¼‰
        large_text = "#å¤§å®¹é‡ãƒ†ã‚¹ãƒˆ#\nãƒ†ã‚¹ãƒˆå†…å®¹\n##\n" * 1000

        start_time = time.time()
        result = self.parser.parse(large_text)
        elapsed_time = time.time() - start_time

        assert isinstance(result, list)
        assert len(result) > 0
        assert elapsed_time < 10.0  # 10ç§’ä»¥å†…

    def test_parallel_processing_capabilities(self):
        """ä¸¦åˆ—å‡¦ç†æ©Ÿèƒ½çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # ä¸¦åˆ—å‡¦ç†é–¾å€¤ãƒ†ã‚¹ãƒˆ
        small_text = "å°ã•ãªãƒ†ã‚­ã‚¹ãƒˆ"
        large_text = "å¤§ããªãƒ†ã‚­ã‚¹ãƒˆ\n" * 20000

        assert not self.parser._should_use_parallel_processing(small_text)
        assert self.parser._should_use_parallel_processing(large_text)

        # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ãƒ†ã‚¹ãƒˆ
        chunks = self.parser._split_into_chunks(large_text)
        assert isinstance(chunks, list)
        assert len(chunks) > 1

    def test_streaming_and_memory_management(self):
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ»ãƒ¡ãƒ¢ãƒªç®¡ç†çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†
        def text_stream():
            for i in range(50):
                yield f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° {i}\n"

        start_time = time.time()
        results = list(self.parser.parse_streaming(text_stream()))
        elapsed_time = time.time() - start_time

        assert len(results) > 0
        assert elapsed_time < 5.0

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å®‰å®šæ€§ï¼ˆçµ±è¨ˆãƒªã‚»ãƒƒãƒˆå«ã‚€ï¼‰
        for i in range(20):
            text = f"ãƒ¡ãƒ¢ãƒªãƒ†ã‚¹ãƒˆ {i}\n" * 50
            result = self.parser.parse(text)
            assert len(result) > 0
            if i % 10 == 0:
                self.parser.reset_statistics()

    def test_concurrent_processing_safety(self):
        """ä¸¦è¡Œå‡¦ç†å®‰å…¨æ€§çµ±åˆãƒ†ã‚¹ãƒˆ"""
        def parse_task(task_id):
            return self.parser.parse(f"ä¸¦è¡Œãƒ†ã‚¹ãƒˆ {task_id}")

        with ThreadPoolExecutor(max_workers=3) as executor:
            tasks = [executor.submit(parse_task, i) for i in range(6)]
            results = []

            for task in tasks:
                try:
                    result = task.result(timeout=2)
                    results.append(result)
                except Exception:
                    pass

            assert len(results) > 0


class TestMainParserProtocols:
    """ãƒ—ãƒ­ãƒˆã‚³ãƒ«æº–æ‹ çµ±åˆãƒ†ã‚¹ãƒˆ"""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        self.parser = MainParser()

    def test_parse_and_validation_protocols(self):
        """ãƒ‘ãƒ¼ã‚¹ãƒ»ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ—ãƒ­ãƒˆã‚³ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆ"""
        content = "ãƒ—ãƒ­ãƒˆã‚³ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆ"

        # ãƒ‘ãƒ¼ã‚¹ãƒ—ãƒ­ãƒˆã‚³ãƒ«
        parse_result = self.parser.parse_protocol(content)
        assert hasattr(parse_result, "success")
        assert hasattr(parse_result, "nodes")
        assert parse_result.success is True
        assert isinstance(parse_result.nodes, list)

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ—ãƒ­ãƒˆã‚³ãƒ«
        validation_errors = self.parser.validate(content)
        assert isinstance(validation_errors, list)

    def test_format_support_and_info_protocols(self):
        """ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œãƒ»æƒ…å ±ãƒ—ãƒ­ãƒˆã‚³ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œç¢ºèª
        supported = ["kumihan", "markdown", "text", "auto"]
        for fmt in supported:
            assert self.parser.supports_format(fmt) is True
        assert self.parser.supports_format("unsupported") is False

        # ãƒ‘ãƒ¼ã‚µãƒ¼æƒ…å ±ãƒ—ãƒ­ãƒˆã‚³ãƒ«
        info = self.parser.get_parser_info_protocol()
        assert isinstance(info, dict)
        required_keys = ["name", "version", "supported_formats", "capabilities"]
        for key in required_keys:
            assert key in info
        assert info["name"] == "MainParser"

    def test_streaming_protocol_integration(self):
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ—ãƒ­ãƒˆã‚³ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆ"""
        def test_stream():
            yield "ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°"
            yield "ãƒ—ãƒ­ãƒˆã‚³ãƒ«"
            yield "çµ±åˆãƒ†ã‚¹ãƒˆ"

        results = list(self.parser.parse_streaming_protocol(test_stream()))
        assert len(results) > 0

        for result in results:
            assert hasattr(result, "success")
            assert hasattr(result, "nodes")


class TestMainParserUtilities:
    """ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£æ©Ÿèƒ½çµ±åˆãƒ†ã‚¹ãƒˆ"""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        self.parser = MainParser()

    def test_element_extraction_and_stats(self):
        """è¦ç´ æŠ½å‡ºãƒ»çµ±è¨ˆæ©Ÿèƒ½çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # è¦ç´ æŠ½å‡ºãƒ†ã‚¹ãƒˆ
        buffer = "#è¦ç´ 1##ãƒ†ã‚­ã‚¹ãƒˆ##è¦ç´ 2##æ®‹ã‚Š"
        elements, remaining = self.parser._extract_complete_elements(buffer)
        assert isinstance(elements, list)
        assert isinstance(remaining, str)

        # çµ±è¨ˆæ›´æ–°ãƒ†ã‚¹ãƒˆ
        self.parser.parse("çµ±è¨ˆãƒ†ã‚¹ãƒˆ")
        initial_stats = self.parser.get_performance_stats()
        self.parser._update_performance_stats(0.1)
        updated_stats = self.parser.get_performance_stats()
        assert updated_stats["total_time"] > initial_stats["total_time"]

    @pytest.mark.parametrize("input_value,expected", [
        ("æœ‰åŠ¹ãªãƒ†ã‚­ã‚¹ãƒˆ", True),
        ("", False),
        ("   ", False),
        (None, False),
        (123, False),
    ])
    def test_input_validation_utilities(self, input_value, expected):
        """å…¥åŠ›æ¤œè¨¼ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£çµ±åˆãƒ†ã‚¹ãƒˆ"""
        result = self.parser._validate_input(input_value)
        assert result is expected

    def test_system_utilities(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # CPUæ•°å–å¾—
        cpu_count = self.parser._get_cpu_count()
        assert cpu_count is None or (isinstance(cpu_count, int) and cpu_count > 0)

    def test_advanced_di_and_factory_integration(self):
        """é«˜åº¦ãªDIãƒ»ãƒ•ã‚¡ã‚¯ãƒˆãƒªçµ±åˆãƒ†ã‚¹ãƒˆ"""
        # DI Containerè¤‡é›‘ã‚·ãƒŠãƒªã‚ª
        mock_container = Mock()
        resolution_calls = 0

        def mock_resolve(cls):
            nonlocal resolution_calls
            resolution_calls += 1
            if resolution_calls > 5:
                raise Exception("Too many calls")
            mock_instance = Mock()
            mock_instance.can_parse.return_value = True
            mock_instance.parse.return_value = [create_node("test", content="resolved")]
            return mock_instance

        mock_container.resolve.side_effect = mock_resolve
        di_parser = MainParser(container=mock_container)
        result = di_parser.parse("DIçµ±åˆãƒ†ã‚¹ãƒˆ")

        assert isinstance(result, list)
        assert resolution_calls <= 5

    def test_import_error_paths_and_edge_cases(self):
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¹ãƒ»ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # DI Container ImportError
        with patch("kumihan_formatter.core.patterns.dependency_injection.get_container") as mock_get:
            mock_get.side_effect = ImportError("DI module not found")
            parser = MainParser()
            assert parser.container is None
            assert parser.parser_factory is None


@pytest.mark.integration
class TestMainParserEndToEnd:
    """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰çµ±åˆãƒ†ã‚¹ãƒˆ"""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        self.parser = MainParser()

    def test_complete_document_processing(self):
        """å®Œå…¨æ–‡æ›¸å‡¦ç†çµ±åˆãƒ†ã‚¹ãƒˆ"""
        document = """#ãƒ¡ã‚¤ãƒ³æ–‡æ›¸#
åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

#ã‚»ã‚¯ã‚·ãƒ§ãƒ³1#
- åŸºæœ¬æ©Ÿèƒ½
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
##

#ã‚»ã‚¯ã‚·ãƒ§ãƒ³2#
å¿œç”¨æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
##

#çµè«–#
å…¨æ©Ÿèƒ½æ­£å¸¸å‹•ä½œç¢ºèª
##"""

        start_time = time.time()
        result = self.parser.parse(document)
        elapsed_time = time.time() - start_time

        assert isinstance(result, list)
        assert len(result) > 0
        assert elapsed_time < 1.0

        stats = self.parser.get_performance_stats()
        assert stats["total_parses"] == 1
        assert stats["total_time"] > 0

    def test_real_world_usage_and_error_recovery(self):
        """å®Ÿä¸–ç•Œä½¿ç”¨ãƒ»ã‚¨ãƒ©ãƒ¼å›å¾©çµ±åˆãƒ†ã‚¹ãƒˆ"""
        # å¤šæ§˜ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ†ã‚¹ãƒˆ
        contents = [
            "çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆ",
            "#è¦‹å‡ºã—#\nå†…å®¹\n##",
            "- ãƒªã‚¹ãƒˆé …ç›®",
            "# ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³\n**å¤ªå­—**",
            "#ä¸å®Œå…¨ãƒ–ãƒ­ãƒƒã‚¯",  # ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹
            "æ­£å¸¸ãƒ†ã‚­ã‚¹ãƒˆ",
        ]

        successful_parses = 0
        for content in contents:
            try:
                result = self.parser.parse(content)
                if isinstance(result, list) and len(result) > 0:
                    successful_parses += 1
            except Exception:
                pass

        assert successful_parses >= len(contents) - 1  # ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹é™¤ã

        final_stats = self.parser.get_performance_stats()
        assert final_stats["total_parses"] >= successful_parses
