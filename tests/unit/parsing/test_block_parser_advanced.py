"""Block Parseré«˜åº¦ãƒ†ã‚¹ãƒˆ - Issue #597 Week 28-29å¯¾å¿œ

ãƒ–ãƒ­ãƒƒã‚¯è§£ææ©Ÿèƒ½ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
Kumihanè¨˜æ³•ã®å®Œå…¨å¯¾å¿œãƒ»ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ»æ€§èƒ½æ¤œè¨¼
"""

import time
from unittest.mock import Mock, patch

import pytest

from kumihan_formatter.core.ast_nodes import (
    Node,
    error_node,
    paragraph,
    toc_marker,
)
from kumihan_formatter.core.block_parser.block_parser import BlockParser
from kumihan_formatter.core.keyword_parser import KeywordParser


class TestBlockParserAdvanced:
    """ãƒ–ãƒ­ãƒƒã‚¯ãƒ‘ãƒ¼ã‚µãƒ¼é«˜åº¦ãƒ†ã‚¹ãƒˆ"""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.keyword_parser = KeywordParser()
        self.block_parser = BlockParser(self.keyword_parser)

    def test_block_parser_initialization(self):
        """ãƒ–ãƒ­ãƒƒã‚¯ãƒ‘ãƒ¼ã‚µãƒ¼åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
        assert self.block_parser.keyword_parser is not None
        assert self.block_parser.marker_validator is not None
        assert self.block_parser.heading_counter == 0
        assert hasattr(self.block_parser, "logger")

    def test_parse_block_marker_basic_functionality(self):
        """åŸºæœ¬ãƒ–ãƒ­ãƒƒã‚¯ãƒãƒ¼ã‚«ãƒ¼è§£æãƒ†ã‚¹ãƒˆ"""
        lines = [
            ";;;è£…é£¾å;;;",
            "ãƒ†ã‚¹ãƒˆå†…å®¹",
            ";;;",
        ]

        node, next_index = self.block_parser.parse_block_marker(lines, 0)

        assert node is not None
        assert next_index == 3
        assert node.type in ["keyword_block", "decorated_block"]

    def test_parse_complex_kumihan_syntax(self):
        """è¤‡é›‘ãªKumihanè¨˜æ³•è§£æãƒ†ã‚¹ãƒˆ"""
        # è¤‡åˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯
        complex_syntax = [
            ";;;æ³¨é‡ˆ;;; é‡è¦ãªå†…å®¹ã§ã™ ;;;",
            ";;;å¼·èª¿;;; ã“ã®éƒ¨åˆ†ã¯ç‰¹ã«é‡è¦ ;;;",
            ";;;å¼•ç”¨;;;",
            "é•·ã„å¼•ç”¨æ–‡ã®å†…å®¹",
            "è¤‡æ•°è¡Œã«ã‚ãŸã‚‹å¼•ç”¨",
            ";;;",
            ";;;ã‚³ãƒ¼ãƒ‰;;;",
            "def example():",
            "    return 'Hello World'",
            ";;;",
        ]

        results = []
        index = 0
        while index < len(complex_syntax):
            if complex_syntax[index].strip().startswith(";;;"):
                node, next_index = self.block_parser.parse_block_marker(
                    complex_syntax, index
                )
                results.append((node, next_index))
                index = next_index
            else:
                index += 1

        # è¤‡æ•°ã®ãƒ–ãƒ­ãƒƒã‚¯ãŒæ­£ã—ãè§£æã•ã‚Œã‚‹
        assert len(results) >= 3
        assert all(node is not None for node, _ in results)

    def test_nested_block_structure_parsing(self):
        """ãƒã‚¹ãƒˆæ§‹é€ ãƒ–ãƒ­ãƒƒã‚¯è§£æãƒ†ã‚¹ãƒˆ"""
        nested_blocks = [
            ";;;å¤–éƒ¨ãƒ–ãƒ­ãƒƒã‚¯;;;",
            "å¤–éƒ¨ã®å†…å®¹",
            ";;;å†…éƒ¨ãƒ–ãƒ­ãƒƒã‚¯;;;",
            "å†…éƒ¨ã®å†…å®¹",
            ";;;",
            "å¤–éƒ¨ã«æˆ»ã‚‹",
            ";;;",
        ]

        # å¤–éƒ¨ãƒ–ãƒ­ãƒƒã‚¯ã®è§£æ
        outer_node, outer_end = self.block_parser.parse_block_marker(nested_blocks, 0)
        assert outer_node is not None
        assert outer_end == len(nested_blocks)

        # å†…éƒ¨ãƒ–ãƒ­ãƒƒã‚¯ã®è§£æ
        inner_node, inner_end = self.block_parser.parse_block_marker(nested_blocks, 2)
        assert inner_node is not None
        assert inner_end == 5

    def test_error_recovery_invalid_markers(self):
        """ç„¡åŠ¹ãªãƒãƒ¼ã‚«ãƒ¼ã§ã®ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ†ã‚¹ãƒˆ"""
        invalid_syntax = [
            ";;ä¸å®Œå…¨ãªãƒãƒ¼ã‚«ãƒ¼",
            ";;;æœ‰åŠ¹ãªãƒãƒ¼ã‚«ãƒ¼;;;",
            "æ­£å¸¸ãªå†…å®¹",
            ";;;",
            ";;ã‚‚ã†ä¸€ã¤ã®ä¸å®Œå…¨",
            ";;;åˆ¥ã®æœ‰åŠ¹ãªãƒãƒ¼ã‚«ãƒ¼;;; å³åº§ã«é–‰ã˜ã‚‹ ;;;",
        ]

        results = []
        index = 0
        while index < len(invalid_syntax):
            line = invalid_syntax[index].strip()
            if line.startswith(";;"):
                node, next_index = self.block_parser.parse_block_marker(
                    invalid_syntax, index
                )
                results.append(
                    (
                        node,
                        next_index,
                        "error" if node and hasattr(node, "error") else "success",
                    )
                )
                index = next_index
            else:
                index += 1

        # ã‚¨ãƒ©ãƒ¼ãƒãƒ¼ãƒ‰ã¨æ­£å¸¸ãƒãƒ¼ãƒ‰ãŒæ··åœ¨
        assert len(results) >= 2
        error_count = sum(1 for _, _, status in results if status == "error")
        success_count = sum(1 for _, _, status in results if status == "success")

        assert error_count > 0  # ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã‚‹
        assert success_count > 0  # æœ‰åŠ¹ãªéƒ¨åˆ†ã¯å‡¦ç†ã•ã‚Œã‚‹

    def test_marker_validation_edge_cases(self):
        """ãƒãƒ¼ã‚«ãƒ¼æ¤œè¨¼ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ"""
        edge_cases = [
            "",  # ç©ºè¡Œ
            ";;;",  # çµ‚äº†ãƒãƒ¼ã‚«ãƒ¼ã®ã¿
            ";;;   ;;;",  # ç©ºã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            ";;; ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",  # çµ‚äº†ãƒãƒ¼ã‚«ãƒ¼ãªã—
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ ;;;",  # é–‹å§‹ãƒãƒ¼ã‚«ãƒ¼ãªã—
            ";;;ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰;;; å†…å®¹ ;;;",  # å³åº§é–‰ã˜
            ";;;ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰;;; å†…å®¹",  # éƒ¨åˆ†çš„ã«æœ‰åŠ¹
            ";;;non-ascii-è¨˜å·;;;",  # éASCIIæ–‡å­—
            ";;;very-long-keyword-that-might-cause-issues;;;",  # é•·ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        ]

        for i, case in enumerate(edge_cases):
            lines = [case]
            node, next_index = self.block_parser.parse_block_marker(lines, 0)

            # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒé©åˆ‡ã«å‹•ä½œ
            assert next_index >= 0
            assert next_index <= len(lines)

            # ç„¡åŠ¹ãªã‚±ãƒ¼ã‚¹ã§ã¯ã‚¨ãƒ©ãƒ¼ãƒãƒ¼ãƒ‰ã¾ãŸã¯NoneãŒè¿”ã•ã‚Œã‚‹
            if case in ["", ";;;", ";;;   ;;;", ";;; ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ ;;;"]:
                assert node is None or (hasattr(node, "error") if node else True)

    def test_performance_large_document_parsing(self):
        """å¤§è¦æ¨¡æ–‡æ›¸ã§ã®æ€§èƒ½ãƒ†ã‚¹ãƒˆ"""
        # å¤§é‡ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’å«ã‚€æ–‡æ›¸ã‚’ç”Ÿæˆ
        large_document = []
        for i in range(100):  # 100å€‹ã®ãƒ–ãƒ­ãƒƒã‚¯
            large_document.extend(
                [
                    f";;;ãƒ–ãƒ­ãƒƒã‚¯{i};;;",
                    f"ãƒ–ãƒ­ãƒƒã‚¯{i}ã®å†…å®¹è¡Œ1",
                    f"ãƒ–ãƒ­ãƒƒã‚¯{i}ã®å†…å®¹è¡Œ2",
                    f"ãƒ–ãƒ­ãƒƒã‚¯{i}ã®å†…å®¹è¡Œ3",
                    ";;;",
                ]
            )

        # è§£ææ™‚é–“ã‚’æ¸¬å®š
        start_time = time.time()

        parsed_blocks = 0
        index = 0
        while index < len(large_document):
            if (
                large_document[index].strip().startswith(";;;")
                and not large_document[index].strip() == ";;;"
            ):
                node, next_index = self.block_parser.parse_block_marker(
                    large_document, index
                )
                if node:
                    parsed_blocks += 1
                index = next_index
            else:
                index += 1

        execution_time = time.time() - start_time

        # è©³ç´°ãªæ€§èƒ½æ¸¬å®šãƒ­ã‚¸ãƒƒã‚¯å¼·åŒ–
        document_text = "\n".join(large_document)
        document_size_bytes = len(document_text.encode("utf-8"))
        document_size_kb = document_size_bytes / 1024

        # è§£æé€Ÿåº¦è¨ˆç®—ï¼ˆms/KBï¼‰
        ms_per_kb = (execution_time * 1000) / document_size_kb

        # è©³ç´°ãªæ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        performance_metrics = {
            "execution_time_ms": execution_time * 1000,
            "document_size_bytes": document_size_bytes,
            "document_size_kb": document_size_kb,
            "ms_per_kb": ms_per_kb,
            "parsed_blocks": parsed_blocks,
            "target_blocks": 100,
            "blocks_per_second": (
                parsed_blocks / execution_time if execution_time > 0 else 0
            ),
            "bytes_per_second": (
                document_size_bytes / execution_time if execution_time > 0 else 0
            ),
        }

        # æ€§èƒ½åŸºæº–ã®ç¢ºèª
        assert execution_time < 1.0, (
            f"å¤§è¦æ¨¡è§£æãŒé…ã™ãã¾ã™: {execution_time:.3f}ç§’\n"
            f"æ€§èƒ½è©³ç´°: {performance_metrics}"
        )
        assert parsed_blocks == 100, f"è§£æãƒ–ãƒ­ãƒƒã‚¯æ•°ãŒä¸æ­£: {parsed_blocks}/100"

        # Issue #597è¦æ±‚ä»•æ§˜: <50ms/KBè§£æ
        assert ms_per_kb < 50.0, (
            f"KBå½“ãŸã‚Šå‡¦ç†æ™‚é–“ãŒç›®æ¨™è¶…é: {ms_per_kb:.2f}ms/KB (ç›®æ¨™: <50ms/KB)\n"
            f"æ€§èƒ½è©³ç´°: {performance_metrics}"
        )

    def test_memory_efficiency_parsing(self):
        """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡æ€§ãƒ†ã‚¹ãƒˆ"""
        import sys

        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
        initial_refs = len([obj for obj in globals().values()])

        # å¤§é‡ã®ãƒ–ãƒ­ãƒƒã‚¯è§£æ
        for batch in range(10):
            test_blocks = [
                [
                    f";;;ãƒ†ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯{i};;;",
                    f"å†…å®¹{i}",
                    ";;;",
                ]
                for i in range(batch * 50, (batch + 1) * 50)
            ]

            flat_blocks = [line for sublist in test_blocks for line in sublist]

            # è§£æå®Ÿè¡Œ
            index = 0
            while index < len(flat_blocks):
                if (
                    flat_blocks[index].strip().startswith(";;;")
                    and not flat_blocks[index].strip() == ";;;"
                ):
                    node, next_index = self.block_parser.parse_block_marker(
                        flat_blocks, index
                    )
                    index = next_index
                else:
                    index += 1

        # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®ç¢ºèª
        final_refs = len([obj for obj in globals().values()])
        ref_growth = final_refs - initial_refs

        # éåº¦ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå¢—åŠ ãŒãªã„ã“ã¨ã‚’ç¢ºèª
        assert ref_growth < 100, f"éåº¦ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå¢—åŠ : {ref_growth}"

    def test_unicode_multilingual_support(self):
        """Unicodeãƒ»å¤šè¨€èªå¯¾å¿œãƒ†ã‚¹ãƒˆ"""
        multilingual_blocks = [
            ";;;æ—¥æœ¬èª;;;",
            "ã“ã‚Œã¯æ—¥æœ¬èªã®ãƒ†ã‚¹ãƒˆã§ã™ã€‚",
            "æ¼¢å­—ã€ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠãŒå«ã¾ã‚Œã¾ã™ã€‚",
            ";;;",
            ";;;English;;;",
            "This is an English test.",
            "It contains ASCII characters.",
            ";;;",
            ";;;EspaÃ±ol;;;",
            "Esta es una prueba en espaÃ±ol.",
            "Contiene caracteres con acentos: Ã¡, Ã©, Ã­, Ã³, Ãº, Ã±.",
            ";;;",
            ";;;Ğ ÑƒÑÑĞºĞ¸Ğ¹;;;",
            "Ğ­Ñ‚Ğ¾ Ñ‚ĞµÑÑ‚ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.",
            "Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ ĞºĞ¸Ñ€Ğ¸Ğ»Ğ»Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹.",
            ";;;",
            ";;;Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©;;;",
            "Ù‡Ø°Ø§ Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.",
            "ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø­Ø±Ù Ø¹Ø±Ø¨ÙŠØ©.",
            ";;;",
            ";;;Emoji;;;",
            "çµµæ–‡å­—ãƒ†ã‚¹ãƒˆ: ğŸŒğŸ—¾ğŸ¯ğŸ“‹âœ…âŒâš ï¸ğŸ”§",
            "Unicode symbols: â†â†’â†‘â†“âˆ€âˆƒâˆˆâˆ‰âˆªâˆ©",
            ";;;",
        ]

        parsed_count = 0
        index = 0
        while index < len(multilingual_blocks):
            line = multilingual_blocks[index].strip()
            if line.startswith(";;;") and not line == ";;;":
                node, next_index = self.block_parser.parse_block_marker(
                    multilingual_blocks, index
                )
                if node:
                    parsed_count += 1
                index = next_index
            else:
                index += 1

        # ã™ã¹ã¦ã®å¤šè¨€èªãƒ–ãƒ­ãƒƒã‚¯ãŒæ­£ã—ãè§£æã•ã‚Œã‚‹
        assert parsed_count == 6

    def test_concurrent_parsing_thread_safety(self):
        """ä¸¦è¡Œè§£æãƒ»ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒ†ã‚¹ãƒˆ"""
        import threading

        results = []
        errors = []

        def concurrent_parsing_worker(worker_id):
            try:
                # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ç‹¬ç«‹ã—ãŸãƒ‘ãƒ¼ã‚µãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
                local_keyword_parser = KeywordParser()
                local_block_parser = BlockParser(local_keyword_parser)

                # ãƒ¯ãƒ¼ã‚«ãƒ¼å›ºæœ‰ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
                worker_blocks = [
                    [
                        f";;;ãƒ¯ãƒ¼ã‚«ãƒ¼{worker_id}ãƒ–ãƒ­ãƒƒã‚¯{i};;;",
                        f"ãƒ¯ãƒ¼ã‚«ãƒ¼{worker_id}ã®å†…å®¹{i}",
                        ";;;",
                    ]
                    for i in range(20)
                ]

                flat_blocks = [line for sublist in worker_blocks for line in sublist]

                # è§£æå®Ÿè¡Œ
                parsed_count = 0
                index = 0
                while index < len(flat_blocks):
                    line = flat_blocks[index].strip()
                    if line.startswith(";;;") and not line == ";;;":
                        node, next_index = local_block_parser.parse_block_marker(
                            flat_blocks, index
                        )
                        if node:
                            parsed_count += 1
                        index = next_index
                    else:
                        index += 1

                results.append((worker_id, parsed_count))

            except Exception as e:
                errors.append((worker_id, str(e)))

        # 5ã¤ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ä¸¦è¡Œå®Ÿè¡Œ
        threads = []
        for i in range(5):
            thread = threading.Thread(target=concurrent_parsing_worker, args=(i,))
            threads.append(thread)
            thread.start()

        # å®Œäº†å¾…æ©Ÿ
        for thread in threads:
            thread.join()

        # çµæœç¢ºèª
        assert len(errors) == 0, f"ä¸¦è¡Œè§£æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {errors}"
        assert len(results) == 5

        # ã™ã¹ã¦ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒæ­£ã—ã„æ•°ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’è§£æ
        for worker_id, parsed_count in results:
            assert (
                parsed_count == 20
            ), f"ãƒ¯ãƒ¼ã‚«ãƒ¼{worker_id}ã®è§£ææ•°ãŒä¸æ­£: {parsed_count}/20"

    def test_stress_malformed_input_resilience(self):
        """ä¸æ­£å…¥åŠ›è€æ€§ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
        malformed_inputs = [
            # æ¥µç«¯ã«é•·ã„è¡Œ
            ";;;" + "A" * 10000 + ";;;",
            # åˆ¶å¾¡æ–‡å­—ã‚’å«ã‚€
            ";;;test\x00\x01\x02;;;",
            # éå¸¸ã«æ·±ã„ãƒã‚¹ãƒˆ
            ";;;level1;;;\n" + ";;;level2;;;\n" * 100 + ";;;\n" * 100,
            # ä¸å®Œå…¨ãªãƒãƒ¼ã‚«ãƒ¼ã®é€£ç¶š
            ";;;\n" * 1000,
            # æ··åœ¨æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é¢¨
            ";;;test\xff\xfe;;;",
            # æ¥µç«¯ã«çŸ­ã„
            ";",
            ";;",
            # å¥‡å¦™ãªçµ„ã¿åˆã‚ã›
            ";;;ãƒ†ã‚¹ãƒˆ;;; å†…å®¹ ;;; è¿½åŠ å†…å®¹",
            # XMLãƒ©ã‚¤ã‚¯ãªæ§‹é€ 
            ";;;tag attr='value';;;content;;;/tag;;;",
        ]

        for i, malformed_input in enumerate(malformed_inputs):
            lines = (
                malformed_input.split("\n")
                if "\n" in malformed_input
                else [malformed_input]
            )

            try:
                # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒé©åˆ‡ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
                node, next_index = self.block_parser.parse_block_marker(lines, 0)

                # ãƒ‘ãƒ¼ã‚µãƒ¼ãŒã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ãªã„
                assert next_index >= 0
                assert next_index <= len(lines)

                # ç„¡åŠ¹ãªå…¥åŠ›ã«å¯¾ã—ã¦é©åˆ‡ãªå¿œç­”ï¼ˆNoneã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ãƒãƒ¼ãƒ‰ï¼‰
                if node is None:
                    # None ã¯æœ‰åŠ¹ãªå¿œç­”
                    pass
                else:
                    # ãƒãƒ¼ãƒ‰ãŒè¿”ã•ã‚Œã‚‹å ´åˆã€åŸºæœ¬çš„ãªæ§‹é€ ã‚’æŒã¤
                    assert hasattr(node, "type") or hasattr(node, "error")

            except Exception as e:
                # äºˆæœŸã—ãªã„ä¾‹å¤–ã¯ç™ºç”Ÿã—ãªã„
                pytest.fail(f"ä¸æ­£å…¥åŠ›{i}ã§ãƒãƒ³ãƒ‰ãƒ«ã•ã‚Œãªã„ä¾‹å¤–ãŒç™ºç”Ÿ: {e}")

    def test_parse_accuracy_kumihan_specification(self):
        """Kumihanè¨˜æ³•ä»•æ§˜æº–æ‹ ç²¾åº¦ãƒ†ã‚¹ãƒˆ"""
        # Kumihanè¨˜æ³•ã®æ¨™æº–çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³
        standard_patterns = [
            # åŸºæœ¬è£…é£¾
            (";;;å¼·èª¿;;; é‡è¦ãªå†…å®¹ ;;;", "inline_decoration"),
            (";;;æ³¨é‡ˆ;;;\nè©³ç´°ãªèª¬æ˜\n;;;", "block_decoration"),
            # è¤‡åˆãƒ‘ã‚¿ãƒ¼ãƒ³
            (";;;å¼•ç”¨;;;\n;;;å¼·èª¿;;; å†…éƒ¨å¼·èª¿ ;;;\nå¼•ç”¨ã®ç¶šã\n;;;", "nested_blocks"),
            # å±æ€§ä»˜ã
            (";;;ç”»åƒ[alt=èª¬æ˜æ–‡];;; ç”»åƒãƒ‘ã‚¹ ;;;", "attributed_block"),
            # ç‰¹æ®Šè¨˜å·
            (";;;è¨˜å·;;; â†’â†â†‘â†“ ;;;", "symbol_content"),
            # æ•°å¼é¢¨
            (";;;æ•°å¼;;; a = b + c ;;;", "formula_content"),
        ]

        accuracy_results = []

        for pattern, expected_type in standard_patterns:
            lines = pattern.split("\n")
            node, next_index = self.block_parser.parse_block_marker(lines, 0)

            if node is not None:
                # è§£ææˆåŠŸ
                accuracy_results.append(True)
            else:
                # è§£æå¤±æ•—
                accuracy_results.append(False)

        # ç²¾åº¦ç›®æ¨™: 99.5%ä»¥ä¸Š
        success_rate = sum(accuracy_results) / len(accuracy_results)
        assert (
            success_rate >= 0.995
        ), f"Kumihanè¨˜æ³•è§£æç²¾åº¦ãŒç›®æ¨™æœªé”: {success_rate:.1%}"

    def test_heading_counter_functionality(self):
        """è¦‹å‡ºã—ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        # è¦‹å‡ºã—ãƒ–ãƒ­ãƒƒã‚¯ã®è§£æ
        heading_blocks = [
            ";;;è¦‹å‡ºã—1;;;",
            "ç¬¬1ç« ã®å†…å®¹",
            ";;;",
            ";;;è¦‹å‡ºã—2;;;",
            "ç¬¬2ç« ã®å†…å®¹",
            ";;;",
            ";;;è¦‹å‡ºã—3;;;",
            "ç¬¬3ç« ã®å†…å®¹",
            ";;;",
        ]

        initial_counter = self.block_parser.heading_counter

        # è¦‹å‡ºã—ãƒ–ãƒ­ãƒƒã‚¯ã‚’é †æ¬¡è§£æ
        index = 0
        heading_count = 0
        while index < len(heading_blocks):
            line = heading_blocks[index].strip()
            if line.startswith(";;;") and "è¦‹å‡ºã—" in line:
                node, next_index = self.block_parser.parse_block_marker(
                    heading_blocks, index
                )
                if node:
                    heading_count += 1
                index = next_index
            else:
                index += 1

        # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãŒæ­£ã—ãå‹•ä½œ
        assert heading_count == 3
        # å®Ÿè£…ã«ã‚ˆã£ã¦ã¯ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãŒæ›´æ–°ã•ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ã“ã¨ã‚’è€ƒæ…®


class TestBlockParserIntegration:
    """ãƒ–ãƒ­ãƒƒã‚¯ãƒ‘ãƒ¼ã‚µãƒ¼çµ±åˆãƒ†ã‚¹ãƒˆ"""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.keyword_parser = KeywordParser()
        self.block_parser = BlockParser(self.keyword_parser)

    def test_integration_with_keyword_parser(self):
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‘ãƒ¼ã‚µãƒ¼ã¨ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        integrated_content = [
            ";;;è¤‡åˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰;;;",
            "åŸºæœ¬å†…å®¹",
            ";;;å†…éƒ¨è£…é£¾;;; å†…éƒ¨ã®å†…å®¹ ;;;",
            "åŸºæœ¬å†…å®¹ã®ç¶šã",
            ";;;",
        ]

        # ãƒ–ãƒ­ãƒƒã‚¯ãƒ‘ãƒ¼ã‚µãƒ¼ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‘ãƒ¼ã‚µãƒ¼ã®é€£æº
        node, next_index = self.block_parser.parse_block_marker(integrated_content, 0)

        assert node is not None
        assert next_index == len(integrated_content)

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‘ãƒ¼ã‚µãƒ¼ãŒå†…éƒ¨ã§æ­£ã—ãå‘¼ã°ã‚Œã¦ã„ã‚‹
        assert self.block_parser.keyword_parser is not None

    def test_real_world_document_parsing(self):
        """å®Ÿä¸–ç•Œæ–‡æ›¸è§£æãƒ†ã‚¹ãƒˆ"""
        real_document = [
            "# æ–‡æ›¸ã‚¿ã‚¤ãƒˆãƒ«",
            "",
            ";;;åºæ–‡;;;",
            "ã“ã®æ–‡æ›¸ã¯ Kumihan-Formatter ã®ãƒ†ã‚¹ãƒˆç”¨ã§ã™ã€‚",
            "æ§˜ã€…ãªè¨˜æ³•ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚",
            ";;;",
            "",
            "## ç¬¬1ç« ",
            "",
            ";;;é‡è¦;;; ã“ã®ç« ã§ã¯é‡è¦ãªæ¦‚å¿µã‚’èª¬æ˜ã—ã¾ã™ ;;;",
            "",
            ";;;ã‚³ãƒ¼ãƒ‰;;;",
            "def example_function():",
            "    return 'Hello, World!'",
            ";;;",
            "",
            ";;;æ³¨é‡ˆ;;;",
            "æ³¨é‡ˆã®å†…å®¹ã§ã™ã€‚",
            "è¤‡æ•°è¡Œã«ã‚ãŸã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚",
            ";;;",
            "",
            "## çµè«–",
            "",
            ";;;ã¾ã¨ã‚;;; ä»¥ä¸Šã§ãƒ†ã‚¹ãƒˆã‚’çµ‚äº†ã—ã¾ã™ ;;;",
        ]

        # å®Ÿéš›ã®æ–‡æ›¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã®è§£æ
        parsed_blocks = []
        index = 0
        while index < len(real_document):
            line = real_document[index].strip()
            if line.startswith(";;;") and not line == ";;;":
                node, next_index = self.block_parser.parse_block_marker(
                    real_document, index
                )
                if node:
                    parsed_blocks.append(node)
                index = next_index
            else:
                index += 1

        # æœŸå¾…ã•ã‚Œã‚‹æ•°ã®ãƒ–ãƒ­ãƒƒã‚¯ãŒè§£æã•ã‚Œã‚‹
        assert len(parsed_blocks) >= 5  # åºæ–‡ã€é‡è¦ã€ã‚³ãƒ¼ãƒ‰ã€æ³¨é‡ˆã€ã¾ã¨ã‚

        # ã™ã¹ã¦ã®ãƒ–ãƒ­ãƒƒã‚¯ãŒæœ‰åŠ¹
        assert all(node is not None for node in parsed_blocks)
