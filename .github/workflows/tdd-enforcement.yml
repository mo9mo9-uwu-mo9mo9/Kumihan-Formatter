name: TDD Enforcement - TDD-First Development System

on:
  push:
    branches: [ "feat/*", "fix/*", "hotfix/*" ]
  pull_request:
    branches: [ main, develop ]
    types: [opened, synchronize, reopened]
  pull_request_review:
    types: [submitted]

env:
  PYTHON_VERSION: "3.12"
  # „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊ∏¨ÂÆöÁî®
  CI_START_TIME: ${{ github.event.head_commit.timestamp }}

jobs:
  tdd-cycle-validation:
    name: TDD Cycle Validation
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # ÂÖ®Â±•Ê≠¥„ÇíÂèñÂæó„Åó„Å¶„Ç≥„Éü„ÉÉ„ÉàËß£Êûê

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: |
            requirements-dev.txt
            pyproject.toml

      - name: Cache Python dependencies
        uses: actions/cache@v4
        id: pip-cache
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements-dev.txt', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Cache Performance Report
        run: |
          echo "üöÄ Performance Metrics:"
          echo "Cache Hit: ${{ steps.pip-cache.outputs.cache-hit }}"
          echo "Build Start: $(date -u +%Y-%m-%dT%H:%M:%SZ)"
          echo "NODE_START_TIME=$(date +%s)" >> $GITHUB_ENV

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Check TDD Session Exists
        id: tdd-session
        run: |
          if [ -f ".tdd_session.json" ]; then
            echo "tdd_session_exists=true" >> $GITHUB_OUTPUT
            echo "‚úÖ TDD session file found"
            cat .tdd_session.json
          else
            echo "tdd_session_exists=false" >> $GITHUB_OUTPUT
            echo "‚ùå TDD session file not found"
            echo "Please start TDD session with: make tdd-start <issue-number>"
          fi

      - name: Validate TDD Cycle History
        id: tdd-cycle
        run: |
          echo "Validating TDD cycle (Red ‚Üí Green ‚Üí Refactor)..."
          
          # „Ç≥„Éü„ÉÉ„ÉàÂ±•Ê≠¥„Åã„ÇâTDD„Çµ„Ç§„ÇØ„É´„ÇíÊ§úË®º
          git log --oneline -10 --grep="Red\|Green\|Refactor" > tdd_commits.log || true
          
          if [ -s tdd_commits.log ]; then
            echo "tdd_cycle_found=true" >> $GITHUB_OUTPUT
            echo "‚úÖ TDD cycle commits found:"
            cat tdd_commits.log
            
            # Red ‚Üí Green ‚Üí Refactor „ÅÆÈ†ÜÂ∫èÁ¢∫Ë™ç
            if grep -q "Red" tdd_commits.log && grep -q "Green" tdd_commits.log; then
              echo "tdd_cycle_complete=true" >> $GITHUB_OUTPUT
              echo "‚úÖ TDD cycle appears complete"
            else
              echo "tdd_cycle_complete=false" >> $GITHUB_OUTPUT
              echo "‚ö†Ô∏è TDD cycle may be incomplete"
            fi
          else
            echo "tdd_cycle_found=false" >> $GITHUB_OUTPUT
            echo "tdd_cycle_complete=false" >> $GITHUB_OUTPUT
            echo "‚ùå No TDD cycle commits found"
          fi

      - name: Run TDD Automation Validation
        id: tdd-automation
        run: |
          echo "Running TDD automation system validation..."
          python scripts/tdd_automation.py --validate > tdd_validation.log 2>&1 || true
          
          if [ $? -eq 0 ]; then
            echo "tdd_automation_valid=true" >> $GITHUB_OUTPUT
            echo "‚úÖ TDD automation validation passed"
          else
            echo "tdd_automation_valid=false" >> $GITHUB_OUTPUT
            echo "‚ùå TDD automation validation failed"
          fi
          
          echo "TDD Automation Log:"
          cat tdd_validation.log

      - name: Check Test-First Implementation
        id: test-first
        run: |
          echo "Checking for test-first implementation evidence..."
          
          # „ÉÜ„Çπ„Éà„Éï„Ç°„Ç§„É´„Å®„ÇΩ„Éº„Çπ„Éï„Ç°„Ç§„É´„ÅÆ„Çø„Ç§„É†„Çπ„Çø„É≥„ÉóÊØîËºÉ
          test_files=$(find tests/ -name "*.py" -type f 2>/dev/null | head -5)
          source_files=$(find kumihan_formatter/ -name "*.py" -type f 2>/dev/null | head -5)
          
          if [ -n "$test_files" ] && [ -n "$source_files" ]; then
            echo "test_first_evidence=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Test and source files found"
            echo "Recent test files:"
            echo "$test_files" | head -3
          else
            echo "test_first_evidence=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è Limited test-first evidence"
          fi

  coverage-enforcement:
    name: Coverage Enforcement
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: |
            requirements-dev.txt
            pyproject.toml

      - name: Cache Python dependencies
        uses: actions/cache@v4
        id: pip-cache
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements-dev.txt', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Cache Performance Report
        run: |
          echo "üöÄ Performance Metrics:"
          echo "Cache Hit: ${{ steps.pip-cache.outputs.cache-hit }}"
          echo "Build Start: $(date -u +%Y-%m-%dT%H:%M:%SZ)"
          echo "NODE_START_TIME=$(date +%s)" >> $GITHUB_ENV

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Cache test results
        uses: actions/cache@v4
        with:
          path: |
            .pytest_cache
            .coverage
            coverage.json
          key: ${{ runner.os }}-test-cache-${{ hashFiles('tests/**/*.py', 'kumihan_formatter/**/*.py') }}
          restore-keys: |
            ${{ runner.os }}-test-cache-

      - name: Run Coverage Check with TDD Standards (Fast Fail)
        id: coverage-check
        run: |
          echo "Running coverage check with TDD standards..."
          
          # ÊÆµÈöéÁöÑÂÆüË°å: Â§±ÊïóÊôÇ„ÅÆÊó©ÊúüÁµÇ‰∫Ü
          set -e  # „Ç®„É©„ÉºÊôÇÂç≥Â∫ß„Å´ÁµÇ‰∫Ü
          
          # Critical Tier: 90%‰ª•‰∏äÂøÖÈ†à (maxfail=3„ÅßÈ´òÈÄüÂåñ)
          python -m pytest \
            --cov=kumihan_formatter \
            --cov-report=json \
            --cov-report=term-missing \
            --cov-fail-under=90 \
            --maxfail=3 \
            --tb=short \
            tests/ > coverage_output.log 2>&1
          
          coverage_exit_code=$?
          
          if [ $coverage_exit_code -eq 0 ]; then
            echo "coverage_meets_standard=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Coverage meets TDD standard (‚â•90%)"
          else
            echo "coverage_meets_standard=false" >> $GITHUB_OUTPUT
            echo "‚ùå Coverage below TDD standard (<90%)"
            # Êó©ÊúüÁµÇ‰∫Ü„Åß„É™„ÇΩ„Éº„ÇπÁØÄÁ¥Ñ
            exit 1
          fi
          
          # „Ç´„Éê„É¨„ÉÉ„Ç∏„É¨„Éù„Éº„ÉàË°®Á§∫
          echo "Coverage Report:"
          cat coverage_output.log
          
          # JSON „É¨„Éù„Éº„Éà„Åã„ÇâÂÆüÈöõ„ÅÆ„Ç´„Éê„É¨„ÉÉ„Ç∏„ÇíÂèñÂæó
          if [ -f coverage.json ]; then
            actual_coverage=$(python -c "import json; data=json.load(open('coverage.json')); print(f\"{data['totals']['percent_covered']:.2f}%\")")
            echo "actual_coverage=$actual_coverage" >> $GITHUB_OUTPUT
            echo "Actual Coverage: $actual_coverage"
          fi

      - name: Upload Coverage Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: tdd-coverage-report
          path: |
            coverage.json
            coverage_output.log

  quality-gate-enforcement:
    name: Quality Gate Enforcement
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: |
            requirements-dev.txt
            pyproject.toml

      - name: Cache Python dependencies
        uses: actions/cache@v4
        id: pip-cache
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements-dev.txt', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Cache Performance Report
        run: |
          echo "üöÄ Performance Metrics:"
          echo "Cache Hit: ${{ steps.pip-cache.outputs.cache-hit }}"
          echo "Build Start: $(date -u +%Y-%m-%dT%H:%M:%SZ)"
          echo "NODE_START_TIME=$(date +%s)" >> $GITHUB_ENV

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run Quality Gate Validation
        id: quality-gate
        run: |
          echo "Running quality gate validation..."
          
          # ÂìÅË≥™„Ç≤„Éº„Éà„ÉÅ„Çß„ÉÉ„ÇØÂÆüË°å
          python scripts/tiered_quality_gate.py > quality_gate_results.log 2>&1
          quality_gate_exit_code=$?
          
          if [ $quality_gate_exit_code -eq 0 ]; then
            echo "quality_gate_passed=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Quality gate validation passed"
          else
            echo "quality_gate_passed=false" >> $GITHUB_OUTPUT
            echo "‚ùå Quality gate validation failed"
          fi
          
          echo "Quality Gate Results:"
          cat quality_gate_results.log

      - name: Upload Quality Gate Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: quality-gate-results
          path: quality_gate_results.log

  security-enforcement:
    name: Security Test Enforcement
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: |
            requirements-dev.txt
            pyproject.toml

      - name: Cache Python dependencies
        uses: actions/cache@v4
        id: pip-cache
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements-dev.txt', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Cache Performance Report
        run: |
          echo "üöÄ Performance Metrics:"
          echo "Cache Hit: ${{ steps.pip-cache.outputs.cache-hit }}"
          echo "Build Start: $(date -u +%Y-%m-%dT%H:%M:%SZ)"
          echo "NODE_START_TIME=$(date +%s)" >> $GITHUB_ENV

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Cache security test results
        uses: actions/cache@v4
        with:
          path: |
            .security_cache
            security_test_results.json
          key: ${{ runner.os }}-security-cache-${{ hashFiles('scripts/security_*.py') }}
          restore-keys: |
            ${{ runner.os }}-security-cache-

      - name: Enforce Security Tests (Parallel Execution)
        id: security-enforcement
        run: |
          echo "Enforcing security test requirements (parallel execution)..."
          
          security_tests_passed=0
          security_tests_total=4
          
          # ‰∏¶ÂàóÂÆüË°å„ÅßÊôÇÈñìÁü≠Á∏Æ
          (
            python scripts/security_sql_injection_test.py && echo "SQL_INJECTION_PASSED" > .sql_result || echo "SQL_INJECTION_FAILED" > .sql_result
          ) &
          (
            python scripts/security_xss_test.py && echo "XSS_PASSED" > .xss_result || echo "XSS_FAILED" > .xss_result
          ) &
          (
            python scripts/security_csrf_test.py && echo "CSRF_PASSED" > .csrf_result || echo "CSRF_FAILED" > .csrf_result
          ) &
          (
            python scripts/security_file_upload_test.py && echo "FILE_UPLOAD_PASSED" > .file_result || echo "FILE_UPLOAD_FAILED" > .file_result
          ) &
          
          # ÂÖ®„ÉÜ„Çπ„ÉàÂÆå‰∫Ü„ÇíÂæÖÊ©ü
          wait
          
          # ÁµêÊûúÈõÜË®à
          [ "$(cat .sql_result 2>/dev/null)" = "SQL_INJECTION_PASSED" ] && ((security_tests_passed++)) && echo "‚úÖ SQL Injection test passed" || echo "‚ùå SQL Injection test failed"
          [ "$(cat .xss_result 2>/dev/null)" = "XSS_PASSED" ] && ((security_tests_passed++)) && echo "‚úÖ XSS protection test passed" || echo "‚ùå XSS protection test failed"
          [ "$(cat .csrf_result 2>/dev/null)" = "CSRF_PASSED" ] && ((security_tests_passed++)) && echo "‚úÖ CSRF protection test passed" || echo "‚ùå CSRF protection test failed"
          [ "$(cat .file_result 2>/dev/null)" = "FILE_UPLOAD_PASSED" ] && ((security_tests_passed++)) && echo "‚úÖ File upload security test passed" || echo "‚ùå File upload security test failed"
          
          # „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó
          rm -f .sql_result .xss_result .csrf_result .file_result
          
          security_pass_rate=$((security_tests_passed * 100 / security_tests_total))
          echo "security_pass_rate=$security_pass_rate" >> $GITHUB_OUTPUT
          echo "security_tests_passed=$security_tests_passed" >> $GITHUB_OUTPUT
          echo "security_tests_total=$security_tests_total" >> $GITHUB_OUTPUT
          
          if [ $security_tests_passed -eq $security_tests_total ]; then
            echo "security_100_percent=true" >> $GITHUB_OUTPUT
            echo "‚úÖ All security tests passed (100%)"
          else
            echo "security_100_percent=false" >> $GITHUB_OUTPUT
            echo "‚ùå Security tests incomplete ($security_pass_rate%)"
            # 100%ÂøÖÈ†à„ÅÆ„Åü„ÇÅÂ§±ÊïóÊôÇ„ÅØÊó©ÊúüÁµÇ‰∫Ü
            exit 1
          fi

  # TDDÂº∑Âà∂Âà§ÂÆö
  tdd-enforcement-gate:
    name: TDD Enforcement Gate
    runs-on: ubuntu-latest
    needs: [tdd-cycle-validation, coverage-enforcement, quality-gate-enforcement, security-enforcement]
    if: always()
    steps:
      - name: Evaluate TDD Compliance
        id: tdd-compliance
        run: |
          echo "üîç Evaluating TDD compliance..."
          
          # ÂêÑ„ÉÅ„Çß„ÉÉ„ÇØÁµêÊûú„ÇíË©ï‰æ°
          tdd_session="${{ needs.tdd-cycle-validation.outputs.tdd_session_exists }}"
          tdd_cycle="${{ needs.tdd-cycle-validation.outputs.tdd_cycle_complete }}"
          coverage="${{ needs.coverage-enforcement.outputs.coverage_meets_standard }}"
          quality_gate="${{ needs.quality-gate-enforcement.outputs.quality_gate_passed }}"
          security="${{ needs.security-enforcement.outputs.security_100_percent }}"
          
          echo "TDD Session: $tdd_session"
          echo "TDD Cycle: $tdd_cycle"
          echo "Coverage (‚â•90%): $coverage"
          echo "Quality Gate: $quality_gate"
          echo "Security (100%): $security"
          
          # ÂøÖÈ†àË¶Å‰ª∂„ÉÅ„Çß„ÉÉ„ÇØ
          required_checks=0
          total_checks=5
          
          [ "$tdd_session" = "true" ] && ((required_checks++)) || echo "‚ùå TDD session missing"
          [ "$tdd_cycle" = "true" ] && ((required_checks++)) || echo "‚ùå TDD cycle incomplete"
          [ "$coverage" = "true" ] && ((required_checks++)) || echo "‚ùå Coverage below 90%"
          [ "$quality_gate" = "true" ] && ((required_checks++)) || echo "‚ùå Quality gate failed"
          [ "$security" = "true" ] && ((required_checks++)) || echo "‚ùå Security tests incomplete"
          
          compliance_rate=$((required_checks * 100 / total_checks))
          echo "TDD Compliance Rate: $compliance_rate% ($required_checks/$total_checks)"
          
          if [ $required_checks -eq $total_checks ]; then
            echo "tdd_compliant=true" >> $GITHUB_OUTPUT
            echo "‚úÖ TDD-First development requirements met"
            echo "üéâ Ready for merge - TDD compliance verified"
          else
            echo "tdd_compliant=false" >> $GITHUB_OUTPUT
            echo "‚ùå TDD-First development requirements NOT met"
            echo "üö´ Merge blocked - Fix TDD compliance issues"
            exit 1
          fi

      - name: Block Non-TDD Pull Requests
        if: needs.tdd-enforcement-gate.outputs.tdd_compliant != 'true'
        run: |
          echo "üö´ MERGE BLOCKED: TDD-First requirements not satisfied"
          echo ""
          echo "Required fixes:"
          echo "1. Ensure TDD session is active (make tdd-start <issue>)"
          echo "2. Complete Red ‚Üí Green ‚Üí Refactor cycle"
          echo "3. Achieve ‚â•90% test coverage"
          echo "4. Pass all quality gates"
          echo "5. Pass 100% of security tests"
          echo ""
          echo "Run 'make tdd-status' to check current TDD session state"
          exit 1

      - name: TDD Compliance Success
        if: needs.tdd-enforcement-gate.outputs.tdd_compliant == 'true'
        run: |
          echo "üéâ TDD-First Development Compliance Verified!"
          echo ""
          echo "‚úÖ All TDD requirements satisfied:"
          echo "  - TDD session active"
          echo "  - Red ‚Üí Green ‚Üí Refactor cycle complete"
          echo "  - Test coverage ‚â•90%"
          echo "  - Quality gates passed"
          echo "  - Security tests 100% passed"
          echo ""
          echo "üöÄ Pull request approved for merge"

      - name: Performance Summary Report
        if: always()
        run: |
          END_TIME=$(date +%s)
          TOTAL_DURATION=$((END_TIME - ${NODE_START_TIME:-$END_TIME}))
          echo ""
          echo "üìä CI/CD Performance Report:"
          echo "  - Total Duration: ${TOTAL_DURATION}s ($(($TOTAL_DURATION / 60))m $(($TOTAL_DURATION % 60))s)"
          echo "  - Cache Strategy: Enabled (Pip + Test + Security)"
          echo "  - Parallel Execution: Security tests (4 parallel)"
          echo "  - Early Exit: Enabled on failures"
          echo ""
          if [ $TOTAL_DURATION -lt 480 ]; then
            echo "üöÄ Performance Target: ‚úÖ Under 8 minutes (Target achieved!)"
          else
            echo "‚ö†Ô∏è  Performance Target: ‚ùå Over 8 minutes (Previous: ~15min)"
          fi